[["index.html", "From sequences to knowledge, improving and learning from sequence alignments. Abstract", " From sequences to knowledge, improving and learning from sequence alignments. Luc Blassel 2022-06-02 Abstract This is the Abstract "],["résumé.html", "Résumé", " Résumé Ceci est le résumé "],["aknowledgments.html", "Aknowledgments", " Aknowledgments Thanks everybody "],["glosssary.html", "Glosssary", " Glosssary What are these terms ? "],["general-introduction.html", "General Introduction Goal of this Thesis Thesis organization", " General Introduction Goal of this Thesis Thesis organization TO COME "],["what-is-sequence-data.html", "Chapter 1 What is Sequence data ? 1.1 Biological sequences, a primer 1.2 Obtaining sequence data 1.3 Sequencing errors, how to account for them ? 1.4 Biological sequences, a computational view (here ?)", " Chapter 1 What is Sequence data ? 1.1 Biological sequences, a primer To fully understand the work that was done during this thesis, as well as the choices that were made some basic knowledge of biology and more particularly genetics are needed. If you are already familiar with biological sequences, feel free to skip ahead to section 1.2. 1.1.1 What is DNA ? DesoxyriboNucleic Acid (DNA) is one of the most important molecules there is, without it complex life as we know it is impossible. It contains all the genetic information of a given organism, that is to say all the information necessary for the organism to: 1) function as a living being and 2) make a perfect copy of itself. This is the case for the overwhelming majority of living organisms on planet earth, from elephants to potatoes, to micro-organisms like bacteria.!g molecular biology tetbo DNA is a polymer, composed of monomeric units called nucleotides. Each nucleotide is composed of Ribose (a five carbon sugar) on which are attached a phosphate group as well as one of four nucleobases: Adenine (A), Cytosine (C), Guanine (G) of Thymine (T). These 4 types of nucleotide monomers link up with one-another, through phosphate-sugar bonds, creating a single strand of DNA. The ordered sequence of these four types of nucleotides in strand encodes all the genetic information necessary for the organism to function. Nucleotides in a strand form strong complementary bonds with nucleotides from another strand, A with T and C with G. These bonds allows two strands of DNA to form the double-helix structure of DNA [1] shown in Figure 1.1. The specificity of nucleotide bonds ensure that the two strands of the double helix are complementary and that the information contained in one strand can be recovered from the other. This ensures a certain structural stability to the DNA molecule and a way to recover the important information that could be lost due to a damaged strand. Figure 1.1: Double-helix structure of DNA The amount of DNA necessary to encode the information varies greatly from organism to organism: 5400 base pairs (5.4kBp) for the \\(\\varphi X174\\) phage [2], 4.9MBp for Escherichia coli [3], 3.1GBp for Homo sapiens [4] all the way up to almost 150GBp for Paris japonica, a Japanese mountain flowering plant [5]. While very small genome size tend to occur in smaller, simpler organisms genome size does not correlate with organism complexity [6] 1.1.2 From Information to action 1.1.2.1 Proteins, their structure and their role The double stranded DNA molecules present in the cells of a living organism contains only information; in order for the organism to live, this information must be read and transformed into actions. Most of the actions necessary for “life” are taken by large molecules called proteins, they have a very wide range of functions from catalyzing reactions in the cell to giving it it’s structure [7]. Proteins are macromolecules, that are made up of one or several chains of amino acids. These chains then link together and fold up in a specific 3 dimensional structure, giving the protein the shape it needs to fulfill it’s goal. This structure is determined by the sequence of amino acids, and a given protein can be identified by this amino acid sequence [7]. This sequence is directly dependent on the information contained in the DNA. First the DNA is transcripted in a similar, but single stranded, molecule called RNA which encodes the same sequence. This RNA molecule is then translated into a protein by the following process [8]: Nucleotides in the RNA sequence are read in groups of 3 called a codon. These codons are read sequentially along the RNA molecule Each codon corresponds to an amino acid, according to the genetic code. The sequence of codons in RNA (and by extension DNA) determines the sequence of amino acids. The translation process is stopped when a specific type of codon is read. With 4 types of nucleotides and codons grouping 3 nucleotides there are \\(4^3=64\\) possible codons. However, as stated above, proteins are only made up of 20 different amino acids, meaning that several different codons correspond to the same amino acid. This gives the translation process a certain robustness to errors that can occur when the DNA is copied to create a new cell, or when it is transformed into RNA prior to protein translation. 1.1.2.2 Making mistakes Going from DNA sequence to protein is quite a complicated process involving several steps, it is therefore possible for a mistake to happen. There are several mechanisms to avoid mistakes and alteration of the genetic information: the complementary nature of the 2 strands of DNA, the redundant nature of the genetic code as well as error correction mechanisms in the molecules that read and write DNA and RNA (polymerases). However, despite all that, some errors still make it through. 1.1.2.2.1 Where can mistakes happen ? There are several sources of error that can alter the genetic information [9]: DNA replication: When a cell divides, or when an organism reproduces, the DNA molecule must be copied in order to transmit genetic information. This process has a very low rate of errors, with as low as 1 error for every billion to every hundred billions of base pairs replicated [10]. This is due to the fact that the DNA polymerase (the protein that is responsible for copying DNA molecules), has a relatively error rate to start with, but mostly due to the error correcting mechanisms that are present in certain cells and bacteria [11]. RNA transcription: error rate between 4 errors for each million [12] to 2 errors for each hundred thousand [13] base pairs transcribed. Other mutagenic events: Ionizing radiation [14], UV rays [15], Toxins [16], heat Stress [17], cold stress [18], oxidative stress [19]. 1.1.2.2.2 What kind of errors are possible? substitution insertion deletion 1.1.2.2.3 What effect can mutations have ? illnesses acquired traits 1.2 Obtaining sequence data In order to study living organisms we need to be able to obtain their genetic information, i.e figure out a way to get the sequence of nucleobases that make up their DNA. 1.2.1 Sanger sequencing, a breakthrough The first true sequencing method was developed in 1977 [20]. Sanger et al. devised a simple method to read the sequence of nucleotides that make up a DNA sequence. Clone sequence / amplify Prepare 4 different sequencing environments with a majority of dNTP (ie regular nucleotides) and in each a single type of ddNTP (a terminator). ddNTP are marked In each test tube add DNA polymerase, primers and denatures DNA fragments you want to sequence Sequence is replicated until incorporation of ddNTP stopping reaction Separate replicated fragments by electrophoresis (i.e shorter fragments go further), 1 ddNTP type in each lane With marked you can see which nucleotide is present at a given position This allowed Sanger et al. to sequence the first whole \\(\\varphi X174\\) bacteriophage genome [2]. This method, although revolutionnary was costly and time consuming. The marking of primers and ddNTP with fluorescence allowed to do the polymerization in a single test tube and use a single lane for electrophoresis [21,22]. The fluorescence also allowed for automated reading (base-calling ?) with optical systems. I need to speak of performance / throughput of these methods here. 1.2.2 Next-generation sequencing Developed to lower cost and more throughput Massively parallel Long reads sequencing Quick summary on PacBio and ONT As a conclusion, mention the work done on protein sequencing, but we usually get the protein sequence from the DNA sequence that is translated from codons. 1.3 Sequencing errors, how to account for them ? general context of sequencing errors 1.3.1 Long read errors Mainly indels, in certain regions of the genomes, particularily homopolymers. 1.3.2 HPC HPC takes repeated runs of a single nucleotide and compresses them to a single occurence Empirically is has been shown to improve mapping and other applications 1.4 Biological sequences, a computational view (here ?) Essentially a text file. Just a long succession of letters, so we can apply text algorithmics to it. References "],["aligning-sequence-data.html", "Chapter 2 Aligning sequence data 2.1 What is an alignment ? 2.2 How do we speed up local alignment ? 2.3 MSA", " Chapter 2 Aligning sequence data 2.1 What is an alignment ? We want to compare individuals, species, whatever. To do this we need to compare what is comparable. Alignment to the rescue. 2.1.1 How to align ? Either decide to align globally or locally. Usually done with dynamic programming by assigning a score to mismatches, indels, … and then choosing the alignment with minimal score. short example of local alignment gap open, gap extend, etc… 2.1.2 Substitution models mismatch depends on models, BLOSUM, PAML, … 2.1.3 Why align ? pairwise alignment to compare two similar sequences mapping to get an idea of where a short sequence comes from on a larger reference. (sequencing reads) 2.2 How do we speed up local alignment ? 2.2.1 Indexed … BLAST,… short explanation of BLAST or suffix-arrays, … 2.2.2 Seeded, minimap2, … How minimap works, rough idea 2.3 MSA When we need to compare a lot of individuals together we can do MSA. NP-hard problem so we need heuristics or tricks Even if we align all sequences pairwise we need to then combine all gaps and stuff -&gt; complicated. 2.3.0.1 Progressive guide tree, clustering of sequences then refine alignment. Good heuristic but with larger datasets, becomes harder 2.3.0.2 HMMs / index alignment / pairwise Example of COVID where homology is high so we can get away with using HMMS / pairwise to root sequence. (point to appendinx with covid align ?) "],["mapping-friendly-sequence-reductions-going-beyond-homopolymer-compression.html", "Chapter 3 Mapping-friendly sequence reductions: going beyond homopolymer compression Abstract 3.1 Introduction 3.2 Methods 3.3 Datasets and Pipelines 3.4 Results 3.5 Discussion 3.6 Limitations of this study 3.7 Code availability Supplementary information", " Chapter 3 Mapping-friendly sequence reductions: going beyond homopolymer compression Luc Blassel1,2*, Paul Medvedev3,4,5, Rayan Chikhi1 1 Sequence Bioinformatics, Department of Computational Biology, Institut Pasteur, Paris, France 2 Sorbonne Université, Collège doctoral, Paris, France 3 Department of Computer Science and Engineering, Pennsylvania State University, University Park, Pennsylvania, United States of America 4 Department of Biochemistry and Molecular Biology, Pennsylvania State University, University Park, Pennsylvania, United States of America 5 Center for Computational Biology and Bioinformatics, Pennsylvania State University, University Park, Pennsylvania, United States of America originally published in iScience in XXX doi:10.1371/journal.pcbi.1008873 Abstract Sequencing errors continue to pose algorithmic challenges to methods working with sequencing data. One of the simplest and most prevalent techniques for ameliorating the detrimental effects of homopolymer expansion/contraction errors present in long read data is homopolymer compression. It collapses runs of repeated nucleotides, with the intuitive goal of removing some of the sequencing errors and often improving mapping sensitivity. Though our intuitive understanding justifies why homopolymer compression works, it in no way implies that it is the best transformation that can be done. In this paper, we explore if there are transformations that can be applied in the same pre-processing manner as homopolymer compression that would achieve better alignment sensitivity. We introduce a more general framework than homopolymer compression, called mapping-friendly sequence reductions. We transform the reference and the reads using these reductions and then apply an alignment algorithm. We demonstrate that some mapping-friendly sequence reductions lead to improved mapping accuracy, outperforming homopolymer compression. 3.1 Introduction Sequencing errors continue to pose algorithmic challenges to methods working with read data. In short-read technologies, these tend to be substitution errors, but in long reads, these tend to be short insertions and deletions; most common are expansions or contractions of homopolymers (i.e. reporting 3 As instead of 4) [23]. Many algorithmic problems, such as alignment, become trivial if not for sequencing errors [24]. Error correction can often decrease the error rate but does not eliminate all errors. Most tools therefore incorporate the uncertainty caused by errors into their underlying algorithms. The higher the error rate, the more detrimental its effect on algorithm speed, memory, and accuracy. While the sequencing error rate of any given technology tends to decrease over time, new technologies entering the market typically have high error rates (e.g. Oxford Nanopore Technologies). Finding better ways to cope with sequencing error therefore remains a top priority in bioinformatics. One of the simplest and most prevalent techniques for ameliorating the detrimental effects of homopolymer expansion/contraction errors is homopolymer compression (abbreviated HPC). HPC simply transforms runs of the same nucleotide within a sequence into a single occurrence of that nucleotide. For example, HPC applied to the sequence AAAGGTTA yields the sequence AGTA. To use HPC in an alignment algorithm, one first compresses the reads and the reference, then aligns each compressed read to the compressed reference, and finally reports all alignment locations, converted into the coordinate system of the uncompressed reference. HPC effectively removes homopolymer expansion/contraction errors from the downstream algorithm. Though there is a trade-off with specificity of the alignment (e.g. some of the compressed alignments may not correspond to true alignments) the improvement in mapping sensitivity usually outweighs it [25]. The first use of HPC that we are aware of was in 2008 as a pre-processing step for 454 pyrosequencing data in the Celera assembler [26]. It is used by a wide range of error-correction algorithms, e.g. for 454 data [27], PacBio data [28], and Oxford Nanopore data [29]. HPC is used in alignment, e.g. by the widely used minimap2 aligner [25]. HPC is also used in long-read assembly, e.g. HiCanu [30], SMARTdenovo [31], or mdBG [32]. HPC is also used for clustering transcriptome reads according to gene family of origin [33]. Overall, HPC has been widely used, with demonstrated benefits. Though our intuitive understanding justifies why HPC works, it in no way implies that it is the best transformation that can be done. Are there transformations that can be applied in the same pre-processing way as HPC that would achieve better alignment sensitivity? In this work, we define a more general notion which we call mapping-friendly sequence reductions. In order to efficiently explore the performance of all reductions, we identify two heuristics to reduce the search space of reductions. We then identify a number of mapping-friendly sequence reductions which are likely to yield better mapping performance than HPC. We evaluate them using two mappers (minimap2 and winnowmap2) on three simulated datasets (whole human genome, human centromere, and whole Drosophila genome). We show that some of these functions provide vastly superior performance in terms of correctly placing high mapping quality reads, compared to either HPC or using raw reads. For example, one function increased the mapping accuracy of minimap2 by an order of magnitude over the entire human genome, keeping an identical fraction of reads mapped. We also evaluate whether HPC sensitivity gains continue to outweigh the specificity cost with the advent of telomere-to-telomere assemblies [4]. These contain many more low-complexity and/or repeated regions such as centromeres and telomeres. HPC may increase mapping ambiguity in these regions by removing small, distinguishing, differences between repeat instances. Indeed, we find that neither HPC nor our mapping-friendly sequence reductions perform better than mapping raw reads on centromeres, hinting at the importance of preserving all sequence information in repeated regions. 3.2 Methods 3.2.1 Streaming sequence reductions We wish to extend the notion of homopolymer compression to a more general function while maintaining its simplicity. What makes HPC simple is that it can be done in a streaming fashion over the sequence while maintaining only a local context. The algorithm can be viewed simply as scanning a string from left to right and, at each new character, outputting that character if and only if it is different from the previous character. In order to prepare for generalizing this algorithm, let us define a function \\(g^\\text{HPC} : \\Sigma^2\\rightarrow\\Sigma\\cup\\{\\varepsilon\\}\\) where \\(\\Sigma\\) is the DNA alphabet, \\(\\varepsilon\\) is the empty character, and \\[\\begin{align*} &amp; g^\\text{HPC}(x_1\\cdot x_2) = \\begin{cases} x_2 &amp; \\text{if } x_1 \\neq x_2 \\\\ \\varepsilon &amp; \\text{if } x_1 = x_2 \\end{cases} \\end{align*}\\] Now, we can view HPC as sliding a window of size 2 over the sequence and at each new window, applying \\(g^\\text{HPC}\\) to the window and concatenating the output to the growing compressed string. Formally, let \\(x\\) be a string, which we index starting from 1. Then, the HPC transformation is defined as \\[\\begin{equation} f(x) = x[1,\\ell-1]\\cdot g(x[1,\\ell]) \\cdot g(x[2, \\ell+1])\\cdots g(x[|x|-\\ell+1,|x|]) \\tag{3.1} \\end{equation}\\] where \\(\\ell = 2\\) and \\(g=g^\\text{HPC}\\). In other words, \\(f\\) is the concatenation of the first \\(\\ell-1\\) characters of \\(x\\) and the sequence of outputs of \\(g\\) applied to a sliding window of length \\(\\ell\\) over \\(x\\). The core of the transformation is given by \\(g\\) and the size of the context \\(\\ell\\), and \\(f\\) is simply the wrapper for \\(g\\) so that the transformation can be applied to arbitrary length strings. With this view in mind, we can generalize HPC while keeping its simplicity by 1) considering different functions \\(g\\) that can be plugged into Equation (3.1) increasing the context that \\(g\\) uses (i.e. setting \\(\\ell&gt;2\\)). Formally, for a given alphabet \\(\\Sigma\\) and a context size \\(\\ell\\), a function \\(T\\) mapping strings to strings is said to be an order-\\(\\ell\\) Streaming sequence reduction (abbreviated SSR) if there exists some \\(g : \\Sigma^\\ell\\rightarrow\\Sigma\\cup\\{\\varepsilon\\}\\) such that \\(T=f\\). Figure 3.1A shows how an SSR can be visualized as a directed graph. Observe that an order-\\(\\ell\\) SSR is defined by a mapping between \\(|\\Sigma|^\\ell\\) inputs and \\(|\\Sigma| + 1\\) outputs. For example, for \\(\\ell=2\\), there are \\(n=16\\) inputs and \\(k=5\\) outputs. Figure 3.1B visualizes HPC in this way. Figure 3.1: Representing and counting mapping-friendly sequence reductions. A: General representation of an order-2 mapping-friendly sequence reduction as a mapping of 16 input dinucleotides, to the 4 nucleotide outputs and the empty character \\(\\varepsilon\\). B: Homopolymer compression is an order-2 MSR. All dinucleotides except those that contain the same nucleotide twice map to the second nucleotide of the pair. The 4 dinucleotides that are the two same nucleotides map to the empty character \\(\\varepsilon\\). C: Our RC-core-insensitive order-2 MSRs are mappings of the 6 representative dinucleotide inputs to the 4 nucleotide outputs and the empty character \\(\\varepsilon\\). The 4 dinucleotides that are their own reverse complement are always mapped to \\(\\varepsilon\\). The remaining 6 dinucleotides are mapped to the complement of the mapped output of the reverse complement dinucleotide input. For example, if AA is mapped to C, then TT (the reverse complement of AA) will be mapped to G (the complement of C). D: Number of possible MSR mappings under the different restrictions presented in the main text. All mappings from 16 dinucleotide inputs to 5 outputs (as in panel A) are represented by the outermost circle. All RC-core-insensitive mappings (as in panel C) are represented by the medium circle. All RC-core-insensitive mappings with only one representative of each equivalence class are represented by the innermost circle. Since we aim to use SSRs in the context of sequencing data, we need to place additional restrictions on how they handle reverse complements. For example, given two strings \\(x\\) (e.g. a read) and \\(y\\) (e.g. a substring of the reference), a mapper might check if \\(x = RC(y)\\). When strings are pre-processed using an SSR \\(f\\), it will end up checking if \\(f(x) = RC(f(y))\\). However, \\(x = RC(y)\\) only implies that \\(f(x) = f(RC(y))\\). In order to have it also imply that \\(f(x) = RC(f(y))\\), we need \\(f\\) to be commutative with RC, i.e. applying SSR then RC needs to be equivalent to applying RC then SSR. We say that \\(f\\) is RC-insensitive if for all \\(x\\), \\(f(RC(x))= RC(f(x))\\). Observe that HPC is RC-insensitive. 3.2.2 Restricting the space of Streaming sequence reductions To discover SSRs that improve mapping performance, our strategy is to put them all to the test by evaluating the results of an actual mapping software over a simulated test dataset reduced by each SSR. However, even with only \\(16\\) inputs and \\(5\\) outputs, the number of possible \\(g\\) mappings for order-2 SSRs is \\(5^{16}\\approx 1.5\\cdot10^{11}\\), which is prohibitive to enumerate. In this section, we describe two ideas for reducing the space of SSRs that we will test. In subsection 3.2.2.1, we show how the restriction to RC-insensitive mappings can be used to reduce the search space. In subsection 3.2.2.2, we exploit the natural symmetry that arises due to Watson-Crick complements to further restrict the search space. These restrictions reduce the number of order-2 SSRs to only , making it feasible to test all of them. Figure 3.1D shows an overview of our restriction process. 3.2.2.1 Reverse complement-core-insensitive Streaming sequence reductions Consider an SSR defined by a function \\(g\\), as in Equation (3.1). Throughout this paper we will consider SSRs that have a related but weaker property than RC-insensitive. We say that an SSR is RC-core-insensitive if the function \\(g\\) that defines it has the property that for every \\(\\ell\\)-mer\\(x\\) and its reverse complement \\(y\\), we have that either \\(g(x)\\) is the reverse complement of \\(g(y)\\) or \\(g(x) = g(y) = \\varepsilon\\). We will restrict our SSR search space to RC-core-insensitive reductions in order to reduce the number of SSRs we will need to test. Let us consider what this means for the case of \\(\\ell=2\\), which will be the focal point of our experimental analysis. There are 16 \\(\\ell\\)-mers(i.e. dinucleotides) in total. Four of them are their own reverse complement: AT, TA, GC, CG. The RC-core-insensitive restriction forces \\(g\\) to map each of these to \\(\\varepsilon\\), since a single nucleotide output cannot be its own reverse complement. This leaves 12 \\(\\ell\\)-mers, which can be broken down into 6 pairs of reverse complements. For each pair, we can order them in lexicographical order and write them as \\((AA,TT), (AC,GT), (AG,CT), (CA,TG), (CC,GG),\\) and \\((GA,TC)\\). Defining \\(g\\) can then be done by assigning an output nucleotide to the first \\(\\ell\\)-mer in each of these pairs (Figure 3.1C). For example, we can define an SSR by assigning \\(g(AA) = C\\), \\(g(AC) = C\\), \\(g(AG) = A\\), \\(g(CA) = A\\), \\(g(CC) = T\\), and \\(g(GA) = G\\). As an example, let us apply the corresponding SSR to an example read \\(r\\): \\[\\begin{align*} r &amp; = \\text{TAAGTTGA} &amp; f(RC(r)) &amp;=\\color{red}{\\text{T}}\\color{green}{\\text{CACCTG}} \\\\ f(r) &amp; =\\text{TCAGGTG} &amp; RC(f(r)) &amp;=\\;\\;\\;\\color{green}{\\text{CACCTG}}\\color{red}{\\text{A}} \\\\ RC(r) &amp; =\\text{TCAACTTA} &amp; &amp; \\end{align*}\\] Observe that the first \\(\\ell-1\\) nucleotides of \\(r\\) (shown in red) are copied as-is, since we do not apply \\(g\\) on them (as per Equation (3.1)). As we see in this example, this implies that \\(f(RC(r))\\) is not necessarily equal to \\(RC(f(r))\\); thus an RC-core-insensitive SSR is not necessarily an RC-insensitive SSR. However, an RC-core-insensitive SSR has the property that for all strings \\(r\\), we have \\(f(RC(r))[\\ell, |r|]) = RC(f(r))[1, |r| - \\ell + 1]\\). In other words, if we drop the \\(\\ell - 1\\) prefix of \\(f(RC(r))\\) and the \\(\\ell - 1\\) suffix of \\(RC(f(r))\\), then the two strings are equal. Though we no longer have the strict RC-insensitive property, this new property suffices for the purpose of mapping long reads. Since the length of the read sequences will be much greater than \\(\\ell\\) (in our results we will only use \\(\\ell=2\\)), having a mismatch in the first or last nucleotide will be practically inconsequential. It is important to note though that there may be other RC-insensitive functions not generated by this construction. For instance, HPC cannot be derived using this method (as it does not map the di-nucleotides AT,TA,GC and CG to \\(\\varepsilon\\)), and yet it is RC-insensitive. We can count the number of RC-core-insensitive SSRs. Let us define \\(i(\\ell)\\) the number of input assignments necessary to fully determine the RC-core-insensitive SSR; one can think of this as the degrees-of-freedom in choosing \\(g\\). As we showed, for \\(\\ell=2\\), we have \\(i(\\ell)=6\\). The number of RC-core-insensitive SSRs is then \\(5^{i(\\ell)}\\). Therefore, for \\(\\ell=2\\), instead of \\(5^{16}\\) possible mappings we have at most \\(5^{6}\\approx1.5\\cdot10^{4}\\) RC-core-insensitive mappings (Figure 3.1D). For an odd \\(\\ell&gt;2\\), there are no \\(\\ell\\)-mers that are their own reverse complements, hence \\(i(\\ell)=4^\\ell/2\\). If \\(\\ell\\) is even then there are \\(4^{\\ell/2}\\) inputs that are their own reverse complements (i.e. we take all possible sequences of length \\(\\ell/2\\) and reconstruct the other half with reverse complements). Thus, \\(i(\\ell)=(4^\\ell- 4^{\\ell/2})/2\\). 3.2.2.2 Equivalence classes of SSRs When performing preliminary tests, we noticed that swapping \\(A\\leftrightarrow T\\) and/or \\(C\\leftrightarrow G\\), as well as swapping the whole \\(A/T\\) pair with the \\(C/G\\) pair in the SSR outputs did not affect the performance. In other words, we could exchange the letters of the output in a way that preserves the Watson-Crick complementary relation. Intuitively, this can be due to the symmetry induced by reverse complements in nucleic acid strands, though we do not have a more rigorous explanation for this effect. In this section, we will formalize this observation by defining the notion of SSR equivalence. This will reduce the space of SSRs that we will need to consider by allowing us to evaluate only one SSR from each equivalence class. Consider an RC-core-insensitive SSR defined by a function \\(g\\), as in Equation (3.1). An \\(\\ell\\)-mer is canonical if it is the not lexicographically larger than its reverse complement. Let \\(I\\) be the set of all \\(\\ell\\)-mers that are canonical and are not reverse complements of each other. Such an SSR’s dimension \\(k\\) is the number of distinct nucleotides that can be output by \\(g\\) on inputs from \\(I\\) (not counting \\(\\varepsilon\\)). The dimension can range from \\(1\\) to \\(4\\). Next, observe that \\(g\\) maps all elements of \\(I\\) to one of \\(k+ 1\\) values (i.e. \\(\\Sigma \\cup \\varepsilon\\)). The output of \\(g\\) on \\(\\ell\\)-mers not in \\(I\\) is determined by its output on \\(\\ell\\)-mers in \\(I\\), since we assume the SSR is RC-core-insensitive. We can therefore view it as a partition of \\(I\\) into \\(k+1\\) sets \\(S_0\\), …, \\(S_k\\), and then having a function \\(t\\) that is an injection from \\(\\{1, \\ldots, k\\}\\) to \\(\\Sigma\\) that assigns an output letter to each partition. Further, we permanently assign the output letter for \\(S_0\\) to be \\(\\varepsilon\\). Note that while \\(S_0\\) could be empty, \\(S_1, \\ldots, S_k\\) cannot be empty by definition of dimension. For example, the SSR used in Section 3.2.2.1 has dimension four and corresponds to the partition \\(S_0 = \\{\\},S_1=\\{AG,CA\\}\\), \\(S_2=\\{CC\\}\\), \\(S_3=\\{AA,AC\\}\\), \\(S_4=\\{GA\\}\\), and to the injection \\(t(1) = A\\), \\(t(2) =T\\), \\(t(3) = C\\), and \\(t(4) = G\\). Let \\(IsComp(x,y)\\) be a function that returns true if two nucleotides \\(x, y \\in \\Sigma \\cup \\{\\varepsilon\\}\\) are Watson-Crick complements, and false otherwise. Consider two SSRs of dimension \\(k\\) defined by \\(S_0, \\ldots, S_k, t\\) and \\(S&#39;_0, , S&#39;_k, t&#39;\\), respectively. We say that they are equivalent iff all the following conditions are met: \\(S_0 = S&#39;_0\\), there exists a permutation \\(\\pi\\) of \\(\\{1,\\ldots, k\\}\\) such that for all \\(1 \\leq i \\leq k\\), we have \\(S_i = S&#39;_{\\pi(i)}\\), for all \\(1 \\leq i &lt; j \\leq k\\), we have \\(IsComp(t(i), t(j)) = IsComp(t&#39;(\\pi(i)), t&#39;(\\pi(j)))\\). One can verify that this definition is indeed an equivalence relation, i.e. it is reflexive, symmetric, and transitive. Therefore, we can partition the set of all SSRs into equivalence classes based on this equivalence relation. One caveat is that a single SSR defined by a function \\(g\\) may correspond to multiple SSRs of the form \\(S_0,\\ldots,S_k,t\\). However, these multiple SSRs are equivalent, hence the resulting equivalence classes are not affected. Furthermore, we can assume that there is some rule to pick one representative SSR for its equivalence class; the rule itself does not matter in our case. Figure 3.1 shows the equivalence classes for \\(\\ell=2\\), for a fixed partition. An equivalence class can be defined by which pair of classes \\(S_i\\) and \\(S_j\\) have complementary outputs under \\(t\\) and \\(t&#39;\\). Let us define \\(o(k)\\) as the number of equivalence classes for a given partition and a given \\(k\\). Then Figure 3.1 shows that \\(o(1)=1\\), \\(o(2)=2\\) and \\(o(3) = o(4) = 3\\). There are thus only 9 equivalence classes for a given partition. Figure 3.2: MSR equivalence classes for a fixed partition of the inputs. \\(S_0\\) is always assigned \\(\\varepsilon\\), so it is represented by a gray node. A blue link between \\(S_i\\) and an \\(S_j\\) denotes that \\(IsComp(t(i), t(j))=\\text{true}\\). The equivalence classes are determined by the Watson-Crick complementary relationships between the rest of the parts, i.e. by all the possible ways to draw the blue links. 3.2.2.3 Counting the number of restricted SSRs In this section, we derive a formula for the number of restricted MSRs, i.e. MSRs that are RC-core-insensitive and that are representative for their equivalence class. Consider the class of RC-core-insensitive MSRs with dimension \\(k\\). In subsection 3.2.2.1, we derived that the degrees-of-freedom in assigning \\(\\ell\\)-mers to an output is \\(i(\\ell) = 4^\\ell/2\\) if \\(\\ell\\) is odd and \\(i(\\ell) = (4^\\ell - 4^{\\ell / 2})/2\\) if \\(\\ell\\) is even. Let \\(C(\\ell,k)\\) be the number of ways that \\(i(\\ell)\\) \\(\\ell\\)-mers can be partitioned into \\(k+1\\) sets \\(S_0, \\ldots, S_k\\), with \\(S_1, \\ldots, S_k\\) required to be non-empty. Then, in subsection 3.2.2.2, we have derived \\(o(k)\\), the number of MSR equivalence classes for each such partition. The number of restricted MSRs can then be written as \\[\\begin{equation} N(\\ell) = \\sum_{k=1}^{4} C(\\ell, k) \\cdot o(k) \\tag{3.2} \\end{equation}\\] To derive the formula for \\(C(\\ell, k)\\), we first recall that the number of ways to partition \\(n\\) elements into \\(k\\) non-empty sets is known as the Stirling number of the second kind and is denoted by \\(\\tiny\\bigg\\{% \\begin{matrix} n \\\\ k \\end{matrix} \\bigg\\} \\) [34]. It can be computed using the formula \\[\\begin{equation*} \\bigg\\{% \\begin{matrix} n \\\\ k \\end{matrix} \\bigg\\} = \\frac{1}{k!}\\sum_{i=0}^k(-1)^i\\bigg( \\begin{matrix} k \\\\ i \\end{matrix} \\bigg) (k-i)^n \\end{equation*}\\] Let \\(j\\) be the number of the \\(i(\\ell)\\) \\(\\ell\\)-mers that are assigned to \\(S_0\\). Note this does not include the \\(\\ell\\)-mers that are self-complementary that are forced to be in \\(S_0\\). Let \\(C(\\ell,k,j)\\) be the number of ways that \\(i(\\ell)\\) \\(\\ell\\)-mers can be partitioned into \\(k+1\\) sets \\(S_0, \\ldots, S_k\\), such that \\(j\\) of the \\(\\ell\\)-mers go into \\(|S_0|\\) and \\(S_1, \\ldots, S_k\\) to are non-empty. We need to consider several cases depending on the value of \\(j\\): In the case that \\(j = 0\\), we are partitioning the \\(i(\\ell)\\) inputs among non-empty sets \\(S_1, \\ldots, S_k\\). Then \\(C(\\ell, k,j) = \\tiny{\\bigg\\{% \\begin{matrix} i(\\ell) \\\\ k \\end{matrix} \\bigg\\} }\\). In the case that \\(1 \\leq j \\leq i(\\ell) - k\\), there are \\(\\tiny{\\bigg( \\begin{matrix} i(\\ell) \\\\ j \\end{matrix} \\bigg) }\\) ways to choose which \\(j\\) \\(\\ell\\)-mers are in \\(S_0\\), and \\(\\tiny{\\bigg\\{% \\begin{matrix} i(\\ell) - j \\\\ k \\end{matrix} \\bigg\\} }\\) ways to partition the remaining \\(\\ell\\)-mers into \\(S_1, \\ldots, S_k\\). Hence, \\(C(\\ell, k,j) = \\tiny{\\bigg( \\begin{matrix} i(\\ell) \\\\ j \\end{matrix} \\bigg) }\\tiny{\\bigg\\{% \\begin{matrix} i(\\ell) - j \\\\ k \\end{matrix} \\bigg\\} }\\). In the case that \\(j &gt; i(\\ell) - k\\), it is impossible to partition the remaining \\(k\\) (or fewer) \\(\\ell\\)-mers into \\(S_1, \\ldots, S_k\\) such that the sets are non-empty. Recall that as we assume the dimension is \\(k\\), each set must contain at least one element. Hence, \\(C(\\ell, k,j) = 0\\). Putting this together into Equation (3.2), we get \\[\\begin{equation*} N(\\ell) = \\sum_{k=1}^4 o(k) \\bigg( \\bigg\\{% \\begin{matrix} i(\\ell) \\\\ k \\end{matrix} \\bigg\\} + \\sum_{j=1}^{i(\\ell) - k}\\bigg( \\begin{matrix} i(\\ell) \\\\ j \\end{matrix} \\bigg) \\bigg\\{% \\begin{matrix} i(\\ell)-j \\\\ k \\end{matrix} \\bigg\\} \\bigg) \\end{equation*}\\] For \\(\\ell=2\\), we have \\(N(2)=2,135\\) restricted MSRs, which is several orders of magnitude smaller than the initial \\(5^{16}\\) possible MSRs and allows us to test the performance of all of them. for order-3 MSRs we get \\(N(3)=2.9\\cdot10^{21}\\) which much smaller than the full search space of \\(5^{4^3}\\approx5.4\\cdot10^{44}\\), for order-4 MSRs we get a similar reduction in search space with \\(N(4)=9.4\\cdot10^{84}\\) as opposed to the full search space of \\(5^{4^4}\\approx8.6\\cdot10^{178}\\). For these higher order MSRs, although the restricted search space is much smaller than the full naive one, it is still too large to exhaustively search. 3.3 Datasets and Pipelines 3.3.1 Datasets The following three reference sequences were used for evaluation: Whole human genome: This reference sequence is a whole genome assembly of the CHM13hTERT human cell line by the Telomere-to-Telomere consortium [@ 4]. We used the 1.1 assembly release (Genbank Assembly ID GCA_009914755.3). Whole Drosophila genome: This reference sequence is a whole genome assembly of a Drosophila melanogaster, release 6.35 (Genbank Assembly ID GCA_000001215.4) [35]. Synthetic centromeric sequence: This sequence was obtained from the TandemTools mapper test data [36]. It is a simulated centromeric sequence that is inherently difficult to map reads to. Appendix A.1 describes how it was constructed. 3.3.2 Simulation pipeline Given a reference sequence, simulated reads were obtained using nanosim [37] with the human_NA12878_DNA_FAB49712_guppy_flipflop pre-trained model, mimicking sequencing with an Oxford Nanopore instrument. The number of simulated reads was chosen to obtain a theoretical coverage of whole genomes around 1.5x, this resulted in simulating \\(\\approx 6.6\\cdot10^5\\) reads for the whole human genome and \\(\\approx 2.6\\cdot10^4\\) reads for the whole Drosophila genome. Since the centromeric sequence is very short, we aimed for a theoretical coverage of 100x which resulted in \\(\\approx 1.3\\cdot10^4\\) simulated reads. For each evaluated SSR, the reads as well as the reference sequence were reduced by applying the SSR to them. The reduced reads were then mapped to the reduced reference using minimap2[25] with the map-ont preset and the -c flag to generate precise alignments. Although HPC is an option in minimap2 we do not use it and we evaluate HPC as any of the other SSRs by transforming the reference and reads prior to mapping. The starting coordinates of the reduced reads on the reduced reference were updated to reflect deletions incurred by the reduction process. The mapping results with translated coordinates were filtered to keep only the primary alignments. This process was done for each of our 2135 SSRs as well as with HPC and the original untransformed reads (denoted as raw). 3.3.3 Evaluation pipeline We use two metrics to evaluate the quality of a mapping of a simulated read set. The first is the fraction of reads mapped, i.e. that have at least one alignment. The second is the error rate, which is the fraction of mapped reads that have an incorrect location as determined by paftools mapeval [25]. This tool considers a read as correctly mapped if the intersection between its true interval of origin, and the interval where it has been mapped to, is at least 10% of the union of both intervals. Furthermore, we measure the error rate as a function of a given mapping quality threshold. Mapping quality (abbreviated mapq) is a metric reported by the aligner that indicates its confidence in read placement; the highest value (60) indicates that the mapping location is likely correct and unique with high probability, and a low value (e.g. 0) indicates that the read has multiple equally likely candidate mappings and that the reported location cannot be trusted. The error rate at a mapq threshold \\(t\\) is then defined as the error rate of reads whose mapping quality is \\(t\\) or above. For example, the error rate at \\(t=0\\) is the error rate of the whole read set, while the error rate at \\(t=60\\) is the error rate of only the most confident read mappings. Observe that the error rate decreases as \\(t\\) increases. 3.4 Results 3.4.1 Selection of mapping-friendly sequence reductions We selected a set of “promising” SSRs starting from all of the SSRs enumerated in Section 3.2.2, that we call mapping-friendly sequence reductions (abbreviated MSR). The selection was performed by considering an independent read set of lower (0.5x) coverage, simulated from the whole human genome reference. This dataset is separate from the ones used for evaluation. Note that overfitting MSRs to a particular genome is acceptable in applications where a custom MSR can be used for each genome. Yet in this work, the same set of selected MSRs will be used across all genomes. Figure 3.3: Illustration of how a respective mapq threshold is chosen for each of our evaluated MSRs. The orange dot shows the error rate and fraction of reads mapped for HPC at mapq threshold 60. Anything below and to the right of this point is strictly better than HPC 60, i.e. it has both a lower error rate and higher fraction of reads mapped. If an evaluated MSR does not pass through this region, then it is discarded from further consideration. In the figure, the blue MSR does pass through this region, indicating that it is better than HPC 60. We identify the leftmost point (marked as a blue dot) and use the mapq threshold at that point as the respective threshold. For each evaluated SSR, we selected, if it exists, the highest mapq threshold for which the mapped read fraction is higher and the error rate is lower than HPC at mapq 60 (\\(0.93\\) and \\(2.1\\cdot 10^{-3}\\) respectively). Figure 3.3 illustrates the idea. Then we identified the 20 SSRs that have the highest fraction of reads mapped at their respective thresholds. Similarly we identified the 20 SSRs with the lowest error rate. Finally we select the 20 SSRs that have the higest percentage of thresholds “better” than HPC at mapq 60; i.e. the number of mapq thresholds for which the SSR has both a higher fraction of reads mapped and lower error rate than HPC at a mapq threshold of 60, divided by the total number of thresholds (=60). The union of these 3 sets of 20 SSRs resulted in a set of 58 “promising” MSRs. Furthermore, we will highlight three MSRs that are “best in their category”, i.e. MSR\\(_{\\text{F}}\\): The MSR with the highest fraction of mapped reads at a mapq threshold of 0. MSR\\(_{\\text{E}}\\): The MSR with the lowest error rate at its respective mapq threshold. MSR\\(_{\\text{P}}\\): The MSR with the highest percentage of mapq thresholds for which it is “better” than HPC at mapq 60. Figure 3.4 shows the actual functions MSR\\(_{\\text{F}}\\), MSR\\(_{\\text{E}}\\), MSR\\(_{\\text{P}}\\). An intriguing property is that they output predominantly As and Ts, with MSR\\(_{\\text{P}}\\) assigning 2 input pairs to the G/C output whereas MSR\\(_{\\text{E}}\\) and MSR\\(_{\\text{F}}\\) assign only one. Additionally, MSR\\(_{\\text{E}}\\) and MSR\\(_{\\text{P}}\\) both assign the {CC,GG} input pair to the deletion output \\(\\varepsilon\\) removing any information corresponding to repetitions of either G or C from the reduced sequence. Overall this means the reduced sequences are much more AT-rich than their raw counterparts, but somehow information pertinent to mapping is retained. Figure 3.4: Graph representations of our highlighted MSRs: MSR\\(_{\\text{E}}\\), MSR\\(_{\\text{F}}\\), and MSR\\(_{\\text{P}}\\). MSR\\(_{\\text{E}}\\) has the lowest error rate of among MSRs at the highest mapq threshold for which it performs better than HPC at mapq 60, MSR\\(_{\\text{F}}\\) has the highest fraction of reads mapped at mapq 60 and MSR\\(_{\\text{P}}\\) has the highest percentage of mapq thresholds for which it outperforms HPC at mapq 60. The grayed out nodes represent the reverse complement of input dinucleotides and outputs, as in Figure 3.1C. For example for MSR\\(_{\\text{E}}\\), AA is mapped to T, so TT is mapped to A. 3.4.2 Mapping-friendly sequence reductions lead to lower mapping errors on whole genomes Across the entire human genome, at high mapping quality thresholds (above 50), our selected 58 MSRs generally have lower mapping error rate than HPC and raw Figure 3.5A and Table 3.1. This is not surprising, as we selected those MSRs partly on the criteria of outperforming HPC at mapq 60; however, it does demonstrate that we did not overfit to the simulated reads used to select the MSRs. Figure 3.5: Performance of our 58 selected mapping-friendly sequence reductions across genomes on reads simulated by nanosim Panel A) shows the whole human genome assembly, B) the subset of mapped reads from panel B that originate from repetitive regions, and C) the “TandemTools” synthetic centromeric reference sequence. We highlighted the best-performing mapping-friendly sequence reductions as MSR E, F and P, respectively in terms of cumulative mapeval error rate, fraction of reads mapped, and percentage of better thresholds than HPC. Each point on a line represents, from left to right, the mapping quality thresholds 60, 50, 40, 30, 20, 10 and 0. For the first point of each line, only reads of mapping quality 60 are considered, and the y value represents the rate of these reads that are not correctly mapped, the x value represents the fraction of simulated reads that are mapped at this threshold. The next point is computed for all reads of mapping quality \\(\\geq50\\), etc. The rightmost point on any curve represents the mapping error rate and the fraction of mapped reads for all primary alignments. The x-axes are clipped for lower mapped read fractions to better differentiate HPC, raw and MSRs E, F and P. Mapping quality is only an indication from the aligner to estimate whether a read mapping is correct, and according to Figure 3.5A the mapping error rate of most MSRs is low even for mapping qualities lower than 60. Therefore, we choose to compare MSR-mapped reads with lower mapping qualities against raw or HPC-mapped reads with the highest (60) mapping quality (which is the mapping quality thresholds most practitioners would use by default). Table 3.1 shows that the three selected MSRs outperform both HPC and raw in terms of mapping error rate, with similar fractions of mapped reads overall. For example on the human genome, at mapq\\(\\geq50\\), MSR\\(_{\\text{F}}\\), MSR\\(_{\\text{P}}\\) and MSR\\(_{\\text{E}}\\) all map more reads than either HPC or raw at mapq=60, and MSR\\(_{\\text{P}}\\) and MSR\\(_{\\text{E}}\\) also have error rates an order of magnitude lower than either HPC or raw. To evaluate the robustness of MSRs E, F and P we investigated the impact of mapping to a different organism or using another mapper. To this effect we repeated the evaluation pipeline in these different settings: Using the Drosophila melanogaster whole genome assembly as reference and mapping with minimap2 Using the whole human genome assembly as reference but mapping with winnowmap2(version 2.02) [38]. The same options as minimap2 were used, and k-mers were counted using meryl [39], considering the top \\(0.02\\%\\) as repetitive (as suggested by the winnowmap2 usage guide). MSRs E, F and P behave very similarly in both of these contexts compared to HPC/raw: by selecting mapped reads with mapq\\(\\geq\\) 50 for the three MSRs we obtain a similar fraction of mapped reads with much lower error rates (Table 3.1). A noticeable exception is the winnowmap2 experiment, where a larger fraction of raw reads are mapped than any other MSR and even HPC. A more detailed results table can be found in Table A.1, and a graph of MSR performance on the whole Drosophila genome in Figure A.7. As Figure A.7 shows, we also evaluated these MSRs on a whole Escherichia coli (Genbank ID U00096.2) genome, where we observed similar results, albeit the best MSRs do not seem to be one of our three candidates. This might mean that specific MSRs are more suited to particular types of genomes. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-aea1bf82{table-layout:auto;width:100%;}.cl-ae9835e8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ae98362e{font-family:'Helvetica';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.3pt;}.cl-ae983638{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-ae985b04{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ae985b0e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-ae98da98{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98daa2{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98daac{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98dab6{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98dac0{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98daca{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98dad4{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98dade{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-ae98dae8{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}labelmapqWhole human genome (minimap2)Whole human genome (winnowmap2)Whole Drosophila genome (minimap2)fractionerrorfractionerrorfractionerrorHPC600.935 +0%1.85e-03 +0%0.894 +0%1.43e-03 +0%0.957 +0%2.27e-03 +0%raw600.921 -1%1.86e-03 +0%0.932 +4%1.75e-03 +23%0.958 +0%2.27e-03 -0%MSRF500.938 +0%1.29e-03 -30%0.886 -1%3.82e-04 -73%0.960 +0%1.37e-03 -39%MSRE500.936 +0%1.17e-04 -94%0.820 -8%8.93e-05 -94%0.954 -0%0 -100%MSRP500.938 0%4.15e-04 -78%0.845 -6%1.14e-04 -92%0.957 +0%8.11e-04 -64% Table 3.1: Performance of MSRs, HPC, and raw mappings across different mappers and reference sequences. For each reference sequence and mapper pair, we report the fraction of reads mapped (“fraction” columns), the paftools mapeval mapping error rate (“error” columns). The percentage differences are computed w.r.t to the respective HPC value. For HPC and the raw these metrics were obtained for alignments of mapping quality of 60. For MSRs E, F and P these metrics were obtained for alignments of mapping quality \\(\\geq 50\\). 3.4.3 Mapping-friendly sequence reductions increase mapping quality on repeated regions of the human genome To evaluate the performance of our MSRs specifically on repeats, we extracted the simulated reads for which an overlap with repeated region of the whole human genome was greater than \\(50\\%\\) of the read length. We then evaluated the MSRs on these reads only. Repeated regions were obtained from https://t2t.gi.ucsc.edu/chm13/hub/t2t-chm13-v1.1/rmsk/rmsk.bigBed. We obtained similar results as on the whole human genome, with MSRs E, F and P performing better than HPC at mapq 50 (Figure 3.5B). At a mapq threshold of 50, the error rate is \\(53\\%\\), \\(31\\%\\), and \\(39\\%\\) lower than HPC at mapq 60 for MSRs E, F and P respectively, while the fraction of mapped reads remains slightly higher. At mapq=60, raw has a error rate \\(40\\%\\) lower than HPC but it the mapped fraction is also \\(17\\%\\) lower. 3.4.4 Raw mapping improves upon HPC on centromeric regions On the “TandemTools” centromeric reference, HPC consistently maps a smaller fraction of reads than raw, across all mapping quality thresholds (Figure 3.5C). Additionally, the error rate for raw is often inferior to that of HPC. The same is true for our selected MSRs: most of them have comparable performance to HPC, but none of them outperform raw mapping (Figure 3.5C). We conjecture this is due to the highly repetitive nature of centromeres. HPC likely removes small unique repetitions in the reads and the reference that might allow mappers to better match reads to a particular occurrence a centromeric pattern. Mapping raw reads on the other hand preserves all bases in the read and better differentiates repeats. Therefore it seems inadvisable to use HPC when mapping reads to highly repetitive regions of a genome, such as a centromere. 3.4.5 Positions of incorrectly mapped reads across the entire human genome To study how MSRs E, F, and P improve over HPC and raw mapping in terms of error rate on the human genome, we selected all the primary alignments that paftools mapeval reported as incorrectly mapped. For HPC and raw, only alignments of mapping quality equal to 60 were considered. To report a comparable fraction of aligned reads, we selected alignments of mapping quality \\(\\geq 50\\) for MSRs. We then reported the origin of those incorrectly mapped reads on whole human genome reference, shown per-chromosome in Appendix A.1. We observe that erroneously mapped reads are not only those from centromeres, and instead originate from many other genomic regions. MSRs E and P have a markedly lower number of these incorrect mappings than either HPC or raw, with 1118 incorrect mappings for raw mappings and 1130 for HPC as opposed to 549, 970 and 361 for MSRs E, F and P respectively. This stays true even for difficult regions of the genome such as chromosome X, where raw and HPC have 70 incorrect mappings as opposed MSRs E and P that have 39, and 27 errors respectively. We also investigated where all simulated reads were mapped on the whole human genome assembly, for raw, HPC and MSRs E,F and P in Figures A.2 to A.6. The correctly mapped reads are, as expected, evenly distributed along each chromosome. The incorrectly mapped reads are however unevenly distributed. For most chromosomes there is a sharp peak in the distribution of incorrectly mapped reads, located at the position of the centromere. For the acrocentric chromosomes, there is a second peak corresponding to the “stalk” satellite region, with an enrichment of incorrectly mapped reads. This is expected since both centromeres and “stalks” are repetitive regions which are a challenge for mapping. For chromosomes 1, 9 and 16 however the majority of incorrectly mapped reads originate in repeated regions just after the centromere. 3.5 Discussion We have introduced the concept of mapping-friendly sequence reduction and shown that it improves the accuracy of the popular mapping tool minimap2 on simulated Oxford Nanopore long reads. We focused on reads with high mapping quality (50-60), as it is a common practice to disregard reads with low mapping quality [40–42]. However across all mapped reads (mapq \\(\\geq 0\\)), HPC and our MSRs have lower mapping accuracies than raw reads, consistent with the recommendation made in minimap2 to not apply HPC to ONT data. Despite this, we newly show the benefit of using HPC (and our MSRs) with minimap2 on ONT data when focusing on high mapping quality reads. Furthermore MSRs provide a higher fraction of high-mapq reads compared to both raw and HPC, as shown on the human and Drosophila genomes. A natural future direction is to also test whether our MSRs perform well on mapping Pacific Biosciences long reads. Furthermore, it is important to highlight that our sampling of MSRs is incomplete. This is of course due to only looking at functions having \\(\\ell=2\\), but also to the operational definition of RC-core-insensitive functions, and finally to taking representatives of equivalence classes. An interesting future direction would consist in exploring other families of MSRs, especially those that would include HPC and/or close variations of it. Additionally, our analyses suggests to not perform HPC on centromeres and other repeated regions, hinting at applying sequence transformations to only some parts of the genomes. We leave this direction for future work. 3.6 Limitations of this study Our proposed MSRs improve upon HPC at mapq 60, both in terms of fraction of reads mapped and error rate, on whole human and Drosophila melanogaster genomes. We chose these sequences because they were from organisms that we deemed different enough, however it would be interesting to verify if our proposed MSRs are still advantageous on very different organisms, e.g. more bacterial or viral genomes. This would allow us to assess the generalizability of our proposed MSRs. We made the choice of using simulated data to be able to compute a mapping error rate. Some metrics, such as fraction of reads mapped might still be informative with regards to the mapping performance benefits of MSRs, even on real data. Evaluating the MSRs on real data might be more challenging but would offer insight into real-world usage of such pre-processing transformations. Finally, the restrictions we imposed to define RC-core-insensitive MSRs though intuitively understandable are somewhat arbitrary, so exploring a larger search space might be beneficial. Alternatively for higher order MSRs, even with our restrictions, the search spaces remain much too large to be explored exhaustively. To mitigate this problem, either further restrictions need to be found, or an alternative, optimization-based exploration method should be implemented. 3.7 Code availability The scripts and pipelines used to obtain the results, as well as do the analysis and figures are available in an online repository at github.com/lucblassel/MSR_discovery Supplementary information Supporting Information can be found in Appendix A References "],["learning-from-alignments.html", "Chapter 4 Learning from alignments 4.1 Alignments are a rich source of information 4.2 Preprocessing the alignment for machine learning 4.3 How to learn from ALNs", " Chapter 4 Learning from alignments 4.1 Alignments are a rich source of information 4.1.1 Pairwise alns we can compare sequences and say if an organism, or in the case of mapping get an idea of where on the genome we are sequencing 4.1.2 MSA Here we have richer 4.1.2.1 Clustering Phylogenetic trees Evolutionary inference Protein structure prediction 4.1.2.2 ML Alphafold Predict location / function predict characteristics i.e. resistance, … 4.2 Preprocessing the alignment for machine learning In order to do some learning we need to have the data in digestible form 4.2.1 Embedding the alignment We need a way to represent, the position and the character in a sequence 4.2.1.1 Physico-chemical embeddings AAIndex, or other embeddings, we add extra info, but we also make a string choice when deciding what features to add 4.2.1.2 Generalistic categorical embeddings One-Hot, etc…, easily interpretable… 4.2.1.3 Learned embeddings language models, transformers, etc… Powerful but hard to interpret what the model actually learns. i.e. “black box” 4.2.2 Choosing a learning target Of course one we have the data in digestible form we need an objective, a goal and once again a multitude 4.2.2.1 Regression Either resistance level, IC50, … 4.2.2.2 Classification Resistant or not, compartiments in the cell, … 4.2.2.3 Task-based… end-to-end training like aligning sequences, this is harder because it requires developing a custom differentiable scoring function based on the task. 4.3 How to learn from ALNs 4.3.1 Tests and statistical learning correlation Fisher Multiple testing ? 4.3.2 Taking interactions into account Regressions w/ regularization RF … 4.3.3 Deep Learning Steiner et al… others "],["hiv-and-drms.html", "Chapter 5 HIV and DRMs 5.1 What are viruses ? 5.2 What is HIV ? 5.3 Drug resistance in HIV", " Chapter 5 HIV and DRMs 5.1 What are viruses ? small presentation / definition of viruses DNA / RNA viruses 5.2 What is HIV ? 5.2.1 Presentation of HIV pandemic history 5.2.2 Replication cycle of HIV proteins ( + computational representation as a string of letters) full cycle 5.3 Drug resistance in HIV When on ART, virus evolves under selectuve pressure and develops resitance -&gt; treatment failure. 5.3.1 How does ART work target the proteins, RT, PR, IN (small history of ART) 5.3.2 different types of resistance NRTI NNRTI Entry inhibitors PI INSTI 5.3.3 Consequences on global health Transmitted DRMS can be very serious , … however fitness cost, … 5.3.4 Finding DRMS Consortiums / HIVDB, UK-CHIC, … stat tests multiple testing phylogenetic correlation assays novel approaches deep learning … "],["HIV-paper.html", "Chapter 6 Using Machine Learning and Big Data to Explore the Drug Resistance Landscape in HIV Abstract Author summary 6.1 Introduction 6.2 Materials and methods 6.3 Results 6.4 Discussion and perspectives Acknowledgments Supporting Information", " Chapter 6 Using Machine Learning and Big Data to Explore the Drug Resistance Landscape in HIV Luc Blassel1,2*, Anna Tostevin3, Christian Julian Villabona-Arenas4,5, Martine Peeters6, Stéphane Hué4,5, Olivier Gascuel1,7# On behalf of the UK HIV Drug Resistance Database\\(\\wedge\\) 1 Unité de Bioinformatique Évolutive, Institut Pasteur, Paris, France 2 Sorbonne Université, Collège doctoral, Paris, France 3 Institute for Global Health, UCL, London, UK 4 Department of Infectious Disease Epidemiology, London School of Hygiene and Tropical Medicine, London, UK 5 Centre for Mathematical Modelling of Infectious Diseases, London School of Hygiene and Tropical Medicine, London, UK 6 TransVIHMI (Recherches Translationnelles sur VIH et Maladies Infectieuses), Université de Montpellier, Institut de Recherche pour le Développement, INSERM, Montpellier, France 7 Institut de Systématique, Evolution, Biodiversité (ISYEB), UMR 7205 - Muséum National d’Histoire Naturelle, CNRS, SU, EPHE and UA, Paris, France # Current address: Institut de Systématique, Evolution, Biodiversité (ISYEB), UMR 7205 - Muséum National d’Histoire Naturelle, CNRS, SU, EPHE and UA, Paris, France * luc.blassel@pasteur.fr (LB) * olivier.gascuel@mnhn.fr (OG) \\(\\wedge\\) Membership list can be found in the acknowledgments section originally published in PLoS Computational Biology in August 2021 doi:10.1371/journal.pcbi.1008873 Abstract Drug resistance mutations (DRMs) appear in HIV under treatment pressure. DRMs are commonly transmitted to naive patients. The standard approach to reveal new DRMs is to test for significant frequency differences of mutations between treated and naive patients. However, we then consider each mutation individually and cannot hope to study interactions between several mutations. Here, we aim to leverage the ever-growing quantity of high-quality sequence data and machine learning methods to study such interactions (i.e. epistasis), as well as try to find new DRMs. We trained classifiers to discriminate between Reverse Transcriptase Inhibitor (RTI)-experienced and RTI-naive samples on a large HIV-1 reverse transcriptase (RT) sequence dataset from the UK (\\(n\\approx 55,000\\)), using all observed mutations as binary representation features. To assess the robustness of our findings, our classifiers were evaluated on independent data sets, both from the UK and Africa. Important representation features for each classifier were then extracted as potential DRMs. To find novel DRMs, we repeated this process by removing either features or samples associated to known DRMs. When keeping all known resistance signal, we detected sufficiently prevalent known DRMs, thus validating the approach. When removing features corresponding to known DRMs, our classifiers retained some prediction accuracy, and six new mutations significantly associated with resistance were identified. These six mutations have a low genetic barrier, are correlated to known DRMs, and are spatially close to either the RT active site or the regulatory binding pocket. When removing both known DRM features and sequences containing at least one known DRM, our classifiers lose all prediction accuracy. These results likely indicate that all mutations directly conferring resistance have been found, and that our newly discovered DRMs are accessory or compensatory mutations. Moreover, apart from the accessory nature of the relationships we found, we did not find any significant signal of further, more subtle epistasis combining several mutations which individually do not seem to confer any resistance. Author summary Almost all drugs to treat HIV target the Reverse Transcriptase (RT) and Drug resistance mutations (DRMs) appear in HIV under treatment pressure. Resistant strains can be transmitted and limit treatment options at the population level. Classically, multiple statistical testing is used to find DRMs, by comparing virus sequences of treated and naive populations. However, with this method, each mutation is considered individually and we cannot hope to reveal any interaction (epistasis) between them. Here, we used machine learning to discover new DRMs and study potential epistasis effects. We applied this approach to a very large UK dataset comprising \\(\\approx 55,000\\) RT sequences. Results robustness was checked on different UK and African datasets. Six new mutations associated to resistance were found. All six have a low genetic barrier and show high correlations with known DRMs. Moreover, all these mutations are close to either the active site or the regulatory binding pocket of RT. Thus, they are good candidates for further wet experiments to establish their role in drug resistance. Importantly, our results indicate that epistasis seems to be limited to the classical scheme where primary DRMs confer resistance and associated mutations modulate the strength of the resistance and/or compensate for the fitness cost induced by DRMs. 6.1 Introduction Drug resistance mutations (DRMs) arise in Human Immunodeficiency Virus-1 (HIV-1) due to antiretroviral treatment pressure, leading to viral rebound and treatment failure [43,44]. Furthermore, drug-resistant HIV strains can be transmitted to treatment-naive individuals and further spread throughout the population over time [45–47]. These transmitted resistant variants limit baseline treatment options and have clinical and public health implications worldwide. Almost all drugs to treat HIV target the reverse transcriptase (RT), encoded by the pol gene. Lists of DRMs are regularly compiled and updated by experts in the field, based on genotype analyses and phenotypic resistance tests or clinical outcome in patients on ART [48–50]. However, with the developement of new antiretroviral drugs that target RT but also other regions of the pol gene like protease or integrase, and the use of anti-retrovirals in high risk populations by pre-exposure prophylaxis (PREP), it is important to further our understanding of HIV polymorphisms and notably the interactions between mutations and epistatic effects. Among known DRMs, some mutations, such as M184V, directly confer resistance to antiretrovirals, more precisely the commonly used NRTI, 3TC (lamivudine) and FTC (emtricitabine), and are called primary or major drug resistance mutations, while some mutations like E40F have an accessory role and increases drug resistance when appearing alongside primary DRMs. Moreover, some mutations like S68G seem to have a compensatory role, but are not known to confer any resistance nor modulate resistance induced by primary DRMs. All of these mutations might have different functions in the virus, but they are all known to be associated with drug resistance phenomena. Therefore, during the rest of this article we will refer to all of these known mutations as resistance associated mutations (RAMs), rather than DRMs which is too specific, and our goal will be to search for new RAMs and study the interactions between known RAMs and the new ones. Classically, new RAMs have been found using statistical testing and large multiple sequence alignments (MSA) of the studied protein [51,52]. Tests are performed for mutations of interest on a given MSA to check if they are associated with the treatment status and outcome of the individual the viral sequences were sampled from. The test significance is corrected for multiple testing as all mutations associated to every MSA position is virtually a resistance mutation and tested. After this preliminary statistical search, the selected mutations are scrutinized to remove the effects of phylogenetic correlation (i.e. typically counting two sequences which are identical or closely related due to transmission rather than independent acquisition twice [53]) and check that the same mutation occurred several times in different subtypes and populations being treated with the same drug. Then, these mutations can be further experimentally tested in vitro or in vivo to validate phenotypic resistance. This method has worked well, but by design it is not ideal for studying the effect of several mutations at once, since if we have to test all couples or triplets of mutations, we quickly lose statistical power when correcting for multiple testing [54], due to the large number of tests to perform. Moreover, phylogenetic correlation is again a critical issue with such an approach. Machine learning has been extensively used to predict resistance to antiretrovirals from sequence data. There are two main approaches to predicting resistance from sequence data. Regression, where machine learning models are trained to predict the value of a drug resistance indicator, typically \\(IC_{50}\\) fold change in response to a given drug [55] or other indicators from phenotypic resistance assays such as PhenoSense [56]. Many methods have been used to predict a resistance level: Support Vector Machines (SVMs) [57], k-Nearest Neighbors (KNN) and Random Forests (RFs) [58], and more recently Artificial Neural Networks (ANNs) [59,60]. Alternatively, this task has also been approached as a classification problem. Given a certain threshold on a phenotypic resistance measure, sequences are given a label of \"resistant\" or \"susceptible\" to a certain drug. Machine learning classifiers are then trained to predict that label. For this task, SVMs and decision trees have been used [61,62], ensemble classifier chains [63,64] and also ANNs [65]. Most recently Steiner et al. [66] have used Deep Learning Architectures to predict resistance status (i.e. classification) from sequence data. Since phenotypic assays are more complicated and costly to perform than simple genotyping, there is a limited number of sequences paired with a resistance level. This is the main limitation of these studies since machine learning methods typically benefit from a large amount of training data. This is especially true for deep neural networks which can need hundreds of thousands of training samples for certain tasks and architectures. However, despite this limitation, approaches proposed in these studies seem to have fairly good predictive accuracy. It is important to note that all of these studies aim to predict if a given sequence is resistant or not to a given drug, they do not aim to find new potential RAMs. Although Steiner et al. [66] have checked that known DRM positions are captured by their models and found several positions potentially associated to resistance, it is not the main goal of their method. It is accepted in machine learning that there is a trade-off between model accuracy and model interpretability. In these previous studies the goal was to make the most accurate predictions possible, using complex models such as SVMs and ANNs, therefore sacrificing interpretability. Here, we have a different approach, using simpler models that might be less accurate but whose predictions we can understand and interpret. We train these models to discriminate RTI-naive from RTI-experienced sequences. Without the need for phenotypic data, we are able to use much larger HIV-1 RT sequence datasets from the UK (\\(n\\approx55,000\\)) (http://www.hivrdb.org.uk/) and Africa (\\(n\\approx4,000\\)) [52]. By using interpretable models, we can extract mutations that are important for determining if a sequence is treated or not and potentially find new mutations potentially associated to resistance. Furthermore, we aim to detect associations between mutations and their effect on antiretroviral resistance in order to study potential underlying epistasis. The African and UK datasets are very different both from genetic and treatment history standpoints, therefore training classifiers on the UK dataset and testing them on the African one, should guarantee the robustness of our findings and greatly alleviate phylogenetic correlation effects. In the following sections, we first describe the data then the methods used. Our results include the assessment of the performance of our classifiers even when trained on data devoid of any known resistance-associated signal; as well as a description of the main features (prevalence and correlation to known mutations, genetic barrier and structural analysis) of six potentially resistance associated mutations, newly discovered thanks to our approach. These results and perspectives are discussed in the concluding section. 6.2 Materials and methods 6.2.1 Data In this study, we used all the drug resistance mutations that appeared in the Stanford HIV Drug resistance database, both for NRTI (Nucleoside Reverse Transcriptase Inhibitors; https://hivdb.stanford.edu/dr-summary/comments/NRTI/) and NNRTI (Non Nucleoside RTI; https://hivdb.stanford.edu/dr-summary/comments/NNRTI/) as known RAMs. To discover new RAMs, assess their statistical significance and study potential epistatic effects, we used two datasets of HIV-1 RT sequences. A large one (\\(n=55,539\\)) from the UK HIV Drug Resistance Database (http://www.hivrdb.org.uk/) and a smaller (\\(n=3,990\\)) one from 10 different western, eastern and central African countries [52]. In the UK dataset, sequences from RTI-naive individuals formed the majority class with 41,921 sequences (75%). In the African dataset, both classes were more balanced with 2,316 RTI-naive sequences (58%). In the UK dataset, RTI-naive sequences had at least one known RAM in 25% of cases, most likely due to transmissions to naive patients or undisclosed treatment history, against 48% in RTI-experienced sequences, thus making the discrimination between the RTI-experienced and RTI-naive sequences particularly difficult. In the African dataset this distribution was more contrasted, with only 14% of RTI-naive sequences having at least one known RAM, versus 83% of RTI-experienced sequences. The African dataset was also much more genetically diverse with 24 different subtypes and CRFs compared to the 2 subtypes (B and C) that we retained for this study from the UK cohort. The majority of the sequences from the African dataset were samples from Cameroon (27%), Democratic Republic of Congo (17%), Burundi (15%), Burkina Faso (13%) and Togo (11%). It is important to note that RTI-experienced sequences in both of these datasets can be considered as resistant to treatment. Since the viral load was sufficiently high to allow for sequencing of the virus, we can consider that the ART has failed. However, in some cases this resistance might be caused by non adherence to ART, rather than by the presence of RAMs, therefore adding some noise to the relationship between treatment status and resistance. In addition to differences in size, balance between RTI-naive and experienced classes, and the genetic difference between the UK and African datasets, there are also significant differences resulting from differing treatment strategies. In the UK and other higher income countries, the treatment is often tailored to the individual with genotype testing, which result in specific treatment as well as thorough follow-ups and high treatment adherence. In the African countries of the dataset that we used, the treatment is ZDV/ d4T (NRTI) + 3TC (NRTI) + NVP/EFV (NNRTI) in most cases [52], and this treatment is generalized to the affected population, with poorer follow-up and adherence than in the UK. This discrepancy could lead to different mutations arising in both datasets, however since the treatment strategy is a combination of both NRTI and NNRTI drug classes, as in many countries, similar RAMs arise [52]. Furthermore, there is potentially more uncertainty in the African dataset than in the UK. For example some individuals may have unofficially taken antiretroviral drugs, but still identify themselves as RTI-naive, or report having some form of ART while not having been treated for HIV [67]. All of this explains the high prevalence of multiple resistance in the African data set: the median number of RAMs in sequences containing at least one RAM is 3 in the African sequences, while it is 1 in UK sequences (Table 6.1). Thus, we can say that African sequences are highly resistant, with possibly different mutations and epistatic effects, compared to their UK counterparts. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-54398774{table-layout:auto;width:90%;}.cl-5431f6bc{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-54320332{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5432033c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-543242de{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-543242df{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-543242e8{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-543242f2{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-543242fc{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-543242fd{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}UKAfricasize55,5393,990RTI naïvewith known RAMs11,429(21%)318(8%)without known RAMs30,492(55%)1,998(50%)RTI experiencedwith known RAMs6,633(12%)1,388(35%)without known RAMs6,985(13%)286(7%)sequences with ≥ 2 known RAMs8,034(14%)1,308(33%)max known RAM number1317Median known RAM number13number of subtypes / CRFs224subtypes / CRFsA0(0%)472(12%)B37,806(68%)64(2%)C17,733(32%)702(18%)CRF02 AG0(0%)1,477(37%) Table 6.1: Summary of the UK and Afican datasets Percentages are computed with regards to the size of the considered dataset (e.g. 21% of the sequences of the UK dataset are RTI-naive and have at least one known RAM). The median number of RAMs was computed only on sequences that had at least one known RAM. All these differences between the two datasets helped us to assess the generalizability of our method and the robustness of the results. That is to say, if signal extracted from the UK dataset was still relevant on such a different dataset as the African one, we could be fairly reassured in regard to the biological and epidemiological relevance of the observed signal. Sequences in both African and UK datasets were already aligned. In order to avoid overly gappy regions of our alignment we selected only positions 41 to 235 of RT for our analysis. We used the Sierra web service (https://hivdb.stanford.edu/page/webservice/) to get amino acid positions relative to the reference HXB2 HIV genome. This allowed us to determine all the amino acids present at each reference position in both datasets, among which we distinguished the “reference amino acids” for each position, corresponding to the B and C subtype reference sequences obtained from the Los Alamos sequence database (http://www.hiv.lanl.gov/). All the other, non-reference amino acids are named “mutations” in the following, and the set of mutations was explored to reveal new potential RAMs. To train our supervised classification methods [68–70], the sequence data needed to be encoded to numerical vectors. A common and intuitive way to do so is to create a single feature in the dataset for each position of the sequence to encode. Each amino acid is then assigned an integer value, and an amino acid sequence is represented by a succession of integers corresponding to each amino acid. There is, however, one drawback with this method: by assigning an integer value to amino acids, we transform a categorical variable into an ordinal variable. Any ordering of amino acids is hard to justify and might introduce bias. To avoid this, we represented each sequence by a binary vector using one-hot encoding. For each position in the sequence to be encoded, amino acids corresponding to mutations are mapped to a binary vector denoting its presence or absence in the sequence. For example, at site 184, amino acids M, G, I, L, T and V are present in the UK dataset. After encoding we will have 5 binary features corresponding to the M184G, M184I, M184L, M184T and M184V mutations. We did not encode the reference amino acid M, but only the mutated amino acids. With this method each mutation in the dataset (\\(n=1,318\\)) corresponds to a single feature. Some of these features corresponded to known RAMs (e.g., M184I and M184V) and are named (known) RAM features in the following (\\(n=121\\)). This encoding allows the classifiers to consider specific mutations and potentially link them to resistance. 6.2.2 Classifier training In order to find new potential RAMs, we first followed the conventional multiple testing approach [52]. We first used Fisher exact tests to identify which of these mutations were significantly associated with anti-retroviral treatment. All the resulting p-values were then corrected for multiple testing using the Bonferroni correction [71]. Those for which the corrected p-value was \\(≤ 0.05\\) were then considered as significantly associated with treatment and potentially implicated in resistance. This method was complemented by our parallel, machine learning based approach. In order to extract potential RAMs, we trained several classifiers to discriminate between RTI-experienced and RTI-naive sequences represented by the binary vectors described above. This classification task does not need any phenotypic resistance measure, allowing us to use much larger and more readily available datasets than other machine learning based approaches previously mentioned. Once the classifiers were trained, we extracted the most important representation features, which corresponded to potentially resistance-associated mutations (PRAM in short). To this aim we chose three interpretable supervised learning classification methods so as to be able to extract those features: Multinomial naive Bayes (NB), which estimates conditional probabilities of being in the RTI-experienced class given a set of representation features [72]; the higher (\\(\\approx 1.0\\)) and the lower (\\(\\approx0\\)) conditional probabilities correspond to the most important features. Logistic regression (LR) with L1 regularization (LASSO) [68] which assigns weights to each of the features, whose sign denotes the importance to one of the 2 classes, and whose absolute value denotes the weight of this importance. Random Forest (RF) , which has feature importance measures based on the Gini impurity in the decision trees [73]. Interpretability was the main driver behind our classification method choice, with the conditional probabilities of NB, the weight or LR and the importance values of RF, we can easily extract which mutations are driving the discrimination of RT sequences. This is why we did not choose to use ANNs which could have led to an increase in accuracy at the cost of interpretability [74–76]. Moreover, these three classification methods have the potential to detect epistatic effects. With RF, the discrimination is based on the combination of a few features (i.e. mutations), while with LR the features are weighted positively or negatively, thus making it possible to detect cumulative effects resulting from a large number of mutations, which individually have no discrimination power. Naive Bayes is a very simple approach, generally fairly accurate, and in between the two others in terms of explanatory power [70]. In order to be able to compare all these approaches in a common framework, we devised a very simple classifier out of the results of the Fisher exact tests. This \"Fisher classifier\" (FC) predicts a sequence as RTI-experienced if it has at least one of the mutations significantly associated to treatment. In this way, we were able to compute metrics for all classification methods and compare their performance. It is important to note that in all of these approaches we chose to discriminate RTI-naive from RTI-experienced sequences, regardless of the type of RTI received. One of the reasons is that we did not have detailed enough treatment history for sequences in the UK and African datasets. Moreover, even without segmenting by treatment type, the size of the training set and the power of our classification methods were both high enough to be able to detect all kinds of resistance associated mutations. We shall see (Result section) that we were able to determine the likely treatment involved by further examining the important extracted features and comparing them to known RAMs. Furthermore, since the treatment strategies are so different between the UK and African sequences, training on sequences having received different treatments should increase the robustness of our classifiers and the relevance of the mutations selected as potentially associated to resistance. To avoid phylogenetic confounding factors (e.g. transmitted mutations within a specific country or region), and avoid finding mutations potentially specific to a given subtype, we split the training and testing sets by HIV-1 M subtype. This resulted in training a set of classifiers on all subtype B sequences of the UK dataset and testing them on subtype C sequences from the UK dataset, training another set of classifiers on the subtype C sequences of the UK dataset and testing on the subtype B sequences from the UK dataset, as well as training a final set of classifiers on the whole UK dataset, but testing it on the smaller African dataset with a completely different phylogenetic makeup and treatment context [52]. Furthermore, in order to identify novel RAMs and study the behavior of the classifiers, we repeated this training scheme on both datasets, each time removing resistance-associated signal incrementally: first by removing all representation features corresponding to known RAMs from the dataset, and second by removing all sequences that had at least one known RAM. This resulted in each type of classifier being trained and tested 9 times, on radically different sets to ensure the interpretability and robustness of the results (see Table 6.2). .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-545c3b0c{table-layout:auto;width:90%;}.cl-5456ad90{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5456baec{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5456ef58{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5456ef62{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5456ef6c{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}Signal removal levelTrained onTested onNoneUKsubtype B(37806)UKsubtype C(17733)UKsubtype C(17733)UKsubtype B(37806)UKsubtypes B &amp; C(55539)Africaall subtypes(3990)Known RAM features removedUKsubtype B(37806)UKsubtype C(17733)UKsubtype C(17733)UKsubtype B(37806)UKsubtypes B &amp; C(55539)Africaall subtypes(3990)Known RAM features sequences with ≥1 known RAM removedUKsubtype B(24422)UKsubtype C(13055)UKsubtype C(13055)UKsubtype B(24422)UKsubtypes B &amp; C(37477)Africaall subtypes(2284) Table 6.2: All training and testing datasets used during this study. The number of sequences in each dataset is shown in parentheses 6.2.3 Measuring classifier performance To compare the performance of our classifiers we used balanced accuracy [77], which is the average of accuracies (i.e. percentages of well-classified sequences) computed separately on each class of the test set. This score takes into account, and corrects for, the imbalance between RTI-naive and RTI-experienced samples, which would lead to a classifier always predicting a sequence as RTI-naive getting a classical accuracy score of up to 77% (i.e. the frequency of naive sequences in the UK dataset). We also computed the adjusted mutual information (AMI) between predicted and true sequence labels, which is a normalized version of MI allowing comparison of performance on differently sized test sets [78]. Additionally, mutual information (MI) was used to compute p-values and assess the significance of the classifiers’ predictive power. The probabilistic performance of the classifiers was evaluated using an adapted Brier score [69] more suited to binary classification, which is the mean squared difference between the actual class (coded by 1 and 0 for the RTI-experienced and RTI-naive samples respectively) and the predicted probability of being RTI-experienced. This approach refines the standard accuracy measure by rewarding methods that well approximate the true status of the sample (eg. predicting a probability of 0.9 while the true status is 1); conversly, binary methods (predicting 0 or 1, but no probabilities) will be penalized if they are often wrong. The Brier approach thus assigns better scores to methods that recognize their ignorance than to methods producing random predictions. 6.3 Results 6.3.1 Classifier performance &amp; interpretation As can be seen in Fig 6.1A and 6.1B, when all RAM features and sequences were kept in the training and testing sets, classifiers had good prediction accuracy, with the machine learning classifiers slightly outperforming the “Fisher” classifier. When removing RAM features from the training and testing sets, the classifiers retained a significant prediction accuracy, especially with the African data set and its multiple RAMs that are observed in a large number of sequences (but removed in this experiment). In this configuration the ML classifiers had a similar performance to the “Fisher” classifier, except for the random forest that is slightly less accurate, likely due to overfitting. Also, when removing sequences that had known RAMs, every classifier lost all prediction accuracy, and none could distinguish RTI-naive from RTI-experienced sequences. Regarding the Brier sore, we see the advantage of the machine learning classifiers over the “Fisher” classifier, which is worse than random predictions when known RAMs are removed. The ability of machine learning classifiers to quantify the resistance status should be an asset for many applications. Figure 6.1: Classifier Performance on UK and African datasets. NB: naive Bayes, LR: Logistic Regression with Lasso regularization, RF: Random Forest, FC: Fisher Classifier, RD: Agnostic random probabilistic classifier (this classifier predicts, as the probability of a sample belonging to a class, the frequency of that class in the training data). A) Adjusted mutual information (higher is better) between ground truth and predictions by classifiers trained on dataset with all features (blue), without features corresponding to known RAMs (orange) and without RAM features and without sequences that have at least 1 known RAM (green). Hatching indicates the training set on which a classifier was trained and the testing set on which the performance was measured. The expected value for a null classifier is 0, and 1 for a perfect classifier and a * denotes that the p-value derived from mutual information is \\(\\leq 0.05\\). For example when trained with all features all the classifiers have a significative MI. Conversly when removing RAM features and RAM sequences none of the classifiers have a significative MI and only LR trained on the entirety of the UK dataset has an AMI \\(&gt;10^{-3}\\) B) Balanced Accuracy score, i.e. average of accuracies per-class (higher is better) for the same classifiers as in a). The red line at \\(y=0.5\\) is the expected balanced accuracy for a null classifier that only predicts the majority class as well as a random uniform (i.e. 50/50) classifier. C) Brier score, which is the mean squared difference between the sample’s experience to RTI and the predicted probability of being RTI experienced (lower is better), for the same classifiers as in A) and B). The fact that classifiers retained prediction accuracy after removing known RAM corresponding features suggests that there was some residual, unknown resistance-associated signal in the data. The fact that this same power was non-existent when removing the known RAM-containing sequences from the training and testing sets, indicates that this residual signal was contained in these already mutated sequences. This suggests that the mutations that are found in the RAM removed experiment (see list below) are most likely accessory mutations that accompany known RAMs. This also suggests that all primary DRMs (i.e., that directly confer antiretroviral resistance) have been identified, which is reassuring from a public health perspective. The performance discrepancy between the UK and African test sets can be explained by several factors. Firstly, African sequences that have known RAMs are more likely to have multiple RAMs, and thus more (known and unknown) resistance-associated features than their UK counterparts (c.f. Table 6.1). This means that resistant African sequences are easier to detect even when removing known RAMs. Secondly, RTI-naive sequences in the UK test sets are more likely to have known RAMs than their African counterparts (c.f. Table 6.1) and therefore more companion mutations. This means that the RTI-naive sequences in the UK test set are more likely to be misclassified as RTI-experienced than in the African test set. 6.3.2 Additional classification results The fact that, when looking at classifiers trained without known RAMs , “Fisher” classifiers perform as well as the machine learning ones, leads us to believe that there is little interaction between mutations that would explain resistance better than taking each mutation separately. It is therefore likely that the kind of epistatic phenomena we were looking for, combining several mutations that do not induce any resistance when taken separately, do not come into play here. We are in a classical scheme where primary DRMs confer resistance and associated mutations reinforce the strength of the resistance and/or compensate for the fitness cost induced by primary DRMs. It is important to remember that in the previous section we were trying (as usual, e.g. see [52]) to find novel mutations associated with resistance by discriminating RTI-naive from RTI-experienced sequences, both with the statistical tests and the classifiers. However, this is intrinsically biased and noisy. Indeed, a RTI-naive sequence is not necessarily susceptible to RTIs as a resistant strain could have been transmitted to the individual. Conversely, an RTI-experienced sequence may not be resistant to treatment, due to poor ART adherence for example. We must therefore keep in mind that the noisy nature of the relationship between resistance and treatment status is partly responsible for the lower performance of classifiers trained on the UK sequences with reduced signal. Moreover, as all the additional resistance signal we detected is associated to the sequences having at least one known RAM (see above), we performed another analysis trying to discriminate between the sequences having at least one known RAM and those having none. The goal was to check that the mutations we discovered by discriminating RTI-experienced from RTI-naive samples, are truly accessory and compensatory mutations. As can be seen in Fig 6.2A and 6.2B, the classifiers trained to discriminate sequences that have at least one known RAM from those that have none, on datasets from which all features corresponding to known RAMs were removed, perform much better than classifiers trained to discriminate RTI-experienced from RTI-naive sequences. This increase in performance is especially visible for classifiers tested on UK sequences (more difficult to classify than the African ones, see above), with an AMI often almost one order of magnitude higher for the known-RAM presence/absence classification task. This further reinforces our belief that all there is a fairly strong residual resistance-signal in sequences that contain known RAMs, due to new accessory and compensatory mutations identified by our classifiers and Fisher tests. As a side note, Logistic regression (LR) consistently outperforms other classifiers, a tendency already observed in Fig 6.1. Figure 6.2: Discrimination between sequences having at least one RAM, and those having none on sequences with training features corresponding to known RAMs removed. NB: naive Bayes, LR: Logistic Regression with Lasso regularization, RF: Random Forest, FC: Fisher Classifier. A) Adjusted mutual information (higher is better) for classifiers trained without features corresponding to known RAMs. The classifiers are either trained to discriminate RTI-naive from RTI-experienced sequences (blue), or sequences with at least one known RAM from sequences that have none (orange). Hatching and braced annotations indicate the training and testing sets resulting in a given performance measure. B) Balanced accuracy, i.e. average of accuracies per-class for the same classifiers as in A) (higher is better). The red line at \\(y=0.5\\) is the expected value for a classifier only predicting the majority class as well as a random uniform (50/50) classifier. 6.3.3 Identifying new mutations from classifiers We assessed the importance of each mutation in the learned internal model of all the classifiers, in the setting where all known RAMs have been removed from the training dataset. For the Fisher classifier, we used one minus the p-value of the exact Fisher test as the importance value, therefore the more significantly associated mutations have the higher importance value and were ranked first. For a given classification task, we ranked each mutation according to the appropriate importance value for each classifier (see above), trained on the B or C subtypes, with the highest importance value having a rank of 0. We then computed the average rank for each mutation and each classification task (RTI-naive/RTI-experienced and RAM present/RAM absent). This gave us, for each classification task, a ranking of mutations potentially associated with resistance that took into account the importance given to this new mutation by each classifier trained on this task. Mutations that were in the 10 most important mutations for both of the classification tasks were considered of interest. Based on these criteria we selected the following potentially resistance-associated mutations (w.r.t. the HXB2 reference genome): L228R, L228H, E203K, D218E, I135L and H208Y. These mutations are referred to as “new mutations” in the rest of this study. To check the epistatic nature of these selected mutations we computed the relative risk \\(RR(new, X)\\) between a new mutation and a binary character \\(X\\). \\(RR(new,X)\\) was computed from the contingency table between \\(new\\) and \\(X\\) as follows: .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-5a1d3bcc{table-layout:auto;width:40%;}.cl-59ed57b8{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-59ed6604{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-59ed9a34{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59ed9a48{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-59ed9a49{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} nameX presentX absentnew presentABnew absentCD \\[ RR(new,X) = \\frac{A}{A+C} \\div \\frac{B}{B+D} \\] The RR gives us a measure for how over-represented each of our new mutations is in sequences that have the \\(X\\) character compared to those that don’t. To get a general idea of this over-representation, for each new mutation we computed \\(RR(new, treatment)\\) comparing the prevalence of the new mutation in RTI-experienced and RTI-naive sequences. We also computed \\(RR(new, with RAM)\\) comparing the prevalence the new mutation in sequences having at least one known RAM and sequences that have none. Both of these RRs are shown in Table 6.3 for each new mutation. We then computed \\(RR(new, RAM)\\) for each known RAM present in more than 0.1% of UK sequences and the new mutations. In Fig 6.3 we see the RRs for which the lower bound of the 95% confidence interval, computed on 1000 bootstrap samples from the UK dataset, was greater than 4. 6.3.4 Detailed analysis of potentially resistance-associated mutations As can be seen in Table 6.3, all of these new mutations except for I135L, are highly over-represented in RTI-experienced sequences and sequences that already have known RAMs, with lower bounds on the 95% RR CI always greater than 5, and often exceeding 10. When looking at the RRs computed for individual RAMs on the UK dataset (Fig 6.3), this impression is confirmed with very high over-representation of these new mutations potentially associated with resistance in sequences that have a given known RAM, with 95% RR lower CI bounds sometimes greater than 80 (H208Y/L210W and D218E/D67N), and most of the time greater than 10. with the noticeable exception of I135L where only 2 known RAMs give RRs with lower CI bounds greater than 4. The RRs computed on the African dataset (B.1) tell a similar story albeit with smaller RR values due to a smaller number of occurrences of both new mutations and known RAMs. .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-5a3e178e{table-layout:auto;width:90%;}.cl-5a3879fa{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-5a388ea4{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5a388eae{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-5a38ecaa{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a38ecbe{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a38ecbf{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a38ecc0{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a38ecc8{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-5a38ecc9{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}UKAfricasize55,5393,990RTI naïvewith known RAMs11,429(21%)318(8%)without known RAMs30,492(55%)1,998(50%)RTI experiencedwith known RAMs6,633(12%)1,388(35%)without known RAMs6,985(13%)286(7%)sequences with ≥ 2 known RAMs8,034(14%)1,308(33%)max known RAM number1317Median known RAM number13number of subtypes / CRFs224subtypes / CRFsA0(0%)472(12%)B37,806(68%)64(2%)C17,733(32%)702(18%)CRF02 AG0(0%)1,477(37%) Table 6.3: Analysis of new potential RAMs. Codon distance: For each new mutation we computed the minimum number of nucleotide mutations to go from the wild amino acid codons to those of the mutated amino acid, as well as the average codon distance between both amino acids, weighted by the prevalence of each wild and mutated codon at the given position in the UK dataset. B62: BLOSUM62 similarity values (e.g. D218E = 2, reflecting that E and D are both negatively charged and highly similar). Count: We looked at the number of occurrences of each new potential RAM in the UK dataset and the corresponding prevalence in parentheses. Relative risks: We computed \\(RR(new, treatment)\\) (e.g. L228R is 18.1 times more prevalent in RTI-experienced sequences compared to RTI-naive sequences in the UK dataset). We also computed \\(RR(new, any~RAM)\\) (e.g. L228R is 115.7 times more prevalent in sequences that have at least one known RAM than in sequences that have none in the UK dataset). The 95% confidence intervals shown under each RR were computed with 1000 bootstrap samples of size \\(n=55,000\\) drawn with replacement from the whole UK dataset. p-values: Fisher exact tests were done on the African dataset (to avoid confounding effects due to phylogenetic correlation) to see if each of these new mutations were more prevalent in RTI-experienced sequences. The same metrics were computed for all known RAMs, the median values are shown in the last two lines of this table, as well as the 5th and 95th percentiles which are shown underneath. \\(RR(RAM,any~RAM)\\) values were computed for any RAM except itself to avoid always having infinite ratios. Figure 6.3: Relative risk of the new mutations with regards to known RAMs on the UK dataset (i.e. the prevalence of the new mutation in sequences with a given known RAM divided by the prevalence of the new mutation in sequences without this RAM). RRs were only computed for mutations (new and RAMs) that appeared in at least 0.1% (=55) sequences. 95% confidence intervals, represented by vertical bars, were computed with 1000 bootstrap samples of UK sequences. Only RRs with a lower CI boundary greater than 4 are shown. The shape and color of the point represents the type of RAM as defined by Stanford’s HIVDB. Blue circle: NRTI, orange square: NNRTI, green diamond: Other. RR values are shown from left to right, by order of decreasing values on the lower bound of the 95% CI. The genetic barrier to resistance for each of these new mutations is quite low, with a minimum of 1 base change for each of them (Table 6.3 ). We also computed the average codon distance (i.e. number of different bases), weighted by the prevalence of wild and mutated codons at the given positions in the UK (Table 6.3 ) and Africa (Table B.5) datasets, and in each case the average codon distance was always close to 1. In other words, at the amino acid level these mutations are expected to be relatively frequent. However, their frequencies are much higher in treated/with-RAM sequences than in naive/without-RAM ones (Table 6.3 ). Moreover, if we look at the BLOSUM62 scores (Table 6.3 ), some of these mutations induce some substantial changes in physicochemical properties, most notably at site 228, which reinforces again the likelihood that these mutations are associated with resistance. These metrics were also computed for all known RAMs (Table 6.3 ). For all these metrics, and the 6 new potential RAMs, values are contained between the 5th and 95th percentiles computed on known RAMs, except for the BLOSUM score of L228H that corresponds to a drastic physicochemical change. To gain more insight on these new mutations we also observed their spatial location on the 3-D HIV-1 RT structure using PyMol [79]. HIV-1 RT is a heterodimer with two subunits translated from the same sequence with different lengths and 3-D structures. The smaller p51 subunit (440 AAs) has a mainly structural role, while the larger p66 (560 AAs) subunit has the active site at positions 110, 185 and 186. The p66 subunit also has a regulatory pocket behind the active site: the non-nucleoside inhibitor binding pocket (NNIBP) formed of several sites of the p66 subunit as well as site 138 of the p51 subunit. Nucleoside RT Inhibitors (NRTI) are nucleotide analogs and bind in the active site, blocking reverse transcription. Non-Nucleoside RT Inhibitors (NNRTI) bind in the NNIBP, changing the protein conformation and blocking reverse transcription. More details on the structure and function of HIV-1 RT can be found in [80]. A general view of where the new mutations are situated with regards to the other important sites of HIV-1 RT is shown in Fig 6.4, and is detailed below. Figure 6.4: Structure of HIV-1 RT with highlighted important sites. The p66 subunit is colored dark gray and the p51 subunit white. The active site is highlighted in blue, and the NNIBP is highlighted in yellow. The sites of new mutations are colored in red. 6.3.4.1 L228R / L228H L228R is the most important of these new mutations according to the feature importance ranking done above. This is reflected in the very high over-representation in RTI-experienced sequences and sequences with known RAMs shown in Table 6.3 . When looking at the detailed RRs shown in Fig 6.3, we observe that L228R presents high RR values with mainly NRTI RAMs, but also with NNRTI RAMs such as Y181C and L100I, and this is even more so h for RRs computed on the African dataset (B.1). L228H is very similar in all regards to L228R, however its highest RRs are exclusively with NRTI RAMs. Site 228 of the p66 subunit is located very close to the active site of RT, where NRTIs operate (Figs 6.4 and B.3) which could explain the role that L228R and L228H seem to have in NRTI resistance. However, site 228 of the p66 subunit is also between sites 227 and 229 which are both part of the NNIBP. Furthermore, both L228H and L228R have very low BLOSUM62 score, of -3 and -2 respectively (Table 6.3 ). Arginine (R) and Histidine (H) are both less hydrophobic that Leucine (L), and have positively charged side-chains. This important change in physicochemical properties could explain the role they both seem to have in NRTI resistance. However, while both Arginine and Histidine are larger than Leucine, Arginine is also fairly larger than Histidine, which is aromatic. This difference between both residues might explain the association L228R seems to have with NNRTI resistance that L228H does not have. 6.3.4.2 E203K / H208Y Both E203K and H208Y are highly over-represented in RTI-experienced sequences and sequences with known RAMs. They both have high RR values for NRTI RAMs. Furthermore the most highly valued RAM RRs in Fig 6.3, are very similar for E203K and H208Y. Structurally they are close to each other on an alpha helix which is close to the active site. Both E203K and H208Y have positive, albeit not maximal, BLOSUM62 scores, meaning they are fairly common substitutions. However, these mutations induce some change in physicochemical properties with Tyrosine (Y) being less polar than Histidine (H), and the change from Glutamic Acid (E) to Lysine (K) corresponding to a change from a negatively charged side chain to a positively charged one. All this, combined with their structural proximity and the shared high RR values for single RAMs, suggests a similar role in NRTI resistance. 6.3.4.3 I135L In Table 6.3 and Fig 6.3, we observe that I135L has the lowest RR values of all the new mutations, with CI bounds lower than 2 in Table 6.3’s general RRs. However, it is the most prevalent of the new mutations. If we look at the detailed RRs of Fig 6.3, we see that I135L is significantly over-represented in sequences with NNRTI RAMs, specifically A98G and P225H. Structurally this makes sense: On the p66 subunit, site 135 is on the outside, far from both the active site and the NNIBP. However, site 135 on the p51 subunit is located very close to the NNIBP (Figs 6.3 and B.2). The BLOSUM62 score for this substitution is quite high (Table 6.3), which is expected since both residues are very similar to one another, differing only by the positioning of one methyl group. However, Leucine (L) is less hydrophobic than Isoleucine (I), despite they are still both classified as hydrophobic residues (Table B.5). The proximity between site 135 and the pocket in which NNRTI RAMs bind, as well as the high RR values for these NNRTI RAMs leads us to believe that I135L could play a subtle accessory role in NNRTI resistance, either by enhancing the effect of some NNRTI RAMs (typically, A98G and P225H), or by compensating for loss of fitness. 6.3.4.4 D218E D218E is also highly over-represented in both RTI-experienced sequences and sequences with known RAMs. It has infinite RR values in the African dataset (Table 6.3), because it is quite rare in this dataset, and all of its 25 occurrences are in sequences that have at least one known RAM and are RTI-experienced. In fact, from the UK dataset we can see that D218E has some of the highest RR values for individual RAMs (along with H208Y). The majority of these very high RR values occur for NRTI RAMs. Site 218 on the p66 subunit is quite close to the RT active site, which could explain the role D218E seems to have in NRTI resistance. Aspartic acid (D) and Glutamic acid (E) are very similar amino acids, both acidic with negatively charged side-chains, as reflected in their fairly high BLOSUM62 score, the main difference between both being molecular weight, with E being slightly larger than D. 6.4 Discussion and perspectives Our method has allowed us to identify six mutations that might play a role in drug resistance in HIV. These mutations are significantly over-represented in RTI-experienced sequences, as well as sequences exhibiting at least one other known RAM. The fact that models trained on the UK are still performant on such a different dataset as the African one strongly suggests that the learned classifier models have acquired generalized knowledge on resistance. For all of these new mutations their spatial positioning on HIV-1 RT is consistent with our conclusions, as all were either close to the active site or the regulatory binding pocket. Some of the mutations we have identified as potentially associated with resistance have been mentioned in previous studies. L228R/H have been observed before [81] and were suggested to be associated with reduced susceptibility to didanosine [82,83]. I135L has been observed in sequences with reduced susceptibility to NNRTIs [84]. H208Y has been associated with NNRTI and NRTI resistance [85] and it has been suggested that it has an accessory role in NRTI resistance [86]. E203K, D218E, L228RH and H208Y have all been mentioned in [87] as probably linked to phenotypic resistance to NRTI and NNRTI. However, none of these mutations has been experimentally confirmed as conferring or helping with drug resistance to the best of our knowledge. The fact that we find them again with a big data analysis of highly different sequences and involved statistical selection procedure combining multiple testing and machine learning, and that we have very high significance, clearly indicates their potential role in resistance. Therefore, we believe they are sufficiently linked to drug resistance that they garner a closer inspection either in-vitro or in-vivo to determine the mechanisms that could allow them to play a role in resistance. With our machine classifiers we seem to have found some RAMs of an accessory nature, over-represented in sequences already containing known RAMs. This is a form of epistasis, where the interaction between the main RAM and the accessory RAM is important. However, we did not manage to find subtler forms of epistasis, in our dataset, where two mutations separately have no effect on resistance but have an effect together. This is partly indicated by the fact that there is a limited performance gap between the Fisher exact tests and more sophisticated classifiers, that are able to reveal significant association of mutations, while each individual mutation has low prediction power. However, one advantage of machine learning classifiers, is that they are probabilistic, meaning that they can give more nuanced insights into the nature or resistance level of a given sequence than the classical binary presence/absence of RAMs approach. In this regard logistic regression appears as a method of choice, showing similar or better performance than other classifiers, and an easy interpretation that is facilitated by the lasso regularization which performs a simple feature selection and retains the most important ones. Similar results were already observed on other sequence analysis tasks [88]. In order to investigate the second form of epistasis further we tested each pair of mutations in the UK dataset (\\(n=867,903\\)) with Fisher exact tests to see if they were linked to treatment status. In order to mitigate the effects of phylogenetic correlation which are sure to have an effect in this type of setting, we tested the pairs that were significantly associated to treatment (\\(n=1,309\\)) again on the African dataset. We also compared these results to the Fisher exact tests executed for each single mutation. We did not find any pair of mutations that was significantly associated, to treatment where neither member were significantly associated individually. Moreover, we only found 3 significantly associated pairs of mutations that did not include at least one known RAM, and they all included one of our newly found potential RAM: L228R + I142V, L228R + F214L and L228H + F214L (see appendix B.6 for details). With therapeutic strategies targeting multiple proteins that are now used, there might be some epistatic effects with other regions of the HIV genome that are targeted by some of the drugs. These potential effects however, lie outside the scope of this study. Because of the lack of detailed treatment history metadata, we did not distinguish mutations arising from NRTIs or NNRTIs. We believe that a large amount of high quality sequence data, along with a sufficiently detailed log of treatments and drugs the sequences were exposed to, could allow us to use our machine-learning approach to find mutations related to specific drugs and thus furthering our knowledge of HIV drug resistance, giving clinicians more tools to manage and help infected patients. Acknowledgments We thank Anna Zhukova, Frédéric Lemoine and Marie Morel for their help and suggestions. We also thank the UK HIV Drug Resistance Database and the UK Collaborative HIV Cohort: Steering committee: David Asboe, Anton Pozniak (Chelsea &amp; Westminster Hospital, London); Patricia Cane (Public Health England, Porton Down); David Chadwick (South Tees Hospitals NHS Trust, Middlesbrough); Duncan Churchill (Brighton and Sussex University Hospitals NHS Trust); Simon Collins (HIV i-Base, London); Valerie Delpech (National Infection Service, Public Health England); Samuel Douthwaite (Guy’s and St. Thomas’ NHS Foundation Trust, London); David Dunn, Kholoud Porter, Anna Tostevin, Oliver Stirrup (Institute for Global Health, UCL); Christophe Fraser (University of Oxford); Anna Maria Geretti (Institute of Infection and Global Health, University of Liverpool); Rory Gunson (Gartnavel General Hospital, Glasgow); Antony Hale (Leeds Teaching Hospitals NHS Trust); Stéphane Hué (London School of Hygiene and Tropical Medicine); Michael Kidd (Public Health England, Birmingham Heartlands Hospital); Linda Lazarus (Expert Advisory Group on AIDS Secretariat, Public Health England); Andrew Leigh-Brown (University of Edinburgh); Tamyo Mbisa (National Infection Service, Public Health England); Nicola Mackie (Imperial NHS Trust, London); Chloe Orkin (Barts Health NHS Trust, London); Eleni Nastouli, Deenan Pillay, Andrew Phillips, Caroline Sabin (University College London, London); Kate Templeton (Royal Infirmary of Edinburgh); Peter Tilston (Manchester Royal Infirmary); Erik Volz (Imperial College London, London); Ian Williams (Mortimer Market Centre, London); Hongyi Zhang (Addenbrooke’s Hospital, Cambridge). Coordinating Center: Institute for Global Health, UCL (David Dunn, Keith Fairbrother, Anna Tostevin, Oliver Stirrup) Centers contributing data: Clinical Microbiology and Public Health Laboratory, Addenbrooke’s Hospital, Cambridge (Justine Dawkins); Guy’s and St Thomas’ NHS Foundation Trust, London (Emma Cunningham, Jane Mullen); PHE – Public Health Laboratory, Birmingham Heartlands Hospital, Birmingham (Michael Kidd); Antiviral Unit, National Infection Service, Public Health England, London (Tamyo Mbisa); Imperial College Health NHS Trust, London (Alison Cox); King’s College Hospital, London (Richard Tandy); Medical Microbiology Laboratory, Leeds Teaching Hospitals NHS Trust (Tracy Fawcett); Specialist Virology Centre, Liverpool (Elaine O’Toole); Department of Clinical Virology, Manchester Royal Infirmary, Manchester (Peter Tilston); Department of Virology, Royal Free Hospital, London (Clare Booth, Ana Garcia-Diaz); Edinburgh Specialist Virology Centre, Royal Infirmary of Edinburgh (Lynne Renwick); Department of Infection &amp; Tropical Medicine, Royal Victoria Infirmary, Newcastle (Matthias L Schmid, Brendan Payne); South Tees Hospitals NHS Trust, Middlesbrough (David Chadwick); Department of Virology, Barts Health NHS Trust, London (Mark Hopkins); Molecular Diagnostic Unit, Imperial College, London (Simon Dustan); University College London Hospitals (Stuart Kirk); West of Scotland Specialist Virology Laboratory, Gartnavel, Glasgow (Rory Gunson, Amanda Bradley-Stewart). Supporting Information Supporting Information can be found in the appendix B References "],["learning-alignments-an-interesting-perspective.html", "Chapter 7 Learning alignments, an interesting perspective 7.1 Learning pairwise alignment 7.2 What else could we learn ?", " Chapter 7 Learning alignments, an interesting perspective 7.1 Learning pairwise alignment 7.1.1 Transformers and deep embedding 7.1.2 DEDAL 7.1.3 predicting an alignment 7.2 What else could we learn ? 7.2.1 Learn to predict seeds or starting positions 7.2.2 Learn pre-processing functions i.e. either connections in MSR graph or sequence 2 sequence models "],["global-references.html", "Global References", " Global References "],["HPC-appendix.html", "A Supporting Information for “Mapping-friendly sequence reductions: going beyond homopolymer compression” A.1 “TandemTools” dataset generation A.2 MSR performance comparison A.3 Origin of incorrectly mapped reads of high mapping quality on whole human genome. A.4 Analyzing read origin on whole human genome A.5 Performance of MSRs on the Drosophila genome", " A Supporting Information for “Mapping-friendly sequence reductions: going beyond homopolymer compression” A.1 “TandemTools” dataset generation This dataset was obtained by taking a human X chromosome HOR sequence, concatenating it 500 times with added mutations in order to obtain an approximately 1 Mbp long sequence. Then 1200 reads were simulated from the sequence using nanosim [37] and assembled using a centromere-tailored pipeline [89]. A 10kbp deletion was then added to this assembly. The resulting sequence is the one we refer to as the “Centromeric sequence”. A.2 MSR performance comparison .tabwid table{ border-spacing:0px !important; border-collapse:collapse; line-height:1; margin-left:auto; margin-right:auto; border-width: 0; display: table; margin-top: 1.275em; margin-bottom: 1.275em; border-color: transparent; } .tabwid_left table{ margin-left:0; } .tabwid_right table{ margin-right:0; } .tabwid td { padding: 0; } .tabwid a { text-decoration: none; } .tabwid thead { background-color: transparent; } .tabwid tfoot { background-color: transparent; } .tabwid table tr { background-color: transparent; } .cl-afc67524{table-layout:auto;width:100%;}.cl-afbdc1c2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-afbdc1cc{font-family:'Helvetica';font-size:6.6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;top:3.3pt;}.cl-afbdc1e0{font-family:'Helvetica';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-afbddac2{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-afbddad6{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-afbe1ffa{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe200e{background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe200f{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe2018{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe2019{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe2022{background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe2023{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe202c{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-afbe202d{background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}labelmapqWhole human genome (minimap2)Whole human genome (winnowmap2)Whole Drosophila genome (minimap2)fractionerrorfractionerrorfractionerrorHPC600.935 +0%1.85e-03 +0%0.894 +0%1.43e-03 +0%0.957 +0%2.27e-03 +0%raw600.921 -1%1.86e-03 +0%0.932 +4%1.75e-03 +23%0.958 +0%2.27e-03 -0%MSRF500.938 +0%1.29e-03 -30%0.886 -1%3.82e-04 -73%0.960 +0%1.37e-03 -39%MSRE500.936 +0%1.17e-04 -94%0.820 -8%8.93e-05 -94%0.954 -0%0 -100%MSRP500.938 0%4.15e-04 -78%0.845 -6%1.14e-04 -92%0.957 +0%8.11e-04 -64% Table A.1: Comparing performance of MSRs on the whole human genome, whole Drosophila melanogaster genome, repeated regions of the whole human genome and synthetic centromeric sequence. Results using minimap2 [25] and winnowmap2 [38]. The number of simulated reads for each reference sequence is given in parentheses and called \\(n\\). Results are reported for mapq thresholds of 60, 50 and 0. The best performance for each category is highlighted in bold. The percentage difference are computed w.r.t HPC at each given threshold. A.3 Origin of incorrectly mapped reads of high mapping quality on whole human genome. Figure A.1: Histogram of the original simulated positions for the incorrectly mapped reads using minimap2 at high mapping qualities across the whole human genome, for several transformation methods. For a given chromosome, each row represents the number of simulated reads starting at that particular region. The dark gray rectangle represents the position of the centromere for that chromosome, obtained from annotations provided by the T2T consortium (http://t2t.gi.ucsc.edu/chm13/hub/t2t-chm13-v1.1/). Similarly for chromosomes 13, 14, 15, 21 and 22, a lighter gray rectangle represents the position of the “stalk” satellites also containing repetitive regions. For HPC and raw reads only alignments of mapping quality 60 were considered. To provide a fair comparison, alignments with mapping qualities \\(\\geq 50\\) were considered for MSRs E, F and P. A.4 Analyzing read origin on whole human genome Figure A.2: Origin of correctly (teal) and incorrectly (red) mapped raw reads Distribution of the origin of correctly and incorrectly mapped simulated reads (in teal and red respectively) on the different chromosomes of the whole human genome. The dark grey rectangle for each chromosome represents the centromere of that chromosome. The lighter gray rectangle on chromosomes 13, 14, 15, 21 and 22 correspond to satellites denoted as “stalk”, another repetitive region. Figure A.3: Origin of correctly (teal) and incorrectly (red) mapped reads, transformed with HPC Distribution of the origin of correctly and incorrectly mapped simulated reads (in teal and red respectively) on the different chromosomes of the whole human genome. The dark grey rectangle for each chromosome represents the centromere of that chromosome. The lighter gray rectangle on chromosomes 13, 14, 15, 21 and 22 correspond to satellites denoted as “stalk”, another repetitive region. Figure A.4: Origin of correctly (teal) and incorrectly (red) mapped reads, transformed with MSRE Distribution of the origin of correctly and incorrectly mapped simulated reads (in teal and red respectively) on the different chromosomes of the whole human genome. The dark grey rectangle for each chromosome represents the centromere of that chromosome. The lighter gray rectangle on chromosomes 13, 14, 15, 21 and 22 correspond to satellites denoted as “stalk”, another repetitive region. Figure A.5: Origin of correctly (teal) and incorrectly (red) mapped reads, transformed with MSRP Distribution of the origin of correctly and incorrectly mapped simulated reads (in teal and red respectively) on the different chromosomes of the whole human genome. The dark grey rectangle for each chromosome represents the centromere of that chromosome. The lighter gray rectangle on chromosomes 13, 14, 15, 21 and 22 correspond to satellites denoted as “stalk”, another repetitive region. Figure A.6: Origin of correctly (teal) and incorrectly (red) mapped reads, transformed with MSRF Distribution of the origin of correctly and incorrectly mapped simulated reads (in teal and red respectively) on the different chromosomes of the whole human genome. The dark grey rectangle for each chromosome represents the centromere of that chromosome. The lighter gray rectangle on chromosomes 13, 14, 15, 21 and 22 correspond to satellites denoted as “stalk”, another repetitive region. A.5 Performance of MSRs on the Drosophila genome Figure A.7: Results of the paftools mapeval evaluation on reads simulated and mapped to whole Drosophila melanogaster and Escherichia coli genomes MSRs E, F and P are shown in different shades of blue to differentiate them from other MSRs. Reads were simulated with nanosim, and mapped with minimap2. The E. coli genome was obtained from Genbank ID U00096.2 References "],["HIV-appendix.html", "B Supporting Information for “Using Machine Learning and Big Data to Explore the Drug Resistance Landscape in HIV” B.1 S1 Appendix (Technical appendix). B.2 S1 Fig. B.3 S2 Fig. B.4 S3 Fig. B.5 S1 Table. B.6 S2 Appendix. (Fisher exact tests) B.7 S1 Data. B.8 S2 Data.", " B Supporting Information for “Using Machine Learning and Big Data to Explore the Drug Resistance Landscape in HIV” B.1 S1 Appendix (Technical appendix). B.1.1 Data B.1.1.1 Data Availability The policy of the UK HIV Drug Resistance Database is to make DNA sequences available to any bona fide researcher who submits a scientifically robust proposal, provided data exchange complies with Information Governance and Data Security Policies in all the relevant countries. This includes replication of findings from published studies, although the researcher would be encouraged to work with the main author of the published paper to understand the nuances of the data. Enquiries should be addressed to iph.hivrdb@ucl.ac.uk in the first instance. More information on the UK dataset is also available on the UK CHIC homepage: www.ukchic.org.uk. Amino acid sequences are made available along with a metadata file. The West and central African dataset is available as supplementary information along with a metadata file containing HIV subtype, treatment information and known RAM presence/absence for each sequence. Predictions made for each sequence of both datasets, by all of the trained classifiers are made available as part of the supplementary data as well as synthetic results from which the figures of the paper were drawn. The importance values for each mutation and each trained classifier are also made available. All the data and metadata files made available are hosted in the online repository linked to this project at the following URL: github.com/lucblassel/HIV-DRM-machine-learning/tree/main/data B.1.1.2 Data Preprocessing For both the African and UK datasets, the sequences were truncated to keep sites 41 to 235 of the RT protein sequence before encoding. This truncation was needed to avoid the perturbation to classifier training due to long gappy regions at the beginning and end of the UK RT alignment caused by shorter sequences. These positions were determined with the Gblocks software [90] with default parameters, except for the Maximum number of sequences for a flanking position, set to 50,000, and the Allowed gap positions, which was set to \"All\". The encoding was done with the OneHotEncoder from the category-encoders python module [91]. B.1.2 Classifiers We used classifier implementations from the scikit-learn python library [92], RandomForestClassifier for the random forest classifier, MultinomialNB for Naïve Bayes and LogisticRegressionCV for logistic regression. RandomForestClassifier was used with default parameters except: \"n_jobs\"=4 \"n_estimators\"=5000 LogisticRegressionCV was used with the following parameters: \"n_jobs\"=4 \"cv\"=10 \"Cs\"=100 \"penalty\"=’l1’ \"multi_class\"=’multinomial’ \"solver\"=’saga’ \"scoring\"=’balanced_accuracy’ MultinomialNB was used with default parameters. For the Fisher exact tests, we used the implementation from the scipy python library [93], and corrected p-values for multiple testing with the statsmodels python library [94] using the \"Bonferroni\" method. B.1.3 Scoring To evaluate classifier performance several measures were used. We computed balanced accuracy instead of classical accuracy, because it can be overly optimistic, especially when assessing a highly biased classifier on an unbalanced test set [77].The balanced accuracy is computed using the following formula, where \\(TP\\) and \\(TN\\) are the number of true positives and true negatives respectively, and \\(FP\\) and \\(FN\\) are the number of false positives and false negatives respectively: \\[ balanced~accuracy = \\frac{1}{2}\\left( \\frac{TP}{TP + FP} + \\frac{TN}{TN + FN} \\right) \\] We also computed adjusted mutual information (AMI). We chose it over mutual information (MI) because it has an upper bound of 1 for a perfect classifier and is not dependent on the size of the test set, allowing us to compare the performance for differently sized test sets [78]. The adjusted mutual information of variables \\(U\\) and \\(V\\) is defined by the following formula, where \\(MI(U,V)\\) is the mutual information between variables \\(U\\) and \\(V\\), \\(H(X)\\) is the entropy of the variable \\(X\\) (= \\(U\\) or \\(V\\)) and \\(E\\{MI(U,V)\\}\\) is the expected MI, as explained in [95]. \\[ AMI(U,V) = \\frac{ MI(U,V) - E\\{MI(U,V)\\} }{ \\frac{1}{2}[H(U) + H(V)] - E\\{MI(U,V)\\} } \\] MI was used to compute the \\(G\\) statistic, which follows the chi-square distribution under the null hypothesis [96]. This was used to compute p-values for each of our classifiers and assess the significance of their performance. \\(G\\) is defined by equation below, where \\(N\\) is the number of samples. \\[G = 2\\cdot N \\cdot MI(U,V)\\] Finally, to check the probabilistic predictive power of the classifiers we also computed the Brier score which is the mean squared difference between the ground truth and the predicted probability of being of the positive class for every sequence in the test set (therefore lower is better for this metric). The Brier score is defined in equation below, where \\(p_t\\) is the predicted probability of being of the positive class for sample \\(t\\) and \\(o_t\\) is the actual class (0 or 1, 1=positive class) of sample \\(t\\): \\[Brier~score=\\frac{1}{N}\\sum_{t=1}^N(p_t-o_t)^2\\] We used the following implementations from the scikit-learn python library [92] with default options: balanced_accuracy_score mutual_info_score adjusted_mutual_info_score brier_score_loss We used the relative risk to observe the relationship between one of our new mutations and a binary character \\(X\\) such as treatment status or presence/absence of a known RAM. \\[ \\begin{aligned} RR(new, X) &amp;= \\frac{prevalence\\left(new~mutation\\mid X=1\\right)}{prevalence\\left(new~mutation\\mid X=0\\right)} \\nonumber\\\\ \\nonumber\\\\ &amp;= \\frac{|(new=1)\\cap(X=1)|}{|(X=1)|}\\div\\frac{|(new=1)\\cap(X=0)|}{|(X=0)|} \\\\ \\end{aligned} \\] B.2 S1 Fig. Figure B.1: Relative risks of the new mutations with regards to known RAMs on the African dataset (i.e. the prevalence of the new mutation in sequences with a given RAM divided by the prevalence of the new mutation in sequences without the RAM). RRs were only computed for mutations (new and RAMs) that appeared in at least 30 sequences, which is why RRs were not computed for H208Y and D218E. 95% confidence intervals, represented by vertical bars, were computed with 1000 bootstrap samples of the African sequences. Only RRs with a lower CI boundary greater than 2 are shown. The shape and color of the point represents the type of RAM as defined by Stanford’s HIVDB. Blue circle: NRTI, orange square: NNRTI, green diamond: Other. For the RR of L228H with regards to M184V, the upper CI bound is infinite. The new RAMs have high RR values for known RAMs similar to those obtained on the UK dataset. We also arrive at similar conclusions, I135L being associated with NNRTIs, E203K and L228H to NRTI and L228R to both. RR values are shown from left to right, by order of decreasing values on the lower bound of the 95% CI. B.3 S2 Fig. Figure B.2: Closeup structural view of the entrance of the NNIBP of HIV-1 RT The p66 subunit is colored in dark gray, the p51 subunit in light gray. The NNIBP is highlighted in yellow. The active site is colored in blue. We can see the physical proximity of I135 (red) to the entrance of the NNIBP. We can also see how L228 (red) is between 2 AAs of the NNIBP. B.4 S3 Fig. Figure B.3: Closeup structural view of the active site of HIV-1 RT. The p66 subunit is colored in dark gray, the p51 subunit in light gray. The active site is highlighted in blue. The NNIBP is colored in yellow. L228, E203 and D218 (red) are also very close on either side of the active site. B.5 S1 Table. Detailed table of “new mutation” characteristics. B.6 S2 Appendix. (Fisher exact tests) Fisher exact tests on pairs of mutations. A detailed explanation of the procedure followed to test pairs of mutations for association with treatment. Detailed numerical results are also given. In order to study epistasis further we conducted conducted Fisher exact tests between every pair of mutations in the UK dataset (\\(n=867,903\\)) and the treatment status, corrected the p-values with the Bonferroni method with an overall risk level \\(\\alpha=0.05\\). Out of these tests, \\(1,309\\) pairs were significantly associated with treatment status. \\(424\\) out of \\(1,309\\) these pairs were two known RAMs, \\(806\\) of these pairs contained one known RAM and only \\(79\\) tests had pairs involving no known RAM at all. Furthermore out of these \\(1,309\\) significantly associated pairs, \\(829\\) contained two mutations that were significantly associated to treatment when testing mutations one by one. In \\(478\\) pairs, one of the two mutations is associated to treatment on its own, and the remaining 2 pairs, none of the mutations were significantly associated with treatment on their own. These 2 pairs were K103R + V179D and T165I + K173Q. The first pair, is a pair of known RAMs and this interaction is characterized in the HIVDb database (https://hivdb.stanford.edu/dr-summary/comments/NNRTI/). The second pair is made up of new mutations, and the corrected p-value is \\(0.02\\). In the Standford HIVDB, T165I has been associated to a reduction in EFV susceptibility. Out of the \\(1,309\\) pairs significantly associated to treatment, \\(151\\) contained at least one of our 6 new potential RAMs, in \\(6\\) cases the pair was made up of 2 of them. In the UK dataset, phylogenetic correlation is likely very impactful with regards to these tests. Indeed, the sequences are far from being independent. In order to alleviate this effect we decided to test the sigficative pairs again on the African dataset, and once more correct with the Bonferroni procedure. Out of the \\(1,309\\) tests \\(294\\) have significative p-values after correction. Out of these \\(221\\) pairs were composed of 2 mutations individually significatively associated with treatment. The remaining \\(73\\) pairs had one mutation significantly associated with treatment. Out of the \\(221\\) significative tests, 156 pairs were composed of 2 known RAMS while \\(135\\) had one known RAM in the pair. The remaining 3 pairs that do not contain a known RAM all contained either L228R or L228H which are both part of our 6 potential RAMS. B.7 S1 Data. Archive of figure generating data. A zip archive containing the processed data used to generate each panel of the main figures. Download data B.8 S2 Data. List of known DRMs. A .csv file containing all the known RAMs used in this project as well as the corresponding feature name in the encoded datasets. Obtained from (hivdb.stanford.edu/dr-summary/comments/NRTI/) and (hivdb.stanford.edu/dr-summary/comments/NNRTI/). Download data References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
