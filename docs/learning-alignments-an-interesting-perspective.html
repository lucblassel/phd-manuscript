<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Learning alignments, an interesting perspective | From sequences to knowledge, improving and learning from sequence alignments</title>
  <meta name="description" content="Chapter 7 Learning alignments, an interesting perspective | From sequences to knowledge, improving and learning from sequence alignments" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Learning alignments, an interesting perspective | From sequences to knowledge, improving and learning from sequence alignments" />
  <meta property="og:type" content="book" />
  
  
  <meta name="github-repo" content="lucblassel/phd-manuscript" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Learning alignments, an interesting perspective | From sequences to knowledge, improving and learning from sequence alignments" />
  
  
  

<meta name="author" content="Luc Blassel" />


<meta name="date" content="2022-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="HIV-paper.html"/>
<link rel="next" href="global-conclusion.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.0.0/tabwid.css" rel="stylesheet" />
<link href="libs/tabwid-1.0.0/scrool.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">From sequences to knowledge,</br> improving and learning from sequence alignments.</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#résumé"><i class="fa fa-check"></i>Résumé</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="list-of-acronyms-and-abbreviations.html"><a href="list-of-acronyms-and-abbreviations.html"><i class="fa fa-check"></i>List of Acronyms and abbreviations</a></li>
<li class="chapter" data-level="" data-path="general-introduction.html"><a href="general-introduction.html"><i class="fa fa-check"></i>General Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="general-introduction.html"><a href="general-introduction.html#organization-of-this-manuscript"><i class="fa fa-check"></i>Organization of this manuscript</a></li>
<li class="chapter" data-level="" data-path="general-introduction.html"><a href="general-introduction.html#research-output"><i class="fa fa-check"></i>Research output</a>
<ul>
<li class="chapter" data-level="" data-path="general-introduction.html"><a href="general-introduction.html#journal-publications"><i class="fa fa-check"></i>Journal publications</a></li>
<li class="chapter" data-level="" data-path="general-introduction.html"><a href="general-introduction.html#presentations-and-posters"><i class="fa fa-check"></i>Presentations and posters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html"><i class="fa fa-check"></i><b>1</b> What is Sequence data ?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#biological-sequences-a-primer"><i class="fa fa-check"></i><b>1.1</b> Biological sequences, a primer</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#what-is-dna"><i class="fa fa-check"></i><b>1.1.1</b> What is DNA ?</a></li>
<li class="chapter" data-level="1.1.2" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#from-information-to-action"><i class="fa fa-check"></i><b>1.1.2</b> From Information to action</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#obtaining-sequence-data"><i class="fa fa-check"></i><b>1.2</b> Obtaining sequence data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#sanger-sequencing-a-breakthrough"><i class="fa fa-check"></i><b>1.2.1</b> Sanger sequencing, a breakthrough</a></li>
<li class="chapter" data-level="1.2.2" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#next-generation-sequencing"><i class="fa fa-check"></i><b>1.2.2</b> Next-generation sequencing</a></li>
<li class="chapter" data-level="1.2.3" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#long-read-sequencing"><i class="fa fa-check"></i><b>1.2.3</b> Long read sequencing</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#sequencing-errors-how-to-account-for-them"><i class="fa fa-check"></i><b>1.3</b> Sequencing errors, how to account for them ?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#error-correction-methods"><i class="fa fa-check"></i><b>1.3.1</b> Error correction methods</a></li>
<li class="chapter" data-level="1.3.2" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#more-accurate-sequencing-methods"><i class="fa fa-check"></i><b>1.3.2</b> More accurate sequencing methods</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#the-special-case-of-homopolymers"><i class="fa fa-check"></i><b>1.4</b> The special case of homopolymers</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#homopolymers-and-the-human-genome"><i class="fa fa-check"></i><b>1.4.1</b> Homopolymers and the human genome</a></li>
<li class="chapter" data-level="1.4.2" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#homopolymers-and-long-reads"><i class="fa fa-check"></i><b>1.4.2</b> Homopolymers and long reads</a></li>
<li class="chapter" data-level="1.4.3" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#accounting-for-homopolymers"><i class="fa fa-check"></i><b>1.4.3</b> Accounting for homopolymers</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="what-is-sequence-data.html"><a href="what-is-sequence-data.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html"><i class="fa fa-check"></i><b>2</b> Aligning sequence data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#what-is-an-alignment"><i class="fa fa-check"></i><b>2.1</b> What is an alignment ?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#why-align"><i class="fa fa-check"></i><b>2.1.1</b> Why align ?</a></li>
<li class="chapter" data-level="2.1.2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#how-to-align-two-sequences"><i class="fa fa-check"></i><b>2.1.2</b> How to align two sequences ?</a></li>
<li class="chapter" data-level="2.1.3" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#scoring-and-substitution-models"><i class="fa fa-check"></i><b>2.1.3</b> Scoring and substitution models</a></li>
<li class="chapter" data-level="2.1.4" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#dealing-with-gaps"><i class="fa fa-check"></i><b>2.1.4</b> Dealing with gaps</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#how-do-we-speed-up-pairwise-alignment"><i class="fa fa-check"></i><b>2.2</b> How do we speed up pairwise alignment ?</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#changing-the-method"><i class="fa fa-check"></i><b>2.2.1</b> Changing the method</a></li>
<li class="chapter" data-level="2.2.2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#seed-and-extend-with-data-structures"><i class="fa fa-check"></i><b>2.2.2</b> Seed and extend with data structures</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#the-specificities-of-read-mapping"><i class="fa fa-check"></i><b>2.3</b> The specificities of read-mapping</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#what-is-read-mapping"><i class="fa fa-check"></i><b>2.3.1</b> What is read-mapping ?</a></li>
<li class="chapter" data-level="2.3.2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#challenges-of-read-mapping"><i class="fa fa-check"></i><b>2.3.2</b> Challenges of read-mapping</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#multiple-sequence-alignment"><i class="fa fa-check"></i><b>2.4</b> Multiple sequence alignment</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#progressive-alignment"><i class="fa fa-check"></i><b>2.4.1</b> Progressive alignment</a></li>
<li class="chapter" data-level="2.4.2" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#other-methods"><i class="fa fa-check"></i><b>2.4.2</b> Other methods</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="aligning-sequence-data.html"><a href="aligning-sequence-data.html#conclusion-1"><i class="fa fa-check"></i><b>2.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="HPC-paper.html"><a href="HPC-paper.html"><i class="fa fa-check"></i><b>3</b> Contribution 1: Improving read alignment by exploring a sequence transformation space</a>
<ul>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#highlights"><i class="fa fa-check"></i>Highlights</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#graphical-abstract"><i class="fa fa-check"></i>Graphical Abstract</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#hpc-abstract"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="3.1" data-path="HPC-paper.html"><a href="HPC-paper.html#hpc-introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="HPC-paper.html"><a href="HPC-paper.html#methods"><i class="fa fa-check"></i><b>3.2</b> Methods</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="HPC-paper.html"><a href="HPC-paper.html#sec:msr-def"><i class="fa fa-check"></i><b>3.2.1</b> Streaming sequence reductions</a></li>
<li class="chapter" data-level="3.2.2" data-path="HPC-paper.html"><a href="HPC-paper.html#sec:enum"><i class="fa fa-check"></i><b>3.2.2</b> Restricting the space of streaming sequence reductions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="HPC-paper.html"><a href="HPC-paper.html#datasets-and-pipelines"><i class="fa fa-check"></i><b>3.3</b> Datasets and Pipelines</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="HPC-paper.html"><a href="HPC-paper.html#datasets"><i class="fa fa-check"></i><b>3.3.1</b> Datasets</a></li>
<li class="chapter" data-level="3.3.2" data-path="HPC-paper.html"><a href="HPC-paper.html#simulation-pipeline"><i class="fa fa-check"></i><b>3.3.2</b> Simulation pipeline</a></li>
<li class="chapter" data-level="3.3.3" data-path="HPC-paper.html"><a href="HPC-paper.html#evaluation-pipeline"><i class="fa fa-check"></i><b>3.3.3</b> Evaluation pipeline</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="HPC-paper.html"><a href="HPC-paper.html#hpc-results"><i class="fa fa-check"></i><b>3.4</b> Results</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="HPC-paper.html"><a href="HPC-paper.html#selection-of-mapping-friendly-sequence-reductions"><i class="fa fa-check"></i><b>3.4.1</b> Selection of mapping-friendly sequence reductions</a></li>
<li class="chapter" data-level="3.4.2" data-path="HPC-paper.html"><a href="HPC-paper.html#mapping-friendly-sequence-reductions-lead-to-lower-mapping-errors-on-whole-genomes"><i class="fa fa-check"></i><b>3.4.2</b> Mapping-friendly sequence reductions lead to lower mapping errors on whole genomes</a></li>
<li class="chapter" data-level="3.4.3" data-path="HPC-paper.html"><a href="HPC-paper.html#mapping-friendly-sequence-reductions-increase-mapping-quality-on-repeated-regions-of-the-human-genome"><i class="fa fa-check"></i><b>3.4.3</b> Mapping-friendly sequence reductions increase mapping quality on repeated regions of the human genome</a></li>
<li class="chapter" data-level="3.4.4" data-path="HPC-paper.html"><a href="HPC-paper.html#raw-mapping-improves-upon-hpc-on-centromeric-regions"><i class="fa fa-check"></i><b>3.4.4</b> Raw mapping improves upon HPC on centromeric regions</a></li>
<li class="chapter" data-level="3.4.5" data-path="HPC-paper.html"><a href="HPC-paper.html#positions-of-incorrectly-mapped-reads-across-the-entire-human-genome"><i class="fa fa-check"></i><b>3.4.5</b> Positions of incorrectly mapped reads across the entire human genome</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="HPC-paper.html"><a href="HPC-paper.html#discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
<li class="chapter" data-level="3.6" data-path="HPC-paper.html"><a href="HPC-paper.html#limitations-of-this-study"><i class="fa fa-check"></i><b>3.6</b> Limitations of this study</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#author-contributions"><i class="fa fa-check"></i>Author contributions</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#declaration-of-interests"><i class="fa fa-check"></i>Declaration of interests</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#star-methods"><i class="fa fa-check"></i>STAR Methods</a>
<ul>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#lead-contact"><i class="fa fa-check"></i>Lead contact</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#materials-availability"><i class="fa fa-check"></i>Materials availability</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#data-and-code-availability"><i class="fa fa-check"></i>Data and code availability</a></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#method-details"><i class="fa fa-check"></i>Method details</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="HPC-paper.html"><a href="HPC-paper.html#supplementary-information"><i class="fa fa-check"></i>Supplementary information</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html"><i class="fa fa-check"></i><b>4</b> Learning from sequences and alignments</a>
<ul>
<li class="chapter" data-level="4.1" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#why-learn-from-alignments"><i class="fa fa-check"></i><b>4.1</b> Why learn from alignments ?</a></li>
<li class="chapter" data-level="4.2" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#what-to-learn"><i class="fa fa-check"></i><b>4.2</b> What to learn ?</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#supervised-learning"><i class="fa fa-check"></i><b>4.2.1</b> Supervised learning</a></li>
<li class="chapter" data-level="4.2.2" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#unsupervised-learning"><i class="fa fa-check"></i><b>4.2.2</b> Unsupervised learning</a></li>
<li class="chapter" data-level="4.2.3" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#others-paradigms"><i class="fa fa-check"></i><b>4.2.3</b> Others paradigms</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#how-to-learn"><i class="fa fa-check"></i><b>4.3</b> How to learn ?</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#general-setting"><i class="fa fa-check"></i><b>4.3.1</b> General setting</a></li>
<li class="chapter" data-level="4.3.2" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#tests-and-statistical-learning"><i class="fa fa-check"></i><b>4.3.2</b> Tests and statistical learning</a></li>
<li class="chapter" data-level="4.3.3" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#more-complex-methods"><i class="fa fa-check"></i><b>4.3.3</b> More complex methods</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#preprocessing-the-alignment-for-machine-learning"><i class="fa fa-check"></i><b>4.4</b> Preprocessing the alignment for machine learning</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#general-purpose-encodings"><i class="fa fa-check"></i><b>4.4.1</b> General purpose encodings</a></li>
<li class="chapter" data-level="4.4.2" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#biological-sequence-specific-encodings"><i class="fa fa-check"></i><b>4.4.2</b> Biological sequence-specific encodings</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="learning-from-sequences-and-alignments.html"><a href="learning-from-sequences-and-alignments.html#conclusion-2"><i class="fa fa-check"></i><b>4.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html"><i class="fa fa-check"></i><b>5</b> Viruses, HIV and drug resistance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#what-are-viruses"><i class="fa fa-check"></i><b>5.1</b> What are viruses ?</a></li>
<li class="chapter" data-level="5.2" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#getting-to-know-hiv"><i class="fa fa-check"></i><b>5.2</b> Getting to know HIV</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#quick-presentation-of-hiv"><i class="fa fa-check"></i><b>5.2.1</b> Quick Presentation of HIV</a></li>
<li class="chapter" data-level="5.2.2" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#the-replication-cycle-of-hiv"><i class="fa fa-check"></i><b>5.2.2</b> The replication cycle of HIV</a></li>
<li class="chapter" data-level="5.2.3" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#genetics-of-hiv"><i class="fa fa-check"></i><b>5.2.3</b> Genetics of HIV</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#drug-resistance-in-hiv"><i class="fa fa-check"></i><b>5.3</b> Drug resistance in HIV</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#a-quick-history-of-art"><i class="fa fa-check"></i><b>5.3.1</b> A quick history of ART</a></li>
<li class="chapter" data-level="5.3.2" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#drug-mechanisms"><i class="fa fa-check"></i><b>5.3.2</b> Main mechanisms of viral proteins, antiretroviral drugs and associated resistance.</a></li>
<li class="chapter" data-level="5.3.3" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#consequences-of-resistance-on-global-health"><i class="fa fa-check"></i><b>5.3.3</b> Consequences of resistance on global health</a></li>
<li class="chapter" data-level="5.3.4" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#finding-drms"><i class="fa fa-check"></i><b>5.3.4</b> Finding DRMs </a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="viruses-hiv-and-drug-resistance.html"><a href="viruses-hiv-and-drug-resistance.html#conclusion-3"><i class="fa fa-check"></i><b>5.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="HIV-paper.html"><a href="HIV-paper.html"><i class="fa fa-check"></i><b>6</b> Contribution 2: Inferring mutation roles from sequence alignments using machine learning</a>
<ul>
<li class="chapter" data-level="" data-path="HIV-paper.html"><a href="HIV-paper.html#abstract-paper"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="HIV-paper.html"><a href="HIV-paper.html#author-summary"><i class="fa fa-check"></i>Author summary</a></li>
<li class="chapter" data-level="6.1" data-path="HIV-paper.html"><a href="HIV-paper.html#hiv-introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="HIV-paper.html"><a href="HIV-paper.html#materials-and-methods"><i class="fa fa-check"></i><b>6.2</b> Materials and methods</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="HIV-paper.html"><a href="HIV-paper.html#data"><i class="fa fa-check"></i><b>6.2.1</b> Data</a></li>
<li class="chapter" data-level="6.2.2" data-path="HIV-paper.html"><a href="HIV-paper.html#classifier-training"><i class="fa fa-check"></i><b>6.2.2</b> Classifier training</a></li>
<li class="chapter" data-level="6.2.3" data-path="HIV-paper.html"><a href="HIV-paper.html#measuring-classifier-performance"><i class="fa fa-check"></i><b>6.2.3</b> Measuring classifier performance</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="HIV-paper.html"><a href="HIV-paper.html#hiv-results"><i class="fa fa-check"></i><b>6.3</b> Results</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="HIV-paper.html"><a href="HIV-paper.html#classifier-performance-interpretation"><i class="fa fa-check"></i><b>6.3.1</b> Classifier performance &amp; interpretation</a></li>
<li class="chapter" data-level="6.3.2" data-path="HIV-paper.html"><a href="HIV-paper.html#additional-classification-results"><i class="fa fa-check"></i><b>6.3.2</b> Additional classification results</a></li>
<li class="chapter" data-level="6.3.3" data-path="HIV-paper.html"><a href="HIV-paper.html#identifying-new-mutations-from-classifiers"><i class="fa fa-check"></i><b>6.3.3</b> Identifying new mutations from classifiers</a></li>
<li class="chapter" data-level="6.3.4" data-path="HIV-paper.html"><a href="HIV-paper.html#detailed-analysis-of-potentially-resistance-associated-mutations"><i class="fa fa-check"></i><b>6.3.4</b> Detailed analysis of potentially resistance-associated mutations</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="HIV-paper.html"><a href="HIV-paper.html#discussion-and-perspectives"><i class="fa fa-check"></i><b>6.4</b> Discussion and perspectives</a></li>
<li class="chapter" data-level="" data-path="HIV-paper.html"><a href="HIV-paper.html#hiv-acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="HIV-paper.html"><a href="HIV-paper.html#supporting-information"><i class="fa fa-check"></i>Supporting Information</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html"><i class="fa fa-check"></i><b>7</b> Learning alignments, an interesting perspective</a>
<ul>
<li class="chapter" data-level="7.1" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#intro-to-deep-learning"><i class="fa fa-check"></i><b>7.1</b> Intro to deep learning</a></li>
<li class="chapter" data-level="7.2" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#learning-sequence-embeddings"><i class="fa fa-check"></i><b>7.2</b> Learning sequence embeddings</a></li>
<li class="chapter" data-level="7.3" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#learning-pairwise-alignment"><i class="fa fa-check"></i><b>7.3</b> Learning pairwise alignment</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#dedal"><i class="fa fa-check"></i><b>7.3.1</b> DEDAL</a></li>
<li class="chapter" data-level="7.3.2" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#predicting-an-alignment"><i class="fa fa-check"></i><b>7.3.2</b> predicting an alignment</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#what-else-could-we-learn"><i class="fa fa-check"></i><b>7.4</b> What else could we learn ?</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#learn-to-predict-seeds-or-starting-positions"><i class="fa fa-check"></i><b>7.4.1</b> Learn to predict seeds or starting positions</a></li>
<li class="chapter" data-level="7.4.2" data-path="learning-alignments-an-interesting-perspective.html"><a href="learning-alignments-an-interesting-perspective.html#learn-pre-processing-functions"><i class="fa fa-check"></i><b>7.4.2</b> Learn pre-processing functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="global-conclusion.html"><a href="global-conclusion.html"><i class="fa fa-check"></i>Global conclusion</a>
<ul>
<li class="chapter" data-level="" data-path="global-conclusion.html"><a href="global-conclusion.html#hpc-part"><i class="fa fa-check"></i>HPC part</a></li>
<li class="chapter" data-level="" data-path="global-conclusion.html"><a href="global-conclusion.html#hiv-part"><i class="fa fa-check"></i>HIV part</a></li>
<li class="chapter" data-level="" data-path="global-conclusion.html"><a href="global-conclusion.html#final-words"><i class="fa fa-check"></i>Final words</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="global-references.html"><a href="global-references.html"><i class="fa fa-check"></i>Global References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="HPC-appendix.html"><a href="HPC-appendix.html"><i class="fa fa-check"></i><b>A</b> Supporting Information for “Mapping-friendly sequence reductions: going beyond homopolymer compression”</a>
<ul>
<li class="chapter" data-level="A.1" data-path="HPC-appendix.html"><a href="HPC-appendix.html#appendix:tandemtools"><i class="fa fa-check"></i><b>A.1</b> “TandemTools” dataset generation</a></li>
<li class="chapter" data-level="A.2" data-path="HPC-appendix.html"><a href="HPC-appendix.html#msr-performance-comparison"><i class="fa fa-check"></i><b>A.2</b> MSR performance comparison</a></li>
<li class="chapter" data-level="A.3" data-path="HPC-appendix.html"><a href="HPC-appendix.html#analyzing-read-origin-on-whole-human-genome"><i class="fa fa-check"></i><b>A.3</b> Analyzing read origin on whole human genome</a></li>
<li class="chapter" data-level="A.4" data-path="HPC-appendix.html"><a href="HPC-appendix.html#performance-of-msrs-on-the-drosophila-genome"><i class="fa fa-check"></i><b>A.4</b> Performance of MSRs on the Drosophila genome</a></li>
<li class="chapter" data-level="A.5" data-path="HPC-appendix.html"><a href="HPC-appendix.html#key-resource-table"><i class="fa fa-check"></i><b>A.5</b> Key Resource Table</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="HIV-intro-appendix.html"><a href="HIV-intro-appendix.html"><i class="fa fa-check"></i><b>B</b> Supporting Information for “HIV and DRMs”</a>
<ul>
<li class="chapter" data-level="B.1" data-path="HIV-intro-appendix.html"><a href="HIV-intro-appendix.html#detailed-list-of-hiv-1-protein-structures-used-for-figure-generation."><i class="fa fa-check"></i><b>B.1</b> Detailed list of HIV-1 protein structures used for figure generation.</a></li>
<li class="chapter" data-level="B.2" data-path="HIV-intro-appendix.html"><a href="HIV-intro-appendix.html#list-of-all-antiretroviral-drugs"><i class="fa fa-check"></i><b>B.2</b> List of all antiretroviral drugs</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="HIV-appendix.html"><a href="HIV-appendix.html"><i class="fa fa-check"></i><b>C</b> Supporting Information for “Using Machine Learning and Big Data to Explore the Drug Resistance Landscape in HIV”</a>
<ul>
<li class="chapter" data-level="C.1" data-path="HIV-appendix.html"><a href="HIV-appendix.html#S1-Appendix"><i class="fa fa-check"></i><b>C.1</b> S1 Appendix (Technical appendix).</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="HIV-appendix.html"><a href="HIV-appendix.html#data-appendix"><i class="fa fa-check"></i><b>C.1.1</b> Data</a></li>
<li class="chapter" data-level="C.1.2" data-path="HIV-appendix.html"><a href="HIV-appendix.html#classifiers"><i class="fa fa-check"></i><b>C.1.2</b> Classifiers</a></li>
<li class="chapter" data-level="C.1.3" data-path="HIV-appendix.html"><a href="HIV-appendix.html#scoring"><i class="fa fa-check"></i><b>C.1.3</b> Scoring</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="HIV-appendix.html"><a href="HIV-appendix.html#s1-fig."><i class="fa fa-check"></i><b>C.2</b> S1 Fig.</a></li>
<li class="chapter" data-level="C.3" data-path="HIV-appendix.html"><a href="HIV-appendix.html#s2-fig."><i class="fa fa-check"></i><b>C.3</b> S2 Fig.</a></li>
<li class="chapter" data-level="C.4" data-path="HIV-appendix.html"><a href="HIV-appendix.html#s3-fig."><i class="fa fa-check"></i><b>C.4</b> S3 Fig.</a></li>
<li class="chapter" data-level="C.5" data-path="HIV-appendix.html"><a href="HIV-appendix.html#S1-Table"><i class="fa fa-check"></i><b>C.5</b> S1 Table.</a></li>
<li class="chapter" data-level="C.6" data-path="HIV-appendix.html"><a href="HIV-appendix.html#S2-Appendix"><i class="fa fa-check"></i><b>C.6</b> S2 Appendix. (Fisher exact tests)</a></li>
<li class="chapter" data-level="C.7" data-path="HIV-appendix.html"><a href="HIV-appendix.html#s1-data."><i class="fa fa-check"></i><b>C.7</b> S1 Data.</a></li>
<li class="chapter" data-level="C.8" data-path="HIV-appendix.html"><a href="HIV-appendix.html#s2-data."><i class="fa fa-check"></i><b>C.8</b> S2 Data.</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://lucblassel.com" target="blank">Back to main website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">From sequences to knowledge, improving and learning from sequence alignments</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-alignments-an-interesting-perspective" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Learning alignments, an interesting perspective<a href="learning-alignments-an-interesting-perspective.html#learning-alignments-an-interesting-perspective" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="intro-to-deep-learning" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Intro to deep learning<a href="learning-alignments-an-interesting-perspective.html#intro-to-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>The perceptron &amp; neuron structure</p></li>
<li><p>MLP</p></li>
<li><p>Deeper and deeper models</p></li>
<li><p>Back Prop -&gt; !!</p></li>
<li><p>Recently super deep network with billions of params</p></li>
</ul>
</div>
<div id="learning-sequence-embeddings" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Learning sequence embeddings<a href="learning-alignments-an-interesting-perspective.html#learning-sequence-embeddings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>(Variational) Auto-encoders:</p>
<ul>
<li>Bottlneck in deep neural neck, task is to predict input. Add noise in the hidden layers -&gt; remove noise or regularize to have smooth latent space and get embeddings</li>
<li>Used for ancestral sequence reconstruction<span class="citation"><sup><a href="#ref-moretaAncestralProteinSequence2022" role="doc-biblioref">671</a></sup></span> and estimating evolutionary distances<span class="citation"><sup><a href="#ref-corsoNeuralDistanceEmbeddings2021" role="doc-biblioref">358</a></sup></span></li>
<li>VAEs used for sequence design as well<span class="citation"><sup><a href="#ref-wuProteinSequenceDesign2021" role="doc-biblioref">672</a>,<a href="#ref-stantonAcceleratingBayesianOptimization2022" role="doc-biblioref">673</a></sup></span></li>
</ul></li>
</ul>
<p>NLP:</p>
<ul>
<li><p>From the field of natural language processing where very high dimensionality (470,000 words in the Merriam-Webster English dictionary<span class="citation"><sup><a href="#ref-HowManyWords" role="doc-biblioref">674</a></sup></span>, so naive one hot is out of the question), we need other ways to transform words into sequences.</p></li>
<li><p>Method of pre-training embedding methods</p></li>
<li><p>Word2Vec derivatives:</p>
<ul>
<li><p>word2Vec<span class="citation"><sup><a href="#ref-mikolovEfficientEstimationWord2013" role="doc-biblioref">675</a>,<a href="#ref-mikolovDistributedRepresentationsWords2013" role="doc-biblioref">676</a></sup></span>, take in a large corpus of text and learns a vector space from it. Then each word in the corpus can be assigned a vector, constraints mean that similar words have similar vectors (i.e. low distance in the vector space). And that the embeddings make sense grammatically (e.g. of the Paper <span class="math inline">\(vec(Madrid) - vec(Spain)\)</span> should be close to <span class="math inline">\(vec(Paris)\)</span> in the learned space.</p>
<ul>
<li><p>Context of a word = window of <span class="math inline">\(k\)</span> words centered around it</p></li>
<li><p>The model is a neural network and the hidden layer corresponds to the embedding (similar to auto-encoders)</p></li>
<li><p>2 ways to train it<span class="citation"><sup><a href="#ref-goldbergWord2vecExplainedDeriving2014" role="doc-biblioref">677</a></sup></span>:</p>
<ul>
<li><p>CBOW (continuous bag of words) = predict word from context</p></li>
<li><p>skip-gram = predict context from word</p></li>
</ul></li>
</ul></li>
<li><p>dna2vec<span class="citation"><sup><a href="#ref-ngDna2vecConsistentVector2017" role="doc-biblioref">678</a></sup></span></p>
<ul>
<li>Used to predict methylation sites<span class="citation"><sup><a href="#ref-liangHyb4mCHybridDNA2vecbased2022" role="doc-biblioref">679</a></sup></span></li>
</ul></li>
<li><p>seq2vec<span class="citation"><sup><a href="#ref-kimothiDistributedRepresentationsBiological2016" role="doc-biblioref">680</a></sup></span></p></li>
<li><p>BioVec/ProtVec/GeneVec<span class="citation"><sup><a href="#ref-asgariContinuousDistributedRepresentation2015" role="doc-biblioref">681</a></sup></span></p>
<ul>
<li>Seq2vec and ProtVec both used in classification<span class="citation"><sup><a href="#ref-kimothiMetricLearningBiological2017" role="doc-biblioref">682</a></sup></span></li>
</ul></li>
</ul></li>
<li><p>Transformers / NN-based language models:</p>
<ul>
<li><p>Also from NLP, more recent development,</p>
<ul>
<li>Some have seen a lot of success like BERT<span class="citation"><sup><a href="#ref-devlinBERTPretrainingDeep2019" role="doc-biblioref">683</a></sup></span> and GPT-3<span class="citation"><sup><a href="#ref-brownLanguageModelsAre2020" role="doc-biblioref">684</a></sup></span></li>
<li>Based on the very popular Transformer architecture<span class="citation"><sup><a href="#ref-vaswaniAttentionAllYou2017" role="doc-biblioref">685</a></sup></span>, with attention maps. Embed features as a linear weighted sum of other features (learn weights).</li>
<li>Allows for long range dependencies to be captured efficiently</li>
<li>LLMs trained with MLM</li>
<li>Replaced methods based on RNNs / LSTMs which have trouble capturing long range dependencies<span class="citation"><sup><a href="#ref-songPretrainingModelBiological2021" role="doc-biblioref">686</a></sup></span>.</li>
</ul></li>
<li><p>protein language models have been developed from this with the same idea.</p>
<ul>
<li><p>ProGen<span class="citation"><sup><a href="#ref-madaniProGenLanguageModeling2020" role="doc-biblioref">687</a></sup></span> and ProGen2<span class="citation"><sup><a href="#ref-eriknijkampProGen2ExploringBoundaries2022" role="doc-biblioref">688</a></sup></span></p></li>
<li><p>ProtBERT<span class="citation"><sup><a href="#ref-elnaggarProtTransCrackingLanguage2021" role="doc-biblioref">369</a></sup></span></p></li>
<li><p>DNABert<span class="citation"><sup><a href="#ref-jiDNABERTPretrainedBidirectional2021" role="doc-biblioref">689</a></sup></span></p></li>
<li><p>They have interesting properties<span class="citation"><sup><a href="#ref-beplerLearningProteinLanguage2021" role="doc-biblioref">690</a></sup></span>:</p>
<ul>
<li><p>Intuitively learn structure of proteins<span class="citation"><sup><a href="#ref-raoTransformerProteinLanguage2020" role="doc-biblioref">691</a>,<a href="#ref-rivesBiologicalStructureFunction2019" role="doc-biblioref">692</a></sup></span></p></li>
<li><p>Learn mutational effects<span class="citation"><sup><a href="#ref-meierLanguageModelsEnable2021" role="doc-biblioref">693</a></sup></span></p></li>
<li><p>Evolutionary characteristics<span class="citation"><sup><a href="#ref-hieEvolutionaryVelocityProtein2022" role="doc-biblioref">694</a></sup></span></p></li>
</ul></li>
<li><p>To counter the space limitations (i.e. sequence length limitations) induced by attention, other types of transformers used, with linear scale attention maps not quadratic<span class="citation"><sup><a href="#ref-choromanskiMaskedLanguageModeling2020" role="doc-biblioref">695</a></sup></span></p></li>
</ul></li>
<li><p>Include information from MSA directly in embedding<span class="citation"><sup><a href="#ref-caiGenomewidePredictionSmall2020" role="doc-biblioref">696</a></sup></span>: transform aligned sequence in to tokens -&gt; use ALBERT to embed tokens</p></li>
<li><p>MSA Transformer<span class="citation"><sup><a href="#ref-raoMSATransformer2021" role="doc-biblioref">697</a></sup></span> that extends attention to include aligned residues from an input MSA as well.</p>
<ul>
<li><p>Similarly: learn on profiles derived from MSAs<span class="citation"><sup><a href="#ref-sturmfelsProfilePredictionAlignmentBased2020" role="doc-biblioref">698</a></sup></span> as a pre-training task for protein language models</p></li>
<li><p>Learn a protein structure model (potts model) directly on the MSA with a mechanism similar to attention<span class="citation"><sup><a href="#ref-sercuNeuralPottsModel2021" role="doc-biblioref">699</a></sup></span></p></li>
</ul></li>
</ul></li>
<li><p>Powerful but hard to interpret what the model actually learns. i.e. “black box” but some work is being done to interpret attention maps<span class="citation"><sup><a href="#ref-vigBERTologyMeetsBiology2021" role="doc-biblioref">700</a></sup></span></p></li>
</ul>
</div>
<div id="learning-pairwise-alignment" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Learning pairwise alignment<a href="learning-alignments-an-interesting-perspective.html#learning-pairwise-alignment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="dedal" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> DEDAL<a href="learning-alignments-an-interesting-perspective.html#dedal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>reference to transformer embedding</p></li>
<li><p>Predict substitution matrix</p></li>
<li><p>Reference other similar works</p></li>
<li><p>drawback: only on proteins</p></li>
</ul>
</div>
<div id="predicting-an-alignment" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> predicting an alignment<a href="learning-alignments-an-interesting-perspective.html#predicting-an-alignment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Transformer models can also predict tokens -&gt; predict “CIGAR string” or a an aligned sequence.</p></li>
<li><p>Challenges:</p>
<ul>
<li><p>Longer sequences in DNA</p></li>
<li><p>Size difference in the case of mapping</p></li>
<li><p>Less information in a single nucleotide token than in proteins….</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="what-else-could-we-learn" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> What else could we learn ?<a href="learning-alignments-an-interesting-perspective.html#what-else-could-we-learn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="learn-to-predict-seeds-or-starting-positions" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Learn to predict seeds or starting positions<a href="learning-alignments-an-interesting-perspective.html#learn-to-predict-seeds-or-starting-positions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>DeepMinimizer</p></li>
<li><p>predict start position given a pair of sequences</p></li>
</ul>
</div>
<div id="learn-pre-processing-functions" class="section level3 hasAnchor" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Learn pre-processing functions<a href="learning-alignments-an-interesting-perspective.html#learn-pre-processing-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>i.e. either connections in MSR graph or sequence 2 sequence models</p>
<p>% </p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body" line-spacing="2">
<div id="ref-corsoNeuralDistanceEmbeddings2021" class="csl-entry">
<div class="csl-left-margin">358. </div><div class="csl-right-inline">Corso, G. <em>et al.</em> <a href="https://proceedings.neurips.cc/paper/2021/hash/9a1de01f893e0d2551ecbb7ce4dc963e-Abstract.html">Neural distance embeddings for biological sequences</a>. in vol. 34 1853918551 (Curran Associates, Inc., 2021).</div>
</div>
<div id="ref-elnaggarProtTransCrackingLanguage2021" class="csl-entry">
<div class="csl-left-margin">369. </div><div class="csl-right-inline">Elnaggar, A. <em>et al.</em> ProtTrans: Towards cracking the language of life’s code through self-supervised deep learning and high performance computing. doi:<a href="https://doi.org/10.48550/arXiv.2007.06225">10.48550/arXiv.2007.06225</a>.</div>
</div>
<div id="ref-moretaAncestralProteinSequence2022" class="csl-entry">
<div class="csl-left-margin">671. </div><div class="csl-right-inline">Moreta, L. S. <em>et al.</em> <a href="https://openreview.net/forum?id=FZoZ7a31GCW">International Conference on Learning Representations</a>. in (2022).</div>
</div>
<div id="ref-wuProteinSequenceDesign2021" class="csl-entry">
<div class="csl-left-margin">672. </div><div class="csl-right-inline">Wu, Z., Johnston, K. E., Arnold, F. H. &amp; Yang, K. K. <a href="https://doi.org/10.1016/j.cbpa.2021.04.004">Protein sequence design with deep generative models</a>. <em>Current Opinion in Chemical Biology</em> <strong>65</strong>, 18–27 (2021).</div>
</div>
<div id="ref-stantonAcceleratingBayesianOptimization2022" class="csl-entry">
<div class="csl-left-margin">673. </div><div class="csl-right-inline">Stanton, S. <em>et al.</em> Accelerating bayesian optimization for biological sequence design with denoising autoencoders. doi:<a href="https://doi.org/10.48550/arXiv.2203.12742">10.48550/arXiv.2203.12742</a>.</div>
</div>
<div id="ref-HowManyWords" class="csl-entry">
<div class="csl-left-margin">674. </div><div class="csl-right-inline"><a href="https://www.merriam-webster.com/help/faq-how-many-english-words">How many words are there in english? | merriam-webster</a>.</div>
</div>
<div id="ref-mikolovEfficientEstimationWord2013" class="csl-entry">
<div class="csl-left-margin">675. </div><div class="csl-right-inline">Mikolov, T., Chen, K., Corrado, G. &amp; Dean, J. Efficient estimation of word representations in vector space. doi:<a href="https://doi.org/10.48550/arXiv.1301.3781">10.48550/arXiv.1301.3781</a>.</div>
</div>
<div id="ref-mikolovDistributedRepresentationsWords2013" class="csl-entry">
<div class="csl-left-margin">676. </div><div class="csl-right-inline">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S. &amp; Dean, J. <a href="https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html">Distributed representations of words and phrases and their compositionality</a>. in vol. 26 (Curran Associates, Inc., 2013).</div>
</div>
<div id="ref-goldbergWord2vecExplainedDeriving2014" class="csl-entry">
<div class="csl-left-margin">677. </div><div class="csl-right-inline">Goldberg, Y. &amp; Levy, O. word2vec explained: Deriving mikolov et al.’s negative-sampling word-embedding method. doi:<a href="https://doi.org/10.48550/arXiv.1402.3722">10.48550/arXiv.1402.3722</a>.</div>
</div>
<div id="ref-ngDna2vecConsistentVector2017" class="csl-entry">
<div class="csl-left-margin">678. </div><div class="csl-right-inline">Ng, P. dna2vec: Consistent vector representations of variable-length k-mers. doi:<a href="https://doi.org/10.48550/arXiv.1701.06279">10.48550/arXiv.1701.06279</a>.</div>
</div>
<div id="ref-liangHyb4mCHybridDNA2vecbased2022" class="csl-entry">
<div class="csl-left-margin">679. </div><div class="csl-right-inline">Liang, Y. <em>et al.</em> <a href="https://doi.org/10.1186/s12859-022-04789-6">Hyb4mC: a hybrid DNA2vec-based model for DNA N4-methylcytosine sites prediction</a>. <em>BMC Bioinformatics</em> <strong>23</strong>, 258 (2022).</div>
</div>
<div id="ref-kimothiDistributedRepresentationsBiological2016" class="csl-entry">
<div class="csl-left-margin">680. </div><div class="csl-right-inline">Kimothi, D., Soni, A., Biyani, P. &amp; Hogan, J. M. Distributed representations for biological sequence analysis. doi:<a href="https://doi.org/10.48550/arXiv.1608.05949">10.48550/arXiv.1608.05949</a>.</div>
</div>
<div id="ref-asgariContinuousDistributedRepresentation2015" class="csl-entry">
<div class="csl-left-margin">681. </div><div class="csl-right-inline">Asgari, E. &amp; Mofrad, M. R. K. <a href="https://doi.org/10.1371/journal.pone.0141287">Continuous distributed representation of biological sequences for deep proteomics and genomics</a>. <em>PLoS ONE</em> <strong>10</strong>, e0141287 (2015).</div>
</div>
<div id="ref-kimothiMetricLearningBiological2017" class="csl-entry">
<div class="csl-left-margin">682. </div><div class="csl-right-inline">Kimothi, D., Shukla, A., Biyani, P., Anand, S. &amp; Hogan, J. M. 2017 IEEE 18th international workshop on signal processing advances in wireless communications (SPAWC). in 1–5 (2017). doi:<a href="https://doi.org/10.1109/SPAWC.2017.8227769">10.1109/SPAWC.2017.8227769</a>.</div>
</div>
<div id="ref-devlinBERTPretrainingDeep2019" class="csl-entry">
<div class="csl-left-margin">683. </div><div class="csl-right-inline">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. doi:<a href="https://doi.org/10.48550/arXiv.1810.04805">10.48550/arXiv.1810.04805</a>.</div>
</div>
<div id="ref-brownLanguageModelsAre2020" class="csl-entry">
<div class="csl-left-margin">684. </div><div class="csl-right-inline">Brown, T. <em>et al.</em> <a href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html">Language models are few-shot learners</a>. in vol. 33 18771901 (Curran Associates, Inc., 2020).</div>
</div>
<div id="ref-vaswaniAttentionAllYou2017" class="csl-entry">
<div class="csl-left-margin">685. </div><div class="csl-right-inline">Vaswani, A. <em>et al.</em> <a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is all you need</a>. in vol. 30 (Curran Associates, Inc., 2017).</div>
</div>
<div id="ref-songPretrainingModelBiological2021" class="csl-entry">
<div class="csl-left-margin">686. </div><div class="csl-right-inline">Song, B. <em>et al.</em> <a href="https://doi.org/10.1093/bfgp/elab025">Pretraining model for biological sequence data.</a> <em>Briefings in Functional Genomics</em> <strong>20</strong>, 181–195 (2021).</div>
</div>
<div id="ref-madaniProGenLanguageModeling2020" class="csl-entry">
<div class="csl-left-margin">687. </div><div class="csl-right-inline">Madani, A. <em>et al.</em> ProGen: Language modeling for protein generation. <em>bioRxiv</em> (2020) doi:<a href="https://doi.org/10.1101/2020.03.07.982272">10.1101/2020.03.07.982272</a>.</div>
</div>
<div id="ref-eriknijkampProGen2ExploringBoundaries2022" class="csl-entry">
<div class="csl-left-margin">688. </div><div class="csl-right-inline">Erik Nijkamp, Jeffrey A. Ruffolo, Eli N. Weinstein, Nikhil Naik &amp; Ali Madani. ProGen2: Exploring the boundaries of protein language models. <em>ArXiv</em> (2022) doi:<a href="https://doi.org/10.48550/arxiv.2206.13517">10.48550/arxiv.2206.13517</a>.</div>
</div>
<div id="ref-jiDNABERTPretrainedBidirectional2021" class="csl-entry">
<div class="csl-left-margin">689. </div><div class="csl-right-inline">Ji, Y., Zhou, Z., Liu, H. &amp; Davuluri, R. V. <a href="https://doi.org/10.1093/bioinformatics/btab083">DNABERT: Pre-trained bidirectional encoder representations from transformers model for DNA-language in genome</a>. <em>Bioinformatics</em> <strong>37</strong>, 2112–2120 (2021).</div>
</div>
<div id="ref-beplerLearningProteinLanguage2021" class="csl-entry">
<div class="csl-left-margin">690. </div><div class="csl-right-inline">Bepler, T. &amp; Berger, B. <a href="https://doi.org/10.1016/j.cels.2021.05.017">Learning the protein language: Evolution, structure, and function.</a> <em>Cell systems</em> <strong>12</strong>, (2021).</div>
</div>
<div id="ref-raoTransformerProteinLanguage2020" class="csl-entry">
<div class="csl-left-margin">691. </div><div class="csl-right-inline">Rao, R., Meier, J., Sercu, T., Ovchinnikov, S. &amp; Rives, A. Transformer protein language models are unsupervised structure learners. doi:<a href="https://doi.org/10.1101/2020.12.15.422761">10.1101/2020.12.15.422761</a>.</div>
</div>
<div id="ref-rivesBiologicalStructureFunction2019" class="csl-entry">
<div class="csl-left-margin">692. </div><div class="csl-right-inline">Rives, A. <em>et al.</em> Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences. <em>bioRxiv</em> 622803 (2019) doi:<a href="https://doi.org/10.1101/622803">10.1101/622803</a>.</div>
</div>
<div id="ref-meierLanguageModelsEnable2021" class="csl-entry">
<div class="csl-left-margin">693. </div><div class="csl-right-inline">Meier, J. <em>et al.</em> <a href="https://doi.org/10.1101/2021.07.09.450648">Language models enable zero-shot prediction of the effects of mutations on protein function</a>. <em>bioRxiv</em> <strong>34</strong>, (2021).</div>
</div>
<div id="ref-hieEvolutionaryVelocityProtein2022" class="csl-entry">
<div class="csl-left-margin">694. </div><div class="csl-right-inline">Hie, B., Kevin K Yang &amp; Kim, S. K. Evolutionary velocity with protein language models predicts evolutionary dynamics of diverse proteins. <em>Cell systems</em> (2022) doi:<a href="https://doi.org/10.1016/j.cels.2022.01.003">10.1016/j.cels.2022.01.003</a>.</div>
</div>
<div id="ref-choromanskiMaskedLanguageModeling2020" class="csl-entry">
<div class="csl-left-margin">695. </div><div class="csl-right-inline">Choromanski, K. <em>et al.</em> Masked language modeling for proteins via linearly scalable long-context transformers. doi:<a href="https://doi.org/10.48550/arXiv.2006.03555">10.48550/arXiv.2006.03555</a>.</div>
</div>
<div id="ref-caiGenomewidePredictionSmall2020" class="csl-entry">
<div class="csl-left-margin">696. </div><div class="csl-right-inline">Cai, T. <em>et al.</em> Genome-wide Prediction of Small Molecule Binding to Remote Orphan Proteins Using Distilled Sequence Alignment Embedding. doi:<a href="https://doi.org/10.1101/2020.08.04.236729">10.1101/2020.08.04.236729</a>.</div>
</div>
<div id="ref-raoMSATransformer2021" class="csl-entry">
<div class="csl-left-margin">697. </div><div class="csl-right-inline">Rao, R. <em>et al.</em> MSA transformer. <em>bioRxiv</em> (2021) doi:<a href="https://doi.org/10.1101/2021.02.12.430858">10.1101/2021.02.12.430858</a>.</div>
</div>
<div id="ref-sturmfelsProfilePredictionAlignmentBased2020" class="csl-entry">
<div class="csl-left-margin">698. </div><div class="csl-right-inline">Sturmfels, P., Vig, J., Madani, A. &amp; Rajani, N. F. Profile prediction: An alignment-based pre-training task for protein sequence models. doi:<a href="https://doi.org/10.48550/arXiv.2012.00195">10.48550/arXiv.2012.00195</a>.</div>
</div>
<div id="ref-sercuNeuralPottsModel2021" class="csl-entry">
<div class="csl-left-margin">699. </div><div class="csl-right-inline">Sercu, T. <em>et al.</em> Neural Potts Model. doi:<a href="https://doi.org/10.1101/2021.04.08.439084">10.1101/2021.04.08.439084</a>.</div>
</div>
<div id="ref-vigBERTologyMeetsBiology2021" class="csl-entry">
<div class="csl-left-margin">700. </div><div class="csl-right-inline">Vig, J. <em>et al.</em> BERTology meets biology: Interpreting attention in protein language models. doi:<a href="https://doi.org/10.48550/arXiv.2006.15222">10.48550/arXiv.2006.15222</a>.</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="HIV-paper.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="global-conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/lucblassel/phd-manuscript/edit/main/07-learning-alignments.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
