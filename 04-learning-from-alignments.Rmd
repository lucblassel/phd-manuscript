# Learning from sequences and alignments

## Why learn from alignments ?

Sequences and sequence alignments are a very rich source of information. As was sated in Chapters \@ref(aligning-sequence-data) and \@ref(HPC-paper), many downstream analyses rely on sequence alignments.

In whole genome assembly, where sequencing reads are combined together to deduce the sequence genome, pairwise sequence alignment is used in reference-based assembly [@martinNextgenerationTranscriptomeAssembly2011; @kyriakidouCurrentStrategiesPolyploid2018] as well as *de novo* [@paszkiewiczNovoAssemblyShort2010; @sohnPresentFutureNovo2018] assembly. It has also been used to deduce protein function [@sleatorOverviewSilicoProtein2010]. It has been used for sequence clustering [@sahlinNovoClusteringLongRead2020] as well as detecting genetic [@koboldtBestPracticesVariant2020] and structural variants [@alkanGenomeStructuralVariation2011; @hoStructuralVariationSequencing2020]. Multiple sequence alignments are also very widely used, mainly in phylogenetic analyses where the evolutionary history of a set of sequences are studied and represented as trees [@morrisonPhylogeneticTreebuilding1996; @kapliPhylogeneticTreeBuilding2020], but they have also been used extensively in protein structure prediction [@kuhlmanAdvancesProteinStructure2019].

More recently, as computational power and datasets have grown, more and more machine learning methods are being used on sequence alignments in order to gain biological insight. In this chapter, we will explore how this can be done as an introduction to Chapter \@ref(HIV-paper) where we present an application: predicting HIV drug resistance mutations.

## What to learn ?

One of the first questions one might ask themselves when wishing to use machine learning with sequence data is "what can I learn?". A simplistic answer to this question would be "a lot of things" as the following section will strive to show. To choose what we learn we must first choose a learning paradigm.

### Supervised learning

Supervised learning is one of the main machine learning paradigms, here we have data that consist of a collection of input and output pairs (e.g. a DNA sequence and an associated species). By feeding these pairs to our algorithm of choice it will learn to predict the output based on the input alone. This is a very powerful way of learning something interesting. We can consider the link between inputs and outputs as extra knowledge that the dataset creator or curator can infuse in the learning algorithm. Within the supervised learning paradigm there are two possible tasks: *regression* and *classification*.

#### Regression tasks

For regression tasks, the outputs of our input-output pairs are encoded by a continuous numerical value. Regression models will therefore output continuous real values. Fortunately, many interesting continuous values can be computed from aligned sequences, and in many cases machine learning models can be trained to predict these variables.

Regression methods have been used to predict drug response in cancer patients [@ammad-ud-dinSystematicIdentificationFeature2017] and resistance levels to drugs in HIV [@steinerDrugResistancePrediction2020a]. These methods are also extensively used in protein structure prediction, where methods are trained to predict residue angles or values in protein contact maps from aligned sequences. [@noeMachineLearningProtein2020; @pearceSolutionProteinStructure2021; @tunyasuvunakoolHighlyAccurateProtein2021; @chengMachineLearningMethods2008; @alquraishiMachineLearningProtein2021] Or directly from an MSA [@jumperHighlyAccurateProtein2021].Regression algorithms have been used to predict protein fitness *in silico* [@wittmannAdvancesMachineLearning2021; @yangMachinelearningguidedDirectedEvolution2019; @liCanMachineLearning2019] to speed up protein engineering, and make some processes like drug development faster and cheaper. They have also been used in many other tasks such as predicting gene expression levels [@xieDeepAutoencoderModel2017] or predicting multiple sequence alignment scores [@ortunoComparingDifferentMachine2015].

In many cases these methods use an encoded representation of the sequences (c.f. Section \@ref(preprocessing-the-alignment-for-machine-learning)) as input, but some represent the inputs as values computed from alignments. For example, protein structure can be predicted from contact maps [@wangAccurateNovoPrediction2017] derived from MSAs, and gene expression levels can be predicted from lists of mutations that are obtained through alignment to a reference sequence [@xieDeepAutoencoderModel2017], this last approach is also used in Chapter \@ref(HIV-paper) to predict drug resistance in HIV.

#### Classification tasks

For classification tasks, the outputs of our input-output pairs are categorical in nature and often represented as discrete integer values. Originally, most classification methods were designed for binary classification with only two possible outputs: a "positive" and a "negative" class. This is a simpler problem to solve than multi-class classification problem where more than two outputs are possible, however most methods that can handle binary classification have been adapted to multi-class classification.

In biology, categorizing and classifying is often at the root of several research problems, as such machine learning classifiers have obvious applications and have been widely used, with sequence data as inputs. Classifiers have been used to predict if a particular virus [@hagaMachineLearningbasedTreatment2020; @zazziPredictingResponseAntiretroviral2012] (also Chapter \@ref(HIV-paper)), or bacteria [@renPredictionAntimicrobialResistance2022; @kimMachineLearningAntimicrobial2022] is resistant to antiviral or antimicrobial drugs respectively. Some classifier models have also been used to predict characteristics at positions in a sequence, like methylation site prediction [@wangPredictingDNAMethylation2016], splicing site detection [@ratschLearningInterpretableSVMs2006] or secondary structure at a particular amino acid residue [@jonesProteinSecondaryStructure1999]. Finally, classifiers have also been used to predict predict more general characteristics of given sequence, like the cellular localization [@weiPredictionHumanProtein2018] or putative function [@wangProteinSequenceProtein2017] of a protein, or the cellular localization of gene expression data [@kelleyBassetLearningRegulatory2016].

I have presented here only a fraction of what is possible to learn from sequences in the supervised learning paradigm, and I hope you will agree with me that there is no shortage of problems in computational biology that are suited to this sort of approach. By using machine learning here, instead of more formal statistical approaches, there is a lower amount of upfront assumptions and the algorithm is tasked with figuring out what features of the data are important or not for the task at hand.

### Unsupervised learning

The second main machine learning paradigm is called, by contrast to supervised learning, unsupervised learning. In this paradigm we do not have input-output pairs but only inputs. The goal of unsupervised machine learning methods is to extract some structure or patterns from the given input without additional guidance.

One of the main tasks in the unsupervised learning paradigm is clustering, wherein similar inputs are grouped together, methods like k-means of hierarchical clustering [@hastieElementsStatisticalLearning2009] often use some type of distance metric between inputs to define these clusters of similar inputs. Clustering can be used for classification tasks, indeed if some characteristics of sequences in a given cluster are known then we can make the assumptions that sequences in the same cluster will be similar and share these characteristics, this has been used to group proteins in families [@kriventsevaClusteringAnalysisProtein2001] for example. Clustering methods can also be used to remove duplicate or near-duplicate sequences in datasets [@fuCDHITAcceleratedClustering2012]. Phylogenetic trees can be considered as a specific type of clustering methods, and they have been used to cluster biological sequences [@balabanTreeClusterClusteringBiological2019].

One of the main obstacles to clustering biological sequences is the need for computing distances between sequences. As stated in Chapter \@ref(aligning-sequence-data), obtaining a biologically relevant distance metric between two sequences, such as the edit-distance, is no easy task. Additionally, in many cases all pairwise distances are needed for clustering, meaning at least a quadratic time and space complexity for a naive clustering algorithm. Two approaches can be used to resolve this problem: devise methods that do not need all pairwise distances [@zoritaStarcodeSequenceClustering2015], or find a way to speed up distance computation. Some methods have been developed to devise distance metrics that are biologically relevant and less expensive to compute that the edit-distance: like the hashing based MASH [@ondovMashFastGenome2016] or dashing [@bakerDashingFastAccurate2019], or the neural network based NeuroSEED [@corsoNeuralDistanceEmbeddings2021].

Unsupervised learning can also be used without clustering, for example unsupervised methods based on maximum likelihood approaches have been used to predict mutational effects in protein sequence [@hopfMutationEffectsPredicted2017] as well as predict recombination hotspots in human genomic sequences [@castroModelSelectionApproach2018].

In many cases, unsupervised learning can be done as a preliminary dimensionality reduction step to a supervised learning task. Indeed biological data is often high-dimensional, and it is often useful to lower the amount of dimensions to speed up computations. Some unsupervised methods can reduce the number of dimensions while retaining most of the information. One such method, Principal Component Analysis (PCA), has been widely used. PCA was applied to distance matrices to compute phylogenetic trees [@haschkaMNHNTreeToolsToolboxTree2021], and work has been done to apply PCA directly to MSAs without needing to go through a distance matrix [@konishiPrincipalComponentAnalysis2019]. PCA is also widely used in clustering applications [@ben-hurDetectingStableClusters2003; @KmeansClusteringPrincipal; @casariSequencespaceToolFamily1995; @clampJalviewJavaAlignment2004].

### Others

-   task based: end-to-end training like aligning sequences, this is harder because it requires developing a custom differentiable scoring function based on the task.

    -   Predict P/P interactions [@townshendEndtoEndLearning3D2019]

    -   microRNA target prediction [@leeDeepTargetEndtoendLearning2016]

-   self-supervised, i.e. train on a proxy task and hope the model learns important features and useful stuff to continue on fully-unsupervised.

    -   Used to find useful info in disordered protein regions [@luDiscoveringMolecularFeatures2022]

    -   Protein language models: [@elnaggarProtTransCrackingLanguage2021]

-   semi-supervised, combined a small amount of labelled data with large amount of unlabeled data that the models can leverage.

    -   used to predict drug-protein interactions [@xiaSemisupervisedDrugproteinInteraction2010]

    -   and transmembrane protein topology [@tamposisSemisupervisedLearningHidden2019]

## How to learn ?

Machine learning regroups a multitude of techniques and methods to extract knowledge and make data-driven predictions. In this section we will quickly go over some of these supervised-learning methods, and go into more detail for techniques used in Chapter \@ref(HIV-paper).

### The general supervised learning paradigm

-   All these methods rely on data (here sequences and alignments)

    -   Usually we split available data into training data (on which the learning is done) and testing data (which we can use to asses the model performance). Sometimes we also have validation data used to evaluate the learning process.

    -   Important that each of these datasets are completely separate -\> avoid data leaks [@kaufmanLeakageDataMining2011].

-   Learning -\> optimization process:

    -   A method has an associated cost, i.e. a performance measure that translates how bad the method is doing at predicting the target on the training data (or a score that measure the good)

    -   We minimize the cost (maximize the score) iteratively over the training data.

    -   The cost function is also called loss function

-   Some semantics (however in a lot of literature cost = loss, e.g. [@Goodfellow-et-al-2016]).

    -   Loss = error we give to a single prediction

    -   Cost = sum of losses over the whole training set/batch

    -   Objective function = what we actually optimize, e.g. cost + regularization

-   Example of a classical cost function, many loss functions in ML [@wangComprehensiveSurveyLoss2022]:

    -   $y_i$ = i^th^real value of the target, $\hat{y}_i$ = i^th^predicted value, for binary classification, $p_i$ = probability that i^th^ observation is in positive class.

    -   regression: $RMSE = \sqrt{\frac{\Sigma^{N}_{i=1} (y_i - \hat{y}_i)^2 }{N}}$\

    -   classification: Cross-Entropy for binary classification: $\frac{1}{N}\sum_{i=1}^N-(y\cdot \log(p) + (1-y)\cdot\log(1-p))$

-   Some performance measures many performance measures (especially in classification [@jiaoPerformanceMeasuresEvaluating2016]) :

    -   Regression:

        -   RMSE see above

        -   $MAE=\frac{\Sigma_{i=1}^N \vert y_i - \hat{y}_i \vert}{N}$

    -   Classification:

        -   Accuracy $\frac{TP + TN}{P + N}$

        -   Balanced accuracy $\frac{TPR + TNR}{2}$

```{r, overfittingCaption}
overfittingCaption <- "**Overfitting behaviour in loss functions.**  
The two curves show how the loss calculated on the training set (blue) and the testing set (red) evolve as training time increases. At first both decrease showing that the model learns informative and generalizable features. At some point, training loss keeps decreasing and testing loss increases, meaning that the model is learning over-specific features on the training set and is no longer generalizable: it is overfitting."
```

```{r, overfitting, label="overfitting", fig.cap=overfittingCaption, eval=knitr::is_html_output(), out.width="70%"}
knitr::include_graphics("figures/Encode-seqs/Overfitting.png")
```

```{=tex}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/Encode-seqs/Overfitting.png}
\extcaption{Overfitting behaviour in loss functions.}{The two curves show how the loss calculated on the training set (blue) and the testing set (red) evolve as training time increases. At first both decrease showing that the model learns informative and generalizable features. At some point, training loss keeps decreasing and testing loss increases, meaning that the model is learning over-specific features on the training set and is no longer generalizable: it is overfitting.}
\label{fig:overfitting}
\end{figure}
```
-   Overfitting [@hastieElementsStatisticalLearning2009] :

    -   What is it ?

    -   How to detect it -\> schematic here of training and testing loss ref to Figure \@ref(fig:overfitting)

-   Cross validation, example of cross validation and schematic ?

    -   Figure to show cross validation

### Tests and statistical learning

-   Simple statistical methods have been used for a long time
-   Simplest possible method:
    -   Statistical testing (e.g. Fisher or Student test)

    -   You use 1 feature and see if if informative of the target, or build ensembles (c.f. Chapter \@ref(HIV-paper))

    -   Relatively poor predictive power.
-   More sophisticated is linear and logistic regression, for regression and classification respectively. [@hastieElementsStatisticalLearning2009]
    -   Model: prediction is weighted sum of numerical features + intercept.

    -   In logistic regression this sum is run through logistic function to get threshold for classification

    -   The loss function is RMSE

    -   Gradient descent is used to optimize the cost, Also exact analytical solution in the simplest case

    -   To avoid overfitting- \> regularization where the either ridge [@hoerlRidgeRegressionBiased1970] or lasso [@tibshiraniRegressionShrinkageSelection1996] .
-   Naive Bayes classifier [@hastieElementsStatisticalLearning2009]
    -   Conditional probabilities

    -   Plug in whatever distribution to compute probabilities

    -   Train with maximum likelihood

    -   Violation of principle (i.e. features are rarely independent)

    -   Retains pretty good predictive power [@zhangOptimalityNaiveBayes; @rishEmpiricalStudyNaive] despite the assumptions being violated
-   Other simple methods like KNN are also often used.

### More complex methods, machine learning

-   One of the first that was widely used and achieved good results in many problems: SVM for classification
    -   Optimal separation hyperplane -\> linear separation [@vapnikEstimationDependencesBased1982]

    -   Can perform non-linear classification with the kernel trick in the early 90's [@boserTrainingAlgorithmOptimal1992; @cortesSupportvectorNetworks1995]

    -   adapted to regression [@druckerSupportVectorRegression1996]
-   A very important algorithm RF:
    -   Introduced by Leo Breiman [@breimanRandomForests2001]

    -   Based on the CART decision tree method [@breimanClassificationRegressionTrees1983]

    -   Based on the Gini index / purity index

    -   Select random features when building a tree

    -   Make the trees vote to get prediction

    -   Good performance compared to other methods presented before [@caruanaEmpiricalComparisonSupervised2006a]
-   More complex variants of RF with boosting where features and input examples are weighted before sampling

Deep learning has been use more frequently and more broadly to get good results across a large number of tasks. This is also true in biological contexts, a short introduction to deep learning will be presented in Chapter \@ref(learning-alignments-an-interesting-perspective).

## Preprocessing the alignment for machine learning

In order to do some learning we need to have the data in digestible form

Most of the methods will transform an aligned sequence into a vector, and therefore the alignment as an input matrix.

Some methods do not use the info of alignment in the embedding directly but use in the training process.

### General purpose embeddings

review [@potdarComparativeStudyCategorical2017]

-   Simple labeling / ordinal coding, i.e. assigning an integer to each character (A=1, C=2, G=3, T=4)

    -   pb -\> assigning artificial order to a purely categorical variable, used in [@steinerDrugResistancePrediction2020a]

-   BItwise labeling -\> encode each character with $n$ bits, for nucleotides 2bits if no gaps (A=00, C=01, G=10, T=11) [@dufresneKmerFileFormat2022; @wrightUsingDECIPHERV22016] for AAs 5 bits necessary explored in [@zamaniAminoAcidEncoding2011]

    -   still a problem of order, for aas used in hashing and bloom filters ...

    -   Often used for hashing/indexing a sequence or compressing, but is also a used scheme in categorical variable encoding in machine learning.

-   One-Hot encoding, widely used: a variable with $d$ levels (for DNA $d=4$) is transformed to a length $d$ sparse binary vector, when the variable is equal to the $i^{th}$ level then the resulting vector has a 1 set in the $i^{th}$ position. (also called orthonormal [@singhEvolutionaryBasedOptimal2018])

    -   Used in Chapter \@ref(HIV-paper) and other papers [@budachPyssterClassificationBiological2018],

    -   one of the problems is the "curse of dimensionality" since the for a sequence of length $n$ we get $n\times d$ features, which can be quite large.

    -   Performance between OH and Ordinal can be quite similar [@choongEvaluationConvolutionaryNeural2017] but easily interpretable (important in Bio)

    -   Has been used for encoding protein sequences as early as 1988 [@qianPredictingSecondaryStructure1988]

```{r, generalEncodingCaption}
generalEncodingCaption <- "**Example of 3 general categorical encoding schemes**  
TODO
"
```

```{r, generalEncoding, label="generalEncoding", cache=FALSE, eval=knitr::is_html_output(), fig.cap=generalEncodingCaption, out.width="70%"}
knitr::include_graphics("figures/Encode-seqs/general_purpose.png")
```

```{=tex}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{figures/Encode-seqs/general_purpose.pdf}
\extcaption{Example of 3 general categorical encoding schemes}{TODO}
\label{fig:generalEncoding}
\end{figure}
```
-   Many general purpose categorical encodings, library in Python [@mcginnisScikitLearnContribCategoricalEncodingRelease2018]

### Biological sequence-specific embeddings

These embeddings were inspired by physico-chemical properties, many encodings in [@zamaniAminoAcidEncoding2011]:

-   AAIndex embedding, based on the the AAIndex database [@kawashima2008],

    -   each amino acid has a number real-valued physico-chemical properties so you can select a subset of them.

    -   A subset of properties identified as informative [@liPredictionProteinStructural2008]

    -   Available in the iFeature python package [@chenIFeaturePythonPackage2018]

    -   Also, combine features from AAIndex with PCA to get ensemble features and use top components [@nanniNewEncodingTechnique2011]

-   Groups:

    -   Based on the Venn diagram defined by Taylor [@taylorClassificationAminoAcid1986], grouping AAs by 9 properties (hydrophobic, polar, small, ...)

    -   We can get a 9-D vector for each residue

    -   An encoding based on that was used as early as 1987 to predict protein secondary structure [@zvelebilPredictionProteinSecondary1987]

    -   Later 5 more groups defined [@kremerMethodSystemComputer2009]

-   BLOMAP [@maetschkeBlomapEncodingAmino2005]:

    -   Non-linear projection of the BLOSUM62 substitution matrix to encode an amino acid in 5 dimensions

    -   Used to predict cleavage sites of HIV-1 protease [@singhEvolutionaryBasedOptimal2018]

-   Others:

    -   frequencies of amino acids -\> very coarse (but low dimensional)

    -   $k$-mer frequencies, often reffered to as $n$-gram encoding [@sahaNovelApproachFind2019], often $n=2$ since as $k$/$n$ grow the dimensions grow exponentially -\> with 20 AAs and $20^n$ dimensions per sequence.

    -   OETMAP, extension of BLOMAP [@gokNewFeatureEncoding2013]

    -   Codon graph encoding proposed in [@zamaniAminoAcidEncoding2011], where an AA is represented by a directed graph of all the codons that make up the AA. The 4x4 adjacency matrix is converted into a length 16 vector representing a single AA.

Other weirder embeddings: chaos game theory used to embed sequences:

-   Applications in BIoinfo [@lochelChaosGameRepresentation2021]

-   Applied for phylogenetics:

    -   classify SARS-CoV 2 sequences [@cartesAccurateFastClade2022] w/ DL

    -   [@niApplyingFrequencyChaos2021]

-   Predict AMR [@renPredictionAntimicrobialResistance2022]

In recent years there has been an explosion of learned embeddings, we will not be talking about it here since it is not useful for Chapter \@ref(HIV-paper), I will go over them shortly in Chapter \@ref(learning-alignments-an-interesting-perspective) however.

## Conclusion

-   Alignments and sequences rich in info

-   plenty to learn with ML

-   the choice of embedding / vector representation of sequences in the alignment is not a simple task

-   Guides what you are able to learn

-   Haven't gone over DL -\> chapter 7

\printbibliography[segment=\therefsegment,heading=subbibintoc,title={References for chapter \thechapter}]
