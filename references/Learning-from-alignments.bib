
@article{alkanGenomeStructuralVariation2011,
  abstract     = {Structural variation was originally defined as insertions, deletions and inversions greater than 1~kb in size, but with the sequencing of human genomes now becoming routine, the operational spectrum of structural variants has widened to include events {$>$}50~bp in length.The main focus of structural variant (SV) studies should be accurate characterization of the copy, content and structure of genomic variants.Methods to discover and genotype structural variation can be divided into two main types: experimental and computational.Experimental methods for discovering SVs include hybridization-based approaches (SNP microarrays and array comparative genomic hybridization) and single-molecule analysis (optical mapping). In addition, PCR-based techniques can be used to genotype SVs.Computational methods use genome sequencing data to discover and genotype SVs. There are four main computational approaches: read-pair, read-depth, split-read and sequence-assembly methods.All existing platforms and methods have different biases and limitations. Accurate characterization of the full spectrum of structural variation remains a challenge.},
  author       = {Alkan, Can and Coe, Bradley P. and Eichler, Evan E.},
  date         = {2011-05},
  doi          = {10.1038/nrg2958},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Alkan et al_2011_Genome structural variation discovery and genotyping.pdf;/Users/lucblassel/Zotero/storage/36DHR8ID/nrg2958.html},
  issn         = {1471-0064},
  issue        = {5},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {Bioinformatics,Genomics,Microarray analysis,Next-generation sequencing,Structural variation,Technology},
  langid       = {english},
  number       = {5},
  pages        = {363--376},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Genome Structural Variation Discovery and Genotyping},
  url          = {https://www.nature.com/articles/nrg2958},
  urldate      = {2022-09-11},
  volume       = {12}
}

@article{alquraishiMachineLearningProtein2021,
  abstract     = {Prediction of protein structure from sequence has been intensely studied for many decades, owing to the problem's importance and its uniquely well-defined physical and computational bases. While progress has historically ebbed and flowed, the past two years saw dramatic advances driven by the increasing “neuralization” of structure prediction pipelines, whereby computations previously based on energy models and sampling procedures are replaced by neural networks. The extraction of physical contacts from the evolutionary record; the distillation of sequence–structure patterns from known structures; the incorporation of templates from homologs in the Protein Databank; and the refinement of coarsely predicted structures into finely resolved ones have all been reformulated using neural networks. Cumulatively, this transformation has resulted in algorithms that can now predict single protein domains with a median accuracy of 2.1~Å, setting the stage for a foundational reconfiguration of the role of biomolecular modeling within the life sciences.},
  author       = {AlQuraishi, Mohammed},
  date         = {2021-12-01},
  doi          = {10.1016/j.cbpa.2021.04.005},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/AlQuraishi_2021_Machine learning in protein structure prediction.pdf;/Users/lucblassel/Zotero/storage/V53ENLVG/S1367593121000508.html},
  issn         = {1367-5931},
  journaltitle = {Current Opinion in Chemical Biology},
  keywords     = {Alphafold,Biophysics,Deep learning,Machine learning,Protein design,Protein folding,Protein modeling,Protein structure,Protein structure prediction},
  langid       = {english},
  pages        = {1--8},
  series       = {Mechanistic {{Biology}} * {{Machine Learning}} in {{Chemical Biology}}},
  shortjournal = {Current Opinion in Chemical Biology},
  title        = {Machine Learning in Protein Structure Prediction},
  url          = {https://www.sciencedirect.com/science/article/pii/S1367593121000508},
  urldate      = {2022-09-07},
  volume       = {65}
}

@article{ammad-ud-dinSystematicIdentificationFeature2017,
  abstract     = {A prime challenge in precision cancer medicine is to identify genomic and molecular features that are predictive of drug treatment responses in cancer cells. Although there are several computational models for accurate drug response prediction, these often lack the ability to infer which feature combinations are the most predictive, particularly for high-dimensional molecular datasets. As increasing amounts of diverse genome-wide data sources are becoming available, there is a need to build new computational models that can effectively combine these data sources and identify maximally predictive feature combinations.We present a novel approach that leverages on systematic integration of data sources to identify response predictive features of multiple drugs. To solve the modeling task we implement a Bayesian linear regression method. To further improve the usefulness of the proposed model, we exploit the known human cancer kinome for identifying biologically relevant feature combinations. In case studies with a synthetic dataset and two publicly available cancer cell line datasets, we demonstrate the improved accuracy of our method compared to the widely used approaches in drug response analysis. As key examples, our model identifies meaningful combinations of features for the well known EGFR, ALK, PLK and PDGFR inhibitors.The source code of the method is available at https://github.com/suleimank/mvlr.Supplementary data are available at Bioinformatics online.},
  author       = {Ammad-ud-din, Muhammad and Khan, Suleiman A and Wennerberg, Krister and Aittokallio, Tero},
  date         = {2017-07-15},
  doi          = {10.1093/bioinformatics/btx266},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ammad-ud-din et al_2017_Systematic identification of feature combinations for predicting drug response.pdf;/Users/lucblassel/Zotero/storage/4IDMRYKH/3953979.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {14},
  pages        = {i359-i368},
  shortjournal = {Bioinformatics},
  title        = {Systematic Identification of Feature Combinations for Predicting Drug Response with {{Bayesian}} Multi-View Multi-Task Linear Regression},
  url          = {https://doi.org/10.1093/bioinformatics/btx266},
  urldate      = {2022-09-07},
  volume       = {33}
}

@inproceedings{asadiRepresentationdimensionalityTradeoffBiological2019,
  abstract   = {Statistical inference from the analysis of biological sequences is widely used in the prediction of structure and biochemical functions of newly found macromolecules. For the application of machine learning methodologies such as kernel methods and artificial neural networks for such inference, variable length sequence data is often embedded in a finite dimensional real-valued space. The corresponding embedding dimensions are often high, leading to technical difficulties centred around the statistical concept of the curse of dimensionality. We demonstrate a trade-off between fidelity of representation of amino acids of proteins and the resulting dimensionality of the embedding space. Clustering chemically similar amino acids, thereby reducing the alphabet size, reduces the accuracy in their variation, but achieves a reduction in the corresponding feature space. We show this trade-off in three different problems of statistical inference, namely, protein-protein interaction, remote homology and secondary structure prediction. We show that in the reduced space performance often improves similar to what is seen in "diminishing returns" type reward-effort curves. We find alphabet reduction schemes taken from the literature, which are based on some biochemical rationale, perform significantly better than arbitrary random clustering of the alphabets. Statistical feature selection from the full 20 amino acid representation is not competitive with any of these. Dimensionality of representation has an important role when mapping sequence data onto fixed dimensions of an Euclidean space. This work shows that dimensionality reduction based on compressing the amino acid alphabet improves inference performance in two widely studied problems and degrades gracefully in the third. Alphabet reduction, which has a principled biochemical basis, is shown to be superior to feature selection which is purely a statistical exercise.},
  author     = {Asadi, Bahman and Niranjan, Mahesan},
  booktitle  = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  date       = {2019-07},
  doi        = {10.1109/IJCNN.2019.8852381},
  eventtitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Asadi_Niranjan_2019_Representation-dimensionality Trade-off in Biological Sequence-based Inference.pdf;/Users/lucblassel/Zotero/storage/5SW7B5PI/8852381.html},
  issn       = {2161-4407},
  keywords   = {Amino acids,Bioinformatics,Biological Sequence Analysis,Curse of Dimensionality,Encoding,Feature extraction,Kernel,Neural networks,Proteins},
  pages      = {1--7},
  title      = {Representation-Dimensionality {{Trade-off}} in {{Biological Sequence-based Inference}}}
}

@article{asgariContinuousDistributedRepresentation2015,
  abstract     = {We introduce a new representation and feature extraction method for biological sequences. Named bio-vectors (BioVec) to refer to biological sequences in general with protein-vectors (ProtVec) for proteins (amino-acid sequences) and gene-vectors (GeneVec) for gene sequences, this representation can be widely used in applications of deep learning in proteomics and genomics. In the present paper, we focus on protein-vectors that can be utilized in a wide array of bioinformatics investigations such as family classification, protein visualization, structure prediction, disordered protein identification, and protein-protein interaction prediction. In this method, we adopt artificial neural network approaches and represent a protein sequence with a single dense n-dimensional vector. To evaluate this method, we apply it in classification of 324,018 protein sequences obtained from Swiss-Prot belonging to 7,027 protein families, where an average family classification accuracy of 93\%±0.06\% is obtained, outperforming existing family classification methods. In addition, we use ProtVec representation to predict disordered proteins from structured proteins. Two databases of disordered sequences are used: the DisProt database as well as a database featuring the disordered regions of nucleoporins rich with phenylalanine-glycine repeats (FG-Nups). Using support vector machine classifiers, FG-Nup sequences are distinguished from structured protein sequences found in Protein Data Bank (PDB) with a 99.8\% accuracy, and unstructured DisProt sequences are differentiated from structured DisProt sequences with 100.0\% accuracy. These results indicate that by only providing sequence data for various proteins into this model, accurate information about protein structure can be determined. Importantly, this model needs to be trained only once and can then be applied to extract a comprehensive set of information regarding proteins of interest. Moreover, this representation can be considered as pre-training for various applications of deep learning in bioinformatics. The related data is available at Life Language Processing Website: http://llp.berkeley.edu and Harvard Dataverse: http://dx.doi.org/10.7910/DVN/JMFHTN.},
  author       = {Asgari, Ehsaneddin and Mofrad, Mohammad R. K.},
  date         = {2015-11-10},
  doi          = {10.1371/journal.pone.0141287},
  eprint       = {26555596},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Asgari_Mofrad_2015_Continuous Distributed Representation of Biological Sequences for Deep.pdf},
  issn         = {1932-6203},
  journaltitle = {PLoS ONE},
  number       = {11},
  pages        = {e0141287},
  pmcid        = {PMC4640716},
  shortjournal = {PLoS One},
  title        = {Continuous {{Distributed Representation}} of {{Biological Sequences}} for {{Deep Proteomics}} and {{Genomics}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640716/},
  urldate      = {2022-09-14},
  volume       = {10}
}

@article{bakerDashingFastAccurate2019,
  abstract     = {Dashing is a fast and accurate software tool for estimating similarities of genomes or sequencing datasets. It uses the HyperLogLog sketch together with cardinality estimation methods that are specialized for set unions and intersections. Dashing summarizes genomes more rapidly than previous MinHash-based methods while providing greater accuracy across a wide range of input sizes and sketch sizes. It can sketch and calculate pairwise distances for over 87K genomes in 6 minutes. Dashing is open source and available at https://github.com/dnbaker/dashing.},
  author       = {Baker, Daniel N. and Langmead, Ben},
  date         = {2019-12-04},
  doi          = {10.1186/s13059-019-1875-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Baker_Langmead_2019_Dashing.pdf;/Users/lucblassel/Zotero/storage/EKQSKWYJ/s13059-019-1875-0.html},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Alignment,Genomic distance,Hyperloglog,Metagenomics,Sequencing,Sketch data structures},
  number       = {1},
  pages        = {265},
  shortjournal = {Genome Biology},
  shorttitle   = {Dashing},
  title        = {Dashing: Fast and Accurate Genomic Distances with {{HyperLogLog}}},
  url          = {https://doi.org/10.1186/s13059-019-1875-0},
  urldate      = {2022-09-19},
  volume       = {20}
}

@article{balabanTreeClusterClusteringBiological2019,
  abstract     = {Clustering homologous sequences based on their similarity is a problem that appears in many bioinformatics applications. The fact that sequences cluster is ultimately the result of their phylogenetic relationships. Despite this observation and the natural ways in which a tree can define clusters, most applications of sequence clustering do not use a phylogenetic tree and instead operate on pairwise sequence distances. Due to advances in large-scale phylogenetic inference, we argue that tree-based clustering is under-utilized. We define a family of optimization problems that, given an arbitrary tree, return the minimum number of clusters such that all clusters adhere to constraints on their heterogeneity. We study three specific constraints, limiting (1) the diameter of each cluster, (2) the sum of its branch lengths, or (3) chains of pairwise distances. These three problems can be solved in time that increases linearly with the size of the tree, and for two of the three criteria, the algorithms have been known in the theoretical computer scientist literature. We implement these algorithms in a tool called TreeCluster, which we test on three applications: OTU clustering for microbiome data, HIV transmission clustering, and divide-and-conquer multiple sequence alignment. We show that, by using tree-based distances, TreeCluster generates more internally consistent clusters than alternatives and improves the effectiveness of downstream applications. TreeCluster is available at https://github.com/niemasd/TreeCluster.},
  author       = {Balaban, Metin and Moshiri, Niema and Mai, Uyen and Jia, Xingfan and Mirarab, Siavash},
  date         = {2019-08-22},
  doi          = {10.1371/journal.pone.0221068},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Balaban et al_2019_TreeCluster.pdf;/Users/lucblassel/Zotero/storage/FYK27Z6Y/article.html},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Algorithms,HIV,HIV epidemiology,Multiple alignment calculation,Phylogenetic analysis,Phylogenetics,Sequence alignment,Trees},
  langid       = {english},
  number       = {8},
  pages        = {e0221068},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS ONE},
  shorttitle   = {{{TreeCluster}}},
  title        = {{{TreeCluster}}: {{Clustering}} Biological Sequences Using Phylogenetic Trees},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0221068},
  urldate      = {2022-09-07},
  volume       = {14}
}

@incollection{ben-hurDetectingStableClusters2003,
  abstract  = {Clustering is one of the most commonly used tools in the analysis of gene expression data (1,2). The usage in grouping genes is based on the premise that coexpression is a result of coregulation. It is often used as a preliminary step in extracting gene networks and inference of gene function (3,4). Clustering of experiments can be used to discover novel phenotypic aspects of cells and tissues (3,5,6), including sensitivity to drugs (7), and can also detect artifacts of experimental conditions (8). Clustering and its applications in biology are presented in greater detail in Chapter 13(see also ref.9). While we focus on gene expression data in this chapter, the methodology presented here is applicable for other types of data as well.},
  author    = {Ben-Hur, Asa and Guyon, Isabelle},
  booktitle = {Functional {{Genomics}}: {{Methods}} and {{Protocols}}},
  date      = {2003},
  doi       = {10.1385/1-59259-364-X:159},
  editor    = {Brownstein, Michael J. and Khodursky, Arkady B.},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ben-Hur_Guyon_2003_Detecting Stable Clusters Using Principal Component Analysis.pdf},
  isbn      = {978-1-59259-364-4},
  keywords  = {Cluster Algorithm,Cluster Structure,Confusion Matrix,Gene Expression Data,Principal Component Analysis},
  langid    = {english},
  location  = {{Totowa, NJ}},
  pages     = {159--182},
  publisher = {{Humana Press}},
  series    = {Methods in {{Molecular Biology}}},
  title     = {Detecting {{Stable Clusters Using Principal Component Analysis}}},
  url       = {https://doi.org/10.1385/1-59259-364-X:159},
  urldate   = {2022-09-08}
}

@article{beplerLearningProteinLanguage2021a,
  abstract     = {Language models have recently emerged as a powerful machine-learning approach for distilling information from massive protein sequence databases. From readily available sequence data alone, these models discover evolutionary, structural, and functional organization across protein space. Using language models, we can encode amino-acid sequences into distributed vector representations that capture their structural and functional properties, as well as evaluate the evolutionary fitness of sequence variants. We discuss recent advances in protein language modeling and their applications to downstream protein property prediction problems. We then consider how these models can be enriched with prior biological knowledge and introduce an approach for encoding protein structural knowledge into the learned representations. The knowledge distilled by these models allows us to improve downstream function prediction through transfer learning. Deep protein language models are revolutionizing protein biology. They suggest new ways to approach protein and therapeutic design. However, further developments are needed to encode strong biological priors into protein language models and to increase their accessibility to the broader community.},
  author       = {Bepler, Tristan and Berger, Bonnie},
  date         = {2021-06-16},
  doi          = {10.1016/j.cels.2021.05.017},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Bepler_Berger_2021_Learning the protein language.pdf;/Users/lucblassel/Zotero/storage/J6Q5SBAB/S2405471221002039.html},
  issn         = {2405-4712},
  journaltitle = {Cell Systems},
  keywords     = {contact prediction,deep neural networks,inductive bias,language models,natural language processing,protein sequences,proteins,transfer learning,transmembrane region prediction},
  langid       = {english},
  number       = {6},
  pages        = {654-669.e3},
  shortjournal = {Cell Systems},
  shorttitle   = {Learning the Protein Language},
  title        = {Learning the Protein Language: {{Evolution}}, Structure, and Function},
  url          = {https://www.sciencedirect.com/science/article/pii/S2405471221002039},
  urldate      = {2022-09-16},
  volume       = {12}
}

@inproceedings{boserTrainingAlgorithmOptimal1992,
  abstract  = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
  author    = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
  booktitle = {Proceedings of the Fifth Annual Workshop on {{Computational}} Learning Theory},
  date      = {1992-07-01},
  doi       = {10.1145/130385.130401},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Boser et al_1992_A training algorithm for optimal margin classifiers.pdf},
  isbn      = {978-0-89791-497-0},
  location  = {{New York, NY, USA}},
  pages     = {144--152},
  publisher = {{Association for Computing Machinery}},
  series    = {{{COLT}} '92},
  title     = {A Training Algorithm for Optimal Margin Classifiers},
  url       = {https://doi.org/10.1145/130385.130401},
  urldate   = {2022-09-16}
}

@book{breimanClassificationRegressionTrees1983,
  author = {Breiman, L. and Friedman, Jerome H. and Olshen, Richard A. and Stone, C. J.},
  date   = {1983},
  doi    = {10.1201/9781315139470},
  ids    = {breimanClassificationRegressionTrees1984},
  title  = {Classification and Regression Trees}
}

@article{brouwerFeedforwardNetworkInput2002,
  abstract     = {The data on which a multi-layer perceptron (MLP) is to be trained to approximate a continuous function may have inputs that are categorical rather than numeric or quantitative such as color, gender, race, etc. A categorical variable causes a discontinuous relationship between an input variable and the output. A MLP, with connection matrices that multiply input values and sigmoid functions that further transform values, represents a continuous mapping in all input variables. A MLP therefore requires that all inputs correspond to numeric, continuously valued variables and represents a continuous function in all input variables. The way that this problem is usually dealt with is to replace the categorical values by numeric ones and treat them as if they were continuously valued. However, there is no meaningful correspondence between the continuous quantities generated this way and the original categorical values. Another approach is to encode the categorical portion of the input using 1-out-of-n encoding and include this code as input to the MLP. The approach in this paper is to segregate categorical variables from the continuous independent variables completely. The MLP is trained with multiple outputs; a separate output unit for each of the allowed combination of values of the categorical independent variables. During training the categorical value or combination of categorical values determines which of the output units should have the target value on it, with the remaining outputs being ‘do not care’. Three data sets were used for comparison of methods. Results show that this approach is much more effective than the conventional approach of assigning continuous variables to the categorical features. In case of the data set where there were several categorical variables the method proposed here is also more effective than the 1-out-of-n input method.},
  author       = {Brouwer, Roelof K.},
  date         = {2002-09-01},
  doi          = {10.1016/S0893-6080(02)00090-4},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Brouwer_2002_A feed-forward network for input that is both categorical and quantitative.pdf;/Users/lucblassel/Zotero/storage/SFQ2RJ9X/S0893608002000904.html},
  issn         = {0893-6080},
  journaltitle = {Neural Networks},
  keywords     = {Anova,Categorical variable regression,Feed forward neural networks,Indicator variables,Multi-layer perceptron,Nominal input},
  langid       = {english},
  number       = {7},
  pages        = {881--890},
  shortjournal = {Neural Networks},
  title        = {A Feed-Forward Network for Input That Is Both Categorical and Quantitative},
  url          = {https://www.sciencedirect.com/science/article/pii/S0893608002000904},
  urldate      = {2022-09-21},
  volume       = {15}
}

@inproceedings{brownLanguageModelsAre2020,
  abstract  = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  author    = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2020},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Brown et al_2020_Language Models are Few-Shot Learners.pdf},
  pages     = {1877--1901},
  publisher = {{Curran Associates, Inc.}},
  title     = {Language {{Models}} Are {{Few-Shot Learners}}},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
  urldate   = {2022-09-14},
  volume    = {33}
}

@article{budachPyssterClassificationBiological2018,
  abstract     = {Convolutional neural networks (CNNs) have been shown to perform exceptionally well in a variety of tasks, including biological sequence classification. Available implementations, however, are usually optimized for a particular task and difficult to reuse. To enable researchers to utilize these networks more easily, we implemented pysster, a Python package for training CNNs on biological sequence data. Sequences are classified by learning sequence and structure motifs and the package offers an automated hyper-parameter optimization procedure and options to visualize learned motifs along with information about their positional and class enrichment. The package runs seamlessly on CPU and GPU and provides a simple interface to train and evaluate a network with a handful lines of code. Using an RNA A-to-I editing dataset and cross-linking immunoprecipitation (CLIP)-seq binding site sequences, we demonstrate that pysster classifies sequences with higher accuracy than previous methods, such as GraphProt or ssHMM, and is able to recover known sequence and structure motifs.pysster is freely available at https://github.com/budach/pysster.Supplementary data are available at Bioinformatics online.},
  author       = {Budach, Stefan and Marsico, Annalisa},
  date         = {2018-09-01},
  doi          = {10.1093/bioinformatics/bty222},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Budach_Marsico_2018_pysster.pdf;/Users/lucblassel/Zotero/storage/VV566GW9/4962494.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {17},
  pages        = {3035--3037},
  shortjournal = {Bioinformatics},
  shorttitle   = {Pysster},
  title        = {Pysster: Classification of Biological Sequences by Learning Sequence and Structure Motifs with Convolutional Neural Networks},
  url          = {https://doi.org/10.1093/bioinformatics/bty222},
  urldate      = {2022-09-12},
  volume       = {34}
}

@misc{caiGenomewidePredictionSmall2020,
  abstract  = {Endogenous or surrogate ligands of a vast number of proteins remain unknown. Identification of small molecules that bind to these orphan proteins will not only shed new light into their biological functions but also provide new opportunities for drug discovery. Deep learning plays an increasing role in the prediction of chemical-protein interactions, but it faces several challenges in protein deorphanization. Bioassay data are highly biased to certain proteins, making it difficult to train a generalizable machine learning model for the proteins that are dissimilar from the ones in the training data set. Pre-training offers a general solution to improving the model generalization, but needs incorporation of domain knowledge and customization of task-specific supervised learning. To address these challenges, we develop a novel protein pre-training method, DIstilled Sequence Alignment Embedding (DISAE), and a module-based fine-tuning strategy for the protein deorphanization. In the benchmark studies, DISAE significantly improves the generalizability and outperforms the state-of-the-art methods with a large margin. The interpretability analysis of pre-trained model suggests that it learns biologically meaningful information. We further use DISAE to assign ligands to 649 human orphan G-Protein Coupled Receptors (GPCRs) and to cluster the human GPCRome by integrating their phylogenetic and ligand relationships. The promising results of DISAE open an avenue for exploring the chemical landscape of entire sequenced genomes.},
  author    = {Cai, Tian and Lim, Hansaim and Abbu, Kyra Alyssa and Qiu, Yue and Nussinov, Ruth and Xie, Lei},
  date      = {2020-08-05},
  doi       = {10.1101/2020.08.04.236729},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cai et al_2020_Genome-wide Prediction of Small Molecule Binding to Remote Orphan Proteins.pdf},
  langid    = {english},
  pages     = {2020.08.04.236729},
  publisher = {{bioRxiv}},
  title     = {Genome-Wide {{Prediction}} of {{Small Molecule Binding}} to {{Remote Orphan Proteins Using Distilled Sequence Alignment Embedding}}},
  url       = {https://www.biorxiv.org/content/10.1101/2020.08.04.236729v1},
  urldate   = {2022-09-14}
}

@misc{cartesAccurateFastClade2022,
  abstract  = {Background: Since the beginning of the COVID-19 pandemic there has been an explosion of sequencing of the SARS-CoV-2 virus, making it the most widely sequenced virus in the history. Several databases and tools have been created to keep track of genome sequences and variants of the virus, most notably the GISAID platform hosts millions of complete genome sequences, and it is continuously expanding every day. A challenging task is the development of fast and accurate tools that are able to distinguish between the different SARS-CoV-2 variants and assign them to a clade. Results: In this paper, we leverage the Frequency Chaos Game Representation (FCGR) and Convolutional Neural Networks (CNNs) to develop an original method that learns how to classify genome sequences that we implement into CouGaR-g, a tool for the clade assignment problem on SARS-CoV-2 sequences. On a testing subset of the GISAID, CouGaR-g achieves an 96.29\% overall accuracy, while a similar tool, Covidex, obtained a 77,12\% overall accuracy. As far as we know, our method is the first using Deep Learning and FCGR for intra-species classification. Furthermore, by using some feature importance methods CouGaR-g allows to identify k-mers that matches SARS-CoV-2 marker variants. Conclusions: By combining FCGR and CNNs, we develop a method that achieves a better accuracy than Covidex (which is based on Random Forest) for clade assignment of SARS-CoV-2 genome sequences, also thanks to our training on a much larger dataset, with comparable running times. Our method implemented in CouGaR-g is able to detect k-mers that capture relevant biological information that distinguishes the clades, known as marker variants. Availability: The trained models can be tested online providing a FASTA file (with one or multiple sequences) at https://huggingface.co/spaces/BIASLab/sars-cov-2-classification-fcgr. CouGaR-g is also available at https://github.com/AlgoLab/CouGaR-g under the GPL.},
  author    = {Cartes, Jorge Avila and Anand, Santosh and Ciccolella, Simone and Bonizzoni, Paola and Vedova, Gianluca Della},
  date      = {2022-06-13},
  doi       = {10.1101/2022.06.13.495912},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cartes et al_2022_Accurate and Fast Clade Assignment via Deep Learning and Frequency Chaos Game.pdf;/Users/lucblassel/Zotero/storage/2AL5W7MN/2022.06.13.html},
  langid    = {english},
  pages     = {2022.06.13.495912},
  publisher = {{bioRxiv}},
  title     = {Accurate and {{Fast Clade Assignment}} via {{Deep Learning}} and {{Frequency Chaos Game Representation}}},
  url       = {https://www.biorxiv.org/content/10.1101/2022.06.13.495912v1},
  urldate   = {2022-06-23}
}

@inproceedings{caruanaEmpiricalComparisonSupervised2006a,
  abstract  = {A number of supervised learning methods have been introduced in the last decade. Unfortunately, the last comprehensive empirical evaluation of supervised learning was the Statlog Project in the early 90's. We present a large-scale empirical comparison between ten supervised learning methods: SVMs, neural nets, logistic regression, naive bayes, memory-based learning, random forests, decision trees, bagged trees, boosted trees, and boosted stumps. We also examine the effect that calibrating the models via Platt Scaling and Isotonic Regression has on their performance. An important aspect of our study is the use of a variety of performance criteria to evaluate the learning methods.},
  author    = {Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle = {Proceedings of the 23rd International Conference on {{Machine}} Learning},
  date      = {2006-06-25},
  doi       = {10.1145/1143844.1143865},
  file      = {/Users/lucblassel/Zotero/storage/NYG38U2K/Caruana and Niculescu-Mizil - 2006 - An empirical comparison of supervised learning alg.pdf},
  ids       = {caruanaEmpiricalComparisonSupervised2006},
  isbn      = {978-1-59593-383-6},
  location  = {{New York, NY, USA}},
  pages     = {161--168},
  publisher = {{Association for Computing Machinery}},
  series    = {{{ICML}} '06},
  title     = {An Empirical Comparison of Supervised Learning Algorithms},
  url       = {https://doi.org/10.1145/1143844.1143865},
  urldate   = {2022-09-19}
}

@article{casariSequencespaceToolFamily1995,
  abstract = {The biological activity of a protein typically depends on the presence of a small number of functional residues. Identifying these residues from the amino acid sequences alone would be useful. Classically, strictly conserved residues are predicted to be functional but often conservation patterns are more complicated. Here, we present a novel method that exploits such patterns for the prediction of functional residues. The method uses a simple but powerful representation of entire proteins, as well as sequence residues as vectors in a generalised `sequence space'. Projection of these vectors onto a lower-dimensional space reveals groups of residues specific for particular subfamilies that are predicted to be directly involved in protein function. Based on the method we present testable predictions for sets of functional residues in SH2 domains and in the conserved box of cyclins.},
  author   = {Casari, Georg and Sander, Chris and Valencia, Alfonso},
  day      = {01},
  doi      = {10.1038/nsb0295-171},
  issn     = {1545-9985},
  journal  = {Nature Structural Biology},
  month    = {Feb},
  number   = {2},
  pages    = {171-178},
  title    = {A method to predict functional residues in proteins},
  url      = {https://doi.org/10.1038/nsb0295-171},
  volume   = {2},
  year     = {1995}
}

@article{castroModelSelectionApproach2018,
  abstract     = {In this paper we consider the problem of segmenting n aligned random sequences of equal length m into a finite number of independent blocks. We propose a penalized maximum likelihood criterion to infer simultaneously the number of points of independence as well as the position of each point. We show how to compute exactly the estimator by means of a dynamic programming algorithm with time complexity O(m2n). We also propose another method, called hierarchical algorithm, that provides an approximation to the estimator when the sample size increases and runs in time O\{mln(m)n\}. Our main theoretical results are the strong consistency of both estimators when the sample size n grows to infinity. We illustrate the convergence of these algorithms through some simulation examples and we apply the method to identify recombination hotspots in real SNPs data.},
  author       = {Castro, Bruno M. and Lemes, Renan B. and Cesar, Jonatas and Hünemeier, Tábita and Leonardi, Florencia},
  date         = {2018-09-01},
  doi          = {10.1016/j.jmva.2018.05.006},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Castro et al_2018_A model selection approach for multiple sequence segmentation and.pdf;/Users/lucblassel/Zotero/storage/B5XJ7QMB/S0047259X18302331.html},
  issn         = {0047-259X},
  journaltitle = {Journal of Multivariate Analysis},
  langid       = {english},
  pages        = {319--330},
  shortjournal = {Journal of Multivariate Analysis},
  title        = {A Model Selection Approach for Multiple Sequence Segmentation and Dimensionality Reduction},
  url          = {https://www.sciencedirect.com/science/article/pii/S0047259X18302331},
  urldate      = {2022-09-07},
  volume       = {167}
}

@article{chengMachineLearningInformation2006,
  abstract     = {Motivation: Recognizing proteins that have similar tertiary structure is the key step of template-based protein structure prediction methods. Traditionally, a variety of alignment methods are used to identify similar folds, based on sequence similarity and sequence-structure compatibility. Although these methods are complementary, their integration has not been thoroughly exploited. Statistical machine learning methods provide tools for integrating multiple features, but so far these methods have been used primarily for protein and fold classification, rather than addressing the retrieval problem of fold recognition-finding a proper template for a given query protein.Results: Here we present a two-stage machine learning, information retrieval, approach to fold recognition. First, we use alignment methods to derive pairwise similarity features for query-template protein pairs. We also use global profile–profile alignments in combination with predicted secondary structure, relative solvent accessibility, contact map and beta-strand pairing to extract pairwise structural compatibility features. Second, we apply support vector machines to these features to predict the structural relevance (i.e. in the same fold or not) of the query-template pairs. For each query, the continuous relevance scores are used to rank the templates. The FOLDpro approach is modular, scalable and effective. Compared with 11 other fold recognition methods, FOLDpro yields the best results in almost all standard categories on a comprehensive benchmark dataset. Using predictions of the top-ranked template, the sensitivity is ∼85, 56, and 27\% at the family, superfamily and fold levels respectively. Using the 5 top-ranked templates, the sensitivity increases to 90, 70, and 48\%.Availability: The FOLDpro server is available with the SCRATCH suite through .Contact:pfbaldi@ics.uci.eduSupplementary information: Supplementary data are available at},
  author       = {Cheng, Jianlin and Baldi, Pierre},
  date         = {2006-06-15},
  doi          = {10.1093/bioinformatics/btl102},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cheng_Baldi_2006_A machine learning information retrieval approach to protein fold recognition.pdf;/Users/lucblassel/Zotero/storage/A442X98H/206813.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {12},
  pages        = {1456--1463},
  shortjournal = {Bioinformatics},
  title        = {A Machine Learning Information Retrieval Approach to Protein Fold Recognition},
  url          = {https://doi.org/10.1093/bioinformatics/btl102},
  urldate      = {2022-08-19},
  volume       = {22}
}

@article{chengMachineLearningMethods2008,
  abstract     = {Machine learning methods are widely used in bioinformatics and computational and systems biology. Here, we review the development of machine learning methods for protein structure prediction, one of the most fundamental problems in structural biology and bioinformatics. Protein structure prediction is such a complex problem that it is often decomposed and attacked at four different levels: 1-D prediction of structural features along the primary sequence of amino acids; 2-D prediction of spatial relationships between amino acids; 3-D prediction of the tertiary structure of a protein; and 4-D prediction of the quaternary structure of a multiprotein complex. A diverse set of both supervised and unsupervised machine learning methods has been applied over the years to tackle these problems and has significantly contributed to advancing the state-of-the-art of protein structure prediction. In this paper, we review the development and application of hidden Markov models, neural networks, support vector machines, Bayesian methods, and clustering methods in 1-D, 2-D, 3-D, and 4-D protein structure predictions.},
  author       = {Cheng, Jianlin and Tegge, Allison N. and Baldi, Pierre},
  date         = {2008},
  doi          = {10.1109/RBME.2008.2008239},
  eventtitle   = {{{IEEE Reviews}} in {{Biomedical Engineering}}},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cheng et al_2008_Machine Learning Methods for Protein Structure Prediction.pdf;/Users/lucblassel/Zotero/storage/GTYARVJE/4664428.html},
  issn         = {1941-1189},
  journaltitle = {IEEE Reviews in Biomedical Engineering},
  keywords     = {Amino acids,Bioinformatics,Biology computing,Hidden Markov models,Learning systems,machine learning,Neural networks,Protein engineering,protein folding,protein structure prediction,Sequences,Support vector machines,Systems biology},
  pages        = {41--49},
  title        = {Machine {{Learning Methods}} for {{Protein Structure Prediction}}},
  volume       = {1}
}

@article{chenIFeaturePythonPackage2018,
  abstract     = {Structural and physiochemical descriptors extracted from sequence data have been widely used to represent sequences and predict structural, functional, expression and interaction profiles of proteins and peptides as well as DNAs/RNAs. Here, we present iFeature, a versatile Python-based toolkit for generating various numerical feature representation schemes for both protein and peptide sequences. iFeature is capable of calculating and extracting a comprehensive spectrum of 18 major sequence encoding schemes that encompass 53 different types of feature descriptors. It also allows users to extract specific amino acid properties from the AAindex database. Furthermore, iFeature integrates 12 different types of commonly used feature clustering, selection and dimensionality reduction algorithms, greatly facilitating training, analysis and benchmarking of machine-learning models. The functionality of iFeature is made freely available via an online web server and a stand-alone toolkit.http://iFeature.erc.monash.edu/; https://github.com/Superzchen/iFeature/.Supplementary data are available at Bioinformatics online.},
  author       = {Chen, Zhen and Zhao, Pei and Li, Fuyi and Leier, André and Marquez-Lago, Tatiana T and Wang, Yanan and Webb, Geoffrey I and Smith, A Ian and Daly, Roger J and Chou, Kuo-Chen and Song, Jiangning},
  date         = {2018-07-15},
  doi          = {10.1093/bioinformatics/bty140},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chen et al_2018_iFeature.pdf;/Users/lucblassel/Zotero/storage/PS5ICIGX/4924718.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {14},
  pages        = {2499--2502},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{iFeature}}},
  title        = {{{iFeature}}: A {{Python}} Package and Web Server for Features Extraction and Selection from Protein and Peptide Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/bty140},
  urldate      = {2022-09-12},
  volume       = {34}
}

@article{chenILearnIntegratedPlatform2020,
  abstract     = {With the explosive growth of biological sequences generated in the post-genomic era, one of the most challenging problems in bioinformatics and computational biology is to computationally characterize sequences, structures and functions in an efficient, accurate and high-throughput manner. A number of online web servers and stand-alone tools have been developed to address this to date; however, all these tools have their limitations and drawbacks in terms of their effectiveness, user-friendliness and capacity. Here, we present iLearn, a comprehensive and versatile Python-based toolkit, integrating the functionality of feature extraction, clustering, normalization, selection, dimensionality reduction, predictor construction, best descriptor/model selection, ensemble learning and results visualization for DNA, RNA and protein sequences. iLearn was designed for users that only want to upload their data set and select the functions they need calculated from it, while all necessary procedures and optimal settings are completed automatically by the software. iLearn includes a variety of descriptors for DNA, RNA and proteins, and four feature output formats are supported so as to facilitate direct output usage or communication with other computational tools. In total, iLearn encompasses 16 different types of feature clustering, selection, normalization and dimensionality reduction algorithms, and five commonly used machine-learning algorithms, thereby greatly facilitating feature analysis and predictor construction. iLearn is made freely available via an online web server and a stand-alone toolkit.},
  author       = {Chen, Zhen and Zhao, Pei and Li, Fuyi and Marquez-Lago, Tatiana T and Leier, André and Revote, Jerico and Zhu, Yan and Powell, David R and Akutsu, Tatsuya and Webb, Geoffrey I and Chou, Kuo-Chen and Smith, A Ian and Daly, Roger J and Li, Jian and Song, Jiangning},
  date         = {2020-05-18},
  doi          = {10.1093/bib/bbz041},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chen et al_2020_iLearn.pdf;/Users/lucblassel/Zotero/storage/J3QX2BKU/5475015.html},
  issn         = {1477-4054},
  journaltitle = {Briefings in Bioinformatics},
  number       = {3},
  pages        = {1047--1057},
  shortjournal = {Briefings in Bioinformatics},
  shorttitle   = {{{iLearn}}},
  title        = {{{iLearn}}: An Integrated Platform and Meta-Learner for Feature Engineering, Machine-Learning Analysis and Modeling of {{DNA}}, {{RNA}} and Protein Sequence Data},
  url          = {https://doi.org/10.1093/bib/bbz041},
  urldate      = {2022-09-07},
  volume       = {21}
}

@inproceedings{choongEvaluationConvolutionaryNeural2017,
  abstract   = {Convolutionary neural network (CNN) is a popular choice for supervised DNA motif prediction due to its excellent performances. To employ CNN, the input DNA sequences are required to be encoded as numerical values and represented as either vectors or multi-dimensional matrices. This paper evaluated a simple and more compact ordinal encoding method versus the popular one-hot encoding for DNA sequences. We compared the performances of both encoding methods using three sets of datasets enriched with DNA motifs. We found that the ordinal encoding performs comparable to the one-hot method but with significant reduction in training time. In addition, the one-hot encoding performances were rather consistent across various datasets but would require suitable CNN configuration to perform well. The ordinal encoding with matrix representation performed best in some of the evaluated datasets. This study implied that the performances of CNN for DNA motif discovery depends on the suitable design of the sequence encoding and representation. The good performances of the ordinal encoding method demonstrates that there are still rooms for improvement for the one-hot encoding method.},
  author     = {Choong, Allen Chieng Hoon and Lee, Nung Kion},
  booktitle  = {2017 {{International Conference}} on {{Computer}} and {{Drone Applications}} ({{IConDA}})},
  date       = {2017-11},
  doi        = {10.1109/ICONDA.2017.8270400},
  eventtitle = {2017 {{International Conference}} on {{Computer}} and {{Drone Applications}} ({{IConDA}})},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Choong_Lee_2017_Evaluation of convolutionary neural networks modeling of DNA sequences using.pdf;/Users/lucblassel/Zotero/storage/JA5DPXSP/8270400.html},
  keywords   = {Biological information theory,convolutionary neural networks,DNA,DNA sequence encoding,Encoding,Machine learning,Mice,motif discovery,Neural networks,Training},
  pages      = {60--65},
  title      = {Evaluation of Convolutionary Neural Networks Modeling of {{DNA}} Sequences Using Ordinal versus One-Hot Encoding Method}
}

@misc{choromanskiMaskedLanguageModeling2020,
  abstract      = {Transformer models have achieved state-of-the-art results across a diverse range of domains. However, concern over the cost of training the attention mechanism to learn complex dependencies between distant inputs continues to grow. In response, solutions that exploit the structure and sparsity of the learned attention matrix have blossomed. However, real-world applications that involve long sequences, such as biological sequence analysis, may fall short of meeting these assumptions, precluding exploration of these models. To address this challenge, we present a new Transformer architecture, Performer, based on Fast Attention Via Orthogonal Random features (FAVOR). Our mechanism scales linearly rather than quadratically in the number of tokens in the sequence, is characterized by sub-quadratic space complexity and does not incorporate any sparsity pattern priors. Furthermore, it provides strong theoretical guarantees: unbiased estimation of the attention matrix and uniform convergence. It is also backwards-compatible with pre-trained regular Transformers. We demonstrate its effectiveness on the challenging task of protein sequence modeling and provide detailed theoretical analysis.},
  archiveprefix = {arXiv},
  author        = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Belanger, David and Colwell, Lucy and Weller, Adrian},
  date          = {2020-09-30},
  doi           = {10.48550/arXiv.2006.03555},
  eprint        = {2006.03555},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Choromanski et al_2020_Masked Language Modeling for Proteins via Linearly Scalable Long-Context.pdf;/Users/lucblassel/Zotero/storage/G6BSHKGU/2006.html},
  keywords      = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  number        = {arXiv:2006.03555},
  primaryclass  = {cs, stat},
  publisher     = {{arXiv}},
  title         = {Masked {{Language Modeling}} for {{Proteins}} via {{Linearly Scalable Long-Context Transformers}}},
  url           = {http://arxiv.org/abs/2006.03555},
  urldate       = {2022-09-16}
}

@article{clampJalviewJavaAlignment2004,
  abstract     = {Summary: Multiple sequence alignment remains a crucial method for understanding the function of groups of related nucleic acid and protein sequences. However, it is known that automatic multiple sequence alignments can often be improved by manual editing. Therefore, tools are needed to view and edit multiple sequence alignments. Due to growth in the sequence databases, multiple sequence alignments can often be large and difficult to view efficiently. The Jalview Java alignment editor is presented here, which enables fast viewing and editing of large multiple sequence alignments.Availability: The Jar file and source code for Jalview is freely available via the World Wide Web at http://www.jalview.org. A Jalview mailing list is also available by e-mailing majordomo@sanger.ac.uk with subscribe Jalview in the body of the mail.},
  author       = {Clamp, Michele and Cuff, James and Searle, Stephen M. and Barton, Geoffrey J.},
  date         = {2004-02-12},
  doi          = {10.1093/bioinformatics/btg430},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Clamp et al_2004_The Jalview Java alignment editor.pdf;/Users/lucblassel/Zotero/storage/9VD3HE7H/186358.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {426--427},
  shortjournal = {Bioinformatics},
  title        = {The {{Jalview Java}} Alignment Editor},
  url          = {https://doi.org/10.1093/bioinformatics/btg430},
  urldate      = {2022-09-08},
  volume       = {20}
}

@inproceedings{corsoNeuralDistanceEmbeddings2021,
  abstract  = {The development of data-dependent heuristics and representations for biological sequences that reflect their evolutionary distance is critical for large-scale biological research. However, popular machine learning approaches, based on continuous Euclidean spaces, have struggled with the discrete combinatorial formulation of the edit distance that models evolution and the hierarchical relationship that characterises real-world datasets. We present Neural Distance Embeddings (NeuroSEED), a general framework to embed sequences in geometric vector spaces, and illustrate the effectiveness of the hyperbolic space that captures the hierarchical structure and provides an average 38\% reduction in embedding RMSE against the best competing geometry. The capacity of the framework and the significance of these improvements are then demonstrated devising supervised and unsupervised NeuroSEED approaches to multiple core tasks in bioinformatics. Benchmarked with common baselines, the proposed approaches display significant accuracy and/or runtime improvements on real-world datasets. As an example for hierarchical clustering, the proposed pretrained and from-scratch methods match the quality of competing baselines with 30x and 15x runtime reduction, respectively.},
  author    = {Corso, Gabriele and Ying, Zhitao and Pándy, Michal and Veličković, Petar and Leskovec, Jure and Liò, Pietro},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2021},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Corso et al_2021_Neural Distance Embeddings for Biological Sequences.pdf},
  pages     = {18539--18551},
  publisher = {{Curran Associates, Inc.}},
  title     = {Neural {{Distance Embeddings}} for {{Biological Sequences}}},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/9a1de01f893e0d2551ecbb7ce4dc963e-Abstract.html},
  urldate   = {2022-09-07},
  volume    = {34}
}

@article{cortesSupportvectorNetworks1995,
  abstract     = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
  author       = {Cortes, Corinna and Vapnik, Vladimir},
  date         = {1995-09-01},
  doi          = {10.1007/BF00994018},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cortes_Vapnik_1995_Support-vector networks.pdf},
  issn         = {1573-0565},
  journaltitle = {Machine Learning},
  keywords     = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
  langid       = {english},
  number       = {3},
  pages        = {273--297},
  shortjournal = {Mach Learn},
  title        = {Support-Vector Networks},
  url          = {https://doi.org/10.1007/BF00994018},
  urldate      = {2022-09-16},
  volume       = {20}
}

@misc{devlinBERTPretrainingDeep2019,
  abstract      = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arXiv},
  author        = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  date          = {2019-05-24},
  doi           = {10.48550/arXiv.1810.04805},
  eprint        = {1810.04805},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Devlin et al_2019_BERT.pdf;/Users/lucblassel/Zotero/storage/EABG33FG/1810.html},
  keywords      = {Computer Science - Computation and Language},
  number        = {arXiv:1810.04805},
  primaryclass  = {cs},
  publisher     = {{arXiv}},
  shorttitle    = {{{BERT}}},
  title         = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  url           = {http://arxiv.org/abs/1810.04805},
  urldate       = {2022-09-14}
}

@inproceedings{dingKmeansClusteringPrincipal2004,
  abstract  = {Principal component analysis (PCA) is a widely used statistical technique for unsupervised dimension reduction. K-means clustering is a commonly used data clustering for performing unsupervised learning tasks. Here we prove that principal components are the continuous solutions to the discrete cluster membership indicators for K-means clustering. New lower bounds for K-means objective function are derived, which is the total variance minus the eigenvalues of the data covariance matrix. These results indicate that unsupervised dimension reduction is closely related to unsupervised learning. Several implications are discussed. On dimension reduction, the result provides new insights to the observed effectiveness of PCA-based data reductions, beyond the conventional noise-reduction explanation that PCA, via singular value decomposition, provides the best low-dimensional linear approximation of the data. On learning, the result suggests effective techniques for K-means data clustering. DNA gene expression and Internet newsgroups are analyzed to illustrate our results. Experiments indicate that the new bounds are within 0.5-1.5\% of the optimal values.},
  author    = {Ding, Chris and He, Xiaofeng},
  booktitle = {Proceedings of the Twenty-First International Conference on {{Machine}} Learning},
  date      = {2004-07-04},
  doi       = {10.1145/1015330.1015408},
  isbn      = {978-1-58113-838-2},
  location  = {{New York, NY, USA}},
  pages     = {29},
  publisher = {{Association for Computing Machinery}},
  series    = {{{ICML}} '04},
  title     = {K-Means Clustering via Principal Component Analysis},
  url       = {https://doi.org/10.1145/1015330.1015408},
  urldate   = {2022-09-23}
}

@inproceedings{druckerSupportVectorRegression1996,
  abstract  = {A  new  regression  technique  based  on  Vapnik's  concept  of  support  vectors  is  introduced.  We compare  support  vector  regression  (SVR)  with  a  committee regression  technique  (bagging)  based  on  regression  trees  and  ridge regression  done in  feature space.  On  the basis of these  experiments,  it  is  expected  that  SVR  will  have  advantages  in  high  dimensionality space because SVR optimization does not depend on the  dimensionality of the input space.},
  author    = {Drucker, Harris and Burges, Christopher J. C. and Kaufman, Linda and Smola, Alex and Vapnik, Vladimir},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {1996},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Drucker et al_1996_Support Vector Regression Machines.pdf},
  publisher = {{MIT Press}},
  title     = {Support {{Vector Regression Machines}}},
  url       = {https://proceedings.neurips.cc/paper/1996/hash/d38901788c533e8286cb6400b40b386d-Abstract.html},
  urldate   = {2022-09-16},
  volume    = {9}
}

@article{dufresneKmerFileFormat2022,
  abstract     = {Bioinformatics applications increasingly rely on ad hoc disk storage of k-mer sets, e.g. for de Bruijn graphs or alignment indexes. Here, we introduce the K-mer File Format as a general lossless framework for storing and manipulating k-mer sets, realizing space savings of 3–5× compared to other formats, and bringing interoperability across tools.Format specification, C++/Rust API, tools: https://github.com/Kmer-File-Format/.Supplementary data are available at Bioinformatics online.},
  author       = {Dufresne, Yoann and Lemane, Teo and Marijon, Pierre and Peterlongo, Pierre and Rahman, Amatur and Kokot, Marek and Medvedev, Paul and Deorowicz, Sebastian and Chikhi, Rayan},
  date         = {2022-07-29},
  doi          = {10.1093/bioinformatics/btac528},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Dufresne et al_2022_The K-mer File Format.pdf;/Users/lucblassel/Zotero/storage/936LNKIC/6651834.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  pages        = {btac528},
  shortjournal = {Bioinformatics},
  shorttitle   = {The {{K-mer File Format}}},
  title        = {The {{K-mer File Format}}: A Standardized and Compact Disk Representation of Sets of k-Mers},
  url          = {https://doi.org/10.1093/bioinformatics/btac528},
  urldate      = {2022-09-12}
}

@article{eickholtDoBoProteinDomain2011,
  abstract     = {Accurate identification of protein domain boundaries is useful for protein structure determination and prediction. However, predicting protein domain boundaries from a sequence is still very challenging and largely unsolved.},
  author       = {Eickholt, Jesse and Deng, Xin and Cheng, Jianlin},
  date         = {2011-02-01},
  doi          = {10.1186/1471-2105-12-43},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Eickholt et al_2011_DoBo.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Decision Threshold,Domain Boundary,Domain Definition,Relative Solvent Accessibility,Support Vector Machine},
  langid       = {english},
  number       = {1},
  pages        = {43},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{DoBo}}},
  title        = {{{DoBo}}: {{Protein}} Domain Boundary Prediction by Integrating Evolutionary Signals and Machine Learning},
  url          = {https://doi.org/10.1186/1471-2105-12-43},
  urldate      = {2022-08-19},
  volume       = {12}
}

@misc{elnaggarProtTransCrackingLanguage2021,
  abstract      = {Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81\%-87\%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81\%) and membrane vs. water-soluble (2-state accuracy Q2=91\%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life. To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans.},
  archiveprefix = {arXiv},
  author        = {Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rihawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and Bhowmik, Debsindhu and Rost, Burkhard},
  date          = {2021-05-04},
  doi           = {10.48550/arXiv.2007.06225},
  eprint        = {2007.06225},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Elnaggar et al_2021_ProtTrans.pdf;/Users/lucblassel/Zotero/storage/993N66DS/2007.html},
  keywords      = {Computer Science - Computation and Language,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  number        = {arXiv:2007.06225},
  primaryclass  = {cs, stat},
  publisher     = {{arXiv}},
  shorttitle    = {{{ProtTrans}}},
  title         = {{{ProtTrans}}: {{Towards Cracking}} the {{Language}} of {{Life}}'s {{Code Through Self-Supervised Deep Learning}} and {{High Performance Computing}}},
  url           = {http://arxiv.org/abs/2007.06225},
  urldate       = {2022-09-07}
}

@article{elnaggarProtTransCrackingLanguage2021b,
  abstract     = {Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models taken from NLP. These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The LMs were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw protein LM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks. The first was a per-residue prediction of protein secondary structure (3-state accuracy Q3=81\%-87\%); the second were per-protein predictions of protein sub-cellular localization (ten-state accuracy: Q10=81\%) and membrane vs. water soluble (2-state accuracy Q2=91\%). For the per-residue predictions the transfer of the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without using evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that protein LMs learned some of the grammar of the language of life. To facilitate future work, we released our models at https://github.com/agemagician/ProtTrans.},
  author       = {Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rehawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and Bhowmik, Debsindhu and Rost, Burkhard},
  date         = {2021-07-07},
  doi          = {10.1109/TPAMI.2021.3095381},
  eprint       = {34232869},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Elnaggar et al_2021_ProtTrans2.pdf},
  issn         = {1939-3539},
  journaltitle = {IEEE transactions on pattern analysis and machine intelligence},
  langid       = {english},
  shortjournal = {IEEE Trans Pattern Anal Mach Intell},
  shorttitle   = {{{ProtTrans}}},
  title        = {{{ProtTrans}}: {{Towards Cracking}} the {{Language}} of {{Lifes Code Through Self-Supervised Deep Learning}} and {{High Performance Computing}}},
  volume       = {PP}
}

@article{fisherInterpretationH2Contingency1922,
  author       = {Fisher, R. A.},
  date         = {1922},
  doi          = {10.2307/2340521},
  eprint       = {2340521},
  eprinttype   = {jstor},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Fisher_1922_On the Interpretation of χ2 from Contingency Tables, and the Calculation of P.pdf},
  issn         = {0952-8385},
  journaltitle = {Journal of the Royal Statistical Society},
  number       = {1},
  pages        = {87--94},
  publisher    = {{[Wiley, Royal Statistical Society]}},
  title        = {On the {{Interpretation}} of Χ2 from {{Contingency Tables}}, and the {{Calculation}} of {{P}}},
  volume       = {85}
}

@article{fuCDHITAcceleratedClustering2012,
  abstract     = {Summary: CD-HIT is a widely used program for clustering biological sequences to reduce sequence redundancy and improve the performance of other sequence analyses. In response to the rapid increase in the amount of sequencing data produced by the next-generation sequencing technologies, we have developed a new CD-HIT program accelerated with a novel parallelization strategy and some other techniques to allow efficient clustering of such datasets. Our tests demonstrated very good speedup derived from the parallelization for up to ∼24 cores and a quasi-linear speedup for up to ∼8 cores. The enhanced CD-HIT is capable of handling very large datasets in much shorter time than previous versions.Availability:http://cd-hit.org.Contact:liwz@sdsc.eduSupplementary information:Supplementary data are available at Bioinformatics online.},
  author       = {Fu, Limin and Niu, Beifang and Zhu, Zhengwei and Wu, Sitao and Li, Weizhong},
  date         = {2012-12-01},
  doi          = {10.1093/bioinformatics/bts565},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Fu et al_2012_CD-HIT.pdf;/Users/lucblassel/Zotero/storage/K4ZF8PJD/192160.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {23},
  pages        = {3150--3152},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{CD-HIT}}},
  title        = {{{CD-HIT}}: Accelerated for Clustering the next-Generation Sequencing Data},
  url          = {https://doi.org/10.1093/bioinformatics/bts565},
  urldate      = {2022-09-19},
  volume       = {28}
}

@article{gokNewFeatureEncoding2013,
  abstract     = {HIV-1 protease has been the subject of intense research for deciphering HIV-1 virus replication process for decades. Knowledge of the substrate specificity of HIV-1 protease will enlighten the way of development of HIV-1 protease inhibitors. In the prediction of HIV-1 protease cleavage site techniques, various feature encoding techniques and machine learning algorithms have been used frequently. In this paper, a new feature amino acid encoding scheme is proposed to predict HIV-1 protease cleavage sites. In the proposed method, we combined orthonormal encoding and Taylor’s venn-diagram. We used linear support vector machines as the classifier in the tests. We also analyzed our technique by comparing some feature encoding techniques. The tests are carried out on PR-1625 and PR-3261 datasets. Experimental results show that our amino acid encoding technique leads to better classification performance than other encoding techniques on a standalone classifier.},
  author       = {Gök, Murat and Özcerit, Ahmet Turan},
  date         = {2013-06-01},
  doi          = {10.1007/s00521-012-0967-5},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Gök_Özcerit_2013_A new feature encoding scheme for HIV-1 protease cleavage site prediction.pdf},
  issn         = {1433-3058},
  journaltitle = {Neural Computing and Applications},
  keywords     = {Feature encoding scheme,Feature extraction,HIV-1 protease specificity,Peptide classification},
  langid       = {english},
  number       = {7},
  pages        = {1757--1761},
  shortjournal = {Neural Comput \& Applic},
  title        = {A New Feature Encoding Scheme for {{HIV-1}} Protease Cleavage Site Prediction},
  url          = {https://doi.org/10.1007/s00521-012-0967-5},
  urldate      = {2022-09-13},
  volume       = {22}
}

@misc{goldbergWord2vecExplainedDeriving2014,
  abstract      = {The word2vec software of Tomas Mikolov and colleagues (https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in "Distributed Representations of Words and Phrases and their Compositionality" by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.},
  archiveprefix = {arXiv},
  author        = {Goldberg, Yoav and Levy, Omer},
  date          = {2014-02-15},
  doi           = {10.48550/arXiv.1402.3722},
  eprint        = {1402.3722},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Goldberg_Levy_2014_word2vec Explained.pdf;/Users/lucblassel/Zotero/storage/H9BW45RS/1402.html},
  keywords      = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  number        = {arXiv:1402.3722},
  primaryclass  = {cs, stat},
  publisher     = {{arXiv}},
  shorttitle    = {Word2vec {{Explained}}},
  title         = {Word2vec {{Explained}}: Deriving {{Mikolov}} et al.'s Negative-Sampling Word-Embedding Method},
  url           = {http://arxiv.org/abs/1402.3722},
  urldate       = {2022-09-13}
}

@book{goodfellowDeepLearning2016,
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date      = {2016},
  publisher = {{MIT Press}},
  title     = {Deep Learning},
  url       = {http://www.deeplearningbook.org}
}

@article{hagaMachineLearningbasedTreatment2020,
  abstract     = {In recent years, the development of diagnostics using artificial intelligence (AI) has been remarkable. AI algorithms can go beyond human reasoning and build diagnostic models from a number of complex combinations. Using next-generation sequencing technology, we identified hepatitis C virus (HCV) variants resistant to directing-acting antivirals (DAA) by whole genome sequencing of full-length HCV genomes, and applied these variants to various machine-learning algorithms to evaluate a preliminary predictive model. HCV genomic RNA was extracted from serum from 173 patients (109 with subsequent sustained virological response [SVR] and 64 without) before DAA treatment. HCV genomes from the 109 SVR and 64 non-SVR patients were randomly divided into a training data set (57 SVR and 29 non-SVR) and a validation-data set (52 SVR and 35 non-SVR). The training data set was subject to nine machine-learning algorithms selected to identify the optimized combination of functional variants in relation to SVR status following DAA therapy. Subsequently, the prediction model was tested by the validation-data set. The most accurate learning method was the support vector machine (SVM) algorithm (validation accuracy, 0.95; kappa statistic, 0.90; F-value, 0.94). The second-most accurate learning algorithm was Multi-layer perceptron. Unfortunately, Decision Tree, and Naive Bayes algorithms could not be fitted with our data set due to low accuracy ({$<$} 0.8). Conclusively, with an accuracy rate of 95.4\% in the generalization performance evaluation, SVM was identified as the best algorithm. Analytical methods based on genomic analysis and the construction of a predictive model by machine-learning may be applicable to the selection of the optimal treatment for other viral infections and cancer.},
  author       = {Haga, Hiroaki and Sato, Hidenori and Koseki, Ayumi and Saito, Takafumi and Okumoto, Kazuo and Hoshikawa, Kyoko and Katsumi, Tomohiro and Mizuno, Kei and Nishina, Taketo and Ueno, Yoshiyuki},
  date         = {2020-11-05},
  doi          = {10.1371/journal.pone.0242028},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Haga et al_2020_A machine learning-based treatment prediction model using whole genome variants.pdf;/Users/lucblassel/Zotero/storage/3VWTQ6KH/article.html},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Algorithms,Amino acid analysis,Forecasting,Genomics,Hepatitis C virus,Machine learning algorithms,Next-generation sequencing,Support vector machines},
  langid       = {english},
  number       = {11},
  pages        = {e0242028},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS ONE},
  title        = {A Machine Learning-Based Treatment Prediction Model Using Whole Genome Variants of Hepatitis {{C}} Virus},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242028},
  urldate      = {2022-09-07},
  volume       = {15}
}

@article{haschkaMNHNTreeToolsToolboxTree2021,
  abstract     = {Genomic sequences are widely used to infer the evolutionary history of a given group of individuals. Many methods have been developed for sequence clustering and tree building. In the early days of genome sequencing, these were often limited to hundreds of sequences but due to the surge of high throughput sequencing, it is now common to have millions of sampled sequences at hand. We introduce MNHN-Tree-Tools, a high performance set of algorithms that builds multi-scale, nested clusters of sequences found in a FASTA file. MNHN-Tree-Tools does not rely on multiple sequence alignment and can thus be used on large datasets to infer a sequence tree. Herein, we outline two applications: a human alpha-satellite repeats classification and a tree of life derivation from 16S/18S rDNA sequences.Open source with a Zlib License via the Git protocol: https://gitlab.in2p3.fr/mnhn-tools/mnhn-tree-tools.A detailed users guide and tutorial: https://gitlab.in2p3.fr/mnhn-tools/mnhn-tree-tools-manual/-/raw/master/manual.pdf.http://treetools.haschka.net.Supplementary data are available at Bioinformatics online.},
  author       = {Haschka, Thomas and Ponger, Loic and Escudé, Christophe and Mozziconacci, Julien},
  date         = {2021-11-01},
  doi          = {10.1093/bioinformatics/btab430},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Haschka et al_2021_MNHN-Tree-Tools.pdf;/Users/lucblassel/Zotero/storage/3729D55H/6294927.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {21},
  pages        = {3947--3949},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{MNHN-Tree-Tools}}},
  title        = {{{MNHN-Tree-Tools}}: A Toolbox for Tree Inference Using Multi-Scale Clustering of a Set of Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/btab430},
  urldate      = {2022-09-08},
  volume       = {37}
}

@article{hassanisaadiInterpretiveTimefrequencyAnalysis2017,
  abstract     = {Time-Frequency (TF) analysis has been extensively used for the analysis of non-stationary numeric signals in the past decade. At the same time, recent studies have statistically confirmed the non-stationarity of genomic non-numeric sequences and suggested the use of non-stationary analysis for these sequences. The conventional approach to analyze non-numeric genomic sequences using techniques specific to numerical data is to convert non-numerical data into numerical values in some way and then apply time or transform domain signal processing algorithms. Nevertheless, this approach raises questions regarding the relative magnitudes under numeric transforms, which can potentially lead to spurious patterns or misinterpretation of results.},
  author       = {Hassani Saadi, Hamed and Sameni, Reza and Zollanvari, Amin},
  date         = {2017-03-22},
  doi          = {10.1186/s12859-017-1524-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hassani Saadi et al_2017_Interpretive time-frequency analysis of genomic sequences.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Genomic signal processing,Interpretive signal processing,Time-frequency analysis},
  langid       = {english},
  number       = {4},
  pages        = {154},
  shortjournal = {BMC Bioinformatics},
  title        = {Interpretive Time-Frequency Analysis of Genomic Sequences},
  url          = {https://doi.org/10.1186/s12859-017-1524-0},
  urldate      = {2022-09-21},
  volume       = {18}
}

@article{hieEvolutionaryVelocityProtein2022a,
  abstract     = {The degree to which evolution is predictable is a fundamental question in biology. Previous attempts to predict the evolution of protein sequences have been limited to specific proteins and to small changes, such as single-residue mutations. Here, we demonstrate that by using a protein language model to predict the local evolution within protein families, we recover a dynamic “vector field” of protein evolution that we call evolutionary velocity (evo-velocity). Evo-velocity generalizes to evolution over vastly different timescales, from viral proteins evolving over years to eukaryotic proteins evolving over geologic eons, and can predict the evolutionary dynamics of proteins that were not used to develop the original model. Evo-velocity also yields new evolutionary insights by predicting strategies of viral-host immune escape, resolving conflicting theories on the evolution of serpins, and revealing a key role of horizontal gene transfer in the evolution of eukaryotic glycolysis.},
  author       = {Hie, Brian L. and Yang, Kevin K. and Kim, Peter S.},
  date         = {2022-04-20},
  doi          = {10.1016/j.cels.2022.01.003},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hie et al_2022_Evolutionary velocity with protein language models predicts evolutionary.pdf;/Users/lucblassel/Zotero/storage/7CW9YWCE/S2405471222000382.html},
  issn         = {2405-4712},
  journaltitle = {Cell Systems},
  keywords     = {evolutionary dynamics,evolutionary predictability,fitness landscape,language models,machine learning,phylogenetic analysis},
  langid       = {english},
  number       = {4},
  pages        = {274-285.e6},
  shortjournal = {Cell Systems},
  title        = {Evolutionary Velocity with Protein Language Models Predicts Evolutionary Dynamics of Diverse Proteins},
  url          = {https://www.sciencedirect.com/science/article/pii/S2405471222000382},
  urldate      = {2022-09-16},
  volume       = {13}
}

@article{hoerlRidgeRegressionBiased1970,
  abstract     = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X′X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X′X to obtain biased estimates with smaller mean square error.},
  annotation   = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00401706.1970.10488634},
  author       = {Hoerl, Arthur E. and Kennard, Robert W.},
  date         = {1970-02-01},
  doi          = {10.1080/00401706.1970.10488634},
  issn         = {0040-1706},
  journaltitle = {Technometrics},
  keywords     = {Ridge Regression: A Historical Context},
  number       = {1},
  pages        = {55--67},
  publisher    = {{Taylor \& Francis}},
  shorttitle   = {Ridge {{Regression}}},
  title        = {Ridge {{Regression}}: {{Biased Estimation}} for {{Nonorthogonal Problems}}},
  url          = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634},
  urldate      = {2022-09-19},
  volume       = {12}
}

@article{hopfMutationEffectsPredicted2017,
  abstract     = {The global effects of epistasis on protein and RNA function are revealed by an unsupervised model of amino acid co-conservation in evolutionary sequence variation.},
  author       = {Hopf, Thomas A. and Ingraham, John B. and Poelwijk, Frank J. and Schärfe, Charlotta P. I. and Springer, Michael and Sander, Chris and Marks, Debora S.},
  date         = {2017-02},
  doi          = {10.1038/nbt.3769},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hopf et al_2017_Mutation effects predicted from sequence co-variation.pdf;/Users/lucblassel/Zotero/storage/CI5CY5J4/nbt.html},
  issn         = {1546-1696},
  issue        = {2},
  journaltitle = {Nature Biotechnology},
  keywords     = {Computational models,Molecular evolution,Mutation,Protein function predictions},
  langid       = {english},
  number       = {2},
  pages        = {128--135},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Biotechnol},
  title        = {Mutation Effects Predicted from Sequence Co-Variation},
  url          = {https://www.nature.com/articles/nbt.3769},
  urldate      = {2022-09-07},
  volume       = {35}
}

@article{hoStructuralVariationSequencing2020,
  abstract     = {Identifying structural variation (SV) is essential for genome interpretation but has been historically difficult due to limitations inherent to available genome technologies. Detection methods that use ensemble algorithms and emerging sequencing technologies have enabled the discovery of thousands of SVs, uncovering information about their ubiquity, relationship to disease and possible effects on biological mechanisms. Given the variability in SV type and size, along with unique detection biases of emerging genomic platforms, multiplatform discovery is necessary to resolve the full spectrum of variation. Here, we review modern approaches for investigating SVs and proffer that, moving forwards, studies integrating biological information with detection will be necessary to comprehensively understand the impact of SV in the human genome.},
  author       = {Ho, Steve S. and Urban, Alexander E. and Mills, Ryan E.},
  date         = {2020-03},
  doi          = {10.1038/s41576-019-0180-9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ho et al_2020_Structural variation in the sequencing era.pdf;/Users/lucblassel/Zotero/storage/QSL4J94Y/s41576-019-0180-9.html},
  issn         = {1471-0064},
  issue        = {3},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {DNA sequencing,Genetic variation,Genomics,Next-generation sequencing,Structural variation},
  langid       = {english},
  number       = {3},
  pages        = {171--189},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Structural Variation in the Sequencing Era},
  url          = {https://www.nature.com/articles/s41576-019-0180-9},
  urldate      = {2022-09-11},
  volume       = {21}
}

@online{HowManyWords,
  file         = {/Users/lucblassel/Zotero/storage/JPAVCG5I/faq-how-many-english-words.html},
  organization = {{Merriam-Webster}},
  title        = {How Many Words Are There in {{English}}?},
  url          = {https://www.merriam-webster.com/help/faq-how-many-english-words},
  urldate      = {2022-09-13}
}

@article{jeffreyChaosGameRepresentation1990,
  abstract     = {This paper presents a new method for representing DNA sequences. It permits the representation and investigation of patterns in sequences, visually revealing previously unknown structures. Based on a technique from chaotic dynamics, the method produces a picture of a gene sequence which displays both local and global patterns. The pictures have a complex structure which varies depending on the sequence. The method is termed Chaos Game Representation (CGR) . CGR raises a new set of questions about the structure of DNA sequences, and is a new tool for investigating gene structure.},
  author       = {Jeffrey, H.Joel},
  date         = {1990-04-25},
  doi          = {10.1093/nar/18.8.2163},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jeffrey_1990_Chaos game representation of gene structure.pdf;/Users/lucblassel/Zotero/storage/V4JQLEIK/2383530.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {8},
  pages        = {2163--2170},
  shortjournal = {Nucleic Acids Research},
  title        = {Chaos Game Representation of Gene Structure},
  url          = {https://doi.org/10.1093/nar/18.8.2163},
  urldate      = {2022-06-23},
  volume       = {18}
}

@article{jeffreyChaosGameRepresentation1990a,
  abstract     = {This paper presents a new method for representing DNA sequences. It permits the representation and investigation of patterns in sequences, visually revealing previously unknown structures. Based on a technique from chaotic dynamics, the method produces a picture of a gene sequence which displays both local and global patterns. The pictures have a complex structure which varies depending on the sequence. The method is termed Chaos Game Representation (CGR). CGR raises a new set of questions about the structure of DNA sequences, and is a new tool for investigating gene structure.},
  author       = {Jeffrey, H J},
  date         = {1990-04-25},
  eprint       = {2336393},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jeffrey_1990_Chaos game representation of gene structure2.pdf},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {8},
  pages        = {2163--2170},
  pmcid        = {PMC330698},
  shortjournal = {Nucleic Acids Res},
  title        = {Chaos Game Representation of Gene Structure.},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC330698/},
  urldate      = {2022-09-21},
  volume       = {18}
}

@article{jiaoPerformanceMeasuresEvaluating2016,
  abstract     = {Many existing bioinformatics predictors are based on machine learning technology. When applying these predictors in practical studies, their predictive performances should be well understood. Different performance measures are applied in various studies as well as different evaluation methods. Even for the same performance measure, different terms, nomenclatures or notations may appear in different context.},
  author       = {Jiao, Yasen and Du, Pufeng},
  date         = {2016-12-01},
  doi          = {10.1007/s40484-016-0081-2},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jiao_Du_2016_Performance measures in evaluating machine learning based bioinformatics.pdf},
  issn         = {2095-4697},
  journaltitle = {Quantitative Biology},
  keywords     = {evaluation methods,machine learning,performance measures},
  langid       = {english},
  number       = {4},
  pages        = {320--330},
  shortjournal = {Quant Biol},
  title        = {Performance Measures in Evaluating Machine Learning Based Bioinformatics Predictors for Classifications},
  url          = {https://doi.org/10.1007/s40484-016-0081-2},
  urldate      = {2022-09-19},
  volume       = {4}
}

@article{jiDNABERTPretrainedBidirectional2021,
  abstract     = {Deciphering the language of non-coding DNA is one of the fundamental problems in genome research. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios.To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, to capture global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We compared DNABERT to the most widely used programs for genome-wide regulatory elements prediction and demonstrate its ease of use, accuracy and efficiency. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on prediction of promoters, splice sites and transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variant candidates. Finally, we demonstrate that pre-trained DNABERT with human genome can even be readily applied to other organisms with exceptional performance. We anticipate that the pre-trained DNABERT model can be fined tuned to many other sequence analyses tasks.The source code, pretrained and finetuned model for DNABERT are available at GitHub (https://github.com/jerryji1993/DNABERT).Supplementary data are available at Bioinformatics online.},
  author       = {Ji, Yanrong and Zhou, Zhihan and Liu, Han and Davuluri, Ramana V},
  date         = {2021-08-01},
  doi          = {10.1093/bioinformatics/btab083},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ji et al_2021_DNABERT.pdf;/Users/lucblassel/Zotero/storage/VTD9JQRC/6128680.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {15},
  pages        = {2112--2120},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{DNABERT}}},
  title        = {{{DNABERT}}: Pre-Trained {{Bidirectional Encoder Representations}} from {{Transformers}} Model for {{DNA-language}} in Genome},
  url          = {https://doi.org/10.1093/bioinformatics/btab083},
  urldate      = {2022-09-16},
  volume       = {37}
}

@article{jonesProteinSecondaryStructure1999a,
  abstract     = {A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST. Despite the simplicity and convenience of the approach used, the results are found to be superior to those produced by other methods, including the popular PHD method according to our own benchmarking results and the results from the recent Critical Assessment of Techniques for Protein Structure Prediction experiment (CASP3), where the method was evaluated by stringent blind testing. Using a new testing set based on a set of 187 unique folds, and three-way cross-validation based on structural similarity criteria rather than sequence similarity criteria used previously (no similar folds were present in both the testing and training sets) the method presented here (PSIPRED) achieved an average Q3score of between 76.5 \% to 78.3 \% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date. Given the success of the method in CASP3, it is reasonable to be confident that the evaluation presented here gives a fair indication of the performance of the method in general.},
  author       = {Jones, David T},
  date         = {1999-09-17},
  doi          = {10.1006/jmbi.1999.3091},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jones_1999_Protein secondary structure prediction based on position-specific scoring.pdf;/Users/lucblassel/Zotero/storage/SU9ZIZ3U/S0022283699930917.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {neural network,protein folding,protein structure prediction,secondary structure,sequence analysis},
  langid       = {english},
  number       = {2},
  pages        = {195--202},
  shortjournal = {Journal of Molecular Biology},
  title        = {Protein Secondary Structure Prediction Based on Position-Specific Scoring {{matrices11Edited}} by {{G}}. {{Von Heijne}}},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022283699930917},
  urldate      = {2022-09-07},
  volume       = {292}
}

@article{kapliPhylogeneticTreeBuilding2020,
  abstract     = {Knowing phylogenetic relationships among species is fundamental for many studies in biology. An accurate phylogenetic tree underpins our understanding of the major transitions in evolution, such as the emergence of new body plans or metabolism, and is key to inferring the origin of new genes, detecting molecular adaptation, understanding morphological character evolution and reconstructing demographic changes in recently diverged species. Although data are ever more plentiful and powerful analysis methods are available, there remain many challenges to reliable tree building. Here, we discuss the major steps of phylogenetic analysis, including identification of orthologous genes or proteins, multiple sequence alignment, and choice of substitution models and inference methodologies. Understanding the different sources of errors and the strategies to mitigate them is essential for assembling an accurate tree of life.},
  author       = {Kapli, Paschalia and Yang, Ziheng and Telford, Maximilian J.},
  date         = {2020-07},
  doi          = {10.1038/s41576-020-0233-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kapli et al_2020_Phylogenetic tree building in the genomic age.pdf;/Users/lucblassel/Zotero/storage/WVUDHD4J/s41576-020-0233-0.html},
  issn         = {1471-0064},
  issue        = {7},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {Evolutionary genetics,Molecular evolution,Phylogenetics,Phylogenomics},
  langid       = {english},
  number       = {7},
  pages        = {428--444},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Phylogenetic Tree Building in the Genomic Age},
  url          = {https://www.nature.com/articles/s41576-020-0233-0},
  urldate      = {2022-09-11},
  volume       = {21}
}

@inproceedings{kaufmanLeakageDataMining2011,
  abstract   = {Deemed "one of the top ten data mining mistakes", leakage is essentially the introduction of information about the data mining target, which should not be legitimately available to mine from. In addition to our own industry experience with real-life projects, controversies around several major public data mining competitions held recently such as the INFORMS 2010 Data Mining Challenge and the IJCNN 2011 Social Network Challenge are evidence that this issue is as relevant today as it has ever been. While acknowledging the importance and prevalence of leakage in both synthetic competitions and real-life data mining projects, existing literature has largely left this idea unexplored. What little has been said turns out not to be broad enough to cover more complex cases of leakage, such as those where the classical i.i.d. assumption is violated, that have been recently documented. In our new approach, these cases and others are explained by explicitly defining modeling goals and analyzing the broader framework of the data mining problem. The resulting definition enables us to derive general methodology for dealing with the issue. We show that it is possible to avoid leakage with a simple specific approach to data management followed by what we call a learn-predict separation, and present several ways of detecting leakage when the modeler has no control over how the data have been collected.},
  author     = {Kaufman, Shachar and Rosset, Saharon and Perlich, Claudia},
  booktitle  = {Proceedings of the 17th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  date       = {2011-08-21},
  doi        = {10.1145/2020408.2020496},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kaufman et al_2011_Leakage in data mining.pdf},
  isbn       = {978-1-4503-0813-7},
  keywords   = {data mining,leakage,predictive modeling,statistical inference},
  location   = {{New York, NY, USA}},
  pages      = {556--563},
  publisher  = {{Association for Computing Machinery}},
  series     = {{{KDD}} '11},
  shorttitle = {Leakage in Data Mining},
  title      = {Leakage in Data Mining: Formulation, Detection, and Avoidance},
  url        = {https://doi.org/10.1145/2020408.2020496},
  urldate    = {2022-09-19}
}

@article{kelleyBassetLearningRegulatory2016,
  abstract     = {The complex language of eukaryotic gene expression remains incompletely understood. Despite the importance suggested by many noncoding variants statistically associated with human disease, nearly all such variants have unknown mechanisms. Here, we address this challenge using an approach based on a recent machine learning advance—deep convolutional neural networks (CNNs). We introduce the open source package Basset to apply CNNs to learn the functional activity of DNA sequences from genomics data. We trained Basset on a compendium of accessible genomic sites mapped in 164 cell types by DNase-seq, and demonstrate greater predictive accuracy than previous methods. Basset predictions for the change in accessibility between variant alleles were far greater for Genome-wide association study (GWAS) SNPs that are likely to be causal relative to nearby SNPs in linkage disequilibrium with them. With Basset, a researcher can perform a single sequencing assay in their cell type of interest and simultaneously learn that cell's chromatin accessibility code and annotate every mutation in the genome with its influence on present accessibility and latent potential for accessibility. Thus, Basset offers a powerful computational approach to annotate and interpret the noncoding genome.},
  author       = {Kelley, David R. and Snoek, Jasper and Rinn, John L.},
  date         = {2016-07},
  doi          = {10.1101/gr.200535.115},
  eprint       = {27197224},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kelley et al_2016_Basset.pdf},
  issn         = {1088-9051},
  journaltitle = {Genome Research},
  number       = {7},
  pages        = {990--999},
  pmcid        = {PMC4937568},
  shortjournal = {Genome Res},
  shorttitle   = {Basset},
  title        = {Basset: Learning the Regulatory Code of the Accessible Genome with Deep Convolutional Neural Networks},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937568/},
  urldate      = {2022-09-07},
  volume       = {26}
}

@article{kimMachineLearningAntimicrobial2022,
  author       = {Kim, Jee In and Maguire, Finlay and Tsang, Kara K. and Gouliouris, Theodore and Peacock, Sharon J. and McAllister, Tim A. and McArthur, Andrew G. and Beiko, Robert G.},
  date         = {2022-05-25},
  doi          = {10.1128/cmr.00179-21},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kim et al_2022_Machine Learning for Antimicrobial Resistance Prediction.pdf},
  journaltitle = {Clinical Microbiology Reviews},
  number       = {0},
  pages        = {e00179-21},
  publisher    = {{American Society for Microbiology}},
  shorttitle   = {Machine {{Learning}} for {{Antimicrobial Resistance Prediction}}},
  title        = {Machine {{Learning}} for {{Antimicrobial Resistance Prediction}}: {{Current Practice}}, {{Limitations}}, and {{Clinical Perspective}}},
  url          = {https://journals.asm.org/doi/full/10.1128/cmr.00179-21},
  urldate      = {2022-09-07},
  volume       = {0}
}

@misc{kimothiDistributedRepresentationsBiological2016,
  abstract      = {Biological sequence comparison is a key step in inferring the relatedness of various organisms and the functional similarity of their components. Thanks to the Next Generation Sequencing efforts, an abundance of sequence data is now available to be processed for a range of bioinformatics applications. Embedding a biological sequence over a nucleotide or amino acid alphabet in a lower dimensional vector space makes the data more amenable for use by current machine learning tools, provided the quality of embedding is high and it captures the most meaningful information of the original sequences. Motivated by recent advances in the text document embedding literature, we present a new method, called seq2vec, to represent a complete biological sequence in an Euclidean space. The new representation has the potential to capture the contextual information of the original sequence necessary for sequence comparison tasks. We test our embeddings with protein sequence classification and retrieval tasks and demonstrate encouraging outcomes.},
  archiveprefix = {arXiv},
  author        = {Kimothi, Dhananjay and Soni, Akshay and Biyani, Pravesh and Hogan, James M.},
  date          = {2016-09-12},
  doi           = {10.48550/arXiv.1608.05949},
  eprint        = {1608.05949},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kimothi et al_2016_Distributed Representations for Biological Sequence Analysis.pdf;/Users/lucblassel/Zotero/storage/D2XD3PSU/1608.html},
  keywords      = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods},
  number        = {arXiv:1608.05949},
  primaryclass  = {cs, q-bio},
  publisher     = {{arXiv}},
  title         = {Distributed {{Representations}} for {{Biological Sequence Analysis}}},
  url           = {http://arxiv.org/abs/1608.05949},
  urldate       = {2022-09-14}
}

@inproceedings{kimothiMetricLearningBiological2017,
  abstract   = {Embedding techniques such as word2vec [1] have gained popularity due to their ability to represent words and their semantic variants as real valued vectors. Biological sequence analysis may also leverage unsupervised feature representations, augmented with supervised learning techniques for tasks like retrieval and classification. Algorithms that rely on distance metrics are computationally efficient and can handle large datasets, however, default distances in the embedded space often yield inadequate accuracy. In this paper, we use class labels to learn a Mahalanobis distance in the embedded feature vector space and show performance improvements over the default Euclidean metric in both retrieval and classification tasks. The approach may be readily generalised, and is and applicable to a wide range of problems in sequence analysis and others involving discrete entities or segmented data streams.},
  author     = {Kimothi, Dhananjay and Shukla, Ankita and Biyani, Pravesh and Anand, Saket and Hogan, James M.},
  booktitle  = {2017 {{IEEE}} 18th {{International Workshop}} on {{Signal Processing Advances}} in {{Wireless Communications}} ({{SPAWC}})},
  date       = {2017-07},
  doi        = {10.1109/SPAWC.2017.8227769},
  eventtitle = {2017 {{IEEE}} 18th {{International Workshop}} on {{Signal Processing Advances}} in {{Wireless Communications}} ({{SPAWC}})},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kimothi et al_2017_Metric learning on biological sequence embeddings.pdf;/Users/lucblassel/Zotero/storage/JUMLW3CK/authors.html},
  issn       = {1948-3252},
  keywords   = {Bioinformatics,Euclidean distance,Proteins,Training},
  pages      = {1--5},
  title      = {Metric Learning on Biological Sequence Embeddings}
}

@article{kingsfordWhatAreDecision2008,
  abstract     = {Decision trees have been applied to problems such as assigning protein function and predicting splice sites. How do these classifiers work, what types of problems can they solve and what are their advantages over alternatives?},
  author       = {Kingsford, Carl and Salzberg, Steven L.},
  date         = {2008-09},
  doi          = {10.1038/nbt0908-1011},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kingsford_Salzberg_2008_What are decision trees.pdf;/Users/lucblassel/Zotero/storage/28ESLAM6/nbt0908-1011.html},
  issn         = {1546-1696},
  issue        = {9},
  journaltitle = {Nature Biotechnology},
  keywords     = {Agriculture,Bioinformatics,Biomedical Engineering/Biotechnology,Biomedicine,Biotechnology,general,Life Sciences},
  langid       = {english},
  number       = {9},
  pages        = {1011--1013},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Biotechnol},
  title        = {What Are Decision Trees?},
  url          = {https://www.nature.com/articles/nbt0908-1011},
  urldate      = {2022-09-20},
  volume       = {26}
}

@article{koboldtBestPracticesVariant2020,
  abstract     = {Next-generation sequencing technologies have enabled a dramatic expansion of clinical genetic testing both for inherited conditions and diseases such as cancer. Accurate variant calling in NGS data is a critical step upon which virtually all downstream analysis and interpretation processes rely. Just as NGS technologies have evolved considerably over the past 10~years, so too have the software tools and approaches for detecting sequence variants in clinical samples. In this review, I discuss the current best practices for variant calling in clinical sequencing studies, with a particular emphasis on trio sequencing for inherited disorders and somatic mutation detection in cancer patients. I describe the relative strengths and weaknesses of panel, exome, and whole-genome sequencing for variant detection. Recommended tools and strategies for calling variants of different classes are also provided, along with guidance on variant review, validation, and benchmarking to ensure optimal performance. Although NGS technologies are continually evolving, and new capabilities (such as long-read single-molecule sequencing) are emerging, the “best practice” principles in this review should be relevant to clinical variant calling in the long term.},
  author       = {Koboldt, Daniel C.},
  date         = {2020-10-26},
  doi          = {10.1186/s13073-020-00791-w},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Koboldt_2020_Best practices for variant calling in clinical sequencing.pdf;/Users/lucblassel/Zotero/storage/CU42XEQF/s13073-020-00791-w.html},
  issn         = {1756-994X},
  journaltitle = {Genome Medicine},
  keywords     = {Best practices,Cancer sequencing,Clinical sequencing,Mutation detection,Next-generation sequencing,Variant calling},
  number       = {1},
  pages        = {91},
  shortjournal = {Genome Medicine},
  title        = {Best Practices for Variant Calling in Clinical Sequencing},
  url          = {https://doi.org/10.1186/s13073-020-00791-w},
  urldate      = {2022-09-11},
  volume       = {12}
}

@article{konishiPrincipalComponentAnalysis2019,
  abstract     = {Sequence data is now widely used to observe relationships among organisms. However, understanding structure of the qualitative data is challenging. Conventionally, the relationships are analysed using a dendrogram that estimates a tree shape. This approach has difficulty in verifying the appropriateness of the tree shape; rather, horizontal gene transfers and mating can make the shape of the relationship as networks. As a connection-free approach, principal component analysis (PCA) is used to summarize the distance matrix, which records distances between each combination of samples. However, this approach is limited regarding the treatment of information of sequence motifs; distances caused by different motifs are mixed up. This hides clues to figure out how the samples are different. As any bases may change independently, a sequence is multivariate data essentially. Hence, differences among samples and bases that contribute to the difference should be observed coincidentally. To archive this, the sequence matrix is transferred to boolean vector and directly analysed by using PCA. The effects are confirmed in diversity of Asiatic lion and human as well as environmental DNA. Resolution of samples and robustness of calculation is improved. Relationship of a direction of difference and causative nucleotides has become obvious at a glance.},
  author       = {Konishi, Tomokazu and Matsukuma, Shiori and Fuji, Hayami and Nakamura, Daiki and Satou, Nozomi and Okano, Kunihiro},
  date         = {2019-12-17},
  doi          = {10.1038/s41598-019-55253-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Konishi et al_2019_Principal Component Analysis applied directly to Sequence Matrix.pdf;/Users/lucblassel/Zotero/storage/6X8GSH2P/s41598-019-55253-0.html},
  issn         = {2045-2322},
  issue        = {1},
  journaltitle = {Scientific Reports},
  keywords     = {Comparative genomics,Evolutionary biology,Speciation},
  langid       = {english},
  number       = {1},
  pages        = {19297},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Sci Rep},
  title        = {Principal {{Component Analysis}} Applied Directly to {{Sequence Matrix}}},
  url          = {https://www.nature.com/articles/s41598-019-55253-0},
  urldate      = {2022-09-08},
  volume       = {9}
}

@patent{kremerMethodSystemComputer2009,
  abstract = {A method is provided for predicting the structure of a macromolecule by modeling the folding process from the unfolded to the folded state based on machine learning a training set of known structures.},
  author   = {Kremer, Stefan and Lac, Hao},
  date     = {2009-01-22},
  file     = {/Users/lucblassel/Google Drive/Zotero_papers/kremer_lac_2009_method,_system_and_computer_program_product_for.pdf},
  holder   = {{University of Guelph}},
  keywords = {known,macromolecule,primary sequence,state,structure},
  number   = {20090024375A1},
  title    = {Method, System and Computer Program Product for Levinthal Process Induction from Known Structure Using Machine Learning},
  type     = {patentus},
  url      = {https://patents.google.com/patent/US20090024375A1/en},
  urldate  = {2018-09-19}
}

@article{kriventsevaClusteringAnalysisProtein2001,
  abstract     = {Various sequence-motif and sequence-cluster databases have been integrated into a new resource known as InterPro. Because the contributing databases have different clustering principles and scoring sensitivities, the combined assignments complement each other for grouping protein families and delineating domains. InterPro and new developments in the analysis of both the phylogenetic profiles of protein families and domain fusion events improve the prediction of specific functions for numerous proteins.},
  author       = {Kriventseva, Evgenia V and Biswas, Margaret and Apweiler, Rolf},
  date         = {2001-06-01},
  doi          = {10.1016/S0959-440X(00)00211-6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kriventseva et al_2001_Clustering and analysis of protein families.pdf;/Users/lucblassel/Zotero/storage/LJPYZY4D/S0959440X00002116.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  keywords     = {phylogenetic profiles,protein clusters,Protein families,Rosetta stone proteins,sequence alignment,sequence motifs,structure/functional relationships},
  langid       = {english},
  number       = {3},
  pages        = {334--339},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Clustering and Analysis of Protein Families},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X00002116},
  urldate      = {2022-09-19},
  volume       = {11}
}

@article{kuhlmanAdvancesProteinStructure2019,
  abstract     = {The prediction of protein three-dimensional structure from amino acid sequence has been a grand challenge problem in computational biophysics for decades, owing to its intrinsic scientific interest and also to the many potential applications for robust protein structure prediction algorithms, from genome interpretation to protein function prediction. More recently, the inverse problem — designing an amino acid sequence that will fold into a specified three-dimensional structure — has attracted growing attention as a potential route to the rational engineering of proteins with functions useful in biotechnology and medicine. Methods for the prediction and design of protein structures have advanced dramatically in the past decade. Increases in computing power and the rapid growth in protein sequence and structure databases have fuelled the development of new data-intensive and computationally demanding approaches for structure prediction. New algorithms for designing protein folds and protein–protein interfaces have been used to engineer novel high-order assemblies and to design from scratch fluorescent proteins with novel or enhanced properties, as well as signalling proteins with therapeutic potential. In this Review, we describe current approaches for protein structure prediction and design and highlight a selection of the successful applications they have enabled.},
  author       = {Kuhlman, Brian and Bradley, Philip},
  date         = {2019-11},
  doi          = {10.1038/s41580-019-0163-x},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kuhlman_Bradley_2019_Advances in protein structure prediction and design.pdf;/Users/lucblassel/Zotero/storage/UBF82QCA/s41580-019-0163-x.html},
  issn         = {1471-0080},
  issue        = {11},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  keywords     = {Computational models,Machine learning,Molecular engineering,Protein design,Protein structure predictions},
  langid       = {english},
  number       = {11},
  pages        = {681--697},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Mol Cell Biol},
  title        = {Advances in Protein Structure Prediction and Design},
  url          = {https://www.nature.com/articles/s41580-019-0163-x},
  urldate      = {2022-09-11},
  volume       = {20}
}

@inproceedings{kunanbayevComplexEncoding2021,
  abstract   = {A salient problem in machine learning is transforming categorical variables into efficient numerical features. This focus is warranted due to the ubiquity of categorical data in real-world applications but, on the contrary, the development of many machine learning methods based on the assumption of having numerical variables. Perhaps the most popular existing categorical to numerical conversion techniques include one-hot encoding, thermometer encoding, and ordinal (integer) encoding. One-hot and thermometer encodings become computationally inefficient and may lead to ill-conditioning for high-cardinality categorical variables as they create high-dimensional data matrices. As ordinal encoding does not change data dimensionality, it is significantly more memory-efficient; however, the spurious ordering induced by ordinal encoding among unordered categorical values can hamstring the performance of constructed predictive models. In this paper, we propose a new encoding technique, namely complex encoding, that provides a symmetric representation of categorical values in the complex plane. To show the efficacy of the complex encoding in terms of error rate and memory usage, we conducted a set of numerical experiments using real datasets and the family of linear discriminant functions for complex Gaussian distributions. Empirical results show that not only complex encoding avoids the ill-conditioning problem of one-hot and thermometer encodings, it can generally lead to a comparable or higher classification accuracy with respect to others (when they are applicable) at the expense of only about two-fold increase in memory usage with respect to ordinal encoding.},
  author     = {Kunanbayev, Kassymzhomart and Temirbek, Islambek and Zollanvari, Amin},
  booktitle  = {2021 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  date       = {2021-07},
  doi        = {10.1109/IJCNN52387.2021.9534094},
  eventtitle = {2021 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kunanbayev et al_2021_Complex Encoding.pdf;/Users/lucblassel/Zotero/storage/HHLSBC5V/9534094.html},
  issn       = {2161-4407},
  keywords   = {Error analysis,Machine learning,Memory management,Neural networks,Software libraries,Symmetric matrices,Thermometers},
  pages      = {1--6},
  title      = {Complex {{Encoding}}}
}

@article{kyriakidouCurrentStrategiesPolyploid2018,
  abstract     = {Polyploidy or duplication of an entire genome occurs in the majority of angiosperms. The understanding of polyploid genomes is important for the improvement of those crops, which humans rely on for sustenance and basic nutrition. As climate change continues to pose a potential threat to agricultural production, there will increasingly be a demand for plant cultivars that can resist biotic and abiotic stresses and also provide needed and improved nutrition. In the past decade, Next Generation Sequencing (NGS) has fundamentally changed the genomics landscape by providing tools for the exploration of polyploid genomes. Here, we review the challenges of the assembly of polyploid plant genomes, and also present recent advances in genomic resources and functional tools in molecular genetics and breeding. As genomes of diploid and less heterozygous progenitor species are increasingly available, we discuss the lack of complexity of these currently available reference genomes as they relate to polyploid crops. Finally, we review recent approaches of haplotyping by phasing and the impact of third generation technologies on polyploid plant genome assembly.},
  author       = {Kyriakidou, Maria and Tai, Helen H. and Anglin, Noelle L. and Ellis, David and Strömvik, Martina V.},
  date         = {2018},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kyriakidou et al_2018_Current Strategies of Polyploid Plant Genome Sequence Assembly.pdf},
  issn         = {1664-462X},
  journaltitle = {Frontiers in Plant Science},
  title        = {Current {{Strategies}} of {{Polyploid Plant Genome Sequence Assembly}}},
  url          = {https://www.frontiersin.org/articles/10.3389/fpls.2018.01660},
  urldate      = {2022-09-11},
  volume       = {9}
}

@inproceedings{leeDeepTargetEndtoendLearning2016,
  abstract   = {MicroRNAs (miRNAs) are short sequences of ribonucleic acids that control the expression of target messenger RNAs (mRNAs) by binding them. Robust prediction of miRNA-mRNA pairs is of utmost importance in deciphering gene regulation but has been challenging because of high false positive rates, despite a deluge of computational tools that normally require laborious manual feature extraction. This paper presents an end-to-end machine learning framework for miRNA target prediction. Leveraged by deep recurrent neural networks-based auto-encoding and sequence-sequence interaction learning, our approach not only delivers an unprecedented level of accuracy but also eliminates the need for manual feature extraction. The performance gap between the proposed method and existing alternatives is substantial (over 25\% increase in F-measure), and deepTarget delivers a quantum leap in the longstanding challenge of robust miRNA target prediction. [availability: http://data.snu.ac.kr/pub/deepTarget]},
  author     = {Lee, Byunghan and Baek, Junghwan and Park, Seunghyun and Yoon, Sungroh},
  booktitle  = {Proceedings of the 7th {{ACM International Conference}} on {{Bioinformatics}}, {{Computational Biology}}, and {{Health Informatics}}},
  date       = {2016-10-02},
  doi        = {10.1145/2975167.2975212},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lee et al_2016_deepTarget.pdf},
  isbn       = {978-1-4503-4225-4},
  keywords   = {deep learning,LSTM,microRNA,recurrent neural networks},
  location   = {{New York, NY, USA}},
  pages      = {434--442},
  publisher  = {{Association for Computing Machinery}},
  series     = {{{BCB}} '16},
  shorttitle = {{{deepTarget}}},
  title      = {{{deepTarget}}: {{End-to-end Learning Framework}} for {{microRNA Target Prediction}} Using {{Deep Recurrent Neural Networks}}},
  url        = {https://doi.org/10.1145/2975167.2975212},
  urldate    = {2022-09-07}
}

@article{liangHyb4mCHybridDNA2vecbased2022,
  abstract     = {DNA N4-methylcytosine is part of the restrictive modification system, which works by regulating some biological processes, for example, the initiation of DNA replication, mismatch repair and inactivation of transposon. However, using experimental methods to detect 4mC sites is time-consuming and expensive. Besides, considering the huge differences in the number of 4mC samples among different species, it is challenging to achieve a robust multi-species 4mC site prediction performance. Hence, it is of great significance to develop effective computational tools to identify 4mC sites.},
  author       = {Liang, Ying and Wu, Yanan and Zhang, Zequn and Liu, Niannian and Peng, Jun and Tang, Jianjun},
  date         = {2022-06-29},
  doi          = {10.1186/s12859-022-04789-6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Liang et al_2022_Hyb4mC.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Capsule Neural Network,DNA N4-methylcytosine,DNA2vec,Site identification,Text Convolutional Neural Network},
  langid       = {english},
  number       = {1},
  pages        = {258},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{Hyb4mC}}},
  title        = {{{Hyb4mC}}: A Hybrid {{DNA2vec-based}} Model for {{DNA N4-methylcytosine}} Sites Prediction},
  url          = {https://doi.org/10.1186/s12859-022-04789-6},
  urldate      = {2022-09-14},
  volume       = {23}
}

@article{liaoCombiningPairwiseSequence2003,
  abstract     = {One key element in understanding the molecular machinery of the cell is to understand the structure and function of each protein encoded in the genome. A very successful means of inferring the structure or function of a previously unannotated protein is via sequence similarity with one or more proteins whose structure or function is already known. Toward this end, we propose a means of representing proteins using pairwise sequence similarity scores. This representation, combined with a discriminative classification algorithm known as the support vector machine (SVM), provides a powerful means of detecting subtle structural and evolutionary relationships among proteins. The algorithm, called SVM-pairwise, when tested on its ability to recognize previously unseen families from the SCOP database, yields significantly better performance than SVM-Fisher, profile HMMs, and PSI-BLAST.},
  author       = {Liao, Li and Noble, William Stafford},
  date         = {2003-12},
  doi          = {10.1089/106652703322756113},
  journaltitle = {Journal of Computational Biology},
  keywords     = {DETECTION,HOMOLOGY,PAIRWISE SEQUENCE COMPARISON,SUPPORT VECTOR MACHINES},
  number       = {6},
  pages        = {857--868},
  publisher    = {{Mary Ann Liebert, Inc., publishers}},
  title        = {Combining {{Pairwise Sequence Similarity}} and {{Support Vector Machines}} for {{Detecting Remote Protein Evolutionary}} and {{Structural Relationships}}},
  url          = {https://www.liebertpub.com/doi/abs/10.1089/106652703322756113},
  urldate      = {2022-08-19},
  volume       = {10}
}

@article{liCanMachineLearning2019,
  abstract     = {Machine learning as a form of artificial intelligence consists of algorithms and statistical models for improving computer performance for different tasks. Training data are utilized for making decisions and predictions. Since directed evolution of enzymes produces huge amounts of potential training data, machine learning seems to be ideally suited to support this protein engineering technique. Machine learning has been used in protein science for a long time with different purposes. This mini-review focuses on the utility of machine learning as an aid in the directed evolution of selective enzymes. Recent studies have shown that the algorithms ASRA and Innov'SAR are well suited as guides when performing saturation mutagenesis at sites lining the binding pocket for enhancing stereoselectivity and activity.},
  annotation   = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adsc.201900149},
  author       = {Li, Guangyue and Dong, Yijie and Reetz, Manfred T.},
  date         = {2019},
  doi          = {10.1002/adsc.201900149},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li et al_2019_Can Machine Learning Revolutionize Directed Evolution of Selective Enzymes.pdf;/Users/lucblassel/Zotero/storage/NAW5N9DP/adsc.html},
  issn         = {1615-4169},
  journaltitle = {Advanced Synthesis \& Catalysis},
  keywords     = {directed evolution,enzymes,machine learning,saturation mutagenesis,stereoselectivity},
  langid       = {english},
  number       = {11},
  pages        = {2377--2386},
  title        = {Can {{Machine Learning Revolutionize Directed Evolution}} of {{Selective Enzymes}}?},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adsc.201900149},
  urldate      = {2022-09-07},
  volume       = {361}
}

@article{liPredictionProteinStructural2008,
  abstract     = {A prior knowledge of protein structural classes can provide useful information about its overall structure, so it is very important for quick and accurate determination of protein structural class with computation method in protein science. One of the key for computation method is accurate protein sample representation. Here, based on the concept of Chou’s pseudo-amino acid composition (AAC, Chou, Proteins: structure, function, and genetics, 43:246–255, 2001), a novel method of feature extraction that combined continuous wavelet transform (CWT) with principal component analysis (PCA) was introduced for the prediction of protein structural classes. Firstly, the digital signal was obtained by mapping each amino acid according to various physicochemical properties. Secondly, CWT was utilized to extract new feature vector based on wavelet power spectrum (WPS), which contains more abundant information of sequence order in frequency domain and time domain, and PCA was then used to reorganize the feature vector to decrease information redundancy and computational complexity. Finally, a pseudo-amino acid composition feature vector was further formed to represent primary sequence by coupling AAC vector with a set of new feature vector of WPS in an orthogonal space by PCA. As a showcase, the rigorous jackknife cross-validation test was performed on the working datasets. The results indicated that prediction quality has been improved, and the current approach of protein representation may serve as a useful complementary vehicle in classifying other attributes of proteins, such as enzyme family class, subcellular localization, membrane protein types and protein secondary structure, etc.},
  author       = {Li, Zhan-Chao and Zhou, Xi-Bin and Dai, Zong and Zou, Xiao-Yong},
  date         = {2008-08-23},
  doi          = {10.1007/s00726-008-0170-2},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/li_et_al_2008_prediction_of_protein_structural_classes_by.pdf},
  issn         = {1438-2199},
  journaltitle = {Amino Acids},
  keywords     = {Pseudo-amino acid composition,Support vector machine,Wavelet power spectrum},
  langid       = {english},
  number       = {2},
  pages        = {415},
  shortjournal = {Amino Acids},
  shorttitle   = {Prediction of Protein Structural Classes by {{Chou}}’s Pseudo Amino Acid Composition},
  title        = {Prediction of Protein Structural Classes by {{Chou}}’s Pseudo Amino Acid Composition: Approached Using Continuous Wavelet Transform and Principal Component Analysis},
  url          = {https://doi.org/10.1007/s00726-008-0170-2},
  urldate      = {2018-09-19},
  volume       = {37}
}

@article{lochelChaosGameRepresentation2021,
  abstract     = {Chaos game representation (CGR), a milestone in graphical bioinformatics, has become a powerful tool regarding alignment-free sequence comparison and feature encoding for machine learning. The algorithm maps a sequence to 2-dimensional space, while an extension of the CGR, the so-called frequency matrix representation (FCGR), transforms sequences of different lengths into equal-sized images or matrices. The CGR is a generalized Markov chain and includes various properties, which allow a unique representation of a sequence. Therefore, it has a broad spectrum of applications in bioinformatics, such as sequence comparison and phylogenetic analysis and as an encoding of sequences for machine learning. This review introduces the construction of CGRs and FCGRs, their applications on DNA and proteins, and gives an overview of recent applications and progress in bioinformatics.},
  author       = {Löchel, Hannah Franziska and Heider, Dominik},
  date         = {2021-01-01},
  doi          = {10.1016/j.csbj.2021.11.008},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Löchel_Heider_2021_Chaos game representation and its applications in bioinformatics.pdf;/Users/lucblassel/Zotero/storage/7SM7EZBK/S2001037021004736.html},
  issn         = {2001-0370},
  journaltitle = {Computational and Structural Biotechnology Journal},
  keywords     = {Alignment-free sequence comparison,Bioinformatics,Chaos game representation,DNA and protein encoding,Machine learning,Sequence analysis},
  langid       = {english},
  pages        = {6263--6271},
  shortjournal = {Computational and Structural Biotechnology Journal},
  title        = {Chaos Game Representation and Its Applications in Bioinformatics},
  url          = {https://www.sciencedirect.com/science/article/pii/S2001037021004736},
  urldate      = {2022-06-23},
  volume       = {19}
}

@article{lochelDeepLearningChaos2020a,
  abstract     = {Classification of protein sequences is one big task in bioinformatics and has many applications. Different machine learning methods exist and are applied on these problems, such as support vector machines (SVM), random forests (RF) and neural networks (NN). All of these methods have in common that protein sequences have to be made machine-readable and comparable in the first step, for which different encodings exist. These encodings are typically based on physical or chemical properties of the sequence. However, due to the outstanding performance of deep neural networks (DNN) on image recognition, we used frequency matrix chaos game representation (FCGR) for encoding of protein sequences into images. In this study, we compare the performance of SVMs, RFs and DNNs, trained on FCGR encoded protein sequences. While the original chaos game representation (CGR) has been used mainly for genome sequence encoding and classification, we modified it to work also for protein sequences, resulting in n-flakes representation, an image with several icosagons.We could show that all applied machine learning techniques (RF, SVM and DNN) show promising results compared to the state-of-the-art methods on our benchmark datasets, with DNNs outperforming the other methods and that FCGR is a promising new encoding method for protein sequences.https://cran.r-project.org/.Supplementary data are available at Bioinformatics online.},
  author       = {Löchel, Hannah F and Eger, Dominic and Sperlea, Theodor and Heider, Dominik},
  date         = {2020-01-01},
  doi          = {10.1093/bioinformatics/btz493},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Löchel et al_2020_Deep learning on chaos game representation for proteins2.pdf;/Users/lucblassel/Zotero/storage/TQRBE95G/5521624.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {1},
  pages        = {272--279},
  shortjournal = {Bioinformatics},
  title        = {Deep Learning on Chaos Game Representation for Proteins},
  url          = {https://doi.org/10.1093/bioinformatics/btz493},
  urldate      = {2022-09-12},
  volume       = {36}
}

@article{luDiscoveringMolecularFeatures2022,
  abstract     = {A major challenge to the characterization of intrinsically disordered regions (IDRs), which are widespread in the proteome, but relatively poorly understood, is the identification of molecular features that mediate functions of these regions, such as short motifs, amino acid repeats and physicochemical properties. Here, we introduce a proteome-scale feature discovery approach for IDRs. Our approach, which we call “reverse homology”, exploits the principle that important functional features are conserved over evolution. We use this as a contrastive learning signal for deep learning: given a set of homologous IDRs, the neural network has to correctly choose a held-out homolog from another set of IDRs sampled randomly from the proteome. We pair reverse homology with a simple architecture and standard interpretation techniques, and show that the network learns conserved features of IDRs that can be interpreted as motifs, repeats, or bulk features like charge or amino acid propensities. We also show that our model can be used to produce visualizations of what residues and regions are most important to IDR function, generating hypotheses for uncharacterized IDRs. Our results suggest that feature discovery using unsupervised neural networks is a promising avenue to gain systematic insight into poorly understood protein sequences.},
  author       = {Lu, Alex X. and Lu, Amy X. and Pritišanac, Iva and Zarin, Taraneh and Forman-Kay, Julie D. and Moses, Alan M.},
  date         = {2022-06-29},
  doi          = {10.1371/journal.pcbi.1010238},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lu et al_2022_Discovering molecular features of intrinsically disordered regions by using.pdf;/Users/lucblassel/Zotero/storage/CH99DWEF/article.html},
  issn         = {1553-7358},
  journaltitle = {PLOS Computational Biology},
  keywords     = {Learning,Neural networks,Phosphorylation,Protein sequencing,Sequence alignment,Sequence motif analysis,Yeast,Yeast and fungal models},
  langid       = {english},
  number       = {6},
  pages        = {e1010238},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS Computational Biology},
  title        = {Discovering Molecular Features of Intrinsically Disordered Regions by Using Evolution for Contrastive Learning},
  url          = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010238},
  urldate      = {2022-09-07},
  volume       = {18}
}

@incollection{maetschkeBlomapEncodingAmino2005,
  author     = {Maetschke, Stefan and Towsey, Michael and Bodén, Mikael},
  booktitle  = {Proceedings of the 3rd {{Asia-Pacific Bioinformatics Conference}}},
  date       = {2005-01},
  doi        = {10.1142/9781860947322_0014},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Maetschke et al_2005_Blomap.pdf},
  isbn       = {978-1-86094-477-2},
  number     = {Volume 1},
  pages      = {141--150},
  publisher  = {{PUBLISHED BY IMPERIAL COLLEGE PRESS AND DISTRIBUTED BY WORLD SCIENTIFIC PUBLISHING CO.}},
  series     = {Series on {{Advances}} in {{Bioinformatics}} and {{Computational Biology}}},
  shorttitle = {Blomap},
  title      = {Blomap: An Encoding of Amino Acids Which Improves Signal Peptide Cleavage Site Prediction},
  url        = {https://www.worldscientific.com/doi/abs/10.1142/9781860947322_0014},
  urldate    = {2022-09-12},
  volume     = {Volume 1}
}

@article{martinNextgenerationTranscriptomeAssembly2011,
  abstract     = {The protocols used for library construction, sequencing and data pre-processing can have a great impact on the quality of an assembled transcriptome and the accuracy of gene expression quantification.Before starting an RNA sequencing (RNA-seq) experiment, one should carefully consider using protocols that are strand-specific, that remove ribosomal RNA and that do not require PCR amplification of the template.Strand-specific RNA-seq protocols are important for correctly assembling overlapping transcripts, especially for compact genomes.The reference-based, or ab initio, assembly strategy requires a reference genome and uses much fewer computing resources than the de novo strategy. However, the quality of the genome and the ability of the short-read aligner to align reads across introns will directly influence the accuracy of the assembled transcripts when using the reference-based strategy.The de novo assembly strategy does not use a reference genome but instead uses a De Bruijn graph to represent overlaps between sequences and assemble transcripts. Most de novo approaches require significant computing resources: random access memory (RAM) is the typical limitation. However, de novo assemblers can assemble trans-spliced genes and novel transcripts that are not present in the genome assembly.To take full advantage of the current assembly strategies, a combined assembly approach should be considered that leverages the strengths of reference-based and de novo assembly strategies.Most transcriptome assemblers are still being developed, and the results from these programs should be evaluated using unbiased quantitative metrics.Transcriptome assembly involves an informatics approach to solve an experimental limitation. As sequencing strategies continually improve, it may no longer be necessary in the near future to assemble transcriptomes, as the read length will be longer than any individual transcript.},
  author       = {Martin, Jeffrey A. and Wang, Zhong},
  date         = {2011-10},
  doi          = {10.1038/nrg3068},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Martin_Wang_2011_Next-generation transcriptome assembly.pdf;/Users/lucblassel/Zotero/storage/QP6FTVEB/nrg3068.html},
  issn         = {1471-0064},
  issue        = {10},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {Gene expression,Next-generation sequencing,RNA,RNA sequencing,Technology,Transcriptomics},
  langid       = {english},
  number       = {10},
  pages        = {671--682},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Next-Generation Transcriptome Assembly},
  url          = {https://www.nature.com/articles/nrg3068},
  urldate      = {2022-09-11},
  volume       = {12}
}

@inproceedings{meierLanguageModelsEnable2021a,
  abstract  = {Modeling the effect of sequence variation on function is a fundamental problem for understanding and designing proteins. Since evolution encodes information about function into patterns in protein sequences, unsupervised models of variant effects can be learned from sequence data. The approach to date has been to fit a model to a family of related sequences. The conventional setting is limited, since a new model must be trained for each prediction task. We show that using only zero-shot inference, without any supervision from experimental data or additional training, protein language models capture the functional effects of sequence variation, performing at state-of-the-art.},
  author    = {Meier, Joshua and Rao, Roshan and Verkuil, Robert and Liu, Jason and Sercu, Tom and Rives, Alex},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2021},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Meier et al_2021_Language models enable zero-shot prediction of the effects of mutations on.pdf},
  pages     = {29287--29303},
  publisher = {{Curran Associates, Inc.}},
  title     = {Language Models Enable Zero-Shot Prediction of the Effects of Mutations on Protein Function},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/f51338d736f95dd42427296047067694-Abstract.html},
  urldate   = {2022-09-16},
  volume    = {34}
}

@inproceedings{mikolovDistributedRepresentationsWords2013,
  abstract  = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships.  In this paper we present several improvements that make the Skip-gram model more expressive and enable it to learn higher quality vectors more rapidly.  We show that by subsampling frequent words we obtain significant speedup,  and also learn higher quality representations as measured by our tasks. We also introduce Negative Sampling, a simplified variant of Noise Contrastive Estimation (NCE) that learns more accurate vectors for frequent words compared to the hierarchical softmax.   An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases.  For example, the meanings of Canada'' and "Air'' cannot be easily combined to obtain "Air Canada''.  Motivated by this example, we present a simple and efficient method for finding phrases, and show that their vector representations can be accurately learned by the Skip-gram model. "},
  author    = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2013},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Mikolov et al_2013_Distributed Representations of Words and Phrases and their Compositionality.pdf},
  publisher = {{Curran Associates, Inc.}},
  title     = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  url       = {https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html},
  urldate   = {2022-09-13},
  volume    = {26}
}

@misc{mikolovEfficientEstimationWord2013,
  abstract      = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  author        = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date          = {2013-09-06},
  doi           = {10.48550/arXiv.1301.3781},
  eprint        = {1301.3781},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Mikolov et al_2013_Efficient Estimation of Word Representations in Vector Space.pdf;/Users/lucblassel/Zotero/storage/SCBL2YRE/1301.html},
  keywords      = {Computer Science - Computation and Language},
  number        = {arXiv:1301.3781},
  primaryclass  = {cs},
  publisher     = {{arXiv}},
  title         = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  url           = {http://arxiv.org/abs/1301.3781},
  urldate       = {2022-09-13}
}

@inproceedings{moretaAncestralProteinSequence2022,
  abstract   = {We introduce a deep generative model for representation learning of biological sequences that, unlike existing models, explicitly represents the evolutionary process. The model makes use of a...},
  author     = {Moreta, Lys Sanz and Rønning, Ola and Al-Sibahi, Ahmad Salim and Hein, Jotun and Theobald, Douglas and Hamelryck, Thomas},
  booktitle  = {International {{Conference}} on {{Learning Representations}}},
  date       = {2022-03-16},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Moreta et al_2022_Ancestral protein sequence reconstruction using a tree-structured.pdf;/Users/lucblassel/Zotero/storage/Z5GZMGKW/forum.html},
  langid     = {english},
  title      = {Ancestral Protein Sequence Reconstruction Using a Tree-Structured {{Ornstein-Uhlenbeck}} Variational Autoencoder},
  url        = {https://openreview.net/forum?id=FZoZ7a31GCW},
  urldate    = {2022-09-13}
}

@article{morrisonPhylogeneticTreebuilding1996,
  abstract     = {Cladistic analysis is an approach to phylogeny reconstruction that groups taxa in such a way that those with historically more-recent ancestors form groups nested within groups of taxa with more-distant ancestors. This nested set of taxa can be represented as a branching diagram or tree (a cladogram), which is an hypothesis of the evolutionary history of the taxa. The analysis is performed by searching for nested groups of shared derived character states. These shared derived character states define monophyletic groups of taxa (clades), which include all of the descendants of the most recent common ancestor. If all of the characters for a set of taxa are congruent, then reconstructing the phylogenetic tree is unproblematic. However, most real data sets contain incongruent characters, and consequently a wide range of tree-building methods has been developed. These methods differ in a variety of characteristics, and they may produce topologically distinct trees for a single data set. None of the currently-available methods are simultaneously efficient, powerful, consistent and robust, and thus there is no single ideal method. However, many of them appear to perform well under a wide range of conditions, with the exception of the UPGMA method and the Invariants method.},
  author       = {Morrison, David A.},
  date         = {1996-06-01},
  doi          = {10.1016/0020-7519(96)00044-6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Morrison_1996_Phylogenetic tree-building.pdf;/Users/lucblassel/Zotero/storage/EHXVSFNK/0020751996000446.html},
  issn         = {0020-7519},
  journaltitle = {International Journal for Parasitology},
  keywords     = {cladistics,cladograms,evolution,Phylogeny},
  langid       = {english},
  number       = {6},
  pages        = {589--617},
  shortjournal = {International Journal for Parasitology},
  title        = {Phylogenetic Tree-Building},
  url          = {https://www.sciencedirect.com/science/article/pii/0020751996000446},
  urldate      = {2022-09-11},
  volume       = {26}
}

@article{nanniNewEncodingTechnique2011,
  abstract     = {Research on peptide classification problems has focused mainly on the study of different encodings and the application of several classification algorithms to achieve improved prediction accuracies. The main drawback of the literature is the lack of an extensive comparison among the available encoding methods on a wide range of classification problems. This paper addresses the fundamental issue of which peptide encoding promises the best results for machine learning classifiers. Two novel encoding methods based on physicochemical properties of the amino acids are proposed and an extensive comparison with several standard encoding methods is performed on three different classification problems (HIV-protease, recognition of T-cell epitopes and prediction of peptides that bind human leukocyte antigens). The experimental results demonstrate the effectiveness of the new encodings and show that the frequently used orthonormal encoding is inferior compared to other methods.},
  author       = {Nanni, Loris and Lumini, Alessandra},
  date         = {2011-04-01},
  doi          = {10.1016/j.eswa.2010.09.005},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Nanni_Lumini_2011_A new encoding technique for peptide classification.pdf;/Users/lucblassel/Zotero/storage/2PSKHKZ4/S0957417410009097.html},
  issn         = {0957-4174},
  journaltitle = {Expert Systems with Applications},
  keywords     = {Amino acid encoding,HIV-protease,Human immune system,Machine learning,Peptide classification,Physicochemical properties},
  langid       = {english},
  number       = {4},
  pages        = {3185--3191},
  shortjournal = {Expert Systems with Applications},
  title        = {A New Encoding Technique for Peptide Classification},
  url          = {https://www.sciencedirect.com/science/article/pii/S0957417410009097},
  urldate      = {2022-09-13},
  volume       = {38}
}

@misc{ngDna2vecConsistentVector2017,
  abstract      = {One of the ubiquitous representation of long DNA sequence is dividing it into shorter k-mer components. Unfortunately, the straightforward vector encoding of k-mer as a one-hot vector is vulnerable to the curse of dimensionality. Worse yet, the distance between any pair of one-hot vectors is equidistant. This is particularly problematic when applying the latest machine learning algorithms to solve problems in biological sequence analysis. In this paper, we propose a novel method to train distributed representations of variable-length k-mers. Our method is based on the popular word embedding model word2vec, which is trained on a shallow two-layer neural network. Our experiments provide evidence that the summing of dna2vec vectors is akin to nucleotides concatenation. We also demonstrate that there is correlation between Needleman-Wunsch similarity score and cosine similarity of dna2vec vectors.},
  archiveprefix = {arXiv},
  author        = {Ng, Patrick},
  date          = {2017-01-23},
  doi           = {10.48550/arXiv.1701.06279},
  eprint        = {1701.06279},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ng_2017_dna2vec.pdf;/Users/lucblassel/Zotero/storage/JNLN9DD6/1701.html},
  keywords      = {Computer Science - Computation and Language,Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  number        = {arXiv:1701.06279},
  primaryclass  = {cs, q-bio, stat},
  publisher     = {{arXiv}},
  shorttitle    = {Dna2vec},
  title         = {Dna2vec: {{Consistent}} Vector Representations of Variable-Length k-Mers},
  url           = {http://arxiv.org/abs/1701.06279},
  urldate       = {2022-09-12}
}

@article{niApplyingFrequencyChaos2021,
  abstract     = {As a very important research direction in the field of bioinformatics, sequence alignment plays a vital role in the research and development of biology. Converting genome sequence to graph by using frequency chaos game representation (FCGR) is an excellent gene sequence mapping technology, which can store rich genetic information into FCGR graphics. To each FCGR image, we construct its perceptual image hashing (PIH) matrix using the bicubic interpolation zooming. The difference of the perceptual hash matrix of each two images is calculated, and the clustering distance of the corresponding two gene sequences is represented by the differentials of the perceptual hash matrix. In this paper, we aligned and analyzed several typical genome sequence datasets including mammalian mitochondrial genes, human immunodeficiency virus 1 (HIV-1) and hepatitis E virus (HEV) to build their evolutionary trees. Experimental results showed that our PIH combining FCGR method (FCGR-PIH) has similar classification accuracy to the classical Clustal W sequence alignment method. Furthermore, 25 complete mitochondrial DNA sequences of cichlid fishes and 27 Escherichia coli/Shigella full genome sequences were selected from the AFproject test platform for tests. The performance benchmark rankings demonstrate the effectiveness of the FCGR-PIH algorithm and its potential for large-scale genome sequence analysis.},
  author       = {Ni, Haiming and Mu, Hongbo and Qi, Dawei},
  date         = {2021-09-01},
  doi          = {10.1016/j.jmgm.2021.107942},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ni et al_2021_Applying frequency chaos game representation with perceptual image hashing to.pdf;/Users/lucblassel/Zotero/storage/TNXM2DLM/S1093326321001133.html},
  issn         = {1093-3263},
  journaltitle = {Journal of Molecular Graphics and Modelling},
  keywords     = {Frequency chaos game representation,Genome sequences alignment,Perceptual image hashing,Phylogenetic tree construction},
  langid       = {english},
  pages        = {107942},
  shortjournal = {Journal of Molecular Graphics and Modelling},
  title        = {Applying Frequency Chaos Game Representation with Perceptual Image Hashing to Gene Sequence Phylogenetic Analyses},
  url          = {https://www.sciencedirect.com/science/article/pii/S1093326321001133},
  urldate      = {2022-06-23},
  volume       = {107}
}

@misc{nijkampProGen2ExploringBoundaries2022,
  abstract      = {Attention-based models trained on protein sequences have demonstrated incredible success at classification and generation tasks relevant for artificial intelligence-driven protein design. However, we lack a sufficient understanding of how very large-scale models and data play a role in effective protein model development. We introduce a suite of protein language models, named ProGen2, that are scaled up to 6.4B parameters and trained on different sequence datasets drawn from over a billion proteins from genomic, metagenomic, and immune repertoire databases. ProGen2 models show state-of-the-art performance in capturing the distribution of observed evolutionary sequences, generating novel viable sequences, and predicting protein fitness without additional finetuning. As large model sizes and raw numbers of protein sequences continue to become more widely accessible, our results suggest that a growing emphasis needs to be placed on the data distribution provided to a protein sequence model. We release the ProGen2 models and code at https://github.com/salesforce/progen.},
  archiveprefix = {arXiv},
  author        = {Nijkamp, Erik and Ruffolo, Jeffrey and Weinstein, Eli N. and Naik, Nikhil and Madani, Ali},
  date          = {2022-06-27},
  doi           = {10.48550/arXiv.2206.13517},
  eprint        = {2206.13517},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Nijkamp et al_2022_ProGen2.pdf;/Users/lucblassel/Zotero/storage/3B94NXJ4/2206.html},
  keywords      = {Computer Science - Machine Learning,Quantitative Biology - Quantitative Methods},
  number        = {arXiv:2206.13517},
  primaryclass  = {cs, q-bio},
  publisher     = {{arXiv}},
  shorttitle    = {{{ProGen2}}},
  title         = {{{ProGen2}}: {{Exploring}} the {{Boundaries}} of {{Protein Language Models}}},
  url           = {http://arxiv.org/abs/2206.13517},
  urldate       = {2022-09-16}
}

@article{noeMachineLearningProtein2020,
  abstract     = {Many aspects of the study of protein folding and dynamics have been affected by the recent advances in machine learning. Methods for the prediction of protein structures from their sequences are now heavily based on machine learning tools. The way simulations are performed to explore the energy landscape of protein systems is also changing as force-fields are started to be designed by means of machine learning methods. These methods are also used to extract the essential information from large simulation datasets and to enhance the sampling of rare events such as folding/unfolding transitions. While significant challenges still need to be tackled, we expect these methods to play an important role on the study of protein folding and dynamics in the near future. We discuss here the recent advances on all these fronts and the questions that need to be addressed for machine learning approaches to become mainstream in protein simulation.},
  author       = {Noé, Frank and De Fabritiis, Gianni and Clementi, Cecilia},
  date         = {2020-02-01},
  doi          = {10.1016/j.sbi.2019.12.005},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Noé et al_2020_Machine learning for protein folding and dynamics.pdf;/Users/lucblassel/Zotero/storage/HNWMRF4Q/S0959440X19301447.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  pages        = {77--84},
  series       = {Folding and {{Binding}} ● {{Proteins}}},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Machine Learning for Protein Folding and Dynamics},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X19301447},
  urldate      = {2022-09-07},
  volume       = {60}
}

@article{ondovMashFastGenome2016,
  abstract     = {Mash extends the MinHash dimensionality-reduction technique to include a pairwise mutation distance and P value significance test, enabling the efficient clustering and search of massive sequence collections. Mash reduces large sequences and sequence sets to small, representative sketches, from which global mutation distances can be rapidly estimated. We demonstrate several use cases, including the clustering of all 54,118 NCBI RefSeq genomes in 33 CPU h; real-time database search using assembled or unassembled Illumina, Pacific Biosciences, and Oxford Nanopore data; and the scalable clustering of hundreds of metagenomic samples by composition. Mash is freely released under a BSD license (https://github.com/marbl/mash).},
  author       = {Ondov, Brian D. and Treangen, Todd J. and Melsted, Páll and Mallonee, Adam B. and Bergman, Nicholas H. and Koren, Sergey and Phillippy, Adam M.},
  date         = {2016-06-20},
  doi          = {10.1186/s13059-016-0997-x},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ondov et al_2016_Mash.pdf;/Users/lucblassel/Zotero/storage/MC25457M/s13059-016-0997-x.html},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Alignment,Comparative genomics,Genomic distance,Metagenomics,Nanopore,Sequencing},
  number       = {1},
  pages        = {132},
  shortjournal = {Genome Biology},
  shorttitle   = {Mash},
  title        = {Mash: Fast Genome and Metagenome Distance Estimation Using {{MinHash}}},
  url          = {https://doi.org/10.1186/s13059-016-0997-x},
  urldate      = {2022-09-19},
  volume       = {17}
}

@article{ortunoComparingDifferentMachine2015,
  abstract     = {The evaluation of multiple sequence alignments (MSAs) is still an open task in bioinformatics. Current MSA scores do not agree about how alignments must be accurately evaluated. Consequently, it is not trivial to know the quality of MSAs when reference alignments are not provided. Recent scores tend to use more complex evaluations adding supplementary biological features. In this work, a set of novel regression approaches are proposed for the MSA evaluation, comparing several supervised learning and mathematical methodologies. Therefore, the following models specifically designed for regression are applied: regression trees, a bootstrap aggregation of regression trees (bagging trees), least-squares support vector machines (LS-SVMs) and Gaussian processes. These algorithms consider a heterogeneous set of biological features together with other standard MSA scores in order to predict the quality of alignments. The most relevant features are then applied to build novel score schemes for the evaluation of alignments. The proposed algorithms are validated by using the BAliBASE benchmark. Additionally, an statistical ANOVA test is performed to study the relevance of these scores considering three alignment factors. According to the obtained results, the four regression models provide accurate evaluations, even outperforming other standard scores such as BLOSUM, PAM or STRIKE.},
  author       = {Ortuño, Francisco M. and Valenzuela, Olga and Prieto, Beatriz and Saez-Lara, Maria Jose and Torres, Carolina and Pomares, Hector and Rojas, Ignacio},
  date         = {2015-09-21},
  doi          = {10.1016/j.neucom.2015.01.080},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ortuño et al_2015_Comparing different machine learning and mathematical regression models to.pdf;/Users/lucblassel/Zotero/storage/73HP7M4V/S0925231215003033.html},
  issn         = {0925-2312},
  journaltitle = {Neurocomputing},
  keywords     = {Alignment quality,Bootstrap aggregation,Decision trees,Gaussian process,Least squares support vector machines (LS-SVM),Multiple sequence alignments (MSAs)},
  langid       = {english},
  pages        = {123--136},
  shortjournal = {Neurocomputing},
  title        = {Comparing Different Machine Learning and Mathematical Regression Models to Evaluate Multiple Sequence Alignments},
  url          = {https://www.sciencedirect.com/science/article/pii/S0925231215003033},
  urldate      = {2022-09-07},
  volume       = {164}
}

@article{paszkiewiczNovoAssemblyShort2010,
  abstract     = {A new generation of sequencing technologies is revolutionizing molecular biology. Illumina’s Solexa and Applied Biosystems’ SOLiD generate gigabases of nucleotide sequence per week. However, a perceived limitation of these ultra-high-throughput technologies is their short read-lengths. De novo assembly of sequence reads generated by classical Sanger capillary sequencing is a mature field of research. Unfortunately, the existing sequence assembly programs were not effective for short sequence reads generated by Illumina and SOLiD platforms. Early studies suggested that, in principle, sequence reads as short as 20–30 nucleotides could be used to generate useful assemblies of both prokaryotic and eukaryotic genome sequences, albeit containing many gaps. The early feasibility studies and proofs of principle inspired several bioinformatics research groups to implement new algorithms as freely available software tools specifically aimed at assembling reads of 30–50 nucleotides in length. This has led to the generation of several draft genome sequences based exclusively on short sequence Illumina sequence reads, recently culminating in the assembly of the 2.25-Gb genome of the giant panda from Illumina sequence reads with an average length of just 52 nucleotides. As well as reviewing recent developments in the field, we discuss some practical aspects such as data filtering and submission of assembly data to public repositories.},
  author       = {Paszkiewicz, Konrad and Studholme, David J.},
  date         = {2010-09-01},
  doi          = {10.1093/bib/bbq020},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Paszkiewicz_Studholme_2010_De novo assembly of short sequence reads.pdf;/Users/lucblassel/Zotero/storage/VIKYVPQG/1746253.html},
  issn         = {1467-5463},
  journaltitle = {Briefings in Bioinformatics},
  number       = {5},
  pages        = {457--472},
  shortjournal = {Briefings in Bioinformatics},
  title        = {De Novo Assembly of Short Sequence Reads},
  url          = {https://doi.org/10.1093/bib/bbq020},
  urldate      = {2022-09-11},
  volume       = {11}
}

@article{pearceSolutionProteinStructure2021,
  abstract     = {{$<$}p{$>$}Since Anfinsen demonstrated that the information encoded in a protein's amino acid sequence determines its structure in 1973, solving the protein structure prediction problem has been the Holy Grail of structural biology. The goal of protein structure prediction approaches is to utilize computational modeling to determine the spatial location of every atom in a protein molecule starting from only its amino acid sequence. Depending on whether homologous structures can be found in the Protein Data Bank (PDB), structure prediction methods have been historically categorized as template-based modeling (TBM) or template-free modeling (FM) approaches. Until recently, TBM has been the most reliable approach to predicting protein structures, and in the absence of reliable templates, the modeling accuracy sharply declines. Nevertheless, the results of the most recent community-wide assessment of protein structure prediction experiment (CASP14) have demonstrated that the protein structure prediction problem can be largely solved through the use of end-to-end deep machine learning techniques, where correct folds could be built for nearly all single-domain proteins without using the PDB templates. Critically, the model quality exhibited little correlation with the quality of available template structures, as well as the number of sequence homologs detected for a given target protein. Thus, the implementation of deep-learning techniques has essentially broken through the 50-year-old modeling border between TBM and FM approaches and has made the success of high-resolution structure prediction significantly less dependent on template availability in the PDB library.{$<$}/p{$>$}},
  author       = {Pearce, Robin and Zhang, Yang},
  date         = {2021-07-01},
  doi          = {10.1016/j.jbc.2021.100870},
  eprint       = {34119522},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Pearce_Zhang_2021_Toward the solution of the protein structure prediction problem.pdf;/Users/lucblassel/Zotero/storage/G24IECSY/fulltext.html},
  issn         = {0021-9258, 1083-351X},
  journaltitle = {Journal of Biological Chemistry},
  langid       = {english},
  number       = {1},
  publisher    = {{Elsevier}},
  shortjournal = {Journal of Biological Chemistry},
  title        = {Toward the Solution of the Protein Structure Prediction Problem},
  url          = {https://www.jbc.org/article/S0021-9258(21)00670-0/abstract},
  urldate      = {2022-09-07},
  volume       = {297}
}

@article{pearsonCriterionThatGiven1900,
  annotation   = {\_eprint: https://doi.org/10.1080/14786440009463897},
  author       = {Pearson, Karl},
  date         = {1900-07-01},
  doi          = {10.1080/14786440009463897},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Pearson_1900_X.pdf},
  issn         = {1941-5982},
  journaltitle = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  number       = {302},
  pages        = {157--175},
  publisher    = {{Taylor \& Francis}},
  title        = {X. {{On}} the Criterion That a given System of Deviations from the Probable in the Case of a Correlated System of Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from Random Sampling},
  url          = {https://doi.org/10.1080/14786440009463897},
  urldate      = {2022-09-20},
  volume       = {50}
}

@article{potdarComparativeStudyCategorical2017,
  abstract     = {In classification analysis, the dependent variable is frequently influenced not only by ratio scale variables, but also by qualitative (nominal scale) variables. Machine Learning algorithms accept only numerical inputs, hence, it is necessary to encode these categorical variables into numerical values using encoding techniques.},
  author       = {Potdar, Kedar and S., Taher and D., Chinmay},
  date         = {2017-10-17},
  doi          = {10.5120/ijca2017915495},
  file         = {/Users/lucblassel/Zotero/storage/X7BB9TAE/Potdar et al. - 2017 - A Comparative Study of Categorical Variable Encodi.pdf},
  issn         = {09758887},
  journaltitle = {International Journal of Computer Applications},
  langid       = {english},
  number       = {4},
  pages        = {7--9},
  shortjournal = {IJCA},
  title        = {A {{Comparative Study}} of {{Categorical Variable Encoding Techniques}} for {{Neural Network Classifiers}}},
  url          = {http://www.ijcaonline.org/archives/volume175/number4/potdar-2017-ijca-915495.pdf},
  urldate      = {2022-09-12},
  volume       = {175}
}

@article{qianPredictingSecondaryStructure1988,
  abstract     = {We present a new method for predicting the secondary structure of globular proteins based on non-linear neural network models. Network models learn from existing protein structures how to predict the secondary structure of local sequences of amino acids. The average success rate of our method on a testing set of proteins non-homologous with the corresponding training set was 64.3\% on three types of secondary structure (α-helix, β-sheet, and coil), with correlation coefficients of Cα = 0.41, Cβ = 0.31 and Ccoll = 0.41. These quality indices are all higher than those of previous methods. The prediction accuracy for the first 25 residues of the N-terminal sequence was significantly better. We conclude from computational experiments on real and artificial structures that no method based solely on local information in the protein sequence is likely to produce significantly better results for non-homologous proteins. The performance of our method of homologous proteins is much better than for non-homologous proteins, but is not as good as simply assuming that homologous sequences have identical structures.},
  author       = {Qian, Ning and Sejnowski, Terrence J.},
  date         = {1988-08-20},
  doi          = {10.1016/0022-2836(88)90564-5},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Qian_Sejnowski_1988_Predicting the secondary structure of globular proteins using neural network.pdf;/Users/lucblassel/Zotero/storage/G3LF73ZV/0022283688905645.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {4},
  pages        = {865--884},
  shortjournal = {Journal of Molecular Biology},
  title        = {Predicting the Secondary Structure of Globular Proteins Using Neural Network Models},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283688905645},
  urldate      = {2022-09-12},
  volume       = {202}
}

@article{raoMSATransformer2021,
  abstract     = {Unsupervised protein language models trained across millions of diverse sequences learn structure and function of proteins. Protein language models studied to date have been trained to perform inference from individual sequences. The longstanding approach in computational biology has been to make inferences from a family of evolutionarily related sequences by fitting a model to each family independently. In this work we combine the two paradigms. We introduce a protein language model which takes as input a set of sequences in the form of a multiple sequence alignment. The model interleaves row and column attention across the input sequences and is trained with a variant of the masked language modeling objective across many protein families. The performance of the model surpasses current state-of-the-art unsupervised structure learning methods by a wide margin, with far greater parameter efficiency than prior state-of-the-art protein language models.},
  annotation   = {MAG ID: 3133458480 S2ID: deee48c5e0ac0407a1e002905caaf2b174bdb0e6},
  author       = {Rao, Roshan and Liu, Jason and {J. Liu} and {R. Verkuil} and Verkuil, Robert and Meier, Joshua and Canny, John and {J. F. Canny} and {P. Abbeel} and Abbeel, Pieter and Sercu, Tom and {Tom Sercu} and Rives, Alexander},
  date         = {2021},
  doi          = {10.1101/2021.02.12.430858},
  journaltitle = {bioRxiv},
  title        = {{{MSA Transformer}}}
}

@misc{raoTransformerProteinLanguage2020,
  abstract  = {Unsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.1},
  author    = {Rao, Roshan and Meier, Joshua and Sercu, Tom and Ovchinnikov, Sergey and Rives, Alexander},
  date      = {2020-12-15},
  doi       = {10.1101/2020.12.15.422761},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Rao et al_2020_Transformer protein language models are unsupervised structure learners.pdf;/Users/lucblassel/Zotero/storage/EM3MCHDN/2020.12.15.html},
  langid    = {english},
  pages     = {2020.12.15.422761},
  publisher = {{bioRxiv}},
  title     = {Transformer Protein Language Models Are Unsupervised Structure Learners},
  url       = {https://www.biorxiv.org/content/10.1101/2020.12.15.422761v1},
  urldate   = {2022-09-16}
}

@article{ratschLearningInterpretableSVMs2006,
  abstract     = {Support Vector Machines (SVMs) – using a variety of string kernels – have been successfully applied to biological sequence classification problems. While SVMs achieve high classification accuracy they lack interpretability. In many applications, it does not suffice that an algorithm just detects a biological signal in the sequence, but it should also provide means to interpret its solution in order to gain biological insight.},
  author       = {Rätsch, Gunnar and Sonnenburg, Sören and Schäfer, Christin},
  date         = {2006-03-20},
  doi          = {10.1186/1471-2105-7-S1-S9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Rätsch et al_2006_Learning Interpretable SVMs for Biological Sequence Classification.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Acceptor Splice Site,Multiple Kernel Learn,Positional Weight Matrix,Splice Site,String Kernel},
  langid       = {english},
  number       = {1},
  pages        = {S9},
  shortjournal = {BMC Bioinformatics},
  title        = {Learning {{Interpretable SVMs}} for {{Biological Sequence Classification}}},
  url          = {https://doi.org/10.1186/1471-2105-7-S1-S9},
  urldate      = {2022-09-07},
  volume       = {7}
}

@article{renPredictionAntimicrobialResistance2022,
  abstract     = {Antimicrobial resistance (AMR) is one of the biggest global problems threatening human and animal health. Rapid and accurate AMR diagnostic methods are thus very urgently needed. However, traditional antimicrobial susceptibility testing (AST) is time-consuming, low throughput and viable only for cultivable bacteria. Machine learning methods may pave the way for automated AMR prediction based on genomic data of the bacteria. However, comparing different machine learning methods for the prediction of AMR based on different encodings and whole-genome sequencing data without previously known knowledge remains to be done.In this study, we evaluated logistic regression (LR), support vector machine (SVM), random forest (RF) and convolutional neural network (CNN) for the prediction of AMR for the antibiotics ciprofloxacin, cefotaxime, ceftazidime and gentamicin. We could demonstrate that these models can effectively predict AMR with label encoding, one-hot encoding and frequency matrix chaos game representation (FCGR encoding) on whole-genome sequencing data. We trained these models on a large AMR dataset and evaluated them on an independent public dataset. Generally, RFs and CNNs perform better than LR and SVM with AUCs up to 0.96. Furthermore, we were able to identify mutations that are associated with AMR for each antibiotic.Source code in data preparation and model training are provided at GitHub website (https://github.com/YunxiaoRen/ML-iAMR).Supplementary data are available at Bioinformatics online.},
  author       = {Ren, Yunxiao and Chakraborty, Trinad and Doijad, Swapnil and Falgenhauer, Linda and Falgenhauer, Jane and Goesmann, Alexander and Hauschild, Anne-Christin and Schwengers, Oliver and Heider, Dominik},
  date         = {2022-01-15},
  doi          = {10.1093/bioinformatics/btab681},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ren et al_2022_Prediction of antimicrobial resistance based on whole-genome sequencing and.pdf;/Users/lucblassel/Zotero/storage/8KSHFZGT/6382301.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {2},
  pages        = {325--334},
  shortjournal = {Bioinformatics},
  title        = {Prediction of Antimicrobial Resistance Based on Whole-Genome Sequencing and Machine Learning},
  url          = {https://doi.org/10.1093/bioinformatics/btab681},
  urldate      = {2022-09-07},
  volume       = {38}
}

@inproceedings{rishEmpiricalStudyNaive,
  abstract     = {The naive Bayes classifier greatly simplify learning by assuming that features are independent given class. Although independence is generally a poor assumption, in practice naive Bayes often competes well with more sophisticated classifiers.},
  author       = {Rish, Irina},
  biburl       = {https://www.bibsonomy.org/bibtex/2c6150221dd474c526ce4d1ca1452d036/sb1989},
  booktitle    = {IJCAI 2001 workshop on empirical methods in artificial intelligence},
  file         = {/Users/lucblassel/Zotero/storage/YQELYLBT/Rish - An empirical study of the naive Bayes classiﬁer.pdf},
  number       = {22},
  organization = {IBM New York},
  pages        = {41--46},
  title        = {An empirical study of the naive Bayes classifier},
  volume       = {3},
  year         = {2001}
}

@inproceedings{sahaNovelApproachFind2019,
  abstract  = {In the field of biological data mining, protein sequence classification is one of the most popular research area. To classify the protein sequence,Saha, Suprativ features must be extracted from the input data. The various researchers used n-gram encoding method to extract feature value. Generally,Bhattacharya, Tanmay to reduce the computational time, the value of n of n-gram encoding method is considered as 2, but accuracy level of classification degrades. So, it is an important research, to find the optimum value of n for n-gram encoding method, where computational time and accuracy level of classification both are acceptable. In this work, an experimental attempt has been made to fixed up the limit of scaling of n-gram encoding method from 2-gram to 5-gram. Standard deviation method has been used for this purpose.},
  author    = {Saha, Suprativ and Bhattacharya, Tanmay},
  booktitle = {International {{Conference}} on {{Innovative Computing}} and {{Communications}}},
  date      = {2019},
  doi       = {10.1007/978-981-13-2354-6_12},
  editor    = {Bhattacharyya, Siddhartha and Hassanien, Aboul Ella and Gupta, Deepak and Khanna, Ashish and Pan, Indrajit},
  isbn      = {9789811323546},
  keywords  = {Data mining,n-gram encoding method,Neural network model,Protein hashing,Rough set,String kernel,Support vector machine},
  langid    = {english},
  location  = {{Singapore}},
  pages     = {101--108},
  publisher = {{Springer}},
  series    = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
  title     = {A {{Novel Approach}} to {{Find}} the {{Saturation Point}} of N-{{Gram Encoding Method}} for {{Protein Sequence Classification Involving Data Mining}}}
}

@misc{sercuNeuralPottsModel2021,
  abstract  = {We propose the Neural Potts Model objective as an amortized optimization problem. The objective enables training a single model with shared parameters to explicitly model energy landscapes across multiple protein families. Given a protein sequence as input, the model is trained to predict a pairwise coupling matrix for a Potts model energy function describing the local evolutionary landscape of the sequence. Couplings can be predicted for novel sequences. A controlled ablation experiment assessing unsupervised contact prediction on sets of related protein families finds a gain from amortization for low-depth multiple sequence alignments; the result is then confirmed on a database with broad coverage of protein sequences.},
  author    = {Sercu, Tom and Verkuil, Robert and Meier, Joshua and Amos, Brandon and Lin, Zeming and Chen, Caroline and Liu, Jason and LeCun, Yann and Rives, Alexander},
  date      = {2021-04-11},
  doi       = {10.1101/2021.04.08.439084},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sercu et al_2021_Neural Potts Model.pdf;/Users/lucblassel/Zotero/storage/R7GHDYKH/2021.04.08.439084v1.html},
  langid    = {english},
  pages     = {2021.04.08.439084},
  publisher = {{bioRxiv}},
  title     = {Neural {{Potts Model}}},
  url       = {https://www.biorxiv.org/content/10.1101/2021.04.08.439084v1},
  urldate   = {2022-09-19}
}

@article{singhEvolutionaryBasedOptimal2018,
  abstract     = {HIV-1 protease site helps to understand the specificity of substrates which antagonizes AIDS by restraining the replication of HIV-1 through inhibitors. Identification of HIV-1 protease cleavage sites by experimental methods are usually labor-intensive thus time-consuming. Several computational intelligence methods have been evaluated to predict cleavage sites. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of encoding techniques in general, more research is needed to provide advance confidence in computational results. The success of an HIV cleavage site prediction system depends heavily on two things: the classifier being used and the features encoding technique applied. For the cleavage sites identification, the role of appropriate feature encoding has not been paid adequate importance. In this investigation, we use two novel ideas for HIV Cleavage site prediction. First, we propose an optimal ensemble formation technique that optimizes the search space of 228 formed by seven encoding techniques and four SVM kernels (7\,×\,4) with the use of genetic algorithm. The second is the utilization of area under receiver operating characteristics (AUC) as a fitness measure for the evaluation of optimal ensemble. The evolutionary algorithm is encoded with binary strings to decide the correlation between the encoding-classifier pair in an ensemble. The proposed method with new ensembling encoding-classifier pair increases the HIV cleavage site prediction significantly. Overall, an appealing degree of predictive accuracy is observed by evolutionary-based ensemble model and hence becomes a valid and best alternative for peptide classification.},
  author       = {Singh, Deepak and Singh, Pradeep and Sisodia, Dilip Singh},
  date         = {2018-11-01},
  doi          = {10.1016/j.eswa.2018.05.003},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Singh et al_2018_Evolutionary based optimal ensemble classifiers for HIV-1 protease cleavage.pdf;/Users/lucblassel/Zotero/storage/24QZHUFV/S095741741830280X.html},
  issn         = {0957-4174},
  journaltitle = {Expert Systems with Applications},
  keywords     = {Amino acid database,Ensemble classifier,Genetic algorithm,HIV-1 protease,Protein encoding,Support vector machine},
  langid       = {english},
  pages        = {86--99},
  shortjournal = {Expert Systems with Applications},
  title        = {Evolutionary Based Optimal Ensemble Classifiers for {{HIV-1}} Protease Cleavage Sites Prediction},
  url          = {https://www.sciencedirect.com/science/article/pii/S095741741830280X},
  urldate      = {2022-09-12},
  volume       = {109}
}

@article{sleatorOverviewSilicoProtein2010,
  abstract     = {As the protein databases continue to expand at an exponential rate, fed by daily uploads from multiple large scale genomic and metagenomic projects, the problem of assigning a function to each new protein has become the focus of significant research interest in recent times. Herein, we review the most recent advances in the field of automated function prediction (AFP). We begin by defining what is meant by biological “function” and the means of describing such functions using standardised machine readable ontologies. We then focus on the various function-prediction programs available, both sequence and structure based, and outline their associated strengths and weaknesses. Finally, we conclude with a brief overview of the future challenges and outstanding questions in the field, which still remain unanswered.},
  author       = {Sleator, Roy D. and Walsh, Paul},
  date         = {2010-03-01},
  doi          = {10.1007/s00203-010-0549-9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sleator_Walsh_2010_An overview of in silico protein function prediction.pdf},
  issn         = {1432-072X},
  journaltitle = {Archives of Microbiology},
  keywords     = {Homology-based transfer,Ontologies,Protein function,Sequence and structure Motifs},
  langid       = {english},
  number       = {3},
  pages        = {151--155},
  shortjournal = {Arch Microbiol},
  title        = {An Overview of in Silico Protein Function Prediction},
  url          = {https://doi.org/10.1007/s00203-010-0549-9},
  urldate      = {2022-09-11},
  volume       = {192}
}

@article{sohnPresentFutureNovo2018,
  abstract     = {As the advent of next-generation sequencing (NGS) technology, various de novo assembly algorithms based on the de Bruijn graph have been developed to construct chromosome-level sequences. However, numerous technical or computational challenges in de novo assembly still remain, although many bright ideas and heuristics have been suggested to tackle the challenges in both experimental and computational settings. In this review, we categorize de novo assemblers on the basis of the type of de Bruijn graphs (Hamiltonian and Eulerian) and discuss the challenges of de novo assembly for short NGS reads regarding computational complexity and assembly ambiguity. Then, we discuss how the limitations of the short reads can be overcome by using a single-molecule sequencing platform that generates long reads of up to several kilobases. In fact, the long read assembly has caused a paradigm shift in whole-genome assembly in terms of algorithms and supporting steps. We also summarize (i) hybrid assemblies using both short and long reads and (ii) overlap-based assemblies for long reads and discuss their challenges and future prospects. This review provides guidelines to determine the optimal approach for a given input data type, computational budget or genome.},
  author       = {Sohn, Jang-il and Nam, Jin-Wu},
  date         = {2018-01-01},
  doi          = {10.1093/bib/bbw096},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sohn_Nam_2018_The present and future of de novo whole-genome assembly.pdf;/Users/lucblassel/Zotero/storage/CS23QCL4/2339783.html},
  issn         = {1477-4054},
  journaltitle = {Briefings in Bioinformatics},
  number       = {1},
  pages        = {23--40},
  shortjournal = {Briefings in Bioinformatics},
  title        = {The Present and Future of de Novo Whole-Genome Assembly},
  url          = {https://doi.org/10.1093/bib/bbw096},
  urldate      = {2022-09-11},
  volume       = {19}
}

@article{songPretrainingModelBiological2021a,
  abstract     = {With the development of high-throughput sequencing technology, biological sequence data reflecting life information becomes increasingly accessible. Particularly on the background of the COVID-19 pandemic, biological sequence data play an important role in detecting diseases, analyzing the mechanism and discovering specific drugs. In recent years, pretraining models that have emerged in natural language processing have attracted widespread attention in many research fields not only to decrease training cost but also to improve performance on downstream tasks. Pretraining models are used for embedding biological sequence and extracting feature from large biological sequence corpus to comprehensively understand the biological sequence data. In this survey, we provide a broad review on pretraining models for biological sequence data. Moreover, we first introduce biological sequences and corresponding datasets, including brief description and accessible link. Subsequently, we systematically summarize popular pretraining models for biological sequences based on four categories: CNN, word2vec, LSTM and Transformer. Then, we present some applications with proposed pretraining models on downstream tasks to explain the role of pretraining models. Next, we provide a novel pretraining scheme for protein sequences and a multitask benchmark for protein pretraining models. Finally, we discuss the challenges and future directions in pretraining models for biological sequences.},
  author       = {Song, Bosheng and Li, Zimeng and Lin, Xuan and Wang, Jianmin and Wang, Tian and Fu, Xiangzheng},
  date         = {2021-05-01},
  doi          = {10.1093/bfgp/elab025},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Song et al_2021_Pretraining model for biological sequence data.pdf;/Users/lucblassel/Zotero/storage/SJBICRWT/6287893.html},
  issn         = {2041-2657},
  journaltitle = {Briefings in Functional Genomics},
  number       = {3},
  pages        = {181--195},
  shortjournal = {Briefings in Functional Genomics},
  title        = {Pretraining Model for Biological Sequence Data},
  url          = {https://doi.org/10.1093/bfgp/elab025},
  urldate      = {2022-09-16},
  volume       = {20}
}

@misc{soueidanMachineLearningMetagenomics2015,
  abstract   = {Owing to the complexity and variability of metagenomic studies, modern machine learning approaches have seen increased usage to answer a variety of question encompassing the full range of metagenomic NGS data analysis. We review here the contribution of machine learning techniques for the field of metagenomics, by presenting known successful approaches in a unified framework. This review focuses on five important metagenomic problems: OTU-clustering, binning, taxonomic profling and assignment, comparative metagenomics and gene prediction. For each of these problems, we identify the most prominent methods, summarize the machine learning approaches used and put them into perspective of similar methods. We conclude our review looking further ahead at the challenge posed by the analysis of interactions within microbial communities and different environments, in a field one could call "integrative metagenomics".},
  author     = {Soueidan, Hayssam and Nikolski, Macha},
  date       = {2015-10-22},
  doi        = {10.48550/arXiv.1510.06621},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Soueidan_Nikolski_2015_Machine learning for metagenomics.pdf;/Users/lucblassel/Zotero/storage/JPF4LECL/1510.html},
  langid     = {english},
  publisher  = {{arXiv}},
  shorttitle = {Machine Learning for Metagenomics},
  title      = {Machine Learning for Metagenomics: Methods and Tools},
  url        = {https://arxiv.org/abs/1510.06621v2},
  urldate    = {2022-08-19}
}

@misc{stantonAcceleratingBayesianOptimization2022,
  abstract      = {Bayesian optimization (BayesOpt) is a gold standard for query-efficient continuous optimization. However, its adoption for drug design has been hindered by the discrete, high-dimensional nature of the decision variables. We develop a new approach (LaMBO) which jointly trains a denoising autoencoder with a discriminative multi-task Gaussian process head, allowing gradient-based optimization of multi-objective acquisition functions in the latent space of the autoencoder. These acquisition functions allow LaMBO to balance the explore-exploit tradeoff over multiple design rounds, and to balance objective tradeoffs by optimizing sequences at many different points on the Pareto frontier. We evaluate LaMBO on two small-molecule design tasks, and introduce new tasks optimizing \textbackslash emph\{in silico\} and \textbackslash emph\{in vitro\} properties of large-molecule fluorescent proteins. In our experiments LaMBO outperforms genetic optimizers and does not require a large pretraining corpus, demonstrating that BayesOpt is practical and effective for biological sequence design.},
  archiveprefix = {arXiv},
  author        = {Stanton, Samuel and Maddox, Wesley and Gruver, Nate and Maffettone, Phillip and Delaney, Emily and Greenside, Peyton and Wilson, Andrew Gordon},
  date          = {2022-07-12},
  doi           = {10.48550/arXiv.2203.12742},
  eprint        = {2203.12742},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Stanton et al_2022_Accelerating Bayesian Optimization for Biological Sequence Design with.pdf;/Users/lucblassel/Zotero/storage/Q3Y4LGJS/2203.html},
  keywords      = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  number        = {arXiv:2203.12742},
  primaryclass  = {cs, q-bio, stat},
  publisher     = {{arXiv}},
  title         = {Accelerating {{Bayesian Optimization}} for {{Biological Sequence Design}} with {{Denoising Autoencoders}}},
  url           = {http://arxiv.org/abs/2203.12742},
  urldate       = {2022-09-13}
}

@misc{sturmfelsProfilePredictionAlignmentBased2020,
  abstract      = {For protein sequence datasets, unlabeled data has greatly outpaced labeled data due to the high cost of wet-lab characterization. Recent deep-learning approaches to protein prediction have shown that pre-training on unlabeled data can yield useful representations for downstream tasks. However, the optimal pre-training strategy remains an open question. Instead of strictly borrowing from natural language processing (NLP) in the form of masked or autoregressive language modeling, we introduce a new pre-training task: directly predicting protein profiles derived from multiple sequence alignments. Using a set of five, standardized downstream tasks for protein models, we demonstrate that our pre-training task along with a multi-task objective outperforms masked language modeling alone on all five tasks. Our results suggest that protein sequence models may benefit from leveraging biologically-inspired inductive biases that go beyond existing language modeling techniques in NLP.},
  archiveprefix = {arXiv},
  author        = {Sturmfels, Pascal and Vig, Jesse and Madani, Ali and Rajani, Nazneen Fatema},
  date          = {2020-11-30},
  doi           = {10.48550/arXiv.2012.00195},
  eprint        = {2012.00195},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sturmfels et al_2020_Profile Prediction.pdf;/Users/lucblassel/Zotero/storage/PMNX56LD/2012.html},
  keywords      = {Computer Science - Machine Learning,Quantitative Biology - Biomolecules},
  number        = {arXiv:2012.00195},
  primaryclass  = {cs, q-bio},
  publisher     = {{arXiv}},
  shorttitle    = {Profile {{Prediction}}},
  title         = {Profile {{Prediction}}: {{An Alignment-Based Pre-Training Task}} for {{Protein Sequence Models}}},
  url           = {http://arxiv.org/abs/2012.00195},
  urldate       = {2022-09-19}
}

@article{tamposisSemisupervisedLearningHidden2019,
  abstract     = {Hidden Markov Models (HMMs) are probabilistic models widely used in applications in computational sequence analysis. HMMs are basically unsupervised models. However, in the most important applications, they are trained in a supervised manner. Training examples accompanied by labels corresponding to different classes are given as input and the set of parameters that maximize the joint probability of sequences and labels is estimated. A main problem with this approach is that, in the majority of the cases, labels are hard to find and thus the amount of training data is limited. On the other hand, there are plenty of unclassified (unlabeled) sequences deposited in the public databases that could potentially contribute to the training procedure. This approach is called semi-supervised learning and could be very helpful in many applications.We propose here, a method for semi-supervised learning of HMMs that can incorporate labeled, unlabeled and partially labeled data in a straightforward manner. The algorithm is based on a variant of the Expectation-Maximization (EM) algorithm, where the missing labels of the unlabeled or partially labeled data are considered as the missing data. We apply the algorithm to several biological problems, namely, for the prediction of transmembrane protein topology for alpha-helical and beta-barrel membrane proteins and for the prediction of archaeal signal peptides. The results are very promising, since the algorithms presented here can significantly improve the prediction performance of even the top-scoring classifiers.Supplementary data are available at Bioinformatics online.},
  author       = {Tamposis, Ioannis A and Tsirigos, Konstantinos D and Theodoropoulou, Margarita C and Kontou, Panagiota I and Bagos, Pantelis G},
  date         = {2019-07-01},
  doi          = {10.1093/bioinformatics/bty910},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Tamposis et al_2019_Semi-supervised learning of Hidden Markov Models for biological sequence.pdf;/Users/lucblassel/Zotero/storage/S7K9ZPD7/5184961.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {13},
  pages        = {2208--2215},
  shortjournal = {Bioinformatics},
  title        = {Semi-Supervised Learning of {{Hidden Markov Models}} for Biological Sequence Analysis},
  url          = {https://doi.org/10.1093/bioinformatics/bty910},
  urldate      = {2022-09-07},
  volume       = {35}
}

@article{taylorClassificationAminoAcid1986,
  abstract     = {A classification of amino acid type is described which is based on a synthesis of physico-chemical and mutation data. This is organised in the form of a Venn diagram from which sub-sets are derived that include groups of amino acids likely to be conserved for similar structural reasons. These sets are used to describe conservation in aligned sequences by allocating to each position the smallest set that contains all the residue types brought together by alignment. This minimal set assignment provides a simple way of reducing the information contained in a sequence alignment to a form which can be analysed by computer yet remains readable.},
  author       = {Taylor, William Ramsay},
  date         = {1986-03-21},
  doi          = {10.1016/S0022-5193(86)80075-3},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/taylor_1986_the_classification_of_amino_acid_conservation.pdf;/Users/lucblassel/Zotero/storage/Q77YLMFU/S0022519386800753.html},
  issn         = {0022-5193},
  journaltitle = {Journal of Theoretical Biology},
  number       = {2},
  pages        = {205--218},
  shortjournal = {Journal of Theoretical Biology},
  title        = {The Classification of Amino Acid Conservation},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022519386800753},
  urldate      = {2018-09-19},
  volume       = {119}
}

@inproceedings{townshendEndtoEndLearning3D2019,
  abstract  = {Despite an explosion in the number of experimentally determined, atomically detailed structures of biomolecules, many critical tasks in structural biology remain data-limited.  Whether performance in such tasks can be improved by using large repositories of tangentially related structural data remains an open question.  To address this question, we focused on a central problem in biology: predicting how proteins interact with one another—that is, which surfaces of one protein bind to those of another protein.  We built a training dataset, the Database of Interacting Protein Structures (DIPS), that contains biases but is two orders of magnitude larger than those used previously.  We found that these biases significantly degrade the performance of existing methods on gold-standard data.  Hypothesizing that assumptions baked into the hand-crafted features on which these methods depend were the source of the problem, we developed the first end-to-end learning model for protein interface prediction, the Siamese Atomic Surfacelet Network (SASNet).  Using only spatial coordinates and identities of atoms, SASNet outperforms state-of-the-art methods trained on gold-standard structural data, even when trained on only 3\% of our new dataset.  Code and data available at https://github.com/drorlab/DIPS.},
  author    = {Townshend, Raphael and Bedi, Rishi and Suriana, Patricia and Dror, Ron},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2019},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Townshend et al_2019_End-to-End Learning on 3D Protein Structure for Interface Prediction.pdf},
  publisher = {{Curran Associates, Inc.}},
  title     = {End-to-{{End Learning}} on {{3D Protein Structure}} for {{Interface Prediction}}},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/6c7de1f27f7de61a6daddfffbe05c058-Abstract.html},
  urldate   = {2022-09-07},
  volume    = {32}
}

@article{tunyasuvunakoolHighlyAccurateProtein2021,
  abstract     = {Protein structures can provide invaluable information, both for reasoning about biological processes and for enabling interventions such as structure-based drug development or targeted mutagenesis. After decades of effort, 17\% of the total residues in human protein sequences are covered by an experimentally determined structure1. Here we markedly expand the structural coverage of the proteome by applying the state-of-the-art machine learning method, AlphaFold2, at a scale that covers almost the entire human proteome (98.5\% of human proteins). The resulting dataset covers 58\% of residues with a confident prediction, of which a subset (36\% of all residues) have very high confidence. We introduce several metrics developed by building on the AlphaFold model and use them to interpret the dataset, identifying strong multi-domain predictions as well as regions that are likely to be disordered. Finally, we provide some case studies to illustrate how high-quality predictions could be used to generate biological hypotheses. We are making our predictions freely available to the community and anticipate that routine large-scale and high-accuracy structure prediction will become an important tool~that will allow new questions to be addressed from a structural perspective.},
  author       = {Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and Žídek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and Velankar, Sameer and Kleywegt, Gerard J. and Bateman, Alex and Evans, Richard and Pritzel, Alexander and Figurnov, Michael and Ronneberger, Olaf and Bates, Russ and Kohl, Simon A. A. and Potapenko, Anna and Ballard, Andrew J. and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Clancy, Ellen and Reiman, David and Petersen, Stig and Senior, Andrew W. and Kavukcuoglu, Koray and Birney, Ewan and Kohli, Pushmeet and Jumper, John and Hassabis, Demis},
  date         = {2021-08},
  doi          = {10.1038/s41586-021-03828-1},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Tunyasuvunakool et al_2021_Highly accurate protein structure prediction for the human proteome.pdf;/Users/lucblassel/Zotero/storage/GAZXMZSH/s41586-021-03828-1.html},
  issn         = {1476-4687},
  issue        = {7873},
  journaltitle = {Nature},
  keywords     = {Machine learning,Protein structure predictions,Proteomic analysis,Structural biology},
  langid       = {english},
  number       = {7873},
  pages        = {590--596},
  publisher    = {{Nature Publishing Group}},
  title        = {Highly Accurate Protein Structure Prediction for the Human Proteome},
  url          = {https://www.nature.com/articles/s41586-021-03828-1},
  urldate      = {2022-09-07},
  volume       = {596}
}

@book{vapnikEstimationDependencesBased1982,
  author     = {Vapnik, Vladimir},
  date       = {1982},
  isbn       = {978-0-387-90733-8},
  location   = {{Berlin, Heidelberg}},
  publisher  = {{Springer-Verlag}},
  shorttitle = {Estimation of {{Dependences Based}} on {{Empirical Data}}},
  title      = {Estimation of {{Dependences Based}} on {{Empirical Data}}: {{Springer Series}} in {{Statistics}} ({{Springer Series}} in {{Statistics}})}
}

@book{vapnikEstimationDependencesBased2006,
  abstract  = {Twenty-?ve years have passed since the publication of the Russian version of the book Estimation of Dependencies Based on Empirical Data (EDBED for short). Twen- ?ve years is a long period of time. During these years many things have happened. Looking back, one can see how rapidly life and technology have changed, and how slow and dif?cult it is to change the theoretical foundation of the technology and its philosophy. I pursued two goals writing this Afterword: to update the technical results presented in EDBED (the easy goal) and to describe a general picture of how the new ideas developed over these years (a much more dif?cult goal). The picture which I would like to present is a very personal (and therefore very biased) account of the development of one particular branch of science, Empirical - ference Science. Such accounts usually are not included in the content of technical publications. I have followed this rule in all of my previous books. But this time I would like to violate it for the following reasons. First of all, for me EDBED is the important milestone in the development of empirical inference theory and I would like to explain why. S- ond, during these years, there were a lot of discussions between supporters of the new 1 paradigm (now it is called the VC theory ) and the old one (classical statistics).},
  author    = {Vapnik, V.},
  date      = {2006-09-28},
  isbn      = {978-0-387-34239-9},
  keywords  = {Mathematics / Applied,Mathematics / General},
  langid    = {english},
  pagetotal = {515},
  publisher = {{Springer Science \& Business Media}},
  title     = {Estimation of {{Dependences Based}} on {{Empirical Data}}}
}

@inproceedings{vaswaniAttentionAllYou2017,
  abstract  = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  date      = {2017},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Vaswani et al_2017_Attention is All you Need.pdf},
  publisher = {{Curran Associates, Inc.}},
  title     = {Attention Is {{All}} You {{Need}}},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  urldate   = {2022-09-16},
  volume    = {30}
}

@misc{vigBERTologyMeetsBiology2021,
  abstract      = {Transformer architectures have proven to learn useful representations for protein classification and generation tasks. However, these representations present challenges in interpretability. In this work, we demonstrate a set of methods for analyzing protein Transformer models through the lens of attention. We show that attention: (1) captures the folding structure of proteins, connecting amino acids that are far apart in the underlying sequence, but spatially close in the three-dimensional structure, (2) targets binding sites, a key functional component of proteins, and (3) focuses on progressively more complex biophysical properties with increasing layer depth. We find this behavior to be consistent across three Transformer architectures (BERT, ALBERT, XLNet) and two distinct protein datasets. We also present a three-dimensional visualization of the interaction between attention and protein structure. Code for visualization and analysis is available at https://github.com/salesforce/provis.},
  archiveprefix = {arXiv},
  author        = {Vig, Jesse and Madani, Ali and Varshney, Lav R. and Xiong, Caiming and Socher, Richard and Rajani, Nazneen Fatema},
  date          = {2021-03-28},
  doi           = {10.48550/arXiv.2006.15222},
  eprint        = {2006.15222},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Vig et al_2021_BERTology Meets Biology.pdf;/Users/lucblassel/Zotero/storage/LNTSXCZ6/2006.html},
  keywords      = {Computer Science - Computation and Language,Computer Science - Machine Learning,I.2,Quantitative Biology - Biomolecules},
  number        = {arXiv:2006.15222},
  primaryclass  = {cs, q-bio},
  publisher     = {{arXiv}},
  shorttitle    = {{{BERTology Meets Biology}}},
  title         = {{{BERTology Meets Biology}}: {{Interpreting Attention}} in {{Protein Language Models}}},
  url           = {http://arxiv.org/abs/2006.15222},
  urldate       = {2022-09-16}
}

@article{wangAccurateNovoPrediction2017,
  abstract     = {Motivation Protein contacts contain key information for the understanding of protein structure and function and thus, contact prediction from sequence is an important problem. Recently exciting progress has been made on this problem, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction. Method This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling (EC) and sequence conservation information through an ultra-deep neural network formed by two deep residual neural networks. The first residual network conducts a series of 1-dimensional convolutional transformation of sequential features; the second residual network conducts a series of 2-dimensional convolutional transformation of pairwise information including output of the first residual network, EC information and pairwise potential. By using very deep residual networks, we can accurately model contact occurrence patterns and complex sequence-structure relationship and thus, obtain higher-quality contact prediction regardless of how many sequence homologs are available for proteins in question. Results Our method greatly outperforms existing methods and leads to much more accurate contact-assisted folding. Tested on 105 CASP11 targets, 76 past CAMEO hard targets, and 398 membrane proteins, the average top L long-range prediction accuracy obtained by our method, one representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21 and 0.30, respectively; the average top L/10 long-range accuracy of our method, CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding using our predicted contacts as restraints but without any force fields can yield correct folds (i.e., TMscore{$>$}0.6) for 203 of the 579 test proteins, while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 79 and 62 of them, respectively. Our contact-assisted models also have much better quality than template-based models especially for membrane proteins. The 3D models built from our contact prediction have TMscore{$>$}0.5 for 208 of the 398 membrane proteins, while those from homology modeling have TMscore{$>$}0.5 for only 10 of them. Further, even if trained mostly by soluble proteins, our deep learning method works very well on membrane proteins. In the recent blind CAMEO benchmark, our fully-automated web server implementing this method successfully folded 6 targets with a new fold and only 0.3L-2.3L effective sequence homologs, including one β protein of 182 residues, one α+β protein of 125 residues, one α protein of 140 residues, one α protein of 217 residues, one α/β of 260 residues and one α protein of 462 residues. Our method also achieved the highest F1 score on free-modeling targets in the latest CASP (Critical Assessment of Structure Prediction), although it was not fully implemented back then. Availability http://raptorx.uchicago.edu/ContactMap/},
  author       = {Wang, Sheng and Sun, Siqi and Li, Zhen and Zhang, Renyu and Xu, Jinbo},
  date         = {2017-01-05},
  doi          = {10.1371/journal.pcbi.1005324},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2017_Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model.pdf;/Users/lucblassel/Zotero/storage/CCUFZ4DY/article.html},
  issn         = {1553-7358},
  journaltitle = {PLOS Computational Biology},
  keywords     = {Convolution,Deep learning,Forecasting,Membrane proteins,Neural networks,Protein folding,Protein structure,Protein structure prediction},
  langid       = {english},
  number       = {1},
  pages        = {e1005324},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS Computational Biology},
  title        = {Accurate {{De Novo Prediction}} of {{Protein Contact Map}} by {{Ultra-Deep Learning Model}}},
  url          = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005324},
  urldate      = {2022-09-07},
  volume       = {13}
}

@article{wangComprehensiveSurveyLoss2022,
  abstract     = {As one of the important research topics in machine learning, loss function plays an important role in the construction of machine learning algorithms and the improvement of their performance, which has been concerned and explored by many researchers. But it still has a big gap to summarize, analyze and compare the classical loss functions. Therefore, this paper summarizes and analyzes 31 classical loss functions in machine learning. Specifically, we describe the loss functions from the aspects of traditional machine learning and deep learning respectively. The former is divided into classification problem, regression problem and unsupervised learning according to the task type. The latter is subdivided according to the application scenario, and here we mainly select object detection and face recognition to introduces their loss functions. In each task or application, in addition to analyzing each loss function from formula, meaning, image and algorithm, the loss functions under the same task or application are also summarized and compared to deepen the understanding and provide help for the selection and improvement of loss function.},
  author       = {Wang, Qi and Ma, Yue and Zhao, Kun and Tian, Yingjie},
  date         = {2022-04-01},
  doi          = {10.1007/s40745-020-00253-5},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2022_A Comprehensive Survey of Loss Functions in Machine Learning.pdf},
  issn         = {2198-5812},
  journaltitle = {Annals of Data Science},
  keywords     = {Deep learning,Loss function,Machine learning,Survey},
  langid       = {english},
  number       = {2},
  pages        = {187--212},
  shortjournal = {Ann. Data. Sci.},
  title        = {A {{Comprehensive Survey}} of {{Loss Functions}} in {{Machine Learning}}},
  url          = {https://doi.org/10.1007/s40745-020-00253-5},
  urldate      = {2022-09-19},
  volume       = {9}
}

@article{wangPredictingDNAMethylation2016,
  abstract     = {The hypo- or hyper-methylation of the human genome is one of the epigenetic features of leukemia. However, experimental approaches have only determined the methylation state of a small portion of the human genome. We developed deep learning based (stacked denoising autoencoders, or SdAs) software named “DeepMethyl” to predict the methylation state of DNA CpG dinucleotides using features inferred from three-dimensional genome topology (based on Hi-C) and DNA sequence patterns. We used the experimental data from immortalised myelogenous leukemia (K562) and healthy lymphoblastoid (GM12878) cell lines to train the learning models and assess prediction performance. We have tested various SdA architectures with different configurations of hidden layer(s) and amount of pre-training data and compared the performance of deep networks relative to support vector machines (SVMs). Using the methylation states of sequentially neighboring regions as one of the learning features, an SdA achieved a blind test accuracy of 89.7\% for GM12878 and 88.6\% for K562. When the methylation states of sequentially neighboring regions are unknown, the accuracies are 84.82\% for GM12878 and 72.01\% for K562. We also analyzed the contribution of genome topological features inferred from Hi-C. DeepMethyl can be accessed at http://dna.cs.usm.edu/deepmethyl/.},
  author       = {Wang, Yiheng and Liu, Tong and Xu, Dong and Shi, Huidong and Zhang, Chaoyang and Mo, Yin-Yuan and Wang, Zheng},
  date         = {2016-01-22},
  doi          = {10.1038/srep19598},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2016_Predicting DNA Methylation State of CpG Dinucleotide Using Genome Topological.pdf;/Users/lucblassel/Zotero/storage/RN6RMC6V/srep19598.html},
  issn         = {2045-2322},
  issue        = {1},
  journaltitle = {Scientific Reports},
  keywords     = {Computer science,Genome informatics,Machine learning},
  langid       = {english},
  number       = {1},
  pages        = {19598},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Sci Rep},
  title        = {Predicting {{DNA Methylation State}} of {{CpG Dinucleotide Using Genome Topological Features}} and {{Deep Networks}}},
  url          = {https://www.nature.com/articles/srep19598},
  urldate      = {2022-09-07},
  volume       = {6}
}

@article{wangProteinSequenceProtein2017,
  abstract     = {Sequence describes the primary structure of a protein, which contains important structural, characteristic, and genetic information and thereby motivates many sequence-based computational approaches to infer protein function. Among them, feature-base approaches attract increased attention because they make prediction from a set of transformed and more biologically meaningful sequence features. However, original features extracted from sequence are usually of high dimensionality and often compromised by irrelevant patterns, therefore dimension reduction is necessary prior to classification for efficient and effective protein function prediction. A protein usually performs several different functions within an organism, which makes protein function prediction a multi-label classification problem. In machine learning, multi-label classification deals with problems where each object may belong to more than one class. As a well-known feature reduction method, linear discriminant analysis (LDA) has been successfully applied in many practical applications. It, however, by nature is designed for single-label classification, in which each object can belong to exactly one class. Because directly applying LDA in multi-label classification causes ambiguity when computing scatters matrices, we apply a new Multi-label Linear Discriminant Analysis (MLDA) approach to address this problem and meanwhile preserve powerful classification capability inherited from classical LDA. We further extend MLDA by \$\textbackslash ell \_1\$ -normalization to overcome the problem of over-counting data points with multiple labels. In addition, we incorporate biological network data using Laplacian embedding into our method, and assess the reliability of predicted putative functions. Extensive empirical evaluations demonstrate promising results of our methods.},
  author       = {Wang, Hua and Yan, Lin and Huang, Heng and Ding, Chris},
  date         = {2017-05},
  doi          = {10.1109/TCBB.2016.2591529},
  eventtitle   = {{{IEEE}}/{{ACM Transactions}} on {{Computational Biology}} and {{Bioinformatics}}},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2017_From Protein Sequence to Protein Function via Multi-Label Linear Discriminant.pdf},
  issn         = {1557-9964},
  journaltitle = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  keywords     = {Amino acids,Feature extraction,linear discriminant analysis,Linear discriminant analysis,multi-label classification,Prediction algorithms,Predictive models,Protein function prediction,Protein sequence},
  number       = {3},
  pages        = {503--513},
  title        = {From {{Protein Sequence}} to {{Protein Function}} via {{Multi-Label Linear Discriminant Analysis}}},
  volume       = {14}
}

@article{weiPredictionHumanProtein2018,
  abstract     = {Protein subcellular localization (PSL), as one of the most critical characteristics of human cells, plays an important role for understanding specific functions and biological processes in cells. Accurate prediction of protein subcellular localization is a fundamental and challenging problem, for which machine learning algorithms have been widely used. Traditionally, the performance of PSL prediction highly depends on handcrafted feature descriptors to represent proteins. In recent years, deep learning has emerged as a hot research topic in the field of machine learning, achieving outstanding success in learning high-level latent features within data samples. In this paper, to accurately predict protein subcellular locations, we propose a deep learning based predictor called DeepPSL by using Stacked Auto-Encoder (SAE) networks. In this predictor, we automatically learn high-level and abstract feature representations of proteins by exploring non-linear relations among diverse subcellular locations, addressing the problem of the need of handcrafted feature representations. Experimental results evaluated with three-fold cross validation show that the proposed DeepPSL outperforms traditional machine learning based methods. It is expected that DeepPSL, as the first predictor in the field of PSL prediction, has great potential to be a powerful computational method complementary to existing tools.},
  author       = {Wei, Leyi and Ding, Yijie and Su, Ran and Tang, Jijun and Zou, Quan},
  date         = {2018-07-01},
  doi          = {10.1016/j.jpdc.2017.08.009},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wei et al_2018_Prediction of human protein subcellular localization using deep learning.pdf;/Users/lucblassel/Zotero/storage/NNMCJIDK/S0743731517302393.html},
  issn         = {0743-7315},
  journaltitle = {Journal of Parallel and Distributed Computing},
  keywords     = {Deep learning,Feature representation,Protein subcellular localization},
  langid       = {english},
  pages        = {212--217},
  shortjournal = {Journal of Parallel and Distributed Computing},
  title        = {Prediction of Human Protein Subcellular Localization Using Deep Learning},
  url          = {https://www.sciencedirect.com/science/article/pii/S0743731517302393},
  urldate      = {2022-09-07},
  volume       = {117}
}

@article{whalenNavigatingPitfallsApplying2022,
  abstract     = {The scale of genetic, epigenomic, transcriptomic, cheminformatic and proteomic data available today, coupled with easy-to-use machine learning (ML) toolkits, has propelled the application of supervised learning in genomics research. However, the assumptions behind the statistical models and performance evaluations in ML software frequently are not met in biological systems. In this Review, we illustrate the impact of several common pitfalls encountered when applying supervised ML in genomics. We explore how the structure of genomics data can bias performance evaluations and predictions. To address the challenges associated with applying cutting-edge ML methods to genomics, we describe solutions and appropriate use cases where ML modelling shows great potential.},
  author       = {Whalen, Sean and Schreiber, Jacob and Noble, William S. and Pollard, Katherine S.},
  date         = {2022-03},
  doi          = {10.1038/s41576-021-00434-9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Whalen et al_2022_Navigating the pitfalls of applying machine learning in genomics.pdf;/Users/lucblassel/Zotero/storage/ZZBNCP2G/s41576-021-00434-9.html},
  issn         = {1471-0064},
  issue        = {3},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {Machine learning,Statistical methods},
  langid       = {english},
  number       = {3},
  pages        = {169--181},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Navigating the Pitfalls of Applying Machine Learning in Genomics},
  url          = {https://www.nature.com/articles/s41576-021-00434-9},
  urldate      = {2022-09-19},
  volume       = {23}
}

@article{whalenNavigatingPitfallsApplying2022a,
  abstract     = {The scale of genetic, epigenomic, transcriptomic, cheminformatic and proteomic data available today, coupled with easy-to-use machine learning (ML) toolkits, has propelled the application of supervised learning in genomics research. However, the assumptions behind the statistical models and performance evaluations in ML software frequently are not met in biological systems. In this Review, we illustrate the impact of several common pitfalls encountered when applying supervised ML in genomics. We explore how the structure of genomics data can bias performance evaluations and predictions. To address the challenges associated with applying cutting-edge ML methods to genomics, we describe solutions and appropriate use cases where ML modelling shows great potential.},
  author       = {Whalen, Sean and Schreiber, Jacob and Noble, William S. and Pollard, Katherine S.},
  date         = {2022-03},
  doi          = {10.1038/s41576-021-00434-9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Whalen et al_2022_Navigating the pitfalls of applying machine learning in genomics2.pdf},
  issn         = {1471-0064},
  issue        = {3},
  journaltitle = {Nature Reviews Genetics},
  keywords     = {Machine learning,Statistical methods},
  langid       = {english},
  number       = {3},
  pages        = {169--181},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Genet},
  title        = {Navigating the Pitfalls of Applying Machine Learning in Genomics},
  url          = {https://www.nature.com/articles/s41576-021-00434-9},
  urldate      = {2022-09-19},
  volume       = {23}
}

@article{wittmannAdvancesMachineLearning2021,
  abstract     = {Machine learning (ML) can expedite directed evolution by allowing researchers to move expensive experimental screens in silico. Gathering sequence-function data for training ML models, however, can still be costly. In contrast, raw protein sequence data is widely available. Recent advances in ML approaches use protein sequences to augment limited sequence-function data for directed evolution. We highlight contributions in a growing effort to use sequences to reduce or eliminate the amount of sequence-function data needed for effective in silico screening. We also highlight approaches that use ML models trained on sequences to generate new functional sequence diversity, focusing on strategies that use these generative models to efficiently explore vast regions of protein space.},
  author       = {Wittmann, Bruce J and Johnston, Kadina E and Wu, Zachary and Arnold, Frances H},
  date         = {2021-08-01},
  doi          = {10.1016/j.sbi.2021.01.008},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wittmann et al_2021_Advances in machine learning for directed evolution.pdf;/Users/lucblassel/Zotero/storage/CZVDNRCJ/S0959440X21000154.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  pages        = {11--18},
  series       = {Engineering and {{Design}} ● {{Membranes}}},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Advances in Machine Learning for Directed Evolution},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X21000154},
  urldate      = {2022-09-07},
  volume       = {69}
}

@article{wrightUsingDECIPHERV22016,
  abstract     = {In recent years, the cost of DNA sequencing has decreased at a rate that has outpaced improvements in memory capacity. It is now common to collect or have access to many gigabytes of biological sequences. This has created an urgent need for approaches that analyze sequences in subsets without requiring all of the sequences to be loaded into memory at one time. It has also opened opportunities to improve the organization and accessibility of information acquired in sequencing projects. The DECIPHER package offers solutions to these problems by assisting in the curation of large sets of biological sequences stored in compressed format inside a database. This approach has many practical advantages over standard bioinformatics workflows, and enables large analyses that would otherwise be prohibitively time consuming.},
  author       = {Wright, Erik S.},
  date         = {2016-05-01},
  doi          = {10.32614/RJ-2016-025},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wright_2016_The R Journal.pdf;/Users/lucblassel/Zotero/storage/LL2EN6NJ/RJ-2016-025.html},
  issn         = {2073-4859},
  journaltitle = {The R Journal},
  number       = {1},
  pages        = {352--359},
  shorttitle   = {The {{R Journal}}},
  title        = {Using {{DECIPHER}} v2.0 to {{Analyze Big Biological Sequence Data}} in {{R}}},
  url          = {https://doi.org/10.32614/RJ-2016-025/},
  urldate      = {2022-09-12},
  volume       = {8}
}

@article{wuProteinSequenceDesign2021,
  abstract     = {Protein engineering seeks to identify protein sequences with optimized properties. When guided by machine learning, protein sequence generation methods can draw on prior knowledge and experimental efforts to improve this process. In this review, we highlight recent applications of machine learning to generate protein sequences, focusing on the emerging field of deep generative methods.},
  author       = {Wu, Zachary and Johnston, Kadina E. and Arnold, Frances H. and Yang, Kevin K.},
  date         = {2021-12-01},
  doi          = {10.1016/j.cbpa.2021.04.004},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wu et al_2021_Protein sequence design with deep generative models.pdf;/Users/lucblassel/Zotero/storage/7YBSP4MY/S136759312100051X.html},
  issn         = {1367-5931},
  journaltitle = {Current Opinion in Chemical Biology},
  keywords     = {Deep learning,Generative models,Protein engineering},
  langid       = {english},
  pages        = {18--27},
  series       = {Mechanistic {{Biology}} * {{Machine Learning}} in {{Chemical Biology}}},
  shortjournal = {Current Opinion in Chemical Biology},
  title        = {Protein Sequence Design with Deep Generative Models},
  url          = {https://www.sciencedirect.com/science/article/pii/S136759312100051X},
  urldate      = {2022-09-13},
  volume       = {65}
}

@article{xiaSemisupervisedDrugproteinInteraction2010,
  abstract     = {Predicting drug-protein interactions from heterogeneous biological data sources is a key step for in silico drug discovery. The difficulty of this prediction task lies in the rarity of known drug-protein interactions and myriad unknown interactions to be predicted. To meet this challenge, a manifold regularization semi-supervised learning method is presented to tackle this issue by using labeled and unlabeled information which often generates better results than using the labeled data alone. Furthermore, our semi-supervised learning method integrates known drug-protein interaction network information as well as chemical structure and genomic sequence data.},
  author       = {Xia, Zheng and Wu, Ling-Yun and Zhou, Xiaobo and Wong, Stephen TC},
  date         = {2010-09-13},
  doi          = {10.1186/1752-0509-4-S2-S6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Xia et al_2010_Semi-supervised drug-protein interaction prediction from heterogeneous.pdf;/Users/lucblassel/Zotero/storage/RKQMZJ4D/1752-0509-4-S2-S6.html},
  issn         = {1752-0509},
  journaltitle = {BMC Systems Biology},
  keywords     = {Chemical Structure Similarity,Drug Domain,Genomic Space,Manifold Regularization,Unlabeled Sample},
  number       = {2},
  pages        = {S6},
  shortjournal = {BMC Systems Biology},
  title        = {Semi-Supervised Drug-Protein Interaction Prediction from Heterogeneous Biological Spaces},
  url          = {https://doi.org/10.1186/1752-0509-4-S2-S6},
  urldate      = {2022-09-07},
  volume       = {4}
}

@article{xieDeepAutoencoderModel2017,
  abstract     = {Gene expression is a key intermediate level that genotypes lead to a particular trait. Gene expression is affected by various factors including genotypes of genetic variants. With an aim of delineating the genetic impact on gene expression, we build a deep auto-encoder model to assess how good genetic variants will contribute to gene expression changes. This new deep learning model is a regression-based predictive model based on the MultiLayer Perceptron and Stacked Denoising Auto-encoder (MLP-SAE). The model is trained using a stacked denoising auto-encoder for feature selection and a multilayer perceptron framework for backpropagation. We further improve the model by introducing dropout to prevent overfitting and improve performance.},
  author       = {Xie, Rui and Wen, Jia and Quitadamo, Andrew and Cheng, Jianlin and Shi, Xinghua},
  date         = {2017-11-17},
  doi          = {10.1186/s12864-017-4226-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Xie et al_2017_A deep auto-encoder model for gene expression prediction.pdf;/Users/lucblassel/Zotero/storage/PBB5RHUQ/s12864-017-4226-0.html},
  issn         = {1471-2164},
  journaltitle = {BMC Genomics},
  keywords     = {Deep learning,Gene expression,Multilayer perceptron,Predictive model,Stacked denoising auto-encoder},
  number       = {9},
  pages        = {845},
  shortjournal = {BMC Genomics},
  title        = {A Deep Auto-Encoder Model for Gene Expression Prediction},
  url          = {https://doi.org/10.1186/s12864-017-4226-0},
  urldate      = {2022-09-07},
  volume       = {18}
}

@article{yangMachinelearningguidedDirectedEvolution2019,
  abstract     = {Protein engineering through machine-learning-guided directed evolution enables the optimization of protein functions. Machine-learning approaches predict how sequence maps to function in a data-driven manner without requiring a detailed model of the underlying physics or biological pathways. Such methods accelerate directed evolution by learning from the properties of characterized variants and using that information to select sequences that are likely to exhibit improved properties. Here we introduce the steps required to build machine-learning sequence–function models and to use those models to guide engineering, making recommendations at each stage. This review covers basic concepts relevant to the use of machine learning for protein engineering, as well as the current literature and applications of this engineering paradigm. We illustrate the process with two case studies. Finally, we look to future opportunities for machine learning to enable the discovery of unknown protein functions and uncover the relationship between protein sequence and function.},
  author       = {Yang, Kevin K. and Wu, Zachary and Arnold, Frances H.},
  date         = {2019-08},
  doi          = {10.1038/s41592-019-0496-6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Yang et al_2019_Machine-learning-guided directed evolution for protein engineering.pdf;/Users/lucblassel/Zotero/storage/TV6MQP4Y/s41592-019-0496-6.html},
  issn         = {1548-7105},
  issue        = {8},
  journaltitle = {Nature Methods},
  keywords     = {Machine learning,Proteins},
  langid       = {english},
  number       = {8},
  pages        = {687--694},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Machine-Learning-Guided Directed Evolution for Protein Engineering},
  url          = {https://www.nature.com/articles/s41592-019-0496-6},
  urldate      = {2022-09-07},
  volume       = {16}
}

@article{yangReviewEnsembleMethods2010,
  abstract     = {Ensemble learning is an intensively studied technique in machine learning and pattern recognition. Recent work in computational biology has seen an increasing use of ensemble learning methods due to their unique advantages in dealing with small sample size, high-dimensionality, and complex data structures. The aim of this article is two-fold. Firstly, it is to provide a review of the most widely used ensemble learning methods and their application in various bioinformatics problems, including the main topics of gene expression, mass spectrometry-based proteomics, gene-gene interaction identification from genome-wide association studies, and prediction of regulatory elements from DNA and protein sequences. Secondly, we try to identify and summarize future trends of ensemble methods in bioinformatics. Promising directions such as ensemble of support vector machines, meta-ensembles, and ensemble based feature selection are discussed.},
  author       = {Yang, Pengyi and Hwa Yang, Yee and B. Zhou, Bing and Y. Zomaya, Albert},
  date         = {2010-12-01},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Yang et al_2010_A Review of Ensemble Methods in Bioinformatics.pdf},
  journaltitle = {Current Bioinformatics},
  keywords     = {aggregating,base,binary dataset,bioinformatics,biologists,biology,biomarker,clustering,data-level perturbation,Dettling,diseases,DNA,empirical evaluation,ensemble feature selection,Ensemble learning,ensemble of support vector machines,gene-gene interaction,Glycosylation,high-dimensional data,hydrophobicity,LogitBoost,mass spectrometry,mass spectrometry-based proteomics,meta ensemble,Meta Ensemble,microarray,Multiboost,phosphorylation,polarity; polarizability,polymorphism,POPULAR ENSEMBLE METHODS,protein-protein interactions,proteins,proteomics,pseudo-amino acid,regulatory elements prediction,SNP interaction,van der Waals volume},
  number       = {4},
  pages        = {296--308},
  shortjournal = {Current Bioinformatics},
  title        = {A {{Review}} of {{Ensemble Methods}} in {{Bioinformatics}}},
  volume       = {5}
}

@inproceedings{zamaniAminoAcidEncoding2011,
  abstract   = {In this paper, we investigate the efficiency of a number of commonly used amino acid encodings by using artificial neural networks and substitution scoring matrices. An important step in many machine learning techniques applied in computational biology is encoding the symbolic data of protein sequences reasonably efficient in numeric vector representations. This encoding can be achieved by either considering the amino acid physicochemical properties or a generic numerical encoding. In order to be effective in the context of a machine learning system, an encoding must preserve information relative to the problem at hand, while diminishing superfluous data. To this end, it is important to measure how much an encoding scheme can conserve the underlying similarities and differences that exist among the amino acids. One way to evaluate the effectiveness of an amino acid encoding scheme is to compare it to the roles that amino acids are actually found to play in biological systems. A numerical representation of the similarities and differences between amino acids can be found in substitution matrices commonly used for sequence alignment, since these substitution matrices are based on measures of the interchangeability of amino acids in biological specimens. In this study, a new encoding scheme is also proposed based on the genetic codon coding occurs during protein synthesis. The experimental results indicate better performances compared to the other commonly used encodings.},
  author     = {Zamani, M. and Kremer, S. C.},
  booktitle  = {2011 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine Workshops}} ({{BIBMW}})},
  date       = {2011-11},
  doi        = {10.1109/BIBMW.2011.6112394},
  eventtitle = {2011 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine Workshops}} ({{BIBMW}})},
  file       = {/Users/lucblassel/Google Drive/Zotero_papers/zamani_kremer_2011_amino_acid_encoding_schemes_for_machine_learning.pdf;/Users/lucblassel/Zotero/storage/53GJFAHZ/6112394.html},
  keywords   = {amino acid encoding scheme,amino acids,Amino acids,Approximation methods,artificial neural network,artificial neural networks,Biological neural networks,biological specimen,biological system,biology computing,computational biology,Encoding,generic numerical encoding,learning (artificial intelligence),machine learning,Matrices,neural nets,numeric vector representation,physicochemical properties,protein sequence,protein synthesis,proteins,Proteins,substitution matrix,substitution scoring matrices,symbolic data,Training},
  pages      = {327--333},
  title      = {Amino Acid Encoding Schemes for Machine Learning Methods}
}

@article{zazziPredictingResponseAntiretroviral2012,
  abstract     = {For a long time, the clinical management of antiretroviral drug resistance was based on sequence analysis of the HIV genome followed by estimating drug susceptibility from the mutational pattern that was detected. The large number of anti-HIV drugs and HIV drug resistance mutations has prompted the development of computer-aided genotype interpretation systems, typically comprising rules handcrafted by experts via careful examination of in vitro and in vivo resistance data. More recently, machine learning approaches have been applied to establish data-driven engines able to indicate the most effective treatments for any patient and virus combination. Systems of this kind, currently including the Resistance Response Database Initiative and the EuResist engine, must learn from the large data sets of patient histories and can provide an objective and accurate estimate of the virological response to different antiretroviral regimens. The EuResist engine was developed by a European consortium of HIV and bioinformatics experts and compares favorably with the most commonly used genotype interpretation systems and HIV drug resistance experts. Next-generation treatment response prediction engines may valuably assist the HIV specialist in the challenging task of establishing effective regimens for patients harboring drug-resistant virus strains. The extensive collection and accurate processing of increasingly large patient data sets are eagerly awaited to further train and translate these systems from prototype engines into real-life treatment decision support tools.},
  author       = {Zazzi, Maurizio and Incardona, Francesca and Rosen-Zvi, Michal and Prosperi, Mattia and Lengauer, Thomas and Altmann, Andre and Sonnerborg, Anders and Lavee, Tamar and Schülter, Eugen and Kaiser, Rolf},
  date         = {2012},
  doi          = {10.1159/000332008},
  eprint       = {22286881},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zazzi et al_2012_Predicting Response to Antiretroviral Treatment by Machine Learning.pdf;/Users/lucblassel/Zotero/storage/NWRSIWQG/332008.html},
  issn         = {0300-5526, 1423-0100},
  journaltitle = {Intervirology},
  langid       = {english},
  number       = {2},
  pages        = {123--127},
  publisher    = {{Karger Publishers}},
  shortjournal = {INT},
  shorttitle   = {Predicting {{Response}} to {{Antiretroviral Treatment}} by {{Machine Learning}}},
  title        = {Predicting {{Response}} to {{Antiretroviral Treatment}} by {{Machine Learning}}: {{The EuResist Project}}},
  url          = {https://www.karger.com/Article/FullText/332008},
  urldate      = {2022-09-07},
  volume       = {55}
}

@inproceedings{zhangOptimalityNaiveBayes,
  abstract  = {Naive Bayes is one of the most efficient and effective inductive learning algorithms for machine learning and data mining. Its competitive performance in classification is surprising, because the conditional independence assumption on which it is based, is rarely true in realworld applications. An open question is: what is the true reason for the surprisingly good performance of naive Bayes in classification? In this paper, we propose a novel explanation on the superb classification performance of naive Bayes. We show that, essentially, the dependence distribution; i.e., how the local dependence of a node distributes in each class, evenly or unevenly, and how the local dependencies of all nodes work together, consistently (supporting a certain classification) or inconsistently (canceling each other out), plays a crucial role. Therefore, no matter how strong the dependences among attributes are, naive Bayes can still be optimal if the dependences distribute evenly in classes, or if the dependences cancel each other out. We propose and prove a sufficient and necessary conditions for the optimality of naive Bayes. Further, we investigate the optimality of naive Bayes under the Gaussian distribution. We present and prove a sufficient condition for the optimality of naive Bayes, in which the dependence between attributes do exist. This provides evidence that dependence among attributes may cancel out each other. In addition, we explore when naive Bayes works well.},
  author    = {Zhang, Harry},
  booktitle = {Proceedings of the the 17th International FLAIRS conference (FLAIRS2004)},
  file      = {/Users/lucblassel/Google Drive/Zotero_papers/zhang_the_optimality_of_naive_bayes.pdf},
  langid    = {english},
  pages     = {6},
  pages     = {562--567},
  title     = {The {{Optimality}} of {{Naive Bayes}}},
  year      = {2004}
}

@article{zoritaStarcodeSequenceClustering2015,
  abstract     = {Motivation: The increasing throughput of sequencing technologies offers new applications and challenges for computational biology. In many of those applications, sequencing errors need to be corrected. This is particularly important when sequencing reads from an unknown reference such as random DNA barcodes. In this case, error correction can be done by performing a pairwise comparison of all the barcodes, which is a computationally complex problem.Results: Here, we address this challenge and describe an exact algorithm to determine which pairs of sequences lie within a given Levenshtein distance. For error correction or redundancy reduction purposes, matched pairs are then merged into clusters of similar sequences. The efficiency of starcode is attributable to the poucet search, a novel implementation of the Needleman–Wunsch algorithm performed on the nodes of a trie. On the task of matching random barcodes, starcode outperforms sequence clustering algorithms in both speed and precision.Availability and implementation: The C source code is available at http://github.com/gui11aume/starcode.Contact:guillaume.filion@gmail.com},
  author       = {Zorita, Eduard and Cuscó, Pol and Filion, Guillaume J.},
  date         = {2015-06-15},
  doi          = {10.1093/bioinformatics/btv053},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zorita et al_2015_Starcode.pdf;/Users/lucblassel/Zotero/storage/92U6LRMW/213875.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {12},
  pages        = {1913--1919},
  shortjournal = {Bioinformatics},
  shorttitle   = {Starcode},
  title        = {Starcode: Sequence Clustering Based on All-Pairs Search},
  url          = {https://doi.org/10.1093/bioinformatics/btv053},
  urldate      = {2022-09-07},
  volume       = {31}
}

@article{zvelebilPredictionProteinSecondary1987,
  abstract     = {The prediction of protein secondary structure (α-helices, β-sheets and coil) is improved by 9\% to 66\% using the information available from a family of homologous sequences. The approach is based both on averaging the Garnier et al. (1978) secondary structure propensities for aligned residues and on the observation that insertions and high sequence variability tend to occur in loop regions between secondary structures. Accordingly, an algorithm first aligns a family of sequences and a value for the extent of sequence conservation at each position is obtained. This value modifies a Gamier et al. prediction on the averaged sequence to yield the improved prediction. In addition, from the sequence conservation and the predicted secondary structure, many active site regions of enzymes can be located (26 out of 43) with limited over-prediction (8 extra). The entire algorithm is fully automatic and is applicable to all structural classes of globular proteins.},
  author       = {Zvelebil, Markéta J. and Barton, Geoffrey J. and Taylor, William R. and Sternberg, Michael J. E.},
  date         = {1987-06-20},
  doi          = {10.1016/0022-2836(87)90501-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zvelebil et al_1987_Prediction of protein secondary structure and active sites using the alignment.pdf;/Users/lucblassel/Zotero/storage/2YGU92LT/0022283687905018.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {4},
  pages        = {957--961},
  shortjournal = {Journal of Molecular Biology},
  title        = {Prediction of Protein Secondary Structure and Active Sites Using the Alignment of Homologous Sequences},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283687905018},
  urldate      = {2022-09-13},
  volume       = {195}
}


