
@inproceedings{abouelhodaEnhancedSuffixArray2002,
  abstract  = {In large scale applications as computational genome analysis, the space requirement of the suffix tree is a severe drawback. In this paper, we present a uniform framework that enables us to systematically replace every string processing algorithm that is based on a bottomup traversal of a suffix tree by a corresponding algorithm based on an enhanced suffix array (a suffix array enhanced with the lcp-table). In this framework, we will show how maximal, supermaximal, and tandem repeats, as well as maximal unique matches can be efficiently computed. Because enhanced suffix arrays require much less space than suffix trees, very large genomes can now be indexed and analyzed, a task which was not feasible before. Experimental results demonstrate that our programs require not only less space but also much less time than other programs developed for the same tasks.},
  author    = {Abouelhoda, Mohamed Ibrahim and Kurtz, Stefan and Ohlebusch, Enno},
  booktitle = {Algorithms in {{Bioinformatics}}},
  date      = {2002},
  doi       = {10.1007/3-540-45784-4_35},
  editor    = {Guigó, Roderic and Gusfield, Dan},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Abouelhoda et al_2002_The Enhanced Suffix Array and Its Applications to Genome Analysis.pdf},
  isbn      = {978-3-540-45784-8},
  keywords  = {Linear Time Algorithm,Main Memory,Space Requirement,Suffix Tree,Tandem Repeat},
  langid    = {english},
  location  = {{Berlin, Heidelberg}},
  pages     = {449--463},
  publisher = {{Springer}},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  title     = {The {{Enhanced Suffix Array}} and {{Its Applications}} to {{Genome Analysis}}}
}

@article{abouelhodaReplacingSuffixTrees2004,
  abstract     = {The suffix tree is one of the most important data structures in string processing and comparative genomics. However, the space consumption of the suffix tree is a bottleneck in large scale applications such as genome analysis. In this article, we will overcome this obstacle. We will show how every algorithm that uses a suffix tree as data structure can systematically be replaced with an algorithm that uses an enhanced suffix array and solves the same problem in the same time complexity. The generic name enhanced suffix array stands for data structures consisting of the suffix array and additional tables. Our new algorithms are not only more space efficient than previous ones, but they are also faster and easier to implement.},
  author       = {Abouelhoda, Mohamed Ibrahim and Kurtz, Stefan and Ohlebusch, Enno},
  date         = {2004-03-01},
  doi          = {10.1016/S1570-8667(03)00065-0},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Abouelhoda et al_2004_Replacing suffix trees with enhanced suffix arrays.pdf},
  issn         = {1570-8667},
  journaltitle = {Journal of Discrete Algorithms},
  keywords     = {Genome comparison,Pattern matching,Repeat analysis,Suffix array,Suffix tree},
  langid       = {english},
  number       = {1},
  pages        = {53--86},
  series       = {The 9th {{International Symposium}} on {{String Processing}} and {{Information Retrieval}}},
  shortjournal = {Journal of Discrete Algorithms},
  title        = {Replacing Suffix Trees with Enhanced Suffix Arrays},
  url          = {https://www.sciencedirect.com/science/article/pii/S1570866703000650},
  urldate      = {2022-09-05},
  volume       = {2}
}

@article{aksamentovNextcladeCladeAssignment2021,
  abstract     = {The variants of concern (VoCs) of SARS-CoV-2 have highlighted the need for a global molecular surveillance of pathogens via whole genome sequencing. Such sequencing, for SARSCoV-2 and other pathogens, is performed by an ever increasing number of labs across the globe, resulting in an increased need for an easy, fast, and decentralized analysis of initial data. Nextclade aligns viral genomes to a reference sequence, calculates several quality control (QC) metrics, assigns sequences to a clade or variant, and identifies changes in the viral proteins relative to the reference sequence. Nextclade is available as a command-line tool and as a web application with completely client based processing, meaning that sequence data doesn’t leave the user’s browser.},
  author       = {Aksamentov, Ivan and Roemer, Cornelius and Hodcroft, Emma and Neher, Richard},
  date         = {2021-11-30},
  doi          = {10.21105/joss.03773},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Aksamentov et al_2021_Nextclade.pdf},
  issn         = {2475-9066},
  journaltitle = {Journal of Open Source Software},
  langid       = {english},
  number       = {67},
  pages        = {3773},
  shortjournal = {JOSS},
  shorttitle   = {Nextclade},
  title        = {Nextclade: Clade Assignment, Mutation Calling and Quality Control for Viral Genomes},
  url          = {https://joss.theoj.org/papers/10.21105/joss.03773},
  urldate      = {2022-06-16},
  volume       = {6}
}

@article{alserTechnologyDictatesAlgorithms2021,
  abstract     = {Aligning sequencing reads onto a reference is an essential step of the majority of genomic analysis pipelines. Computational algorithms for read alignment have evolved in accordance with technological advances, leading to today’s diverse array of alignment methods. We provide a systematic survey of algorithmic foundations and methodologies across 107 alignment methods, for both short and long reads. We provide a rigorous experimental evaluation of 11 read aligners to demonstrate the effect of these underlying algorithms on speed and efficiency of read alignment. We discuss how general alignment algorithms have been tailored to the specific needs of various domains in biology.},
  author       = {Alser, Mohammed and Rotman, Jeremy and Deshpande, Dhrithi and Taraszka, Kodi and Shi, Huwenbo and Baykal, Pelin Icer and Yang, Harry Taegyun and Xue, Victor and Knyazev, Sergey and Singer, Benjamin D. and Balliu, Brunilda and Koslicki, David and Skums, Pavel and Zelikovsky, Alex and Alkan, Can and Mutlu, Onur and Mangul, Serghei},
  date         = {2021-08-26},
  doi          = {10.1186/s13059-021-02443-7},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Alser et al_2021_Technology dictates algorithms.pdf;/Users/lucblassel/Zotero/storage/4PQTNUS2/s13059-021-02443-7.html},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  number       = {1},
  pages        = {249},
  shortjournal = {Genome Biology},
  shorttitle   = {Technology Dictates Algorithms},
  title        = {Technology Dictates Algorithms: Recent Developments in Read Alignment},
  url          = {https://doi.org/10.1186/s13059-021-02443-7},
  urldate      = {2022-06-15},
  volume       = {22}
}

@incollection{altschul27LocalAlignment1996,
  abstract  = {This chapter discusses the study of local alignment statistics, the distribution of optimal gapped subalignment scores, and the evidence that two parameters are sufficient to describe both the form of this distribution and its dependence on sequence length. Using a random protein model, the relevant statistical parameters are calculated for a variety of substitution matrices and gap costs. An analysis of these parameters elucidates the relative effectiveness of affine as opposed to length-proportional gap costs. Thus, sum statistics provide a method for evaluating sequence similarity that treats short and long gaps differently. By example, the chapter shows how this method has the potential to increase search sensitivity. The statistics described can be applied to the results of fast alignment (FASTA) searches or to those from a variation of the basic local alignment search tool (BLAST) programs.},
  author    = {Altschul, Stephen F. and Gish, Warren},
  booktitle = {Methods in {{Enzymology}}},
  date      = {1996-01-01},
  doi       = {10.1016/S0076-6879(96)66029-7},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul_Gish_1996_[27] Local alignment statistics.pdf;/Users/lucblassel/Zotero/storage/AAQ9D3AI/S0076687996660297.html},
  langid    = {english},
  pages     = {460--480},
  publisher = {{Academic Press}},
  series    = {Computer {{Methods}} for {{Macromolecular Sequence Analysis}}},
  title     = {[27] {{Local}} Alignment Statistics},
  url       = {https://www.sciencedirect.com/science/article/pii/S0076687996660297},
  urldate   = {2022-06-15},
  volume    = {266}
}

@article{altschulAminoAcidSubstitution1991,
  abstract     = {Protein sequence alignments have become an important tool for molecular biologists. Local alignments are frequently constructed with the aid of a “substitution score matrix” that specifies a score for aligning each pair of amino acid residues. Over the years, many different substitution matrices have been proposed, based on a wide variety of rationales. Statistical results, however, demonstrate that any such matrix is implicitly a “log-odds” matrix, with a specific target distribution for aligned pairs of amino acid residues. In the light of information theory, it is possible to express the scores of a substitution matrix in bits and to see that different matrices are better adapted to different purposes. The most widely used matrix for protein sequence comparison has been the PAM-250 matrix. It is argued that for database searches the PAM-120 matrix generally is more appropriate, while for comparing two specific proteins with suspected homology the PAM-200 matrix is indicated. Examples discussed include the lipocalins, human α1B-glycoprotein, the cystic fibrosis transmembrane conductance regulator and the globins.},
  author       = {Altschul, Stephen F.},
  date         = {1991-06-05},
  doi          = {10.1016/0022-2836(91)90193-A},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul_1991_Amino acid substitution matrices from an information theoretic perspective.pdf;/Users/lucblassel/Zotero/storage/37UNU2YU/002228369190193A.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {alignment algorithms,homology,pattern recognition,sequence comparison,statistical significance},
  langid       = {english},
  number       = {3},
  pages        = {555--565},
  shortjournal = {Journal of Molecular Biology},
  title        = {Amino Acid Substitution Matrices from an Information Theoretic Perspective},
  url          = {https://www.sciencedirect.com/science/article/pii/002228369190193A},
  urldate      = {2022-06-15},
  volume       = {219}
}

@article{altschulBasicLocalAlignment1990,
  abstract     = {A new approach to rapid sequence comparison, basic local alignment search tool (BLAST), directly approximates alignments that optimize a measure of local similarity, the maximal segment pair (MSP) score. Recent mathematical results on the stochastic properties of MSP scores allow an analysis of the performance of this method as well as the statistical significance of alignments it generates. The basic algorithm is simple and robust; it can be implemented in a number of ways and applied in a variety of contexts including straightforward DNA and protein sequence database searches, motif searches, gene identification searches, and in the analysis of multiple regions of similarity in long DNA sequences. In addition to its flexibility and tractability to mathematical analysis, BLAST is an order of magnitude faster than existing sequence comparison tools of comparable sensitivity.},
  author       = {Altschul, S. F. and Gish, W. and Miller, W. and Myers, E. W. and Lipman, D. J.},
  date         = {1990-10-05},
  doi          = {10.1016/S0022-2836(05)80360-2},
  eprint       = {2231712},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul et al_1990_Basic local alignment search tool.pdf},
  ids          = {altschupBasicLocalAlignment},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {Algorithms,Amino Acid Sequence,Base Sequence,Databases; Factual,Mutation,Sensitivity and Specificity,Sequence Homology; Nucleic Acid,Software},
  langid       = {english},
  number       = {3},
  pages        = {403--410},
  shortjournal = {J Mol Biol},
  title        = {Basic Local Alignment Search Tool},
  volume       = {215}
}

@article{altschulGapCostsMultiple1989,
  abstract     = {Standard methods for aligning pairs of biological sequences charge for the most common mutations, which are substitutions, deletions and insertions. Because a single mutation may insert or delete several nucleotides, gap costs that are not directly proportional to gap length are usually the most effective. How to extend such gap costs to alignments of three or more sequences is not immediately obvious, and a variety of approaches have been taken. This paper argues that, since gap and substitution costs together specify optimal alignments, they should be defined using a common rationale. Specifically, a new definition of gap costs for multiple alignments is proposed and compared with previous ones. Since the new definition links a multiple alignment's cost to that of its pairwise projections, it allows knowledge gained about two-sequence alignments to bear on the multiple alignment problem. Also, such linkage is a key element of recent algorithms that have rendered practical the simultaneous alignment of as many as six sequences.},
  author       = {Altschul, Stephen F.},
  date         = {1989-06-03},
  doi          = {10.1016/S0022-5193(89)80196-1},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul_1989_Gap costs for multiple sequence alignment.pdf;/Users/lucblassel/Zotero/storage/ABTZDVJ5/S0022519389801961.html},
  issn         = {0022-5193},
  journaltitle = {Journal of Theoretical Biology},
  langid       = {english},
  number       = {3},
  pages        = {297--309},
  shortjournal = {Journal of Theoretical Biology},
  title        = {Gap Costs for Multiple Sequence Alignment},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022519389801961},
  urldate      = {2022-09-06},
  volume       = {138}
}

@article{altschulGappedBLASTPSIBLAST1997,
  abstract     = {The BLAST programs are widely used tools for searching protein and DNA databases for sequence similarities. For protein comparisons, a variety of definitional, algorithmic and statistical refinements described here permits the execution time of the BLAST programs to be decreased substantially while enhancing their sensitivity to weak similarities. A new criterion for triggering the extension of word hits, combined with a new heuristic for generating gapped alignments, yields a gapped BLAST program that runs at approximately three times the speed of the original. In addition, a method is introduced for automatically combining statistically significant alignments produced by BLAST into a position-specific score matrix, and searching the database using this matrix. The resulting Position-Specific Iterated BLAST (PSIBLAST) program runs at approximately the same speed per iteration as gapped BLAST, but in many cases is much more sensitive to weak but biologically relevant sequence similarities. PSI-BLAST is used to uncover several new and interesting members of the BRCT superfamily.},
  author       = {Altschul, Stephen F. and Madden, Thomas L. and Schäffer, Alejandro A. and Zhang, Jinghui and Zhang, Zheng and Miller, Webb and Lipman, David J.},
  date         = {1997-09-01},
  doi          = {10.1093/nar/25.17.3389},
  file         = {/Users/lucblassel/Zotero/storage/S6KFC744/Altschul et al. - 1997 - Gapped BLAST and PSI-BLAST a new generation of pr.pdf;/Users/lucblassel/Zotero/storage/I5253WXG/1061651.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {17},
  pages        = {3389--3402},
  shortjournal = {Nucleic Acids Research},
  shorttitle   = {Gapped {{BLAST}} and {{PSI-BLAST}}},
  title        = {Gapped {{BLAST}} and {{PSI-BLAST}}: A New Generation of Protein Database Search Programs},
  url          = {https://doi.org/10.1093/nar/25.17.3389},
  urldate      = {2022-09-02},
  volume       = {25}
}

@article{altschulGeneralizedAffineGap1998,
  abstract     = {Based on the observation that a single mutational event can delete or insert multiple residues, affine gap costs for sequence alignment charge a penalty for the existence of a gap, and a further length-dependent penalty. From structural or multiple alignments of distantly related proteins, it has been observed that conserved residues frequently fall into ungapped blocks separated by relatively nonconserved regions. To take advantage of this structure, a simple generalization of affine gap costs is proposed that allows nonconserved regions to be effectively ignored. The distribution of scores from local alignments using these generalized gap costs is shown empirically to follow an extreme value distribution. Examples are presented for which generalized affine gap costs yield superior alignments from the standpoints both of statistical significance and of alignment accuracy. Guidelines for selecting generalized affine gap costs are discussed, as is their possible application to multiple alignment. Proteins 32:88–96, 1998. Published 1998 Wiley-Liss, Inc. This article is a US government work and, as such, is in the public domain in the United States of America.},
  author       = {Altschul, Stephen F.},
  date         = {1998},
  doi          = {10.1002/(SICI)1097-0134(19980701)32:1<88::AID-PROT10>3.0.CO;2-J},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/altschul_1998_generalized_affine_gap_costs_for_protein_sequence.pdf;/Users/lucblassel/Zotero/storage/EKBKEEIC/(SICI)1097-0134(19980701)32188AID-PROT103.0.html},
  issn         = {1097-0134},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  keywords     = {BRCA1,multiple alignment,pattern recognition,statistical significance,structural alignment},
  langid       = {english},
  number       = {1},
  pages        = {88--96},
  title        = {Generalized Affine Gap Costs for Protein Sequence Alignment},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0134%2819980701%2932%3A1%3C88%3A%3AAID-PROT10%3E3.0.CO%3B2-J},
  urldate      = {2019-08-19},
  volume       = {32}
}

@article{altschulOptimalSequenceAlignment1986,
  abstract     = {When comparing two biological sequences, it is often desirable for a gap to be assigned a cost not directly proportional to its length. If affine gap costs are employed, in other words if opening a gap costsv and each null in the gap costsu, the algorithm of Gotoh (1982,J. molec. Biol.162, 705) finds the minimum cost of aligning two sequences in orderMN steps. Gotoh's algorithm attempts to find only one from among possibly many optimal (minimum-cost) alignments, but does not always succeed. This paper provides an example for which this part of Gotoh's algorithm fails and describes an algorithm that finds all and only the optimal alignments. This modification of Gotoh's algorithm still requires orderMN steps. A more precise form of path graph than previously used is needed to represent accurately all optimal alignments for affine gap costs.},
  author       = {Altschul, Stephen F. and Erickson, Bruce W.},
  date         = {1986-01-01},
  doi          = {10.1016/S0092-8240(86)90010-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul_Erickson_1986_Optimal sequence alignment using affine gap costs.pdf;/Users/lucblassel/Zotero/storage/EUJF8B9I/S0092824086900108.html},
  issn         = {0092-8240},
  journaltitle = {Bulletin of Mathematical Biology},
  langid       = {english},
  number       = {5},
  pages        = {603--616},
  shortjournal = {Bulletin of Mathematical Biology},
  title        = {Optimal Sequence Alignment Using Affine Gap Costs},
  url          = {https://www.sciencedirect.com/science/article/pii/S0092824086900108},
  urldate      = {2022-08-26},
  volume       = {48}
}

@incollection{altschulSubstitutionMatrices2013,
  abstract   = {A substitution matrix is a collection of scores for aligning nucleotides or amino acids with one another. These scores generally represent the relative ease with which one nucleotide or amino acid may mutate into or substitute for another, and they are used to measure similarity in sequence alignments. Substitution matrices are used in conjunction with gap costs to construct local or global alignments. A local alignment substitution matrix implicitly corresponds to a set of target frequencies for aligned letters, which characterise the alignments the matrix may most easily distinguish from chance. Thus different substitution matrices are optimal for comparing related sequences that have diverged to differing degrees. The point accepted mutation and blocks substitution matrix (BLOSUM) series of matrices for protein sequence comparison have been derived from collections of related sequences. Special-purpose matrices may be appropriate for comparing sequences with biased nucleotide or amino acid composition. Key Concepts: Match/mismatch scores generally are suboptimal for comparing protein sequences. A log-odds substitution matrix is characterised by its target frequencies and scale. All local-alignment substitution matrices are implicitly log-odds matrices. Different substitution matrices are tailored to different degrees of evolutionary divergence. Amino acid substitution matrices are constructed from curated sets of alignments. The sequence divergence for which a substitution matrix is tailored may be measured by relative entropy. Special matrices may be preferred for comparing sequences with nonstandard nucleotide or amino acid composition. For gapped local alignments, statistical parameters must be estimated by random simulation. For protein-coding DNA, distant relationships are more easily detected at the protein than at the DNA level. For global alignments, an equivalent scoring system results from adding 2x to all substitution scores, and x to the score for each letter aligned with a null.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470015902.a0005265.pub3},
  author     = {Altschul, Stephen F},
  booktitle  = {{{eLS}}},
  date       = {2013},
  doi        = {10.1002/9780470015902.a0005265.pub3},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul_2013_Substitution Matrices.pdf;/Users/lucblassel/Zotero/storage/X8XDQAMV/9780470015902.a0005265.html},
  isbn       = {978-0-470-01590-2},
  keywords   = {alignment score,BLOSUM matrices,gap costs,local alignment statistics,PAM matrices,sequence similarity},
  langid     = {english},
  publisher  = {{John Wiley \& Sons, Ltd}},
  title      = {Substitution {{Matrices}}},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470015902.a0005265.pub3},
  urldate    = {2022-06-14}
}

@article{altschulWeightsDataRelated1989,
  abstract     = {How can one characterize a set of data collected from different biological species, or indeed any set of data related by an evolutionary tree? The structure imposed by the tree implies that the data are not independent, and for most applications this should be taken into account. We describe strategies for weighting the data that circumvent some of the problems of dependency.},
  author       = {Altschul, Stephen F. and Carroll, Raymond J. and Lipman, David J.},
  date         = {1989-06-20},
  doi          = {10.1016/0022-2836(89)90234-9},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Altschul et al_1989_Weights for data related by a tree.pdf},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {4},
  pages        = {647--653},
  shortjournal = {Journal of Molecular Biology},
  title        = {Weights for Data Related by a Tree},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283689902349},
  urldate      = {2022-06-16},
  volume       = {207}
}

@article{armstrongWholeGenomeAlignmentComparative2019,
  abstract     = {Rapidly improving sequencing technology coupled with computational developments in sequence assembly are making reference-quality genome assembly economical. Hundreds of vertebrate genome assemblies are now publicly available, and projects are being proposed to sequence thousands of additional species in the next few years. Such dense sampling of the tree of life should give an unprecedented new understanding of evolution and allow a detailed determination of the events that led to the wealth of biodiversity around us. To gain this knowledge, these new genomes must be compared through genome alignment (at the sequence level) and comparative annotation (at the gene level). However, different alignment and annotation methods have different characteristics; before starting a comparative genomics analysis, it is important to understand the nature of, and biases and limitations inherent in, the chosen methods. This review is intended to act as a technical but high-level overview of the field that should provide this understanding. We briefly survey the state of the genome alignment and comparative annotation fields and potential future directions for these fields in a new, large-scale era of comparative genomics.},
  author       = {Armstrong, Joel and Fiddes, Ian T. and Diekhans, Mark and Paten, Benedict},
  date         = {2019},
  doi          = {10.1146/annurev-animal-020518-115005},
  eprint       = {30379572},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/armstrong_et_al_2019_whole-genome_alignment_and_comparative_annotation.pdf},
  journaltitle = {Annual Review of Animal Biosciences},
  number       = {1},
  pages        = {41--64},
  title        = {Whole-{{Genome Alignment}} and {{Comparative Annotation}}},
  url          = {https://doi.org/10.1146/annurev-animal-020518-115005},
  urldate      = {2019-08-13},
  volume       = {7}
}

@article{baichooComputationalComplexityAlgorithms2017,
  abstract     = {A multitude of algorithms for sequence comparison, short-read assembly and whole-genome alignment have been developed in the general context of molecular biology, to support technology development for high-throughput sequencing, numerous applications in genome biology and fundamental research on comparative genomics. The computational complexity of these algorithms has been previously reported in original research papers, yet this often neglected property has not been reviewed previously in a systematic manner and for a wider audience. We provide a review of space and time complexity of key sequence analysis algorithms and highlight their properties in a comprehensive manner, in order to identify potential opportunities for further research in algorithm or data structure optimization. The complexity aspect is poised to become pivotal as we will be facing challenges related to the continuous increase of genomic data on unprecedented scales and complexity in the foreseeable future, when robust biological simulation at the cell level and above becomes a reality.},
  author       = {Baichoo, Shakuntala and Ouzounis, Christos A.},
  date         = {2017-06-01},
  doi          = {10.1016/j.biosystems.2017.03.003},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/baichoo_ouzounis_2017_computational_complexity_of_algorithms_for.pdf;/Users/lucblassel/Zotero/storage/XA8HU5B7/S0303264717300461.html},
  issn         = {0303-2647},
  journaltitle = {Biosystems},
  keywords     = {Bioinformatics algorithms,Computational complexity,Genome alignment,Sequence comparison,Short-read assembly},
  pages        = {72--85},
  shortjournal = {Biosystems},
  title        = {Computational Complexity of Algorithms for Sequence Comparison, Short-Read Assembly and Genome Alignment},
  url          = {http://www.sciencedirect.com/science/article/pii/S0303264717300461},
  urldate      = {2019-08-13},
  volume       = {156--157}
}

@article{batzoglouManyFacesSequence2005,
  abstract     = {Starting with the sequencing of the mouse genome in 2002, we have entered a period where the main focus of genomics will be to compare multiple genomes in order to learn about human biology and evolution at the DNA level. Alignment methods are the main computational component of this endeavour. This short review aims to summarise the current status of research in alignments, emphasising large-scale genomic comparisons and suggesting possible directions that will be explored in the near future.},
  author       = {Batzoglou, Serafim},
  date         = {2005-03-01},
  doi          = {10.1093/bib/6.1.6},
  file         = {/Users/lucblassel/Zotero/storage/PR4ZS5EQ/Batzoglou - 2005 - The many faces of sequence alignment.pdf},
  issn         = {1467-5463},
  journaltitle = {Briefings in Bioinformatics},
  number       = {1},
  pages        = {6--22},
  shortjournal = {Briefings in Bioinformatics},
  title        = {The Many Faces of Sequence Alignment},
  url          = {https://doi.org/10.1093/bib/6.1.6},
  urldate      = {2022-05-16},
  volume       = {6}
}

@article{bellmanTheoryDynamicProgramming1954,
  abstract     = {Advancing research. Creating connections.},
  author       = {Bellman, Richard},
  date         = {1954},
  doi          = {10.1090/S0002-9904-1954-09848-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Bellman_1954_The theory of dynamic programming.pdf},
  issn         = {0002-9904, 1936-881X},
  journaltitle = {Bulletin of the American Mathematical Society},
  langid       = {english},
  number       = {6},
  pages        = {503--515},
  shortjournal = {Bull. Amer. Math. Soc.},
  title        = {The Theory of Dynamic Programming},
  url          = {https://www.ams.org/bull/1954-60-06/S0002-9904-1954-09848-8/},
  urldate      = {2022-06-14},
  volume       = {60}
}

@article{bennerEmpiricalStructuralModels1993,
  abstract     = {The exhaustive matching of the protein sequence database makes possible a broadly based study of insertions and deletions (indels) during divergent evolution. In this study, the probability of a gap in an alignment of a pair of homologous protein sequences was found to increase with the evolutionary distance measured in PAM units (number of accepted point mutations per 100 amino acid residues). A relationship between the average number of amino acid residues between indels and evolutionary distance suggests that a unit 30 to 40 amino acid residues in length remains, on average, undisrupted by indels during divergent evolution. Further, the probability of a gap was found to be inversely proportional to gap length raised to the 1·7 power. This empirical law fits closely over the entire range of gap lengths examined. Gap length distribution is largely independent of evolutionary distance. These results rule out the widely used linear gap penalty as a satisfactory formula for scoring gaps when constructing alignments. Further, the observed gap length distribution can be explained by a simple model of selective pressures governing the acceptance of indels during divergent evolution. Finally, this model provides theoretical support for using indels as part of "parsing algorithms", important in the de novo prediction of the folded structure of proteins form the sequence data.},
  author       = {Benner, Steven A. and Cohen, Mark A. and Gonnet, Gaston H.},
  date         = {1993-02-20},
  doi          = {10.1006/jmbi.1993.1105},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Benner et al_1993_Empirical and Structural Models for Insertions and Deletions in the Divergent.pdf;/Users/lucblassel/Zotero/storage/NEW5JTQ6/S0022283683711058.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {evolution,insertions/deletions,protein structure,protein structure prediction},
  langid       = {english},
  number       = {4},
  pages        = {1065--1082},
  shortjournal = {Journal of Molecular Biology},
  title        = {Empirical and {{Structural Models}} for {{Insertions}} and {{Deletions}} in the {{Divergent Evolution}} of {{Proteins}}},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022283683711058},
  urldate      = {2022-06-14},
  volume       = {229}
}

@incollection{berettaAlgorithmsStringsSequences2019,
  author     = {Beretta, Stefano},
  booktitle  = {Encyclopedia of {{Bioinformatics}} and {{Computational Biology}}},
  date       = {2019},
  doi        = {10.1016/B978-0-12-809633-8.20317-8},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Beretta_2019_Algorithms for Strings and Sequences.pdf},
  isbn       = {978-0-12-811432-2},
  langid     = {english},
  pages      = {22--29},
  publisher  = {{Elsevier}},
  shorttitle = {Algorithms for {{Strings}} and {{Sequences}}},
  title      = {Algorithms for {{Strings}} and {{Sequences}}: {{Pairwise Alignment}}},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/B9780128096338203178},
  urldate    = {2022-06-14}
}

@article{bermanProteinDataBank2000,
  abstract     = {Abstract.  The Protein Data Bank (PDB; http://www.rcsb.org/pdb/ ) is the single worldwide archive of structural data of biological macromolecules. This paper de},
  author       = {Berman, Helen M. and Westbrook, John and Feng, Zukang and Gilliland, Gary and Bhat, T. N. and Weissig, Helge and Shindyalov, Ilya N. and Bourne, Philip E.},
  date         = {2000-01-01},
  doi          = {10.1093/nar/28.1.235},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/berman_et_al_2000_the_protein_data_bank.pdf;/Users/lucblassel/Zotero/storage/3HDGBDLR/2384399.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  langid       = {english},
  number       = {1},
  pages        = {235--242},
  shortjournal = {Nucleic Acids Res},
  title        = {The {{Protein Data Bank}}},
  url          = {https://academic.oup.com/nar/article/28/1/235/2384399},
  urldate      = {2019-08-14},
  volume       = {28}
}

@article{blackshieldsSequenceEmbeddingFast2010,
  abstract     = {The most widely used multiple sequence alignment methods require sequences to be clustered as an initial step. Most sequence clustering methods require a full distance matrix to be computed between all pairs of sequences. This requires memory and time proportional to N2 for N sequences. When N grows larger than 10,000 or so, this becomes increasingly prohibitive and can form a significant barrier to carrying out very large multiple alignments.},
  author       = {Blackshields, Gordon and Sievers, Fabian and Shi, Weifeng and Wilm, Andreas and Higgins, Desmond G.},
  date         = {2010-05-14},
  doi          = {10.1186/1748-7188-5-21},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Blackshields et al_2010_Sequence embedding for fast construction of guide trees for multiple sequence.pdf},
  issn         = {1748-7188},
  journaltitle = {Algorithms for Molecular Biology},
  keywords     = {Alignment Quality,Distance Matrix,Guide Tree,Principle Component Analysis,Seed Sequence},
  langid       = {english},
  number       = {1},
  pages        = {21},
  shortjournal = {Algorithms Mol Biol},
  title        = {Sequence Embedding for Fast Construction of Guide Trees for Multiple Sequence Alignment},
  url          = {https://doi.org/10.1186/1748-7188-5-21},
  urldate      = {2022-09-06},
  volume       = {5}
}

@article{blaisdellMeasureSimilaritySets1986,
  author       = {Blaisdell, B E},
  date         = {1986-07},
  doi          = {10.1073/pnas.83.14.5155},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Blaisdell_1986_A measure of the similarity of sets of sequences not requiring sequence.pdf},
  journaltitle = {Proceedings of the National Academy of Sciences},
  number       = {14},
  pages        = {5155--5159},
  publisher    = {{Proceedings of the National Academy of Sciences}},
  title        = {A Measure of the Similarity of Sets of Sequences Not Requiring Sequence Alignment.},
  url          = {https://www.pnas.org/doi/abs/10.1073/pnas.83.14.5155},
  urldate      = {2022-06-16},
  volume       = {83}
}

@book{bradleyAppliedMathematicalProgramming1977,
  abstract   = {Mathematical programming: an overview; solving linear programs; sensitivity analysis; duality in linear programming; mathematical programming in practice; integration of strategic and tactical planning in the aluminum industry; planning the mission and composition of the U.S. merchant Marine fleet; network models; integer programming; design of a naval tender job shop; dynamic programming; large-scale systems; nonlinear programming; a system for bank portfolio planning; vectors and matrices; linear programming in matrix form; a labeling algorithm for the maximun-flow network problem.},
  author     = {Bradley, Stephen P. and Hax, Arnoldo C. and Magnanti, Thomas L.},
  date       = {1977},
  eprint     = {MSWdWv3Gn5cC},
  eprinttype = {googlebooks},
  isbn       = {978-0-201-00464-9},
  keywords   = {Mathematics / General},
  langid     = {english},
  pagetotal  = {750},
  publisher  = {{Addison-Wesley Publishing Company}},
  title      = {Applied {{Mathematical Programming}}}
}

@article{brayAVIDGlobalAlignment2003,
  abstract     = {In this paper we describe a new global alignment method called AVID. The method is designed to be fast, memory efficient, and practical for sequence alignments of large genomic regions up to megabases long. We present numerous applications of the method, ranging from the comparison of assemblies to alignment of large syntenic genomic regions and whole genome human/mouse alignments. We have also performed a quantitative comparison of AVID with other popular alignment tools. To this end, we have established a format for the representation of alignments and methods for their comparison. These formats and methods should be useful for future studies. The tools we have developed for the alignment comparisons, as well as the AVID program, are publicly available. See Web Site References section for AVID Web address and Web addresses for other programs discussed in this paper.},
  author       = {Bray, Nick and Dubchak, Inna and Pachter, Lior},
  date         = {2003-01-01},
  doi          = {10.1101/gr.789803},
  eprint       = {12529311},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Bray et al_2003_AVID.pdf},
  issn         = {1088-9051},
  journaltitle = {Genome Research},
  number       = {1},
  pages        = {97--102},
  pmcid        = {PMC430967},
  shortjournal = {Genome Res},
  shorttitle   = {{{AVID}}},
  title        = {{{AVID}}: {{A Global Alignment Program}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC430967/},
  urldate      = {2022-06-15},
  volume       = {13}
}

@article{brindaRNFGeneralFramework2016,
  abstract     = {Motivation: Read simulators combined with alignment evaluation tools provide the most straightforward way to evaluate and compare mappers. Simulation of reads is accompanied by information about their positions in the source genome. This information is then used to evaluate alignments produced by the mapper. Finally, reports containing statistics of successful read alignments are created. In default of standards for encoding read origins, every evaluation tool has to be made explicitly compatible with the simulator used to generate reads.Results: To solve this obstacle, we have created a generic format Read Naming Format (R nf ) for assigning read names with encoded information about original positions. Futhermore, we have developed an associated software package R nf Tools containing two principal components. MIS hmash applies one of popular read simulating tools (among D wg S im , A rt , M ason , C u R e S im , etc.) and transforms the generated reads into R nf format. LAVE nder evaluates then a given read mapper using simulated reads in R nf format. A special attention is payed to mapping qualities that serve for parametrization of R oc curves, and to evaluation of the effect of read sample contamination. Availability and implementation:  R nf Tools: http://karel-brinda.github.io/rnftools Spec. of R nf : http://karel-brinda.github.io/rnf-specContact:karel.brinda@univ-mlv.fr},
  author       = {Břinda, Karel and Boeva, Valentina and Kucherov, Gregory},
  date         = {2016-01-01},
  doi          = {10.1093/bioinformatics/btv524},
  file         = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Břinda et al_2016_RNF.pdf;/Users/lucblassel/Zotero/storage/PN2BJI75/1742858.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {1},
  pages        = {136--139},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{RNF}}},
  title        = {{{RNF}}: A General Framework to Evaluate {{NGS}} Read Mappers},
  url          = {https://doi.org/10.1093/bioinformatics/btv524},
  urldate      = {2022-06-02},
  volume       = {32}
}

@article{brindaRNFGeneralFramework2016a,
  abstract     = {Motivation: Read simulators combined with alignment evaluation tools provide the most straightforward way to evaluate and compare mappers. Simulation of reads is accompanied by information about their positions in the source genome. This information is then used to evaluate alignments produced by the mapper. Finally, reports containing statistics of successful read alignments are created. In default of standards for encoding read origins, every evaluation tool has to be made explicitly compatible with the simulator used to generate reads.Results: To solve this obstacle, we have created a generic format Read Naming Format (R nf ) for assigning read names with encoded information about original positions. Futhermore, we have developed an associated software package R nf Tools containing two principal components. MIS hmash applies one of popular read simulating tools (among D wg S im , A rt , M ason , C u R e S im , etc.) and transforms the generated reads into R nf format. LAVE nder evaluates then a given read mapper using simulated reads in R nf format. A special attention is payed to mapping qualities that serve for parametrization of R oc curves, and to evaluation of the effect of read sample contamination. Availability and implementation:  R nf Tools: http://karel-brinda.github.io/rnftools Spec. of R nf : http://karel-brinda.github.io/rnf-specContact:karel.brinda@univ-mlv.fr},
  author       = {Břinda, Karel and Boeva, Valentina and Kucherov, Gregory},
  date         = {2016-01-01},
  doi          = {10.1093/bioinformatics/btv524},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Břinda et al_2016_RNF2.pdf;/Users/lucblassel/Zotero/storage/7KRK2KGP/1742858.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {1},
  pages        = {136--139},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{RNF}}},
  title        = {{{RNF}}: A General Framework to Evaluate {{NGS}} Read Mappers},
  url          = {https://doi.org/10.1093/bioinformatics/btv524},
  urldate      = {2022-06-15},
  volume       = {32}
}

@article{buchfinkFastSensitiveProtein2015,
  abstract     = {The alignment of sequencing reads against a protein reference database is a major computational bottleneck in metagenomics and data-intensive evolutionary projects. Although recent tools offer improved performance over the gold standard BLASTX, they exhibit only a modest speedup or low sensitivity. We introduce DIAMOND, an open-source algorithm based on double indexing that is 20,000 times faster than BLASTX on short reads and has a similar degree of sensitivity.},
  author       = {Buchfink, Benjamin and Xie, Chao and Huson, Daniel H.},
  date         = {2015-01},
  doi          = {10.1038/nmeth.3176},
  eprint       = {25402007},
  eprinttype   = {pmid},
  issn         = {1548-7105},
  journaltitle = {Nature Methods},
  keywords     = {Algorithms,Base Sequence,Humans,Metagenomics,Microbiota,Sensitivity and Specificity,Sequence Alignment,Sequence Analysis; DNA,Software},
  langid       = {english},
  number       = {1},
  pages        = {59--60},
  shortjournal = {Nat Methods},
  title        = {Fast and Sensitive Protein Alignment Using {{DIAMOND}}},
  volume       = {12}
}

@article{buchfinkSensitiveProteinAlignments2021,
  abstract     = {We are at the beginning of a genomic revolution in which all known species are planned to be sequenced. Accessing such data for comparative analyses is crucial in this new age of data-driven biology. Here, we introduce an improved version of DIAMOND that greatly exceeds previous search performances and harnesses supercomputing to perform tree-of-life scale protein alignments in hours, while matching the sensitivity of the gold standard BLASTP.},
  author       = {Buchfink, Benjamin and Reuter, Klaus and Drost, Hajk-Georg},
  date         = {2021-04},
  doi          = {10.1038/s41592-021-01101-x},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Buchfink et al_2021_Sensitive protein alignments at tree-of-life scale using DIAMOND.pdf;/Users/lucblassel/Zotero/storage/4SJ3HQWT/s41592-021-01101-x.html},
  issn         = {1548-7105},
  issue        = {4},
  journaltitle = {Nature Methods},
  keywords     = {Computational biology and bioinformatics,Genome informatics,Genomic analysis,Sequencing,Software},
  langid       = {english},
  number       = {4},
  pages        = {366--368},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Sensitive Protein Alignments at Tree-of-Life Scale Using {{DIAMOND}}},
  url          = {https://www.nature.com/articles/s41592-021-01101-x},
  urldate      = {2022-06-16},
  volume       = {18}
}

@report{burrowsBlockSortingLosslessData1994,
  abstract    = {We describe a block-sorting, lossless data compression algorithm, and our implementation of that algorithm. We compare the performance of our implementation with widely available data compressors running on the same hardware. The algorithm works by applying a reversible transformation to a block of input text. The transformation does not itself compress the data, but re-orders it to make it easy to compress with simple algorithms such as move-to-front encoding. Our algorithm achieves speed comparable to algorithms based on the techniques of Lempel and Ziv, but optains compression close to the best statistical modelling techniques. The size of the input block must be large (a few kilobytes) to achieve good compression.},
  author      = {Burrows, Michael and Wheeler, David},
  date        = {1994},
  file        = {/Users/lucblassel/Zotero/storage/NZQASCBR/summary.html},
  institution = {{DIGITAL SRC RESEARCH REPORT}},
  title       = {A {{Block-Sorting Lossless Data Compression Algorithm}}}
}

@article{canzarShortReadMapping2017,
  abstract     = {Ultra-high-throughput next-generation sequencing (NGS) technology allows us to determine the sequence of nucleotides of many millions of DNA molecules in parallel. Accompanied by a dramatic reduction in cost since its introduction in 2004, NGS technology has provided a new way of addressing a wide range of biological and biomedical questions, from the study of human genetic disease to the analysis of gene expression, protein-DNA interactions, and patterns of DNA methylation. The data generated by NGS instruments comprise huge numbers of very short DNA sequences, or “reads,” that carry little information by themselves. These reads therefore have to be pieced together by well-engineered algorithms to reconstruct biologically meaningful measurements, such as the level of expression of a gene. To solve this complex, high-dimensional puzzle, reads must be mapped back to a reference genome to determine their origin. Due to sequencing errors and to genuine differences between the reference genome and the individual being sequenced, this mapping process must be tolerant of mismatches, insertions, and deletions. Although optimal alignment algorithms to solve this problem have long been available, the practical requirements of aligning hundreds of millions of short reads to the 3-billion-base-pair-long human genome have stimulated the development of new, more efficient methods, which today are used routinely throughout the world for the analysis of NGS data.},
  author       = {Canzar, Stefan and Salzberg, Steven L.},
  date         = {2017-03},
  doi          = {10.1109/JPROC.2015.2455551},
  eventtitle   = {Proceedings of the {{IEEE}}},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Canzar_Salzberg_2017_Short Read Mapping.pdf;/Users/lucblassel/Zotero/storage/TAZIATXB/7244195.html},
  issn         = {1558-2256},
  journaltitle = {Proceedings of the IEEE},
  keywords     = {Algorithm design and analysis,Bioinformatics,Burrows–Wheeler transform,DNA,DNA sequencing,Genomics,sequence alignment,Sequential analysis,string matching,suffix trees,Throughput},
  number       = {3},
  pages        = {436--458},
  shorttitle   = {Short {{Read Mapping}}},
  title        = {Short {{Read Mapping}}: {{An Algorithmic Tour}}},
  volume       = {105}
}

@article{cartwrightLogarithmicGapCosts2006,
  abstract     = {Background Studies on the distribution of indel sizes have consistently found that they obey a power law. This finding has lead several scientists to propose that logarithmic gap costs, G (k) = a + c ln k, are more biologically realistic than affine gap costs, G (k) = a + bk, for sequence alignment. Since quick and efficient affine costs are currently the most popular way to globally align sequences, the goal of this paper is to determine whether logarithmic gap costs improve alignment accuracy significantly enough the merit their use over the faster affine gap costs. Results A group of simulated sequences pairs were globally aligned using affine, logarithmic, and log-affine gap costs. Alignment accuracy was calculated by comparing resulting alignments to actual alignments of the sequence pairs. Gap costs were then compared based on average alignment accuracy. Log-affine gap costs had the best accuracy, followed closely by affine gap costs, while logarithmic gap costs performed poorly. Subsequently a model was developed to explain the results. Conclusion In contrast to initial expectations, logarithmic gap costs produce poor alignments and are actually not implied by the power-law behavior of gap sizes, given typical match and mismatch costs. Furthermore, affine gap costs not only produce accurate alignments but are also good approximations to biologically realistic gap costs. This work provides added confidence for the biological relevance of existing alignment algorithms.},
  author       = {Cartwright, Reed A},
  date         = {2006-12-05},
  doi          = {10.1186/1471-2105-7-527},
  eprint       = {17147805},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cartwright_2006_Logarithmic gap costs decrease alignment accuracy.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  pages        = {527},
  pmcid        = {PMC1770940},
  shortjournal = {BMC Bioinformatics},
  title        = {Logarithmic Gap Costs Decrease Alignment Accuracy},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1770940/},
  urldate      = {2022-08-26},
  volume       = {7}
}

@article{cartwrightProblemsSolutionsEstimating2009,
  abstract     = {Insertions and deletions (indels) are fundamental but understudied components of molecular evolution. Here we present an expectation–maximization algorithm built on a pair hidden Markov model that is able to properly handle indels in neutrally evolving DNA sequences. From a data set of orthologous introns, we estimate relative rates and length distributions of indels among primates and rodents. This technique has the advantage of potentially handling large genomic data sets. We find that a zeta power-law model of indel lengths provides a much better fit than the traditional geometric model and that indel processes are conserved between our taxa. The estimated relative rates are about 12–16 indels per 100 substitutions, and the estimated power-law magnitudes are about 1.6–1.7. More significantly, we find that using the traditional geometric/affine model of indel lengths introduces artifacts into evolutionary analysis, casting doubt on studies of the evolution and diversity of indel formation using traditional models and invalidating measures of species divergence that include indel lengths.},
  author       = {Cartwright, Reed A.},
  date         = {2009-02-01},
  doi          = {10.1093/molbev/msn275},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cartwright_2009_Problems and Solutions for Estimating Indel Rates and Length Distributions.pdf;/Users/lucblassel/Zotero/storage/9LU7F4JR/1034550.html},
  issn         = {0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  number       = {2},
  pages        = {473--480},
  shortjournal = {Molecular Biology and Evolution},
  title        = {Problems and {{Solutions}} for {{Estimating Indel Rates}} and {{Length Distributions}}},
  url          = {https://doi.org/10.1093/molbev/msn275},
  urldate      = {2022-08-26},
  volume       = {26}
}

@article{cetinPlasmonicSensorCould2018,
  abstract     = {We demonstrated a proof-of-principle concept of a label-free platform that enables nucleic acid sequencing by binding methodology. The system utilizes gold surfaces having high fidelity plasmonic nanohole arrays which are very sensitive to minute changes of local refractive indices. Our novel surface chemistry approach ensures accurate identification of correct bases at individual positions along a targeted DNA sequence on the gold surface. Binding of the correct base on the gold sensing surface triggers strong spectral variations within the nanohole optical response, which provides a high signal-to-noise ratio and accurate sequence data. Integrating our label-free sequencing platform with a lens-free imaging-based device, we reliably determined targeted DNA sequences by monitoring the changes within the plasmonic diffraction images. Consequently, this new label-free surface chemistry technique, integrated with plasmonic lens-free imaging platform, will enable monitoring multiple biomolecular binding events, which could initiate new avenues for high-throughput nucleic acid sequencing.},
  author       = {Cetin, Arif E. and Iyidogan, Pinar and Hayashi, Yuki and Wallen, Mark and Vijayan, Kandaswamy and Tu, Eugene and Nguyen, Michael and Oliphant, Arnold},
  date         = {2018-03-23},
  doi          = {10.1021/acssensors.7b00957},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cetin et al_2018_Plasmonic Sensor Could Enable Label-Free DNA Sequencing.pdf;/Users/lucblassel/Zotero/storage/RNWPJLQK/acssensors.html},
  journaltitle = {ACS Sensors},
  number       = {3},
  pages        = {561--568},
  publisher    = {{American Chemical Society}},
  shortjournal = {ACS Sens.},
  title        = {Plasmonic {{Sensor Could Enable Label-Free DNA Sequencing}}},
  url          = {https://doi.org/10.1021/acssensors.7b00957},
  urldate      = {2022-06-17},
  volume       = {3}
}

@article{chaissonMappingSingleMolecule2012,
  abstract     = {Recent methods have been developed to perform high-throughput sequencing of DNA by Single Molecule Sequencing (SMS). While Next-Generation sequencing methods may produce reads up to several hundred bases long, SMS sequencing produces reads up to tens of kilobases long. Existing alignment methods are either too inefficient for high-throughput datasets, or not sensitive enough to align SMS reads, which have a higher error rate than Next-Generation sequencing.},
  author       = {Chaisson, Mark J. and Tesler, Glenn},
  date         = {2012-09-19},
  doi          = {10.1186/1471-2105-13-238},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chaisson_Tesler_2012_Mapping single molecule sequencing reads using basic local alignment with.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Alignment Method,Anchor Length,Mapping Quality,Successive Refinement,Suffix Array},
  number       = {1},
  pages        = {238},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {Mapping Single Molecule Sequencing Reads Using Basic Local Alignment with Successive Refinement ({{BLASR}})},
  title        = {Mapping Single Molecule Sequencing Reads Using Basic Local Alignment with Successive Refinement ({{BLASR}}): Application and Theory},
  url          = {https://doi.org/10.1186/1471-2105-13-238},
  urldate      = {2022-06-17},
  volume       = {13}
}

@article{chaoDevelopmentsAlgorithmsSequence2022,
  abstract     = {The continuous development of sequencing technologies has enabled researchers to obtain large amounts of biological sequence data, and this has resulted in increasing demands for software that can perform sequence alignment fast and accurately. A number of algorithms and tools for sequence alignment have been designed to meet the various needs of biologists. Here, the ideas that prevail in the research of sequence alignment and some quality estimation methods for multiple sequence alignment tools are summarized.},
  author       = {Chao, Jiannan and Tang, Furong and Xu, Lei},
  date         = {2022-04-06},
  doi          = {10.3390/biom12040546},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chao et al_2022_Developments in Algorithms for Sequence Alignment.pdf},
  issn         = {2218-273X},
  journaltitle = {Biomolecules},
  langid       = {english},
  number       = {4},
  pages        = {546},
  shortjournal = {Biomolecules},
  shorttitle   = {Developments in {{Algorithms}} for {{Sequence Alignment}}},
  title        = {Developments in {{Algorithms}} for {{Sequence Alignment}}: {{A Review}}},
  url          = {https://www.mdpi.com/2218-273X/12/4/546},
  urldate      = {2022-06-13},
  volume       = {12}
}

@article{chenAcceleratingNextGeneration2014,
  abstract     = {To compare the newly determined sequences against the subject sequences stored in the databases is a critical job in the bioinformatics. Fortunately, recent survey reports that the state-of-the-art aligners are already fast enough to handle the ultra amount of short sequence reads in the reasonable time. However, for aligning the long sequence reads ({$>$}400 bp) generated by the next generation sequencing (NGS) technology, it is still quite inefficient with present aligners. Furthermore, the challenge becomes more and more serious as the lengths and the amounts of the sequence reads are both keeping increasing with the improvement of the sequencing technology. Thus, it is extremely urgent for the researchers to enhance the performance of the long read alignment. In this paper, we propose a novel FPGA-based system to improve the efficiency of the long read mapping. Compared to the state-of-the-art long read aligner BWA-SW, our accelerating platform could achieve a high performance with almost the same sensitivity. Experiments demonstrate that, for reads with lengths ranging from 512 up to 4,096 base pairs, the described system obtains a 10x -48x speedup for the bottleneck of the software. As to the whole mapping procedure, the FPGA-based platform could achieve a 1.8x -3:3x speedup versus the BWA-SW aligner, reducing the alignment cycles from weeks to days.},
  author       = {Chen, Peng and Wang, Chao and Li, Xi and Zhou, Xuehai},
  date         = {2014-09},
  doi          = {10.1109/TCBB.2014.2326876},
  eventtitle   = {{{IEEE}}/{{ACM Transactions}} on {{Computational Biology}} and {{Bioinformatics}}},
  file         = {/Users/lucblassel/Zotero/storage/596I5XUQ/6822570.html},
  issn         = {1557-9964},
  journaltitle = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  keywords     = {Acceleration,Bioinformatics,BWA-SW,Genomics,hardware acceleration,Indexes,long read mapping,Sequence alignment,Sequential analysis,Smith-Waterman,Software,Software algorithms},
  number       = {5},
  pages        = {840--852},
  title        = {Accelerating the {{Next Generation Long Read Mapping}} with the {{FPGA-Based System}}},
  volume       = {11}
}

@article{chengFMtreeFastLocating2018,
  abstract     = {As a fundamental task in bioinformatics, searching for massive short patterns over a long text has been accelerated by various compressed full-text indexes. These indexes are able to provide similar searching functionalities to classical indexes, e.g. suffix trees and suffix arrays, while requiring less space. For genomic data, a well-known family of compressed full-text indexes, called FM-indexes, presents unmatched performance in practice. One major drawback of FM-indexes is that their locating operations, which report all occurrence positions of patterns in a given text, are not efficient, especially for the patterns with many occurrences.In this paper, we introduce a novel locating algorithm, FMtree, to fast retrieve all occurrence positions of any pattern via FM-indexes. When searching for a pattern over a given text, FMtree organizes the search space of the locating operation into a conceptual multiway tree. As a result, multiple occurrence positions of this pattern can be retrieved simultaneously by traversing the multiway tree. Compared with existing locating algorithms, our tree-based algorithm reduces large numbers of redundant operations and presents better data locality. Experimental results show that FMtree is usually one order of magnitude faster than the state-of-the-art algorithms, and still memory-efficient.FMtree is freely available at https://github.com/chhylp123/FMtree.Supplementary data are available at Bioinformatics online.},
  author       = {Cheng, Haoyu and Wu, Ming and Xu, Yun},
  date         = {2018-02-01},
  doi          = {10.1093/bioinformatics/btx596},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Cheng et al_2018_FMtree.pdf;/Users/lucblassel/Zotero/storage/DFTQPM9G/4160683.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {416--424},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{FMtree}}},
  title        = {{{FMtree}}: A Fast Locating Algorithm of {{FM-indexes}} for Genomic Data},
  url          = {https://doi.org/10.1093/bioinformatics/btx596},
  urldate      = {2022-09-05},
  volume       = {34}
}

@incollection{chiaromonteScoringPairwiseGenomic2001,
  author    = {Chiaromonte, F. and Yap, V. B. and Miller, W.},
  booktitle = {Biocomputing 2002},
  date      = {2001-12},
  doi       = {10.1142/9789812799623_0012},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chiaromonte et al_2001_Scoring pairwise genomic sequence alignments.pdf},
  isbn      = {978-981-02-4777-5},
  pages     = {115--126},
  publisher = {{WORLD SCIENTIFIC}},
  title     = {Scoring Pairwise Genomic Sequence Alignments},
  url       = {https://www.worldscientific.com/doi/abs/10.1142/9789812799623_0012},
  urldate   = {2022-06-14}
}

@inproceedings{chikhiRepresentationBruijnGraphs2014,
  abstract  = {The de Bruijn graph plays an important role in bioinformatics, especially in the context of de novo assembly. However, the representation of the de Bruijn graph in memory is a computational bottleneck for many assemblers. Recent papers proposed a navigational data structure approach in order to improve memory usage. We prove several theoretical space lower bounds to show the limitations of these types of approaches. We further design and implement a general data structure (dbgfm) and demonstrate its use on a human whole-genome dataset, achieving space usage of 1.5 GB and a 46\% improvement over previous approaches. As part of dbgfm, we develop the notion of frequency-based minimizers and show how it can be used to enumerate all maximal simple paths of the de Bruijn graph using only 43 MB of memory. Finally, we demonstrate that our approach can be integrated into an existing assembler by modifying the ABySS software to use dbgfm.},
  author    = {Chikhi, Rayan and Limasset, Antoine and Jackman, Shaun and Simpson, Jared T. and Medvedev, Paul},
  booktitle = {Research in {{Computational Molecular Biology}}},
  date      = {2014},
  doi       = {10.1007/978-3-319-05269-4_4},
  editor    = {Sharan, Roded},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Chikhi et al_2014_On the Representation of de Bruijn Graphs.pdf},
  isbn      = {978-3-319-05269-4},
  keywords  = {External Memory,Hash Table,Memory Usage,Query Time,Simple Path},
  langid    = {english},
  location  = {{Cham}},
  pages     = {35--55},
  publisher = {{Springer International Publishing}},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  title     = {On the {{Representation}} of de {{Bruijn Graphs}}}
}

@article{chowdhuryReviewMultipleSequence2017,
  abstract     = {Sequence alignment is an active research area in the field of bioinformatics. It is also a crucial task as it guides many other tasks like phylogenetic analysis, function, and/or structure prediction of biological macromolecules like DNA, RNA, and Protein. Proteins are the building blocks of every living organism. Although protein alignment problem has been studied for several decades, unfortunately, every available method produces alignment results differently for a single alignment problem. Multiple sequence alignment is characterized as a very high computational complex problem. Many stochastic methods, therefore, are considered for improving the accuracy of alignment. Among them, many researchers frequently use Genetic Algorithm. In this study, we have shown different types of the method applied in alignment and the recent trends in the multiobjective genetic algorithm for solving multiple sequence alignment. Many recent studies have demonstrated considerable progress in finding the alignment accuracy.},
  author       = {Chowdhury, Biswanath and Garai, Gautam},
  date         = {2017-10-01},
  doi          = {10.1016/j.ygeno.2017.06.007},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/chowdhury_garai_2017_a_review_on_multiple_sequence_alignment_from_the.pdf;/Users/lucblassel/Zotero/storage/AJRGPZ56/S0888754317300551.html},
  issn         = {0888-7543},
  journaltitle = {Genomics},
  keywords     = {Genetic algorithm,Multiobjective function,Multiple sequence alignment},
  number       = {5},
  pages        = {419--431},
  shortjournal = {Genomics},
  title        = {A Review on Multiple Sequence Alignment from the Perspective of Genetic Algorithm},
  url          = {http://www.sciencedirect.com/science/article/pii/S0888754317300551},
  urldate      = {2019-08-13},
  volume       = {109}
}

@article{dailyParasailSIMDLibrary2016,
  abstract     = {Sequence alignment algorithms are a key component of many bioinformatics applications.},
  author       = {Daily, Jeff},
  date         = {2016-02-10},
  doi          = {10.1186/s12859-016-0930-z},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Daily_2016_Parasail.pdf;/Users/lucblassel/Zotero/storage/ZGL6YX2P/s12859-016-0930-z.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Database search,Needleman-Wunsch,Semi-global alignment,Sequence alignment,SIMD,Smith-Waterman},
  number       = {1},
  pages        = {81},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {Parasail},
  title        = {Parasail: {{SIMD C}} Library for Global, Semi-Global, and Local Pairwise Sequence Alignments},
  url          = {https://doi.org/10.1186/s12859-016-0930-z},
  urldate      = {2022-06-14},
  volume       = {17}
}

@article{darrellMachineLearningInterdependent2015,
  abstract     = {One of the most common assumptions in many machine learning and data analysis tasks is that the given data points are realizations of independent and identically distributed (IID) random variables. However, this assumption is often violated, e.g., when training and test data come from different distributions (dataset bias or domain shift) or the data points are highly interdependent (e.g., when the data exhibits temporal or spatial correlations). Both scenarios are typical situations in visual recognition and computational biology. For instance, computer vision and image analysis models can be learned from object-centric internet resources, but are often rather applied to real-world scenes. In computational biology and personalized medicine, training data may be recorded at a particular hospital, but the model is applied to make predictions on data from different hospitals, where patients exhibit a different population structure. In the seminar report, we discuss, present, and explore new machine learning methods that can deal with non-i.i.d. data as well as new application scenarios.},
  author       = {Darrell, Trevor and Kloft, Marius and Pontil, Massimiliano and Rätsch, Gunnar and Rodner, Erik},
  date         = {2015},
  doi          = {10.4230/DagRep.5.4.18},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/darrell_et_al_2015_machine_learning_with_interdependent_and.pdf},
  journaltitle = {Dagstuhl Reports},
  keywords     = {COMEFROM,Computation,Computational biology,Computer vision,Data point,Image analysis,Interdependence,Machine learning,Personalization,Test data},
  pages        = {18--55},
  title        = {Machine {{Learning}} with {{Interdependent}} and {{Non-identically Distributed Data}} ({{Dagstuhl Seminar}} 15152)},
  volume       = {5}
}

@article{dayhoffModelEvolutionaryChange1978,
  author       = {Dayhoff, M.O. and Schwartz, R.M. and Orcutt, B.C.},
  date         = {1978},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/dayhoff_et_al_1978_a_model_of_evolutionary_change_in_proteins.pdf;/Users/lucblassel/Zotero/storage/X23ANDDW/display.html},
  journaltitle = {A Model of Evolutionary Change in Proteins},
  pages        = {345--352},
  title        = {A {{Model}} of {{Evolutionary Change}} in {{Proteins}}}
}

@article{delcherFastAlgorithmsLargescale2002,
  abstract     = {We describe a suffix-tree algorithm that can align the entire genome sequences of eukaryotic and prokaryotic organisms with minimal use of computer time and memory. The new system, MUMmer 2, runs three times faster while using one-third as much memory as the original MUMmer system. It has been used successfully to align the entire human and mouse genomes to each other, and to align numerous smaller eukaryotic and prokaryotic genomes. A new module permits the alignment of multiple DNA sequence fragments, which has proven valuable in the comparison of incomplete genome sequences. We also describe a method to align more distantly related genomes by detecting protein sequence homology. This extension to MUMmer aligns two genomes after translating the sequence in all six reading frames, extracts all matching protein sequences and then clusters together matches. This method has been applied to both incomplete and complete genome sequences in order to detect regions of conserved synteny, in which multiple proteins from one organism are found in the same order and orientation in another. The system code is being made freely available by the authors.},
  author       = {Delcher, Arthur L. and Phillippy, Adam and Carlton, Jane and Salzberg, Steven L.},
  date         = {2002-06-01},
  doi          = {10.1093/nar/30.11.2478},
  eprint       = {12034836},
  eprinttype   = {pmid},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {11},
  pages        = {2478--2483},
  pmcid        = {PMC117189},
  shortjournal = {Nucleic Acids Res},
  title        = {Fast Algorithms for Large-Scale Genome Alignment and Comparison},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC117189/},
  urldate      = {2022-06-15},
  volume       = {30}
}

@article{doProbConsProbabilisticConsistencybased2005,
  abstract     = {To study gene evolution across a wide range of organisms, biologists need accurate tools for multiple sequence alignment of protein families. Obtaining accurate alignments, however, is a difficult computational problem because of not only the high computational cost but also the lack of proper objective functions for measuring alignment quality. In this paper, we introduce probabilistic consistency, a novel scoring function for multiple sequence comparisons. We present ProbCons, a practical tool for progressive protein multiple sequence alignment based on probabilistic consistency, and evaluate its performance on several standard alignment benchmark data sets. On the BAliBASE, SABmark, and PREFAB benchmark alignment databases, ProbCons achieves statistically significant improvement over other leading methods while maintaining practical speed. ProbCons is publicly available as a Web resource.},
  author       = {Do, Chuong B. and Mahabhashyam, Mahathi S.P. and Brudno, Michael and Batzoglou, Serafim},
  date         = {2005-02},
  doi          = {10.1101/gr.2821705},
  eprint       = {15687296},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/do_et_al_2005_probcons.pdf},
  issn         = {1088-9051},
  journaltitle = {Genome Research},
  number       = {2},
  pages        = {330--340},
  pmcid        = {PMC546535},
  shortjournal = {Genome Res},
  shorttitle   = {{{ProbCons}}},
  title        = {{{ProbCons}}: {{Probabilistic}} Consistency-Based Multiple Sequence Alignment},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC546535/},
  urldate      = {2019-08-19},
  volume       = {15}
}

@article{doProbConsProbabilisticConsistencybased2005a,
  abstract     = {To study gene evolution across a wide range of organisms, biologists need accurate tools for multiple sequence alignment of protein families. Obtaining accurate alignments, however, is a difficult computational problem because of not only the high computational cost but also the lack of proper objective functions for measuring alignment quality. In this paper, we introduce probabilistic consistency, a novel scoring function for multiple sequence comparisons. We present ProbCons, a practical tool for progressive protein multiple sequence alignment based on probabilistic consistency, and evaluate its performance on several standard alignment benchmark data sets. On the BAliBASE, SABmark, and PREFAB benchmark alignment databases, ProbCons achieves statistically significant improvement over other leading methods while maintaining practical speed. ProbCons is publicly available as a Web resource.},
  author       = {Do, Chuong B. and Mahabhashyam, Mahathi S. P. and Brudno, Michael and Batzoglou, Serafim},
  date         = {2005-01-02},
  doi          = {10.1101/gr.2821705},
  eprint       = {15687296},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Do et al_2005_ProbCons.pdf;/Users/lucblassel/Zotero/storage/9CKA85AH/330.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {2},
  pages        = {330--340},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  shorttitle   = {{{ProbCons}}},
  title        = {{{ProbCons}}: {{Probabilistic}} Consistency-Based Multiple Sequence Alignment},
  url          = {https://genome.cshlp.org/content/15/2/330},
  urldate      = {2022-06-16},
  volume       = {15}
}

@article{doron-faigenboimCombinedEmpiricalMechanistic2007,
  abstract     = {The evolutionary selection forces acting on a protein are commonly inferred using evolutionary codon models by contrasting the rate of synonymous to nonsynonymous substitutions. Most widely used models are based on theoretical assumptions and ignore the empirical observation that distinct amino acids differ in their replacement rates. In this paper, we develop a general method that allows assimilation of empirical amino acid replacement probabilities into a codon-substitution matrix. In this way, the resulting codon model takes into account not only the transition–transversion bias and the nonsynonymous/synonymous ratio, but also the different amino acid replacement probabilities as specified in empirical amino acid matrices. Different empirical amino acid replacement matrices, such as secondary structure–specific matrices or organelle-specific matrices (e.g., mitochondria and chloroplasts), can be incorporated into the model, making it context dependent. Using a diverse set of coding DNA sequences, we show that the novel model better fits biological data as compared with either mechanistic or empirical codon models. Using the suggested model, we further analyze human immunodeficiency virus type 1 protease sequences obtained from drug-treated patients and reveal positive selection in sites that are known to confer drug resistance to the virus.},
  author       = {Doron-Faigenboim, Adi and Pupko, Tal},
  date         = {2007-02-01},
  doi          = {10.1093/molbev/msl175},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Doron-Faigenboim_Pupko_2007_A Combined Empirical and Mechanistic Codon Model.pdf;/Users/lucblassel/Zotero/storage/55YPJ9LI/1149749.html},
  issn         = {0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  number       = {2},
  pages        = {388--397},
  shortjournal = {Molecular Biology and Evolution},
  title        = {A {{Combined Empirical}} and {{Mechanistic Codon Model}}},
  url          = {https://doi.org/10.1093/molbev/msl175},
  urldate      = {2022-06-14},
  volume       = {24}
}

@book{durbinBiologicalSequenceAnalysis1998,
  abstract   = {Probabilistic models are becoming increasingly important in analysing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analysing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it aims to be accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time present the state-of-the-art in this new and highly important field.},
  author     = {Durbin, Richard and Eddy, Sean R. and Krogh, Anders and Mitchison, Graeme},
  date       = {1998},
  doi        = {10.1017/CBO9780511790492},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Durbin et al_1998_Biological Sequence Analysis.pdf;/Users/lucblassel/Zotero/storage/4BE6NNSD/921BB7B78B745198829EF96BC7E0F29D.html},
  isbn       = {978-0-521-62971-3},
  location   = {{Cambridge}},
  publisher  = {{Cambridge University Press}},
  shorttitle = {Biological {{Sequence Analysis}}},
  title      = {Biological {{Sequence Analysis}}: {{Probabilistic Models}} of {{Proteins}} and {{Nucleic Acids}}},
  url        = {https://www.cambridge.org/core/books/biological-sequence-analysis/921BB7B78B745198829EF96BC7E0F29D},
  urldate    = {2022-06-15}
}

@article{earlAlignathonCompetitiveAssessment2014,
  abstract     = {Multiple sequence alignments (MSAs) are a prerequisite for a wide variety of evolutionary analyses. Published assessments and benchmark data sets for protein and, to a lesser extent, global nucleotide MSAs are available, but less effort has been made to establish benchmarks in the more general problem of whole-genome alignment (WGA). Using the same model as the successful Assemblathon competitions, we organized a competitive evaluation in which teams submitted their alignments and then assessments were performed collectively after all the submissions were received. Three data sets were used: Two were simulated and based on primate and mammalian phylogenies, and one was comprised of 20 real fly genomes. In total, 35 submissions were assessed, submitted by 10 teams using 12 different alignment pipelines. We found agreement between independent simulation-based and statistical assessments, indicating that there are substantial accuracy differences between contemporary alignment tools. We saw considerable differences in the alignment quality of differently annotated regions and found that few tools aligned the duplications analyzed. We found that many tools worked well at shorter evolutionary distances, but fewer performed competitively at longer distances. We provide all data sets, submissions, and assessment programs for further study and provide, as a resource for future benchmarking, a convenient repository of code and data for reproducing the simulation assessments.},
  author       = {Earl, Dent and Nguyen, Ngan and Hickey, Glenn and Harris, Robert S. and Fitzgerald, Stephen and Beal, Kathryn and Seledtsov, Igor and Molodtsov, Vladimir and Raney, Brian J. and Clawson, Hiram and Kim, Jaebum and Kemena, Carsten and Chang, Jia-Ming and Erb, Ionas and Poliakov, Alexander and Hou, Minmei and Herrero, Javier and Kent, William James and Solovyev, Victor and Darling, Aaron E. and Ma, Jian and Notredame, Cedric and Brudno, Michael and Dubchak, Inna and Haussler, David and Paten, Benedict},
  date         = {2014-01-12},
  doi          = {10.1101/gr.174920.114},
  eprint       = {25273068},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/earl_et_al_2014_alignathon.pdf;/Users/lucblassel/Zotero/storage/7ZC4CTHR/2077.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {12},
  pages        = {2077--2089},
  shortjournal = {Genome Res.},
  shorttitle   = {Alignathon},
  title        = {Alignathon: A Competitive Assessment of Whole-Genome Alignment Methods},
  url          = {http://genome.cshlp.org/content/24/12/2077},
  urldate      = {2019-08-13},
  volume       = {24}
}

@article{echaveCausesEvolutionaryRate2016,
  abstract     = {It has long been recognized that certain sites within a protein, such as sites in the protein core or catalytic residues in enzymes, are more conserved than are other sites. However, our understanding of rate variation among sites remains surprisingly limited. Recent progress to address this includes the development of a wide array of reliable methods to estimate site-specific substitution rates from sequence alignments. In addition, several molecular traits have been identified that correlate with site-specific rates, and novel mechanistic, biophysical models have been proposed to explain the observed correlations. Nonetheless, at best, current models explain approximately 60\% of the observed variance, highlighting the limitations of current methods and models, and the need for new research directions.},
  author       = {Echave, Julian and Spielman, Stephanie J. and Wilke, Claus O.},
  date         = {2016-02},
  doi          = {10.1038/nrg.2015.18},
  eprint       = {26781812},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/echave_et_al_2016_causes_of_evolutionary_rate_variation_among.pdf},
  issn         = {1471-0056},
  journaltitle = {Nature reviews. Genetics},
  number       = {2},
  pages        = {109--121},
  pmcid        = {PMC4724262},
  shortjournal = {Nat Rev Genet},
  title        = {Causes of Evolutionary Rate Variation among Protein Sites},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4724262/},
  urldate      = {2019-08-19},
  volume       = {17}
}

@inproceedings{eddyMultipleAlignmentUsing,
  abstract  = {Asimulated annealing methodis described for training hidden Markovmodels and producing multiple sequencealignments frominitially unaligned protein or DNAsequences. Simulated annealing in turn uses a dynamic programmingalgorithm for correctly sampling suboptimal multiple alignments according to their probability and a Boltzmanntemperature factor. The quality of simulated annealing alignments is evaluated on structural alignmentsof ten different protein families, and comparedto the performance of other HMMtraining methods and the ClnstalW program. Simulated annealing is better able to find near-global optima in the multiple alignment probability landscape than the other tested HMMtraining methods. Neither ClustalW nor simulated annealing produce consistently better alignments comparedto each other. Examinationof the specific cases in which ClustalW outperforms simulated annealing, and vice versa, provides insight into the strengths and weaknesses of current hidden Markovmodelapproaches.},
  author    = {Eddy, Sean R},
  booktitle = {{International Conference on Intelligent Systems for Molecular Biology}},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Eddy_Multiple Alignment Using Hidden Markov Models.pdf},
  langid    = {english},
  pages     = {7},
  title     = {Multiple {{Alignment Using Hidden Markov Models}}},
  year      = {1995}
}

@article{edgarComparisonScoringFunctions2004,
  abstract     = {Motivation:In recent years, several methods have been proposed for aligning two protein sequence profiles, with reported improvements in alignment accuracy and homolog discrimination versus sequence–sequence methods (e.g. BLAST) and profile–sequence methods (e.g. PSI-BLAST). Profile–profile alignment is also the iterated step in progressive multiple sequence alignment algorithms such as CLUSTALW. However, little is known about the relative performance of different profile–profile scoring functions. In this work, we evaluate the alignment accuracy of 23 different profile–profile scoring functions by comparing alignments of 488 pairs of sequences with identity ≤30\% against structural alignments. We optimize parameters for all scoring functions on the same training set and use profiles of alignments from both PSI-BLAST and SAM-T99. Structural alignments are constructed from a consensus between the FSSP database and CE structural aligner. We compare the results with sequence–sequence and sequence–profile methods, including BLAST and PSI-BLAST.Results: We find that profile–profile alignment gives an average improvement over our test set of typically 2–3\% over profile–sequence alignment and ∼40\% over sequence–sequence alignment. No statistically significant difference is seen in the relative performance of most of the scoring functions tested. Significantly better results are obtained with profiles constructed from SAM-T99 alignments than from PSI-BLAST alignments.Availability: Source code, reference alignments and more detailed results are freely available at http://phylogenomics.berkeley.edu/profilealignment/},
  author       = {Edgar, Robert C. and Sjölander, Kimmen},
  date         = {2004-05-22},
  doi          = {10.1093/bioinformatics/bth090},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Edgar_Sjölander_2004_A comparison of scoring functions for protein sequence profile alignment.pdf;/Users/lucblassel/Zotero/storage/HH3T8ERI/210230.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {8},
  pages        = {1301--1308},
  shortjournal = {Bioinformatics},
  title        = {A Comparison of Scoring Functions for Protein Sequence Profile Alignment},
  url          = {https://doi.org/10.1093/bioinformatics/bth090},
  urldate      = {2022-06-16},
  volume       = {20}
}

@article{edgarMultipleSequenceAlignment2006,
  abstract     = {Multiple sequence alignments are an essential tool for protein structure and function prediction, phylogeny inference and other common tasks in sequence analysis. Recently developed systems have advanced the state of the art with respect to accuracy, ability to scale to thousands of proteins and flexibility in comparing proteins that do not share the same domain architecture. New multiple alignment benchmark databases include PREFAB, SABMARK, OXBENCH and IRMBASE. Although CLUSTALW is still the most popular alignment tool to date, recent methods offer significantly better alignment quality and, in some cases, reduced computational cost.},
  author       = {Edgar, Robert C and Batzoglou, Serafim},
  date         = {2006-06-01},
  doi          = {10.1016/j.sbi.2006.04.004},
  file         = {/Users/lucblassel/Zotero/storage/ZHCNLMXU/Edgar and Batzoglou - 2006 - Multiple sequence alignment.pdf},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  number       = {3},
  pages        = {368--373},
  series       = {Nucleic Acids/{{Sequences}} and Topology},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Multiple Sequence Alignment},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X06000704},
  urldate      = {2022-05-16},
  volume       = {16}
}

@article{edgarMultipleSequenceAlignment2006a,
  abstract     = {Multiple sequence alignments are an essential tool for protein structure and function prediction, phylogeny inference and other common tasks in sequence analysis. Recently developed systems have advanced the state of the art with respect to accuracy, ability to scale to thousands of proteins and flexibility in comparing proteins that do not share the same domain architecture. New multiple alignment benchmark databases include PREFAB, SABMARK, OXBENCH and IRMBASE. Although CLUSTALW is still the most popular alignment tool to date, recent methods offer significantly better alignment quality and, in some cases, reduced computational cost.},
  author       = {Edgar, Robert C and Batzoglou, Serafim},
  date         = {2006-06-01},
  doi          = {10.1016/j.sbi.2006.04.004},
  file         = {/Users/lucblassel/Zotero/storage/NCTSS68F/S0959440X06000704.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  number       = {3},
  pages        = {368--373},
  series       = {Nucleic Acids/{{Sequences}} and Topology},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Multiple Sequence Alignment},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X06000704},
  urldate      = {2022-06-16},
  volume       = {16}
}

@article{edgarMUSCLEMultipleSequence2004,
  abstract     = {We describe MUSCLE, a new computer program for creating multiple alignments of protein sequences. Elements of the algorithm include fast distance estimation using k mer counting, progressive alignment using a new profile function we call the log‐expectation score, and refinement using tree‐dependent restricted partitioning. The speed and accuracy of MUSCLE are compared with T‐Coffee, MAFFT and CLUSTALW on four test sets of reference alignments: BAliBASE, SABmark, SMART and a new benchmark, PREFAB. MUSCLE achieves the highest, or joint highest, rank in accuracy on each of these sets. Without refinement, MUSCLE achieves average accuracy statistically indistinguishable from T‐Coffee and MAFFT, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer. The MUSCLE program, source code and PREFAB test data are freely available at http://www.drive5. com/muscle.},
  author       = {Edgar, Robert C.},
  date         = {2004-03-01},
  doi          = {10.1093/nar/gkh340},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Edgar_2004_MUSCLE2.pdf;/Users/lucblassel/Zotero/storage/TERNBU8G/2380623.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {5},
  pages        = {1792--1797},
  shortjournal = {Nucleic Acids Research},
  shorttitle   = {{{MUSCLE}}},
  title        = {{{MUSCLE}}: Multiple Sequence Alignment with High Accuracy and High Throughput},
  url          = {https://doi.org/10.1093/nar/gkh340},
  urldate      = {2022-06-16},
  volume       = {32}
}

@article{edgarMUSCLEMultipleSequence2004a,
  abstract     = {In a previous paper, we introduced MUSCLE, a new program for creating multiple alignments of protein sequences, giving a brief summary of the algorithm and showing MUSCLE to achieve the highest scores reported to date on four alignment accuracy benchmarks. Here we present a more complete discussion of the algorithm, describing several previously unpublished techniques that improve biological accuracy and / or computational complexity. We introduce a new option, MUSCLE-fast, designed for high-throughput applications. We also describe a new protocol for evaluating objective functions that align two profiles.},
  author       = {Edgar, Robert C.},
  date         = {2004-08-19},
  doi          = {10.1186/1471-2105-5-113},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Edgar_2004_MUSCLE.pdf;/Users/lucblassel/Zotero/storage/R7LAAQBF/1471-2105-5-113.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Amino Acid Type,Fractional Identity,Global Alignment,Multiple Sequence Alignment Program,Profile Function},
  number       = {1},
  pages        = {113},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{MUSCLE}}},
  title        = {{{MUSCLE}}: A Multiple Sequence Alignment Method with Reduced Time and Space Complexity},
  url          = {https://doi.org/10.1186/1471-2105-5-113},
  urldate      = {2022-06-16},
  volume       = {5}
}

@article{edgarSearchClusteringOrders2010,
  abstract     = {Motivation: Biological sequence data is accumulating rapidly, motivating the development of improved high-throughput methods for sequence classification.Results: UBLAST and USEARCH are new algorithms enabling sensitive local and global search of large sequence databases at exceptionally high speeds. They are often orders of magnitude faster than BLAST in practical applications, though sensitivity to distant protein relationships is lower. UCLUST is a new clustering method that exploits USEARCH to assign sequences to clusters. UCLUST offers several advantages over the widely used program CD-HIT, including higher speed, lower memory use, improved sensitivity, clustering at lower identities and classification of much larger datasets.Availability: Binaries are available at no charge for non-commercial use at http://www.drive5.com/usearchContact:robert@drive5.comSupplementary information:Supplementary data are available at Bioinformatics online.},
  author       = {Edgar, Robert C.},
  date         = {2010-10-01},
  doi          = {10.1093/bioinformatics/btq461},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Edgar_2010_Search and clustering orders of magnitude faster than BLAST.pdf;/Users/lucblassel/Zotero/storage/TGY4AWTL/230188.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {19},
  pages        = {2460--2461},
  shortjournal = {Bioinformatics},
  title        = {Search and Clustering Orders of Magnitude Faster than {{BLAST}}},
  url          = {https://doi.org/10.1093/bioinformatics/btq461},
  urldate      = {2022-06-15},
  volume       = {26}
}

@article{edgarSyncmersAreMore2021,
  abstract     = {Minimizers are widely used to select subsets of fixed-length substrings (k-mers) from biological sequences in applications ranging from read mapping to taxonomy prediction and indexing of large datasets. The minimizer of a string of w consecutive k-mers is the k-mer with smallest value according to an ordering of all k-mers. Syncmers are defined here as a family of alternative methods which select k-mers by inspecting the position of the smallest-valued substring of length s {$<$} k within the k-mer. For example, a closed syncmer is selected if its smallest s-mer is at the start or end of the k-mer. At least one closed syncmer must be found in every window of length (k − s) k-mers. Unlike a minimizer, a syncmer is identified by its sequence alone, and is therefore synchronized in the following sense: if a given k-mer is selected from one sequence, it will also be selected from any other sequence. Also, minimizers can be deleted by mutations in flanking sequence, which cannot happen with syncmers. Experiments on minimizers with parameters used in the minimap2 read mapper and Kraken taxonomy prediction algorithm respectively show that syncmers can simultaneously achieve both lower density and higher conservation compared to minimizers.},
  author       = {Edgar, Robert},
  date         = {2021-02-05},
  doi          = {10.7717/peerj.10805},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Edgar_2021_Syncmers are more sensitive than minimizers for selecting conserved k‑mers in.pdf;/Users/lucblassel/Zotero/storage/HAV6YJJB/10805.html},
  issn         = {2167-8359},
  journaltitle = {PeerJ},
  langid       = {english},
  pages        = {e10805},
  publisher    = {{PeerJ Inc.}},
  shortjournal = {PeerJ},
  title        = {Syncmers Are More Sensitive than Minimizers for Selecting Conserved K‑mers in Biological Sequences},
  url          = {https://peerj.com/articles/10805},
  urldate      = {2022-09-05},
  volume       = {9}
}

@inproceedings{ekimRandomizedParallelAlgorithm2020,
  abstract  = {As the volume of next generation sequencing data increases, an urgent need for algorithms to efficiently process the data arises. Universal hitting sets (UHS) were recently introduced as an alternative to the central idea of minimizers in sequence analysis with the hopes that they could more efficiently address common tasks such as computing hash functions for read overlap, sparse suffix arrays, and Bloom filters. A UHS is a set of k-mers that hit every sequence of length L, and can thus serve as indices to L-long sequences. Unfortunately, methods for computing small UHSs are not yet practical for real-world sequencing instances due to their serial and deterministic nature, which leads to long runtimes and high memory demands when handling typical values of k (e.g. \$\$k {$>$} 13\$\$). To address this bottleneck, we present two algorithmic innovations to significantly decrease runtime while keeping memory usage low: (i) we leverage advanced theoretical and architectural techniques to parallelize and decrease memory usage in calculating k-mer hitting numbers; and (ii) we build upon techniques from randomized Set Cover to select universal k-mers much faster. We implemented these innovations in PASHA, the first randomized parallel algorithm for generating near-optimal UHSs, which newly handles \$\$k {$>$} 13\$\$. We demonstrate empirically that PASHA produces sets only slightly larger than those of serial deterministic algorithms; moreover, the set size is provably guaranteed to be within a small constant factor of the optimal size. PASHA’s runtime and memory-usage improvements are orders of magnitude faster than the current best algorithms. We expect our newly-practical construction of UHSs to be adopted in many high-throughput sequence analysis pipelines.},
  author    = {Ekim, Barış and Berger, Bonnie and Orenstein, Yaron},
  booktitle = {Research in {{Computational Molecular Biology}}},
  date      = {2020},
  doi       = {10.1007/978-3-030-45257-5_3},
  editor    = {Schwartz, Russell},
  file      = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Ekim et al_2020_A Randomized Parallel Algorithm for Efficiently Finding Near-Optimal Universal.pdf},
  isbn      = {978-3-030-45257-5},
  keywords  = {Parallelization,Randomization,Universal hitting sets},
  langid    = {english},
  location  = {{Cham}},
  pages     = {37--53},
  publisher = {{Springer International Publishing}},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  title     = {A {{Randomized Parallel Algorithm}} for {{Efficiently Finding Near-Optimal Universal Hitting Sets}}}
}

@book{EncyclopediaBioinformaticsComputational2018,
  abstract   = {Encyclopedia of Bioinformatics and Computational Biology: ABC of Bioinformatics, Three Volume Set combines elements of computer science, information technology, mathematics, statistics and biotechnology, providing the methodology and in silico solutions to mine biological data and processes. The book covers Theory, Topics and Applications, with a special focus on Integrative –omics and Systems Biology. The theoretical, methodological underpinnings of BCB, including phylogeny are covered, as are more current areas of focus, such as translational bioinformatics, cheminformatics, and environmental informatics. Finally, Applications provide guidance for commonly asked questions. This major reference work spans basic and cutting-edge methodologies authored by leaders in the field, providing an invaluable resource for students, scientists, professionals in research institutes, and a broad swath of researchers in biotechnology and the biomedical and pharmaceutical industries. Brings together information from computer science, information technology, mathematics, statistics and biotechnology  Written and reviewed by leading experts in the field, providing a unique and authoritative resource Focuses on the main theoretical and methodological concepts before expanding on specific topics and applications Includes interactive images, multimedia tools and crosslinking to further resources and databases},
  author     = {Ranganathan, Shoba and Nakai, Kenta and Schonbach, Christian},
  date       = {2018-08-21},
  eprint     = {rs51DwAAQBAJ},
  eprinttype = {googlebooks},
  isbn       = {978-0-12-811432-2},
  keywords   = {Computers / Bioinformatics,Computers / Business & Productivity Software / Business Intelligence,Computers / Business & Productivity Software / General,Medical / Biostatistics,Science / Life Sciences / Genetics & Genomics,Science / Life Sciences / Molecular Biology},
  langid     = {english},
  pagetotal  = {3421},
  publisher  = {{Elsevier}},
  shorttitle = {Encyclopedia of {{Bioinformatics}} and {{Computational Biology}}},
  title      = {Encyclopedia of {{Bioinformatics}} and {{Computational Biology}}: {{ABC}} of {{Bioinformatics}}}
}

@article{essoussiComparisonFourPairwise2007,
  abstract     = {Protein sequence alignment has become an essential task in modern molecular biology research. A number of alignment techniques have been documented in          literature and their corresponding tools are made available as freeware and commercial software. The choice and use of these tools for sequence alignment          through the complete interpretation of alignment results is often considered non-trivial by end-users with limited skill in Bioinformatics algorithm development.          Here, we discuss the comparison of sequence alignment techniques based on dynamic programming (N-W, S-W) and heuristics (LFASTA, BL2SEQ) for four sets of sequence          data towards an educational purpose. The analysis suggests that heuristics based methods are faster than dynamic programming methods in alignment speed.},
  author       = {Essoussi, Nadia and Fayech, Sondes},
  date         = {2007-12-28},
  doi          = {10.6026/97320630002166},
  eprint       = {21670797},
  eprinttype   = {pmid},
  issn         = {0973-2063},
  journaltitle = {Bioinformation},
  number       = {4},
  pages        = {166--168},
  pmcid        = {PMC2255065},
  shortjournal = {Bioinformation},
  title        = {A Comparison of Four Pair-Wise Sequence Alignment Methods},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2255065/},
  urldate      = {2022-06-15},
  volume       = {2}
}

@article{felsensteinEvolutionaryTreesDNA1981,
  abstract     = {The application of maximum likelihood techniques to the estimation of evolutionary trees from nucleic acid sequence data is discussed. A computationally feasible method for finding such maximum likelihood estimates is developed, and a computer program is available. This method has advantages over the traditional parsimony algorithms, which can give misleading results if rates of evolution differ in different lineages. It also allows the testing of hypotheses about the constancy of evolutionary rates by likelihood ratio tests, and gives rough indication of the error of the estimate of the tree.},
  author       = {Felsenstein, Joseph},
  date         = {1981-11-01},
  doi          = {10.1007/BF01734359},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Felsenstein_1981_Evolutionary trees from DNA sequences.pdf},
  issn         = {1432-1432},
  journaltitle = {Journal of Molecular Evolution},
  keywords     = {DNA sequences,Estimation,Evolution,Maximum likelihood,Parsimony,Phylogeny},
  langid       = {english},
  number       = {6},
  pages        = {368--376},
  shortjournal = {J Mol Evol},
  shorttitle   = {Evolutionary Trees from {{DNA}} Sequences},
  title        = {Evolutionary Trees from {{DNA}} Sequences: {{A}} Maximum Likelihood Approach},
  url          = {https://doi.org/10.1007/BF01734359},
  urldate      = {2022-06-14},
  volume       = {17}
}

@incollection{feng21ProgressiveAlignment1996,
  abstract  = {This chapter discusses the progressive alignment of amino acid sequences and construction of phylogenetic trees from them and a much improved, easier to use, set of programs, which is refer to as ProPack––a packet of programs centering on progressive alignment. The changes pertain mainly to speeding up the calculations and reducing the number of manual operations; the basic idea of progressive alignment remains the same. The principal new features of ProPack are introduction of an option for choosing an alternative amino acid substitution matrix, automatic elimination of negative branch lengths in the calculation of phylogenetic trees, addition of a bootstrap analysis option, and inclusion of a simple program for converting output to a form that can be used to draw trees on a microcomputer with standard software. The bootstrapping is restricted to solutions with no negative branch lengths, a necessary condition if the likelihoods are to have any meaning.},
  author    = {Feng, Da-Fei and Doolittle, Russell F.},
  booktitle = {Methods in {{Enzymology}}},
  date      = {1996-01-01},
  doi       = {10.1016/S0076-6879(96)66023-6},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Feng_Doolittle_1996_[21] Progressive alignment of amino acid sequences and construction of.pdf;/Users/lucblassel/Zotero/storage/XTMURIDP/S0076687996660236.html},
  langid    = {english},
  pages     = {368--382},
  publisher = {{Academic Press}},
  series    = {Computer {{Methods}} for {{Macromolecular Sequence Analysis}}},
  title     = {[21] {{Progressive}} Alignment of Amino Acid Sequences and Construction of Phylogenetic Trees from Them},
  url       = {https://www.sciencedirect.com/science/article/pii/S0076687996660236},
  urldate   = {2022-06-15},
  volume    = {266}
}

@article{fengProgressiveSequenceAlignment1987,
  abstract     = {SummaryA progressive alignment method is described that utilizes the Needleman and Wunsch pairwise alignment algorithm iteratively to achieve the multiple alignment of a set of protein sequences and to construct an evolutionary tree depicting their relationship. The sequences are assumed a priori to share a common ancestor, and the trees are constructed from difference matrices derived directly from the multiple alignment. The thrust of the method involves putting more trust in the comparison of recently diverged sequences than in those evolved in the distant past. In particular, this rule is followed: “once a gap, always a gap”. The method has been applied to three sets of protein sequences: 7 superoxide dismutases, 11 globins, and 9 tyrosine kinase-like sequences. Multiple alignments and phylogenetic trees for these sets of sequences were determined and compared with trees derived by conventional pairwise treatments. In several instances, the progressive method led to trees that appeared to be more in line with biological expectations than were trees obtained by more commonly used methods.},
  author       = {Feng, Da-Fei and Doolittle, Russell F.},
  date         = {1987-08-01},
  doi          = {10.1007/BF02603120},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/feng_doolittle_1987_progressive_sequence_alignment_as_a.pdf},
  issn         = {1432-1432},
  journaltitle = {Journal of Molecular Evolution},
  keywords     = {Evolutionary trees,Multiple sequence alignments},
  langid       = {english},
  number       = {4},
  pages        = {351--360},
  shortjournal = {J Mol Evol},
  title        = {Progressive Sequence Alignment as a Prerequisitetto Correct Phylogenetic Trees},
  url          = {https://doi.org/10.1007/BF02603120},
  urldate      = {2019-08-19},
  volume       = {25}
}

@inproceedings{ferraginaOpportunisticDataStructures2000,
  abstract   = {We address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because text T[1,u] is stored using O(H/sub k/(T))+o(1) bits per input symbol in the worst case, where H/sub k/(T) is the kth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary string P[1,p], the opportunistic data structure allows to search for the occurrences of P in T in O(p+occlog/sup /spl epsiv//u) time (for any fixed /spl epsiv/{$>$}0). If data are uncompressible we achieve the best space bound currently known (Grossi and Vitter, 2000); on compressible data our solution improves the succinct suffix array of (Grossi and Vitter, 2000) and the classical suffix tree and suffix array data structures either in space or in query time or both. We also study our opportunistic data structure in a dynamic setting and devise a variant achieving effective search and update time bounds. Finally, we show how to plug our opportunistic data structure into the Glimpse tool (Manber and Wu, 1994). The result is an indexing tool which achieves sublinear space and sublinear query time complexity.},
  author     = {Ferragina, P. and Manzini, G.},
  booktitle  = {Proceedings 41st {{Annual Symposium}} on {{Foundations}} of {{Computer Science}}},
  date       = {2000-11},
  doi        = {10.1109/SFCS.2000.892127},
  eventtitle = {Proceedings 41st {{Annual Symposium}} on {{Foundations}} of {{Computer Science}}},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ferragina_Manzini_2000_Opportunistic data structures with applications.pdf;/Users/lucblassel/Zotero/storage/RIBF5CXK/892127.html},
  ids        = {ferraginaOpportunisticDataStructures2000a},
  issn       = {0272-5428},
  keywords   = {Computer science,Costs,Data engineering,Data structures,Entropy,Fault tolerance,Indexing,Plugs,Postal services,Tree data structures},
  pages      = {390--398},
  title      = {Opportunistic Data Structures with Applications}
}

@article{fickettFastOptimalAlignment1984,
  abstract     = {We show how to speed up sequence alignment algorithms of the type Introduced by Needleman and Wunsch (and generalized by Sellers and research-articles). Faster alignment algorithms have been introduced, but always at the cost of possibly getting sub-optimal alignments. Our modification results in the optimal alignment still being found, often In 1/10 the usual time. What we do is reorder the computation of the usual alignment matrix so that the optimal alignment is ordinarily found when only a small fraction of the matrix is filled. The number of matrix elements which have to be computed is related to the distance between the sequences being aligned; the better the optimal alignment, the faster the algorithm runs.},
  author       = {Fickett, James W.},
  date         = {1984-01-11},
  doi          = {10.1093/nar/12.1Part1.175},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Fickett_1984_Fast optimal alignment.pdf;/Users/lucblassel/Zotero/storage/JSD7BSTG/2889706.html},
  issn         = {0305-1048},
  issue        = {1Part1},
  journaltitle = {Nucleic Acids Research},
  pages        = {175--179},
  shortjournal = {Nucleic Acids Research},
  title        = {Fast Optimal Alignment},
  url          = {https://doi.org/10.1093/nar/12.1Part1.175},
  urldate      = {2022-06-15},
  volume       = {12}
}

@article{finnHMMERWebServer2011,
  abstract     = {HMMER is a software suite for protein sequence similarity searches using probabilistic methods. Previously, HMMER has mainly been available only as a computationally intensive UNIX command-line tool, restricting its use. Recent advances in the software, HMMER3, have resulted in a 100-fold speed gain relative to previous versions. It is now feasible to make efficient profile hidden Markov model (profile HMM) searches via the web. A HMMER web server (http://hmmer.janelia.org) has been designed and implemented such that most protein database searches return within a few seconds. Methods are available for searching either a single protein sequence, multiple protein sequence alignment or profile HMM against a target sequence database, and for searching a protein sequence against Pfam. The web server is designed to cater to a range of different user expertise and accepts batch uploading of multiple queries at once. All search methods are also available as RESTful web services, thereby allowing them to be readily integrated as remotely executed tasks in locally scripted workflows. We have focused on minimizing search times and the ability to rapidly display tabular results, regardless of the number of matches found, developing graphical summaries of the search results to provide quick, intuitive appraisement of them.},
  author       = {Finn, Robert D. and Clements, Jody and Eddy, Sean R.},
  date         = {2011-07-01},
  doi          = {10.1093/nar/gkr367},
  eprint       = {21593126},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Finn et al_2011_HMMER web server.pdf},
  issn         = {0305-1048},
  issue        = {Web Server issue},
  journaltitle = {Nucleic Acids Research},
  pages        = {W29-W37},
  pmcid        = {PMC3125773},
  shortjournal = {Nucleic Acids Res},
  shorttitle   = {{{HMMER}} Web Server},
  title        = {{{HMMER}} Web Server: Interactive Sequence Similarity Searching},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3125773/},
  urldate      = {2022-06-15},
  volume       = {39}
}

@article{finnPfamProteinFamilies2014,
  abstract     = {Abstract.  Pfam, available via servers in the UK (http://pfam.sanger.ac.uk/) and the USA (http://pfam.janelia.org/), is a widely used database of protein famili},
  author       = {Finn, Robert D. and Bateman, Alex and Clements, Jody and Coggill, Penelope and Eberhardt, Ruth Y. and Eddy, Sean R. and Heger, Andreas and Hetherington, Kirstie and Holm, Liisa and Mistry, Jaina and Sonnhammer, Erik L. L. and Tate, John and Punta, Marco},
  date         = {2014-01-01},
  doi          = {10.1093/nar/gkt1223},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/finn_et_al_2014_pfam.pdf;/Users/lucblassel/Zotero/storage/KRI4ZYRZ/1062431.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  langid       = {english},
  number       = {D1},
  pages        = {D222-D230},
  shortjournal = {Nucleic Acids Res},
  shorttitle   = {Pfam},
  title        = {Pfam: The Protein Families Database},
  url          = {https://academic.oup.com/nar/article/42/D1/D222/1062431},
  urldate      = {2019-08-14},
  volume       = {42}
}

@article{finnPfamProteinFamilies2016,
  abstract     = {In the last two years the Pfam database () has undergone a substantial reorganisation to reduce the effort involved in making a release, thereby permitting more frequent releases. Arguably the most significant of these changes is that Pfam is now primarily ...},
  author       = {Finn, Robert D. and Coggill, Penelope and Eberhardt, Ruth Y. and Eddy, Sean R. and Mistry, Jaina and Mitchell, Alex L. and Potter, Simon C. and Punta, Marco and Qureshi, Matloob and Sangrador-Vegas, Amaia and Salazar, Gustavo A. and Tate, John and Bateman, Alex},
  date         = {2016-01-01},
  doi          = {10.1093/nar/gkv1344},
  eprint       = {26673716},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Finn et al_2016_The Pfam protein families database.pdf;/Users/lucblassel/Zotero/storage/VVCK643X/PMC4702930.html},
  issue        = {Database issue},
  journaltitle = {Nucleic Acids Research},
  langid       = {english},
  pages        = {D279},
  publisher    = {{Oxford University Press}},
  shorttitle   = {The {{Pfam}} Protein Families Database},
  title        = {The {{Pfam}} Protein Families Database: Towards a More Sustainable Future},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4702930/},
  urldate      = {2022-06-15},
  volume       = {44}
}

@article{fitchOptimalSequenceAlignments1983,
  author       = {Fitch, Walter M. and Smith, Temple F.},
  date         = {1983-03},
  doi          = {10.1073/pnas.80.5.1382},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Fitch_Smith_1983_Optimal sequence alignments.pdf},
  journaltitle = {Proceedings of the National Academy of Sciences},
  number       = {5},
  pages        = {1382--1386},
  publisher    = {{Proceedings of the National Academy of Sciences}},
  title        = {Optimal Sequence Alignments},
  url          = {https://www.pnas.org/doi/abs/10.1073/pnas.80.5.1382},
  urldate      = {2022-08-26},
  volume       = {80}
}

@article{frohmbergGPASImprovedVersion2012,
  abstract     = {Several highly efficient alignment tools have been released over the past few years, including those taking advantage of GPUs (Graphics Processing Units). G-PAS (GPU-based Pairwise Alignment Software) was one of them, however, with a couple of interesting features that made it unique. Nevertheless, in order to adapt it to a new computational architecture some changes had to be introduced. In this paper we present G-PAS 2.0 – a new version of the software for performing high-throughput alignment. Results show, that the new version is faster nearly by a fourth on the same hardware, reaching over 20 GCUPS (Giga Cell Updates Per Second).},
  author       = {Frohmberg, W. and Kierzynka, M. and Blazewicz, J. and Wojciechowski, P.},
  date         = {2012-12-01},
  doi          = {10.2478/v10175-012-0062-1},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Frohmberg et al_2012_G-PAS 2.pdf},
  issn         = {0239-7528},
  journaltitle = {Bulletin of the Polish Academy of Sciences: Technical Sciences},
  langid       = {english},
  number       = {3},
  pages        = {491--494},
  title        = {G-{{PAS}} 2.0 – an Improved Version of Protein Alignment Tool with an Efficient Backtracking Routine on Multiple {{GPUs}}},
  url          = {http://journals.pan.pl/dlibra/publication/96876/edition/83624/content},
  urldate      = {2022-06-14},
  volume       = {60}
}

@article{garrigaLargeMultipleSequence2019,
  abstract     = {Multiple sequence alignments (MSAs) are used for structural1,2 and evolutionary predictions1,2, but the complexity of aligning large datasets requires the use of approximate solutions3, including the progressive algorithm4. Progressive MSA methods start by aligning the most similar sequences and subsequently incorporate the remaining sequences, from leaf to root, based on a guide tree. Their accuracy declines substantially as the number of sequences is scaled up5. We introduce a regressive algorithm that enables MSA of up to 1.4 million sequences on a standard workstation and substantially improves accuracy on datasets larger than 10,000 sequences. Our regressive algorithm works the other way around from the progressive algorithm and begins by aligning the most dissimilar sequences. It uses an efficient divide-and-conquer strategy to run third-party alignment methods in linear time, regardless of their original complexity. Our approach will enable analyses of extremely large genomic datasets such as the recently announced Earth BioGenome Project, which comprises 1.5 million eukaryotic genomes6.},
  author       = {Garriga, Edgar and Di Tommaso, Paolo and Magis, Cedrik and Erb, Ionas and Mansouri, Leila and Baltzis, Athanasios and Laayouni, Hafid and Kondrashov, Fyodor and Floden, Evan and Notredame, Cedric},
  date         = {2019-12},
  doi          = {10.1038/s41587-019-0333-6},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Garriga et al_2019_Large multiple sequence alignments with a root-to-leaf regressive method.pdf;/Users/lucblassel/Zotero/storage/JTP9UFSH/s41587-019-0333-6.html},
  issn         = {1546-1696},
  issue        = {12},
  journaltitle = {Nature Biotechnology},
  keywords     = {Computational models,Phylogenetics},
  langid       = {english},
  number       = {12},
  pages        = {1466--1470},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Biotechnol},
  title        = {Large Multiple Sequence Alignments with a Root-to-Leaf Regressive Method},
  url          = {https://www.nature.com/articles/s41587-019-0333-6},
  urldate      = {2022-06-16},
  volume       = {37}
}

@article{gentlemanBioconductorOpenSoftware2004,
  abstract     = {The Bioconductor project is an initiative for the collaborative creation of extensible software for computational biology and bioinformatics. The goals of the project include: fostering collaborative development and widespread use of innovative software, reducing barriers to entry into interdisciplinary scientific research, and promoting the achievement of remote reproducibility of research results. We describe details of our aims and methods, identify current challenges, compare Bioconductor to other open bioinformatics projects, and provide working examples.},
  author       = {Gentleman, Robert C. and Carey, Vincent J. and Bates, Douglas M. and Bolstad, Ben and Dettling, Marcel and Dudoit, Sandrine and Ellis, Byron and Gautier, Laurent and Ge, Yongchao and Gentry, Jeff and Hornik, Kurt and Hothorn, Torsten and Huber, Wolfgang and Iacus, Stefano and Irizarry, Rafael and Leisch, Friedrich and Li, Cheng and Maechler, Martin and Rossini, Anthony J. and Sawitzki, Gunther and Smith, Colin and Smyth, Gordon and Tierney, Luke and Yang, Jean YH and Zhang, Jianhua},
  date         = {2004-09-15},
  doi          = {10.1186/gb-2004-5-10-r80},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Gentleman et al_2004_Bioconductor.pdf},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Acute Lymphocytic Leukemia,Application Programming Interface,Data Package,Portable Document Format,Software Project},
  langid       = {english},
  number       = {10},
  pages        = {R80},
  shortjournal = {Genome Biol},
  shorttitle   = {Bioconductor},
  title        = {Bioconductor: Open Software Development for Computational Biology and Bioinformatics},
  url          = {https://doi.org/10.1186/gb-2004-5-10-r80},
  urldate      = {2022-06-14},
  volume       = {5}
}

@article{goonesekereContextspecificAminoAcid2008,
  abstract     = {The sequence homology detection relies on score matrices, which reflect the frequency of amino acid substitutions observed in a dataset of homologous sequences. The substitution matrices in popular use today are usually constructed without consideration of the structural context in which the substitution takes place. Here, we present amino acid substitution matrices specific for particular polar–nonpolar environment of the amino acid. As expected, these matrices [context-specific substitution matrices (CSSMs)] show striking differences from the popular BLOSUM62 matrix, which does not include structural information. When incorporated into BLAST and PSI-BLAST, CSSM outperformed BLOSUM matrices as assessed by ROC curve analyses of the number of true and false hits and by the accuracy of the sequence alignments to the hit sequences. These findings are also of relevance to profile–profile-based methods of homology detection, since CSSMs may help build a better profile. Profiles generated for protein sequences in PDB using CSSM-PSI-BLAST will be made available for searching via RPSBLAST through our web site http://lmbbi.nci.nih.gov/. Proteins 2008; 71:910–919. Published 2007 Wiley-Liss, Inc.},
  annotation   = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/prot.21775},
  author       = {Goonesekere, Nalin C. W. and Lee, Byungkook},
  date         = {2008},
  doi          = {10.1002/prot.21775},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Goonesekere_Lee_2008_Context-specific amino acid substitution matrices and their use in the.pdf;/Users/lucblassel/Zotero/storage/GIAFKVN4/prot.html},
  issn         = {1097-0134},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  keywords     = {CSSM,environment polarity,fold recognition,homology detection,score matrix,sequence alignment},
  langid       = {english},
  number       = {2},
  pages        = {910--919},
  title        = {Context-Specific Amino Acid Substitution Matrices and Their Use in the Detection of Protein Homologs},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.21775},
  urldate      = {2022-06-14},
  volume       = {71}
}

@article{goonesekereFrequencyGapsObserved2004,
  abstract     = {Gap penalty is an important component of the scoring scheme that is needed when searching for homologous proteins and for accurate alignment of protein sequences. Most homology search and sequence alignment algorithms employ a heuristic ‘affine gap penalty’ scheme q+r × n, in which q is the penalty for opening a gap, r the penalty for extending it and n the gap length. In order to devise a more rational scoring scheme, we examined the pattern of gaps that occur in a database of structurally aligned protein domain pairs. We find that the logarithm of the frequency of gaps varies linearly with the length of the gap, but with a break at a gap of length 3, and is well approximated by two linear regression lines with R2 values of 1.0 and 0.99. The bilinear behavior is retained when gaps are categorized by secondary structures of the two residues flanking the gap. Similar results were obtained when another, totally independent, structurally aligned protein pair database was used. These results suggest a modification of the affine gap penalty function.},
  author       = {Goonesekere, Nalin C. W. and Lee, Byungkook},
  date         = {2004-05-01},
  doi          = {10.1093/nar/gkh610},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Goonesekere_Lee_2004_Frequency of gaps observed in a structurally aligned protein pair database.pdf;/Users/lucblassel/Zotero/storage/4X2N3G9X/1037247.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {9},
  pages        = {2838--2843},
  shortjournal = {Nucleic Acids Research},
  title        = {Frequency of Gaps Observed in a Structurally Aligned Protein Pair Database Suggests a Simple Gap Penalty Function},
  url          = {https://doi.org/10.1093/nar/gkh610},
  urldate      = {2022-08-26},
  volume       = {32}
}

@article{gotohImprovedAlgorithmMatching1982,
  abstract     = {The algorithm of Waterman et al. (1976) for matching biological sequences was modified under some limitations to be accomplished in essentially MN steps, instead of the M2N steps necessary in the original algorithm. The limitations do not seriously reduce the generality of the original method, and the present method is available for most practical uses. The algorithm can be executed on a small computer with a limited capacity of core memory.},
  author       = {Gotoh, Osamu},
  date         = {1982-12-15},
  doi          = {10.1016/0022-2836(82)90398-9},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {3},
  pages        = {705--708},
  shortjournal = {Journal of Molecular Biology},
  title        = {An Improved Algorithm for Matching Biological Sequences},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283682903989},
  urldate      = {2022-06-14},
  volume       = {162}
}

@article{gronauOptimalImplementationsUPGMA2007,
  abstract     = {In this work we consider hierarchical clustering algorithms, such as UPGMA, which follow the closest-pair joining scheme. We survey optimal O(n2)-time implementations of such algorithms which use a ‘locally closest’ joining scheme, and specify conditions under which this relaxed joining scheme is equivalent to the original one (i.e. ‘globally closest’).},
  author       = {Gronau, Ilan and Moran, Shlomo},
  date         = {2007-12-16},
  doi          = {10.1016/j.ipl.2007.07.002},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Gronau_Moran_2007_Optimal implementations of UPGMA and other common clustering algorithms.pdf;/Users/lucblassel/Zotero/storage/85ZFL4C9/S0020019007001767.html},
  issn         = {0020-0190},
  journaltitle = {Information Processing Letters},
  keywords     = {Computational complexity,Design of algorithms,Hierarchical clustering,Input–output specification,UPGMA},
  langid       = {english},
  number       = {6},
  pages        = {205--210},
  shortjournal = {Information Processing Letters},
  title        = {Optimal Implementations of {{UPGMA}} and Other Common Clustering Algorithms},
  url          = {https://www.sciencedirect.com/science/article/pii/S0020019007001767},
  urldate      = {2022-09-06},
  volume       = {104}
}

@article{guindonNewAlgorithmsMethods2010,
  abstract     = {PhyML is a phylogeny software based on the maximum-likelihood principle. Early PhyML versions used a fast algorithm performing nearest neighbor interchanges to improve a reasonable starting tree topology. Since the original publication (Guindon S., Gascuel O. 2003. A simple, fast and accurate algorithm to estimate large phylogenies by maximum likelihood. Syst. Biol. 52:696–704), PhyML has been widely used (\&gt;2500 citations in ISI Web of Science) because of its simplicity and a fair compromise between accuracy and speed. In the meantime, research around PhyML has continued, and this article describes the new algorithms and methods implemented in the program. First, we introduce a new algorithm to search the tree space with user-defined intensity using subtree pruning and regrafting topological moves. The parsimony criterion is used here to filter out the least promising topology modifications with respect to the likelihood function. The analysis of a large collection of real nucleotide and amino acid data sets of various sizes demonstrates the good performance of this method. Second, we describe a new test to assess the support of the data for internal branches of a phylogeny. This approach extends the recently proposed approximate likelihood-ratio test and relies on a nonparametric, Shimodaira–Hasegawa–like procedure. A detailed analysis of real alignments sheds light on the links between this new approach and the more classical nonparametric bootstrap method. Overall, our tests show that the last version (3.0) of PhyML is fast, accurate, stable, and ready to use. A Web server and binary files are available from http://www.atgc-montpellier.fr/phyml/.},
  author       = {Guindon, Stéphane and Dufayard, Jean-François and Lefort, Vincent and Anisimova, Maria and Hordijk, Wim and Gascuel, Olivier},
  date         = {2010-05-01},
  doi          = {10.1093/sysbio/syq010},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Guindon et al_2010_New Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies.pdf;/Users/lucblassel/Zotero/storage/BLY4ZWQW/1702850.html},
  issn         = {1063-5157},
  journaltitle = {Systematic Biology},
  number       = {3},
  pages        = {307--321},
  shortjournal = {Systematic Biology},
  shorttitle   = {New {{Algorithms}} and {{Methods}} to {{Estimate Maximum-Likelihood Phylogenies}}},
  title        = {New {{Algorithms}} and {{Methods}} to {{Estimate Maximum-Likelihood Phylogenies}}: {{Assessing}} the {{Performance}} of {{PhyML}} 3.0},
  url          = {https://doi.org/10.1093/sysbio/syq010},
  urldate      = {2022-06-14},
  volume       = {59}
}

@article{guSizeDistributionInsertions1995,
  abstract     = {The size distributions of deletions, insertions, and indels (i.e., insertions or deletions) were studied, using 78 human processed pseudogenes and other published data sets. The following results were obtained: (1) Deletions occur more frequently than do insertions in sequence evolution; none of the pseudogenes studied shows significantly more insertions than deletions. (2) Empirically, the size distributions of deletions, insertions, and indels can be described well by a power law, i.e., fk= Ck−b, where fkis the frequency of deletion, insertion, or indel with gap length k, b is the power parameter, and C is the normalization factor. (3) The estimates of b for deletions and insertions from the same data set are approximately equal to each other, indicating that the size distributions for deletions and insertions are approximately identical. (4) The variation in the estimates of b among various data sets is small, indicating that the effect of local structure exists but only plays a secondary role in the size distribution of deletions and insertions. (5) The linear gap penalty, which is most commonly used in sequence alignment, is not supported by our analysis; rather, the power law for the size distribution of indels suggests that an appropriate gap penalty is wk= a + b ln k, where a is the gap creation cost and blnk is the gap extension cost. (6) The higher frequency of deletion over insertion suggests that the gap creation cost of insertion (ai) should be larger than that of deletion (ad); that is, ai− ad= In R, where R is the frequency ratio of deletions to insertions.},
  author       = {Gu, Xun and Li, Wen-Hsiung},
  date         = {1995-04-01},
  doi          = {10.1007/BF00164032},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Gu_Li_1995_The size distribution of insertions and deletions in human and rodent.pdf},
  issn         = {1432-1432},
  journaltitle = {Journal of Molecular Evolution},
  keywords     = {Deletions,Gap penalty,Insertions,Pseudogenes,Sequence alignment},
  langid       = {english},
  number       = {4},
  pages        = {464--473},
  shortjournal = {J Mol Evol},
  title        = {The Size Distribution of Insertions and Deletions in Human and Rodent Pseudogenes Suggests the Logarithmic Gap Penalty for Sequence Alignment},
  url          = {https://doi.org/10.1007/BF00164032},
  urldate      = {2022-06-14},
  volume       = {40}
}

@article{haghshenasLordFASTSensitiveFast2019,
  abstract     = {Motivation: Recent advances in genomics and precision medicine have been made possible through the application of high throughput sequencing (HTS) to large collections of human genomes. Although HTS technologies have proven their use in cataloging human genome variation, computational analysis of the data they generate is still far from being perfect. The main limitation of Illumina and other popular sequencing technologies is their short read length relative to the lengths of (common) genomic repeats. Newer (single molecule sequencing - SMS) technologies such as Pacific Biosciences and Oxford Nanopore are producing longer reads, making it theoretically possible to overcome the difficulties imposed by repeat regions. Unfortunately, because of their high sequencing error rate, reads generated by these technologies are very difficult to work with and cannot be used in many of the standard downstream analysis pipelines. Note that it is not only difficult to find the correct mapping locations of such reads in a reference genome, but also to establish their correct alignment so as to differentiate sequencing errors from real genomic variants. Furthermore, especially since newer SMS instruments provide higher throughput, mapping and alignment need to be performed much faster than before, maintaining high sensitivity. Results: We introduce lordFAST, a novel long-read mapper that is specifically designed to align reads generated by PacBio and potentially other SMS technologies to a reference. lordFAST not only has higher sensitivity than the available alternatives, it is also among the fastest and has a very low memory footprint. Availability and implementation: lordFAST is implemented in C++ and supports multi-threading. The source code of lordFAST is available at https://github.com/vpc-ccg/lordfast. Supplementary information: Supplementary data are available at Bioinformatics online.},
  author       = {Haghshenas, Ehsan and Sahinalp, S. Cenk and Hach, Faraz},
  date         = {2019-01-01},
  doi          = {10.1093/bioinformatics/bty544},
  eprint       = {30561550},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Haghshenas et al_2019_lordFAST.pdf},
  issn         = {1367-4811},
  journaltitle = {Bioinformatics (Oxford, England)},
  keywords     = {Computational Biology,Genome; Human,Genomics,High-Throughput Nucleotide Sequencing,Humans,Sequence Analysis; DNA,Software},
  langid       = {english},
  number       = {1},
  pages        = {20--27},
  pmcid        = {PMC6298053},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{lordFAST}}},
  title        = {{{lordFAST}}: Sensitive and {{Fast Alignment Search Tool}} for {{LOng}} Noisy {{Read}} Sequencing {{Data}}},
  volume       = {35}
}

@book{hammingCodingInformationTheory1980,
  author     = {Hamming, Richard Wesley},
  date       = {1980},
  eprint     = {ed5QAAAAMAAJ},
  eprinttype = {googlebooks},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hamming_1980_Coding and Information Theory.pdf},
  ids        = {hamming1980coding},
  isbn       = {978-0-13-139139-0},
  langid     = {english},
  lccn       = {79015159},
  pagetotal  = {264},
  publisher  = {{Prentice-Hall}},
  title      = {Coding and {{Information Theory}}}
}

@article{hannenhalliTransformingCabbageTurnip1999,
  abstract     = {Genomes frequently evolve by reversals ρ(i,j) that transform a gene order π1 … πiπi+1 … πj-1πj … πn into π1 … πiπj-1 … πi+1πj … πn. Reversal distance between permutations π and σis the minimum number of reversals to transform π into Α. Analysis of genome rearrangements in molecular biology started in the late 1930's, when Dobzhansky and Sturtevant published a milestone paper presenting a rearrangement scenario with 17 inversions between the species of Drosophilia. Analysis of genomes evolving by inversions leads to a combinatorial problem of sorting by reversals studied in detail recently. We study sorting of signed permutations by reversals, a problem that adequately models rearrangements in a small genomes like chloroplast or mitochondrial DNA. The previously suggested approximation algorithms for sorting signed permutations by reversals compute the reversal distance between permutations with an astonishing accuracy for both simulated and biological data. We prove a duality theorem explaining this intriguing performance and show that there exists a “hidden” parameter that allows one to compute the reversal distance between signed permutations in polynomial time.},
  author       = {Hannenhalli, Sridhar and Pevzner, Pavel A.},
  date         = {1999-01-01},
  doi          = {10.1145/300515.300516},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hannenhalli_Pevzner_1999_Transforming cabbage into turnip.pdf},
  issn         = {0004-5411},
  journaltitle = {Journal of the ACM},
  keywords     = {computational biology,genetics},
  number       = {1},
  pages        = {1--27},
  shortjournal = {J. ACM},
  shorttitle   = {Transforming Cabbage into Turnip},
  title        = {Transforming Cabbage into Turnip: Polynomial Algorithm for Sorting Signed Permutations by Reversals},
  url          = {https://doi.org/10.1145/300515.300516},
  urldate      = {2022-06-14},
  volume       = {46}
}

@article{hardisonComparativeGenomics2003,
  abstract     = {Comparing the genomes of two different species allow the exploration of a host of intriguing evolutionary and genetic questions.},
  author       = {Hardison, Ross C.},
  date         = {2003-11-17},
  doi          = {10.1371/journal.pbio.0000058},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hardison_2003_Comparative Genomics.pdf;/Users/lucblassel/Zotero/storage/AHNUCI3V/article.html},
  issn         = {1545-7885},
  journaltitle = {PLOS Biology},
  keywords     = {Comparative genomics,DNA,Human genomics,Invertebrate genomics,Mammalian genomics,Multiple alignment calculation,Plant genomics,Sequence alignment},
  langid       = {english},
  number       = {2},
  pages        = {e58},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS Biology},
  title        = {Comparative {{Genomics}}},
  url          = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0000058},
  urldate      = {2022-06-14},
  volume       = {1}
}

@article{hatemBenchmarkingShortSequence2013,
  abstract     = {The development of next-generation sequencing instruments has led to the generation of millions of short sequences in a single run. The process of aligning these reads to a reference genome is time consuming and demands the development of fast and accurate alignment tools. However, the current proposed tools make different compromises between the accuracy and the speed of mapping. Moreover, many important aspects are overlooked while comparing the performance of a newly developed tool to the state of the art. Therefore, there is a need for an objective evaluation method that covers all the aspects. In this work, we introduce a benchmarking suite to extensively analyze sequencing tools with respect to various aspects and provide an objective comparison.},
  author       = {Hatem, Ayat and Bozdağ, Doruk and Toland, Amanda E. and Çatalyürek, Ümit V.},
  date         = {2013-06-07},
  doi          = {10.1186/1471-2105-14-184},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hatem et al_2013_Benchmarking short sequence mapping tools.pdf;/Users/lucblassel/Zotero/storage/YM2AV78K/1471-2105-14-184.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Benchmark,Next-generation sequencing,Sequence analysis,Short sequence mapping},
  number       = {1},
  pages        = {184},
  shortjournal = {BMC Bioinformatics},
  title        = {Benchmarking Short Sequence Mapping Tools},
  url          = {https://doi.org/10.1186/1471-2105-14-184},
  urldate      = {2022-06-15},
  volume       = {14}
}

@article{henikoffAminoAcidSubstitution1992,
  abstract     = {Methods for alignment of protein sequences typically measure similarity by using a substitution matrix with scores for all possible exchanges of one amino acid with another. The most widely used matrices are based on the Dayhoff model of evolutionary rates. Using a different approach, we have derived substitution matrices from about 2000 blocks of aligned sequence segments characterizing more than 500 groups of related proteins. This led to marked improvements in alignments and in searches using queries from each of the groups.},
  author       = {Henikoff, S. and Henikoff, J. G.},
  date         = {1992-11-15},
  doi          = {10.1073/pnas.89.22.10915},
  eprint       = {1438297},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/henikoff_henikoff_1992_amino_acid_substitution_matrices_from_protein.pdf;/Users/lucblassel/Zotero/storage/RGVXYQK9/10915.html},
  issn         = {0027-8424, 1091-6490},
  journaltitle = {Proceedings of the National Academy of Sciences},
  langid       = {english},
  number       = {22},
  pages        = {10915--10919},
  shortjournal = {PNAS},
  title        = {Amino Acid Substitution Matrices from Protein Blocks},
  url          = {https://www.pnas.org/content/89/22/10915},
  urldate      = {2019-08-12},
  volume       = {89}
}

@article{hirschberg1977information,
  author       = {Hirschberg, Daniel S.},
  date         = {1977},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hirschberg_1977_An information theoretic lower bound for the longest common subsequence problem.pdf},
  journaltitle = {Rice University ECE Technical Report},
  number       = {7705},
  title        = {An Information Theoretic Lower Bound for the Longest Common Subsequence Problem}
}

@article{hirschbergLinearSpaceAlgorithm1975,
  abstract     = {The problem of finding a longest common subsequence of two strings has been solved in quadratic time and space. An algorithm is presented which will solve this problem in quadratic time and in linear space.},
  author       = {Hirschberg, D. S.},
  date         = {1975-06-01},
  doi          = {10.1145/360825.360861},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hirschberg_1975_A linear space algorithm for computing maximal common subsequences.pdf},
  issn         = {0001-0782},
  journaltitle = {Communications of the ACM},
  keywords     = {editing,longest common sequence,string correction,subsequence},
  number       = {6},
  pages        = {341--343},
  shortjournal = {Commun. ACM},
  title        = {A Linear Space Algorithm for Computing Maximal Common Subsequences},
  url          = {https://doi.org/10.1145/360825.360861},
  urldate      = {2022-06-13},
  volume       = {18}
}

@article{huangTimeefficientLinearspaceLocal1991,
  abstract     = {Dynamic programming algorithms to determine similar regions of two sequences are useful for analyzing biosequence data. This paper presents a time-efficient algorithm that produces k best “non-intersecting” local alignments for any chosen k. The algorithm's main strength is that it needs only O(M + N + K) space, where M and N are the lengths of the given sequences and K is the total length of the computed alignments.},
  author       = {Huang, Xiaoqiu and Miller, Webb},
  date         = {1991-09-01},
  doi          = {10.1016/0196-8858(91)90017-D},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Huang_Miller_1991_A time-efficient, linear-space local similarity algorithm.pdf;/Users/lucblassel/Zotero/storage/C7TFJE47/019688589190017D.html},
  issn         = {0196-8858},
  journaltitle = {Advances in Applied Mathematics},
  langid       = {english},
  number       = {3},
  pages        = {337--357},
  shortjournal = {Advances in Applied Mathematics},
  title        = {A Time-Efficient, Linear-Space Local Similarity Algorithm},
  url          = {https://www.sciencedirect.com/science/article/pii/019688589190017D},
  urldate      = {2022-06-14},
  volume       = {12}
}

@article{huLSCplusFastSolution2016a,
  abstract     = {Background The single molecule, real time (SMRT) sequencing technology of Pacific Biosciences enables the acquisition of transcripts from end to end due to its ability to produce extraordinarily long reads ({$>$}10~kb). This new method of transcriptome sequencing has been applied to several projects on humans and model organisms. However, the raw data from SMRT sequencing are of relatively low quality, with a random error rate of approximately 15~\%, for which error correction using next-generation sequencing (NGS) short reads is typically necessary. Few tools have been designed that apply a hybrid sequencing approach that combines NGS and SMRT data, and the most popular existing tool for error correction, LSC, has computing resource requirements that are too intensive for most laboratory and research groups. These shortcomings severely limit the application of SMRT long reads for transcriptome analysis. Results Here, we report an improved tool (LSCplus) for error correction with the LSC program as a reference. LSCplus overcomes the disadvantage of LSC’s time consumption and improves quality. Only 1/3–1/4 of the time and 1/20–1/25 of the error correction time is required using LSCplus compared with that required for using LSC. Conclusions LSCplus is freely available at http://www.herbbol.org:8001/lscplus/. Sample calculations are provided illustrating the precision and efficiency of this method regarding error correction and isoform detection. Electronic supplementary material The online version of this article (doi:10.1186/s12859-016-1316-y) contains supplementary material, which is available to authorized users.},
  author       = {Hu, Ruifeng and Sun, Guibo and Sun, Xiaobo},
  date         = {2016-11-09},
  doi          = {10.1186/s12859-016-1316-y},
  eprint       = {27829364},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Hu et al_2016_LSCplus2.pdf},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  pages        = {451},
  pmcid        = {PMC5103424},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{LSCplus}}},
  title        = {{{LSCplus}}: A Fast Solution for Improving Long Read Accuracy by Short Read Alignment},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5103424/},
  urldate      = {2022-06-17},
  volume       = {17}
}

@inproceedings{huoSimulatedAnnealingAlgorithm2007,
  abstract   = {For multiple sequence alignment problem in molecular biological sequence analysis, when input sequence number is very large, many heuristic algorithms have been proposed to improve the computation speed and the quality of alignment. We present a novel algorithm SASAlign for multiple sequence alignment. This can guarantee that the multiple alignment obtained from the SASAlign is within a factor of two from the optimal multiple sequence alignment. Experimental results show that the proposed algorithm is feasible, as the SASAlign algorithm outperforms the HMMT and SA for most of the cases and is competitive with the other methods, such as ClustalW, SAGA, MultAlign, and DiAlign.},
  author     = {Huo, Hongwei and Stojkovic, Vojislav},
  booktitle  = {Third {{International Conference}} on {{Natural Computation}} ({{ICNC}} 2007)},
  date       = {2007-08},
  doi        = {10.1109/ICNC.2007.139},
  eventtitle = {Third {{International Conference}} on {{Natural Computation}} ({{ICNC}} 2007)},
  file       = {/Users/lucblassel/Zotero/storage/7C4GDKJK/4344358.html},
  issn       = {2157-9563},
  keywords   = {Analytical models,Biological system modeling,Biology computing,Computational modeling,Computer science,Hidden Markov models,Proteins,Sequences,Simulated annealing,Testing},
  pages      = {270--274},
  title      = {A Simulated Annealing Algorithm for Multiple Sequence Alignment with Guaranteed Accuracy},
  volume     = {2}
}

@article{ishikawaMultipleSequenceAlignment1993,
  abstract     = {We have developed simulated annealing algorithms to solve the problem of multiple sequence alignment. The algorithm wns shown to give the optimal solution as confirmed by the rigorous dynamic programming algorithm for three-sequence alignment. To overcome long execution times for simulated annealing, we utilized a parallel computer. A sequential algorithm, a simple parallel algorithm and the temperature parallel algorithm were tested on a problem. The results were compared with the result obtained by a conventional tree-based algorithm where alignments were merged by two-' dynamic programming. Every annealing algorithm produced a better energy value than the conventional algorithm. The best energy value, which probably represents the optimal solution, wns reached within a reasonable time by both of the parallel annealing algorithms. We consider the temperature parallel algorithm of simulated annealing to be the most suitable for finding the optimal multiple sequence alignment because the algorithm does not require any scheduling for optimization. The algorithm is also usefiui for refining multiple alignments obtained by other hewistic methods.},
  author       = {Ishikawa, Masato and Toya, Tomoyuki and Hoshida, Masaki and Nitta, Katsumi and Ogiwara, Atushi and Kanehisa, Minoru},
  date         = {1993-06-01},
  doi          = {10.1093/bioinformatics/9.3.267},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ishikawa et al_1993_Multiple sequence alignment by parallel simulated annealing.pdf;/Users/lucblassel/Zotero/storage/W8G9KQUX/225167.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {267--273},
  shortjournal = {Bioinformatics},
  title        = {Multiple Sequence Alignment by Parallel Simulated Annealing},
  url          = {https://doi.org/10.1093/bioinformatics/9.3.267},
  urldate      = {2022-06-16},
  volume       = {9}
}

@article{jafariUsingDeepReinforcement2019,
  abstract     = {In the present paper, we use a deep reinforcement learning (DRL) approach for solving the multiple sequence alignment problem which is an NP-complete problem. Multiple Sequence Alignment problem simply refers to the process of arranging initial sequences of DNA, RNA or proteins in order to maximize their regions of similarity. Multiple Sequence Alignment is the first step in solving many bioinformatics problems such as constructing phylogenetic trees. In this study, our proposed approach models the Multiple Sequence Alignment problem as a DRL problem and utilizes long short-term memory networks for estimation phase in the reinforcement learning algorithm. Furthermore, the actor-critic algorithm with experience-replay method is used for much quicker convergence process. Using deep Q-learning (an RL approach) and Q-network overcomes the complexity of other approaches. The experimental evaluation is performed on 8 different real-life datasets and in every used dataset our approach outperforms other well-known approaches and tools such as MAFFT, ClustalW, and other heuristic approaches in case of scoring in solving the MSA problem.},
  author       = {Jafari, Reza and Javidi, Mohammad Masoud and Kuchaki Rafsanjani, Marjan},
  date         = {2019-05-18},
  doi          = {10.1007/s42452-019-0611-4},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/jafari_et_al_2019_using_deep_reinforcement_learning_approach_for.pdf},
  issn         = {2523-3971},
  journaltitle = {SN Applied Sciences},
  keywords     = {Bioinformatics,Deep reinforcement learning,LSTM,Multiple sequence alignment},
  langid       = {english},
  number       = {6},
  pages        = {592},
  shortjournal = {SN Appl. Sci.},
  title        = {Using Deep Reinforcement Learning Approach for Solving the Multiple Sequence Alignment Problem},
  url          = {https://doi.org/10.1007/s42452-019-0611-4},
  urldate      = {2019-08-13},
  volume       = {1}
}

@article{jainFastAdaptiveAlgorithm2018,
  abstract     = {Whole-genome alignment is an important problem in genomics for comparing different species, mapping draft assemblies to reference genomes and identifying repeats. However, for large plant and animal genomes, this task remains compute and memory intensive. In addition, current practical methods lack any guarantee on the characteristics of output alignments, thus making them hard to tune for different application requirements.We introduce an approximate algorithm for computing local alignment boundaries between long DNA sequences. Given a minimum alignment length and an identity threshold, our algorithm computes the desired alignment boundaries and identity estimates using kmer-based statistics, and maintains sufficient probabilistic guarantees on the output sensitivity. Further, to prioritize higher scoring alignment intervals, we develop a plane-sweep based filtering technique which is theoretically optimal and practically efficient. Implementation of these ideas resulted in a fast and accurate assembly-to-genome and genome-to-genome mapper. As a result, we were able to map an error-corrected whole-genome NA12878 human assembly to the hg38 human reference genome in about 1\,min total execution time and \&lt;4 GB memory using eight CPU threads, achieving significant improvement in memory-usage over competing methods. Recall accuracy of computed alignment boundaries was consistently found to be \&gt;97\% on multiple datasets. Finally, we performed a sensitive self-alignment of the human genome to compute all duplications of length ≥1 Kbp and ≥90\% identity. The reported output achieves good recall and covers twice the number of bases than the current UCSC browser’s segmental duplication annotation.https://github.com/marbl/MashMap},
  author       = {Jain, Chirag and Koren, Sergey and Dilthey, Alexander and Phillippy, Adam M and Aluru, Srinivas},
  date         = {2018-09-01},
  doi          = {10.1093/bioinformatics/bty597},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jain et al_2018_A fast adaptive algorithm for computing whole-genome homology maps.pdf;/Users/lucblassel/Zotero/storage/M56AKJGY/5093242.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {17},
  pages        = {i748-i756},
  shortjournal = {Bioinformatics},
  title        = {A Fast Adaptive Algorithm for Computing Whole-Genome Homology Maps},
  url          = {https://doi.org/10.1093/bioinformatics/bty597},
  urldate      = {2022-09-05},
  volume       = {34}
}

@article{jainFastApproximateAlgorithm2018,
  abstract     = {Emerging single-molecule sequencing technologies from Pacific Biosciences and Oxford Nanopore have revived interest in long-read mapping algorithms. Alignment-based seed-and-extend methods demonstrate good accuracy, but face limited scalability, while faster alignment-free methods typically trade decreased precision for efficiency. In this article, we combine a fast approximate read mapping algorithm based on minimizers with a novel MinHash identity estimation technique to achieve both scalability and precision. In contrast to prior methods, we develop a mathematical framework that defines the types of mapping targets we uncover, establish probabilistic estimates of p-value and sensitivity, and demonstrate tolerance for alignment error rates up to 20\%. With this framework, our algorithm automatically adapts to different minimum length and identity requirements and provides both positional and identity estimates for each mapping reported. For mapping human PacBio reads to the hg38 reference, our method is 290\,×\,faster than Burrows–Wheeler Aligner-MEM with a lower memory footprint and recall rate of 96\%. We further demonstrate the scalability of our method by mapping noisy PacBio reads (each ≥5\,kbp in length) to the complete NCBI RefSeq database containing 838 Gbp of sequence and {$>$}60,000 genomes.},
  author       = {Jain, Chirag and Dilthey, Alexander and Koren, Sergey and Aluru, Srinivas and Phillippy, Adam M.},
  date         = {2018-07-01},
  doi          = {10.1089/cmb.2018.0036},
  eprint       = {29708767},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jain et al_2018_A Fast Approximate Algorithm for Mapping Long Reads to Large Reference Databases.pdf},
  issn         = {1066-5277},
  journaltitle = {Journal of Computational Biology},
  number       = {7},
  pages        = {766--779},
  pmcid        = {PMC6067103},
  shortjournal = {J Comput Biol},
  title        = {A {{Fast Approximate Algorithm}} for {{Mapping Long Reads}} to {{Large Reference Databases}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6067103/},
  urldate      = {2022-06-17},
  volume       = {25}
}

@article{jainLongreadMappingRepetitive2022,
  abstract     = {Approximately 5–10\% of the human genome remains inaccessible due to the presence of repetitive sequences such as segmental duplications and tandem repeat arrays. We show that existing long-read mappers often yield incorrect alignments and variant calls within long, near-identical repeats, as they remain vulnerable to allelic bias. In the presence of a nonreference allele within a repeat, a read sampled from that region could be mapped to an incorrect repeat copy. To address this limitation, we developed a new long-read mapping method, Winnowmap2, by using minimal confidently alignable substrings. Winnowmap2 computes each read mapping through a collection of confident subalignments. This approach is more tolerant of structural variation and more sensitive to paralog-specific variants within repeats. Our experiments highlight that Winnowmap2 successfully addresses the issue of allelic bias, enabling more accurate downstream variant calls in repetitive sequences.},
  author       = {Jain, Chirag and Rhie, Arang and Hansen, Nancy F. and Koren, Sergey and Phillippy, Adam M.},
  date         = {2022-06},
  doi          = {10.1038/s41592-022-01457-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jain et al_2022_Long-read mapping to repetitive reference sequences using Winnowmap2.pdf;/Users/lucblassel/Zotero/storage/REQLW58V/s41592-022-01457-8.html},
  issn         = {1548-7105},
  issue        = {6},
  journaltitle = {Nature Methods},
  keywords     = {Genome informatics,Genomics,Software},
  langid       = {english},
  number       = {6},
  pages        = {705--710},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Long-Read Mapping to Repetitive Reference Sequences Using {{Winnowmap2}}},
  url          = {https://www.nature.com/articles/s41592-022-01457-8},
  urldate      = {2022-06-15},
  volume       = {19}
}

@article{jeanmouginMultipleSequenceAlignment1998,
  author       = {Jeanmougin, François and Thompson, Julie D. and Gouy, Manolo and Higgins, Desmond G. and Gibson, Toby J.},
  date         = {1998-10-01},
  doi          = {10.1016/S0968-0004(98)01285-7},
  eprint       = {9810230},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jeanmougin et al_1998_Multiple sequence alignment with Clustal X.pdf;/Users/lucblassel/Zotero/storage/QI6GJIHP/S0968-0004(98)01285-7.html},
  issn         = {0968-0004},
  journaltitle = {Trends in Biochemical Sciences},
  keywords     = {alignment,clustal,database search},
  langid       = {english},
  number       = {10},
  pages        = {403--405},
  publisher    = {{Elsevier}},
  shortjournal = {Trends in Biochemical Sciences},
  title        = {Multiple Sequence Alignment with {{Clustal X}}},
  url          = {https://www.cell.com/trends/biochemical-sciences/abstract/S0968-0004(98)01285-7},
  urldate      = {2022-08-26},
  volume       = {23}
}

@article{jonesProteinSecondaryStructure1999,
  abstract     = {A two-stage neural network has been used to predict protein secondary structure based on the position specific scoring matrices generated by PSI-BLAST. Despite the simplicity and convenience of the approach used, the results are found to be superior to those produced by other methods, including the popular PHD method according to our own benchmarking results and the results from the recent Critical Assessment of Techniques for Protein Structure Prediction experiment (CASP3), where the method was evaluated by stringent blind testing. Using a new testing set based on a set of 187 unique folds, and three-way cross-validation based on structural similarity criteria rather than sequence similarity criteria used previously (no similar folds were present in both the testing and training sets) the method presented here (PSIPRED) achieved an average Q3 score of between 76.5\% to 78.3\% depending on the precise definition of observed secondary structure used, which is the highest published score for any method to date. Given the success of the method in CASP3, it is reasonable to be confident that the evaluation presented here gives a fair indication of the performance of the method in general.},
  author       = {Jones, D. T.},
  date         = {1999-09-17},
  doi          = {10.1006/jmbi.1999.3091},
  eprint       = {10493868},
  eprinttype   = {pmid},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {Algorithms,Neural Networks (Computer),Protein Folding,Protein Structure; Secondary,Sequence Analysis},
  langid       = {english},
  number       = {2},
  pages        = {195--202},
  shortjournal = {J. Mol. Biol.},
  title        = {Protein Secondary Structure Prediction Based on Position-Specific Scoring Matrices},
  volume       = {292}
}

@article{jonesRapidGenerationMutation1992,
  abstract     = {An efficient means for generating mutation data matrices from large numbers of protein sequences is presented here. By means of an approximate peptide-based sequence comparison algorithm, the set sequences are clustered at the 85\% identity level. The closest relating pairs of sequences are aligned, and observed amino acid exchanges tallied in a matrix. The raw mutation frequency matrix is processed in a similar way to that described by Dayhoffet al. (1978), and so the resulting matrices may be easily used in current sequence analysis applications, in place of the standard mutation data matrices, which have not been updated for 13 years. The method is fast enough to process the entire SWISS-PROT databank in 20 h on a Sun SPARCstation 1, and is fast enough to generate a matrix from a specific family or class of proteins in minutes. Differences observed between our 250 PAM mutation data matrix and the matrix calculated by Dayhoff et al. are briefly discussed.},
  author       = {Jones, David T. and Taylor, William R. and Thornton, Janet M.},
  date         = {1992-06-01},
  doi          = {10.1093/bioinformatics/8.3.275},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jones et al_1992_The rapid generation of mutation data matrices from protein sequences.pdf;/Users/lucblassel/Zotero/storage/J4SK8TLM/193076.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {275--282},
  shortjournal = {Bioinformatics},
  title        = {The Rapid Generation of Mutation Data Matrices from Protein Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/8.3.275},
  urldate      = {2022-06-16},
  volume       = {8}
}

@article{jumperHighlyAccurateProtein2021,
  abstract     = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50~years9. Despite recent progress10–14, existing methods fall far~short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
  author       = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  date         = {2021-08},
  doi          = {10.1038/s41586-021-03819-2},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Jumper et al_2021_Highly accurate protein structure prediction with AlphaFold.pdf;/Users/lucblassel/Zotero/storage/ZKLWQXZH/s41586-021-03819-2.html},
  issn         = {1476-4687},
  issue        = {7873},
  journaltitle = {Nature},
  keywords     = {Computational biophysics,Machine learning,Protein structure predictions,Structural biology},
  langid       = {english},
  number       = {7873},
  pages        = {583--589},
  publisher    = {{Nature Publishing Group}},
  title        = {Highly Accurate Protein Structure Prediction with {{AlphaFold}}},
  url          = {https://www.nature.com/articles/s41586-021-03819-2},
  urldate      = {2022-06-14},
  volume       = {596}
}

@article{justComputationalComplexityMultiple2001,
  abstract     = {It is shown that the multiple alignment problem with SP-score is NP-hard for each scoring matrix in a broad class M that includes most scoring matrices actually used in biological applications. The problem remains NP-hard even if sequences can only be shifted relative to each other and no internal gaps are allowed. It is also shown that there is a scoring matrix M0 such that the multiple alignment problem for M0 is MAX-SNP-hard, regardless of whether or not internal gaps are allowed.},
  author       = {Just, Winfried},
  date         = {2001-11},
  doi          = {10.1089/106652701753307511},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Just_2001_Computational Complexity of Multiple Sequence Alignment with SP-Score.pdf},
  journaltitle = {Journal of Computational Biology},
  keywords     = {MAX-SNP-HARDNESS,NP-HARDNESS,POLYNOMIAL TIME APPROXIMATION SCHEME,SCORING MATRIX,SEQUENCE ALIGNMENT},
  number       = {6},
  pages        = {615--623},
  publisher    = {{Mary Ann Liebert, Inc., publishers}},
  title        = {Computational {{Complexity}} of {{Multiple Sequence Alignment}} with {{SP-Score}}},
  url          = {https://www.liebertpub.com/doi/abs/10.1089/106652701753307511},
  urldate      = {2022-06-16},
  volume       = {8}
}

@article{karlinMethodsAssessingStatistical1990,
  abstract     = {An unusual pattern in a nucleic acid or protein sequence or a region of strong similarity shared by two or more sequences may have biological significance. It is therefore desirable to know whether such a pattern can have arisen simply by chance. To identify interesting sequence patterns, appropriate scoring values can be asigned to the individual residues of a single sequence or to sets of residues when several sequences are compared. For single sequences, such scores can reflect biophysical properties such as charge, volume, hydrophobicity, or secondary structure potential; for multiple sequences, they can reflect nucleotide or amino acid similarity measured in a wide variety of ways. Using an appropriate random model, we present a theory that provides precise numerical formulas for assessing the statistical significance of any region with high aggregate score. A second class of results describes the composition of high-scoring segments. In certain contexts, these permit the choice of scoring systems which are "optimal" for distinguishing biologically relevant patterns. Examples are given of applications of the theory to a variety of protein sequences, highlighting segments with unusual biological features. These include distinctive charge regions in transcription factors and protooncogene products, pronounced hydrophobic segments in various receptor and transport proteins, and statistically ignificant subalignments involving the recently characterized cystic fibrosis gene.},
  author       = {Karlin, S and Altschul, S F},
  date         = {1990-03},
  doi          = {10.1073/pnas.87.6.2264},
  eprint       = {2315319},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Karlin_Altschul_1990_Methods for assessing the statistical significance of molecular sequence.pdf},
  issn         = {0027-8424, 1091-6490},
  journaltitle = {Proceedings of the National Academy of Sciences},
  langid       = {english},
  number       = {6},
  pages        = {2264--2268},
  pmcid        = {PMC53667},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  title        = {Methods for Assessing the Statistical Significance of Molecular Sequence Features by Using General Scoring Schemes.},
  url          = {https://pnas.org/doi/full/10.1073/pnas.87.6.2264},
  urldate      = {2022-06-15},
  volume       = {87}
}

@article{karplusPredictingProteinStructure1999,
  abstract     = {This paper presents results of blind predictions submitted to the CASP3 protein structure prediction experiment. We made predictions using the SAM-T98 method, an iterative hidden Markov model–based method for constructing protein family profiles. The method is purely sequence-based, using no structural information, and yet was able to predict structures as well as all but five of the structure-based methods in CASP3. Proteins Suppl 1999;3:121–125. © 1999 Wiley-Liss, Inc.},
  annotation   = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0134\%281999\%2937\%3A3\%2B\%3C121\%3A\%3AAID-PROT16\%3E3.0.CO\%3B2-Q},
  author       = {Karplus, Kevin and Barrett, Christian and Cline, Melissa and Diekhans, Mark and Grate, Leslie and Hughey, Richard},
  date         = {1999},
  doi          = {10.1002/(SICI)1097-0134(1999)37:3+<121::AID-PROT16>3.0.CO;2-Q},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Karplus et al_1999_Predicting protein structure using only sequence information.pdf;/Users/lucblassel/Zotero/storage/X2CHSND9/(SICI)1097-0134(1999)373+121AID-PROT163.0.html},
  issn         = {1097-0134},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  keywords     = {hidden Markov model,protein structure prediction,remote homolog search,SAM-T98},
  langid       = {english},
  number       = {S3},
  pages        = {121--125},
  title        = {Predicting Protein Structure Using Only Sequence Information},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0134%281999%2937%3A3%20%3C121%3A%3AAID-PROT16%3E3.0.CO%3B2-Q},
  urldate      = {2022-06-14},
  volume       = {37}
}

@article{katohMAFFTNovelMethod2002,
  abstract     = {A multiple sequence alignment program, MAFFT, has been developed. The CPU time is drastically reduced as compared with existing methods. MAFFT includes two novel techniques. (i) Homo logous regions are rapidly identified by the fast Fourier transform (FFT), in which an amino acid sequence is converted to a sequence composed of volume and polarity values of each amino acid residue. (ii) We propose a simplified scoring system that performs well for reducing CPU time and increasing the accuracy of alignments even for sequences having large insertions or extensions as well as distantly related sequences of similar length. Two different heuristics, the progressive method (FFT‐NS‐2) and the iterative refinement method (FFT‐NS‐i), are implemented in MAFFT. The performances of FFT‐NS‐2 and FFT‐NS‐i were compared with other methods by computer simulations and benchmark tests; the CPU time of FFT‐NS‐2 is drastically reduced as compared with CLUSTALW with comparable accuracy. FFT‐NS‐i is over 100 times faster than T‐COFFEE, when the number of input sequences exceeds 60, without sacrificing the accuracy.},
  author       = {Katoh, Kazutaka and Misawa, Kazuharu and Kuma, Kei‐ichi and Miyata, Takashi},
  date         = {2002-07-15},
  doi          = {10.1093/nar/gkf436},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Katoh et al_2002_MAFFT.pdf;/Users/lucblassel/Zotero/storage/TRS7CI2S/2904316.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {14},
  pages        = {3059--3066},
  shortjournal = {Nucleic Acids Research},
  shorttitle   = {{{MAFFT}}},
  title        = {{{MAFFT}}: A Novel Method for Rapid Multiple Sequence Alignment Based on Fast {{Fourier}} Transform},
  url          = {https://doi.org/10.1093/nar/gkf436},
  urldate      = {2022-06-15},
  volume       = {30}
}

@article{katohPartTreeAlgorithmBuild2007,
  abstract     = {Motivation: To construct a multiple sequence alignment (MSA) of a large number (\&gt;∼10\,000) of sequences, the calculation of a guide tree with a complexity of O(N2) to O(N3), where N is the number of sequences, is the most time-consuming process.Results: To overcome this limitation, we have developed an approximate algorithm, PartTree, to construct a guide tree with an average time complexity of O(N log N). The new MSA method with the PartTree algorithm can align ∼60\,000 sequences in several minutes on a standard desktop computer. The loss of accuracy in MSA caused by this approximation was estimated to be several percent in benchmark tests using Pfam.Availability: The present algorithm has been implemented in the MAFFT sequence alignment package ().Contact:katoh@bioreg.kyushu-u.ac.jpSupplementary information: Supplementary information is available at Bioinformatics online.},
  author       = {Katoh, Kazutaka and Toh, Hiroyuki},
  date         = {2007-02-01},
  doi          = {10.1093/bioinformatics/btl592},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Katoh_Toh_2007_PartTree.pdf;/Users/lucblassel/Zotero/storage/T3WM65VB/Katoh and Toh - 2007 - PartTree an algorithm to build an approximate tre.pdf;/Users/lucblassel/Zotero/storage/7UHGRFES/235634.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {372--374},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{PartTree}}},
  title        = {{{PartTree}}: An Algorithm to Build an Approximate Tree from a Large Number of Unaligned Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/btl592},
  urldate      = {2022-09-06},
  volume       = {23}
}

@article{kimMultipleSequenceAlignment1994,
  abstract     = {Multiple sequence alignment is a useful technique for studying molecular evolution and analyzing structure-sequence relationships. Dynamic programming of multiple sequence alignment has been widely used to find an optimal alignment. However, dynamic programming does not allow for certain types of gap costs, and it limits the number of sequences that can be aligned due to its high computational complexity. The focus of this paper is to use simulated annealing as the basis for developing an efficient multiple sequence alignment algorithm. An algorithm called Multiple Sequence Alignment using Simulated Annealing (MSASA) has been developed. The computational complexity of MSASA is significantly reduced by replacing the high-temperature phase of the annealing process by a fast heuristic algorithm. This heuristic algorithm facilitates in minimizing the solution set of the low-temperature phase of the annealing process. Compared to the dynamic programming approach, MSASA can (i) use natural gap costs which can generate better solution, (ii) align more sequences and (iii) take less computation time.},
  author       = {Kim, Jin and Pramanik, Sakti and Chung, Moon Jung},
  date         = {1994-07-01},
  doi          = {10.1093/bioinformatics/10.4.419},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kim et al_1994_Multiple sequence alignment using simulated annealing.pdf;/Users/lucblassel/Zotero/storage/S2J54B8A/230746.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {4},
  pages        = {419--426},
  shortjournal = {Bioinformatics},
  title        = {Multiple Sequence Alignment Using Simulated Annealing},
  url          = {https://doi.org/10.1093/bioinformatics/10.4.419},
  urldate      = {2022-06-16},
  volume       = {10}
}

@article{kozlovRAxMLNGFastScalable2019,
  abstract     = {Phylogenies are important for fundamental biological research, but also have numerous applications in biotechnology, agriculture and medicine. Finding the optimal tree under the popular maximum likelihood (ML) criterion is known to be NP-hard. Thus, highly optimized and scalable codes are needed to analyze constantly growing empirical datasets.We present RAxML-NG, a from-scratch re-implementation of the established greedy tree search algorithm of RAxML/ExaML. RAxML-NG offers improved accuracy, flexibility, speed, scalability, and usability compared with RAxML/ExaML. On taxon-rich datasets, RAxML-NG typically finds higher-scoring trees than IQTree, an increasingly popular recent tool for ML-based phylogenetic inference (although IQ-Tree shows better stability). Finally, RAxML-NG introduces several new features, such as the detection of terraces in tree space and the recently introduced transfer bootstrap support metric.The code is available under GNU GPL at https://github.com/amkozlov/raxml-ng. RAxML-NG web service (maintained by Vital-IT) is available at https://raxml-ng.vital-it.ch/.Supplementary data are available at Bioinformatics online.},
  author       = {Kozlov, Alexey M and Darriba, Diego and Flouri, Tomáš and Morel, Benoit and Stamatakis, Alexandros},
  date         = {2019-11-01},
  doi          = {10.1093/bioinformatics/btz305},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/Kozlov et al_2019_RAxML-NG.pdf;/Users/lucblassel/Zotero/storage/M6Y8Y98C/5487384.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {21},
  pages        = {4453--4455},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{RAxML-NG}}},
  title        = {{{RAxML-NG}}: A Fast, Scalable and User-Friendly Tool for Maximum Likelihood Phylogenetic Inference},
  url          = {https://doi.org/10.1093/bioinformatics/btz305},
  urldate      = {2021-05-18},
  volume       = {35}
}

@article{kozlovRAxMLNGFastScalable2019a,
  abstract     = {Phylogenies are important for fundamental biological research, but also have numerous applications in biotechnology, agriculture and medicine. Finding the optimal tree under the popular maximum likelihood (ML) criterion is known to be NP-hard. Thus, highly optimized and scalable codes are needed to analyze constantly growing empirical datasets.We present RAxML-NG, a from-scratch re-implementation of the established greedy tree search algorithm of RAxML/ExaML. RAxML-NG offers improved accuracy, flexibility, speed, scalability, and usability compared with RAxML/ExaML. On taxon-rich datasets, RAxML-NG typically finds higher-scoring trees than IQTree, an increasingly popular recent tool for ML-based phylogenetic inference (although IQ-Tree shows better stability). Finally, RAxML-NG introduces several new features, such as the detection of terraces in tree space and the recently introduced transfer bootstrap support metric.The code is available under GNU GPL at https://github.com/amkozlov/raxml-ng. RAxML-NG web service (maintained by Vital-IT) is available at https://raxml-ng.vital-it.ch/.Supplementary data are available at Bioinformatics online.},
  author       = {Kozlov, Alexey M and Darriba, Diego and Flouri, Tomáš and Morel, Benoit and Stamatakis, Alexandros},
  date         = {2019-11-01},
  doi          = {10.1093/bioinformatics/btz305},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kozlov et al_2019_RAxML-NG2.pdf;/Users/lucblassel/Zotero/storage/28RUNL4V/5487384.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {21},
  pages        = {4453--4455},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{RAxML-NG}}},
  title        = {{{RAxML-NG}}: A Fast, Scalable and User-Friendly Tool for Maximum Likelihood Phylogenetic Inference},
  url          = {https://doi.org/10.1093/bioinformatics/btz305},
  urldate      = {2022-06-14},
  volume       = {35}
}

@article{krishnadevAlignHUSHAlignmentHMMs2011,
  abstract     = {Sensitive remote homology detection and accurate alignments especially in the midnight zone of sequence similarity are needed for better function annotation and structural modeling of proteins. An algorithm, AlignHUSH for HMM-HMM alignment has been developed which is capable of recognizing distantly related domain families The method uses structural information, in the form of predicted secondary structure probabilities, and hydrophobicity of amino acids to align HMMs of two sets of aligned sequences. The effect of using adjoining column(s) information has also been investigated and is found to increase the sensitivity of HMM-HMM alignments and remote homology detection.},
  author       = {Krishnadev, Oruganty and Srinivasan, Narayanaswamy},
  date         = {2011-07-05},
  doi          = {10.1186/1471-2105-12-275},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Krishnadev_Srinivasan_2011_AlignHUSH.pdf;/Users/lucblassel/Zotero/storage/9CVJ64KT/1471-2105-12-275.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Alignment Accuracy,Position Specific Scoring Matrix,Reference Alignment,Scop Database,Secondary Structure Information},
  number       = {1},
  pages        = {275},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{AlignHUSH}}},
  title        = {{{AlignHUSH}}: {{Alignment}} of {{HMMs}} Using Structure and Hydrophobicity Information},
  url          = {https://doi.org/10.1186/1471-2105-12-275},
  urldate      = {2022-06-15},
  volume       = {12}
}

@article{kumarMEGAMolecularEvolutionary1994,
  abstract     = {A computer program package called MEGA has been developed for estimating evolutionary distances, reconstructing phylogenetic trees and computing basic statistical quantities from molecular data. It is written in C++ and is intended to be used on IBM and IBM-compatible personal computers. In this program, various methods for estimating evolutionary distances from nucleotide and amino acid sequence data, three different methods of phylogenetic inference (UPGMA, neighborjoining and maximum parsimony) and two statistical tests of topological differences are included. For the maximum parsimony method, new algorithms of branch-and-bound and heuristic searches are implemented. In addition, MEGA computes statistical quantities such as nucleotide and amino acid frequencies, transition/transversion biases, codon frequencies (codon usage tables), and the number of variable sites in specified segments in nucleotide and amino acid sequences. Advanced on-screen sequence data and phylogenetictree editors facilitate publication-quality outputs with a wide range of printers. Integrated and interactive designs, on-line context-sensitive helps, and a text-file editor make MEGA easy to use.},
  author       = {Kumar, Sudhir and Tamura, Koichiro and Nei, Masatoshi},
  date         = {1994-04-02},
  doi          = {10.1093/bioinformatics/10.2.189},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kumar et al_1994_MEGA.pdf;/Users/lucblassel/Zotero/storage/YQ44S2R4/184377.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {2},
  pages        = {189--191},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{MEGA}}},
  title        = {{{MEGA}}: {{Molecular Evolutionary Genetics Analysis}} Software for Microcomputers},
  url          = {https://doi.org/10.1093/bioinformatics/10.2.189},
  urldate      = {2022-06-14},
  volume       = {10}
}

@article{kurtzVersatileOpenSoftware2004,
  abstract     = {The newest version of MUMmer easily handles comparisons of large eukaryotic genomes at varying evolutionary distances, as demonstrated by applications to multiple genomes. Two new graphical viewing tools provide alternative ways to analyze genome alignments. The new system is the first version of MUMmer to be released as open-source software. This allows other developers to contribute to the code base and freely redistribute the code. The MUMmer sources are available at http://www.tigr.org/software/mummer.},
  author       = {Kurtz, Stefan and Phillippy, Adam and Delcher, Arthur L. and Smoot, Michael and Shumway, Martin and Antonescu, Corina and Salzberg, Steven L.},
  date         = {2004-01-30},
  doi          = {10.1186/gb-2004-5-2-r12},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Kurtz et al_2004_Versatile and open software for comparing large genomes.pdf},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Code Base,Down Syndrome,Maximal Match,Potential Anchor,Suffix Tree},
  langid       = {english},
  number       = {2},
  pages        = {R12},
  shortjournal = {Genome Biol},
  title        = {Versatile and Open Software for Comparing Large Genomes},
  url          = {https://doi.org/10.1186/gb-2004-5-2-r12},
  urldate      = {2022-06-14},
  volume       = {5}
}

@article{lamCompressedIndexingLocal2008,
  abstract     = {Motivation: Recent experimental studies on compressed indexes (BWT, CSA, FM-index) have confirmed their practicality for indexing very long strings such as the human genome in the main memory. For example, a BWT index for the human genome (with about 3 billion characters) occupies just around 1 G bytes. However, these indexes are designed for exact pattern matching, which is too stringent for biological applications. The demand is often on finding local alignments (pairs of similar substrings with gaps allowed). Without indexing, one can use dynamic programming to find all the local alignments between a text T and a pattern P in O(|T||P|) time, but this would be too slow when the text is of genome scale (e.g. aligning a gene with the human genome would take tens to hundreds of hours). In practice, biologists use heuristic-based software such as BLAST, which is very efficient but does not guarantee to find all local alignments.Results: In this article, we show how to build a software called BWT-SW that exploits a BWT index of a text T to speed up the dynamic programming for finding all local alignments. Experiments reveal that BWT-SW is very efficient (e.g. aligning a pattern of length 3 000 with the human genome takes less than a minute). We have also analyzed BWT-SW mathematically for a simpler similarity model (with gaps disallowed), and we show that the expected running time is O(|T|0.628|P|) for random strings. As far as we know, BWT-SW is the first practical tool that can find all local alignments. Yet BWT-SW is not meant to be a replacement of BLAST, as BLAST is still several times faster than BWT-SW for long patterns and BLAST is indeed accurate enough in most cases (we have used BWT-SW to check against the accuracy of BLAST and found that only rarely BLAST would miss some significant alignments).Availability:www.cs.hku.hk/\textasciitilde ckwong3/bwtswContact:twlam@cs.hku.hk},
  author       = {Lam, T. W. and Sung, W. K. and Tam, S. L. and Wong, C. K. and Yiu, S. M.},
  date         = {2008-03-15},
  doi          = {10.1093/bioinformatics/btn032},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lam et al_2008_Compressed indexing and local alignment of DNA.pdf;/Users/lucblassel/Zotero/storage/USZ49HL5/193908.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {6},
  pages        = {791--797},
  shortjournal = {Bioinformatics},
  title        = {Compressed Indexing and Local Alignment of {{DNA}}},
  url          = {https://doi.org/10.1093/bioinformatics/btn032},
  urldate      = {2022-06-15},
  volume       = {24}
}

@article{langmeadFastGappedreadAlignment2012,
  abstract     = {The Bowtie 2 software achieves fast, sensitive, accurate and memory-efficient gapped alignment of sequencing reads using the full-text minute index and hardware-accelerated dynamic programming algorithms.},
  annotation   = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Bioinformatics;Genomics;Sequencing Subject\_term\_id: bioinformatics;genomics;sequencing},
  author       = {Langmead, Ben and Salzberg, Steven L.},
  date         = {2012-04},
  doi          = {10.1038/nmeth.1923},
  file         = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Langmead_Salzberg_2012_Fast gapped-read alignment with Bowtie 2.pdf},
  issn         = {1548-7105},
  issue        = {4},
  journaltitle = {Nature Methods},
  keywords     = {Bioinformatics,Genomics,Sequencing},
  langid       = {english},
  number       = {4},
  pages        = {357--359},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Fast Gapped-Read Alignment with {{Bowtie}} 2},
  url          = {https://www.nature.com/articles/nmeth.1923},
  urldate      = {2021-10-27},
  volume       = {9}
}

@article{langmeadTandemSimulationFramework2017,
  abstract     = {Read alignment is the first step in most sequencing data analyses. Because a read’s point of origin can be ambiguous, aligners report a mapping quality, which is the probability that the reported alignment is incorrect. Despite its importance, there is no established and general method for calculating mapping quality. I describe a framework for predicting mapping qualities that works by simulating a set of tandem reads. These are like the input reads in important ways, but the true point of origin is known. I implement this method in an accurate and low-overhead tool called Qtip, which is compatible with popular aligners.},
  author       = {Langmead, Ben},
  date         = {2017-08-10},
  doi          = {10.1186/s13059-017-1290-3},
  file         = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Langmead_2017_A tandem simulation framework for predicting mapping quality.pdf;/Users/lucblassel/Zotero/storage/D526DNA7/s13059-017-1290-3.html},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Mapping,Quality,Read alignment,Sequencing},
  number       = {1},
  pages        = {152},
  shortjournal = {Genome Biology},
  title        = {A Tandem Simulation Framework for Predicting Mapping Quality},
  url          = {https://doi.org/10.1186/s13059-017-1290-3},
  urldate      = {2022-06-02},
  volume       = {18}
}

@article{langmeadTandemSimulationFramework2017a,
  abstract     = {Read alignment is the first step in most sequencing data analyses. Because a read’s point of origin can be ambiguous, aligners report a mapping quality, which is the probability that the reported alignment is incorrect. Despite its importance, there is no established and general method for calculating mapping quality. I describe a framework for predicting mapping qualities that works by simulating a set of tandem reads. These are like the input reads in important ways, but the true point of origin is known. I implement this method in an accurate and low-overhead tool called Qtip, which is compatible with popular aligners.},
  author       = {Langmead, Ben},
  date         = {2017-08-10},
  doi          = {10.1186/s13059-017-1290-3},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Langmead_2017_A tandem simulation framework for predicting mapping quality2.pdf;/Users/lucblassel/Zotero/storage/8WE85MC8/s13059-017-1290-3.html},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Mapping,Quality,Read alignment,Sequencing},
  number       = {1},
  pages        = {152},
  shortjournal = {Genome Biology},
  title        = {A Tandem Simulation Framework for Predicting Mapping Quality},
  url          = {https://doi.org/10.1186/s13059-017-1290-3},
  urldate      = {2022-06-15},
  volume       = {18}
}

@article{leeGenomicDarkMatter2012,
  abstract     = {Motivation: Genome resequencing and short read mapping are two of the primary tools of genomics and are used for many important applications. The current state-of-the-art in mapping uses the quality values and mapping quality scores to evaluate the reliability of the mapping. These attributes, however, are assigned to individual reads and do not directly measure the problematic repeats across the genome. Here, we present the Genome Mappability Score (GMS) as a novel measure of the complexity of resequencing a genome. The GMS is a weighted probability that any read could be unambiguously mapped to a given position and thus measures the overall composition of the genome itself.Results: We have developed the Genome Mappability Analyzer to compute the GMS of every position in a genome. It leverages the parallelism of cloud computing to analyze large genomes, and enabled us to identify the 5–14\% of the human, mouse, fly and yeast genomes that are difficult to analyze with short reads. We examined the accuracy of the widely used BWA/SAMtools polymorphism discovery pipeline in the context of the GMS, and found discovery errors are dominated by false negatives, especially in regions with poor GMS. These errors are fundamental to the mapping process and cannot be overcome by increasing coverage. As such, the GMS should be considered in every resequencing project to pinpoint the ‘dark matter’ of the genome, including of known clinically relevant variations in these regions.Availability: The source code and profiles of several model organisms are available at http://gma-bio.sourceforge.netContact:hlee@cshl.eduSupplementary Information: Supplementary data are available at Bioinformatics online.},
  author       = {Lee, Hayan and Schatz, Michael C.},
  date         = {2012-08-15},
  doi          = {10.1093/bioinformatics/bts330},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lee_Schatz_2012_Genomic dark matter.pdf;/Users/lucblassel/Zotero/storage/MGD8ULSY/323484.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {16},
  pages        = {2097--2105},
  shortjournal = {Bioinformatics},
  shorttitle   = {Genomic Dark Matter},
  title        = {Genomic Dark Matter: The Reliability of Short Read Mapping Illustrated by the Genome Mappability Score},
  url          = {https://doi.org/10.1093/bioinformatics/bts330},
  urldate      = {2022-09-06},
  volume       = {28}
}

@article{leePredictingProteinFunction2007,
  abstract     = {While the number of sequenced genomes continues to grow, experimentally verified functional annotation of whole genomes remains patchy. Structural genomics projects are yielding many protein structures that have unknown function. Nevertheless, subsequent experimental investigation is costly and time-consuming, which makes computational methods for predicting protein function very attractive. There is an increasing number of noteworthy methods for predicting protein function from sequence and structural data alone, many of which are readily available to cell biologists who are aware of the strengths and pitfalls of each available technique.},
  author       = {Lee, David and Redfern, Oliver and Orengo, Christine},
  date         = {2007-12},
  doi          = {10.1038/nrm2281},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/lee_et_al_2007_predicting_protein_function_from_sequence_and.pdf;/Users/lucblassel/Zotero/storage/66DV7NPR/nrm2281.html},
  issn         = {1471-0080},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  langid       = {english},
  number       = {12},
  pages        = {995--1005},
  title        = {Predicting Protein Function from Sequence and Structure},
  url          = {https://www.nature.com/articles/nrm2281},
  urldate      = {2019-08-19},
  volume       = {8}
}

@article{leePredictingProteinFunction2007a,
  abstract     = {'Inheritance through homology' is the most common and generally more accessible approach to function prediction, but orthology should be established where possible to improve confidence in predictions.The body of functional annotations of proteins is becoming increasingly computer-readable and is being organized in ways that can enhance the scope of in silico prediction methods.Significant advances in complete genome sequencing have resulted in a new generation of methods that exploit sequence analysis on the genome level.Curated protein family resources can often guide the assignment of protein functions and the detection of motifs or sequence patterns.New approaches are being developed to identify functional residues in proteins; these can then be applied to divide larger protein families into more specific functional subfamilies.There have been exciting new developments in databases of experimentally determined protein–protein interactions, as well as genomic inference methods for predicting these interactions.Non-homology-based function prediction methods that exploit the properties of sequences and not their evolutionary history are also becoming more successful.Recent Structural Genomics Initiatives (SGIs) are attempting to target functionally diverse relatives within protein families.Function prediction from structure can be achieved by global comparison of protein structures to detect homology or through the use of structural templates derived from the active sites of enzymes. It is also possible to explore the protein surface for sequence-conserved patches, clefts and electrostatic potentials.In general terms, it is best to seek and compare the results of several methods to predict the function of novel proteins. Meta-servers simplify this by providing easy access to a range of the best-performing methods.Future developments will see more efficient integration of prediction methods and experimental data; for example, microarrays, yeast two-hybrid screens and tandem affinity purification. Better understanding of the diversification of function in protein families will permit more sophisticated means of predicting function and functional networks.},
  author       = {Lee, David and Redfern, Oliver and Orengo, Christine},
  date         = {2007-12},
  doi          = {10.1038/nrm2281},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lee et al_2007_Predicting protein function from sequence and structure.pdf;/Users/lucblassel/Zotero/storage/8X73HSD5/nrm2281.html},
  issn         = {1471-0080},
  issue        = {12},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  keywords     = {Biochemistry,Cancer Research,Cell Biology,Developmental Biology,general,Life Sciences,Stem Cells},
  langid       = {english},
  number       = {12},
  pages        = {995--1005},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Rev Mol Cell Biol},
  title        = {Predicting Protein Function from Sequence and Structure},
  url          = {https://www.nature.com/articles/nrm2281},
  urldate      = {2022-06-14},
  volume       = {8}
}

@article{leImprovedGeneralAmino2008,
  abstract     = {Amino acid replacement matrices are an essential basis of protein phylogenetics. They are used to compute substitution probabilities along phylogeny branches and thus the likelihood of the data. They are also essential in protein alignment. A number of replacement matrices and methods to estimate these matrices from protein alignments have been proposed since the seminal work of Dayhoff et al. (1972). An important advance was achieved by Whelan and Goldman (2001) and their WAG matrix, thanks to an efficient maximum likelihood estimation approach that accounts for the phylogenies of sequences within each training alignment. We further refine this method by incorporating the variability of evolutionary rates across sites in the matrix estimation and using a much larger and diverse database than BRKALN, which was used to estimate WAG. To estimate our new matrix (called LG after the authors), we use an adaptation of the XRATE software and 3,912 alignments from Pfam, comprising ∼50,000 sequences and ∼6.5 million residues overall. To evaluate the LG performance, we use an independent sample consisting of 59 alignments from TreeBase and randomly divide Pfam alignments into 3,412 training and 500 test alignments. The comparison with WAG and JTT shows a clear likelihood improvement. With TreeBase, we find that 1) the average Akaike information criterion gain per site is 0.25 and 0.42, when compared with WAG and JTT, respectively; 2) LG is significantly better than WAG for 38 alignments (among 59), and significantly worse with 2 alignments only; and 3) tree topologies inferred with LG, WAG, and JTT frequently differ, indicating that using LG impacts not only the likelihood value but also the output tree. Results with the test alignments from Pfam are analogous. LG and a PHYML implementation can be downloaded from http://atgc.lirmm.fr/LG.},
  author       = {Le, Si Quang and Gascuel, Olivier},
  date         = {2008-07-01},
  doi          = {10.1093/molbev/msn067},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Le_Gascuel_2008_An Improved General Amino Acid Replacement Matrix.pdf;/Users/lucblassel/Zotero/storage/B5QANMCK/1041491.html},
  issn         = {0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  number       = {7},
  pages        = {1307--1320},
  shortjournal = {Molecular Biology and Evolution},
  title        = {An {{Improved General Amino Acid Replacement Matrix}}},
  url          = {https://doi.org/10.1093/molbev/msn067},
  urldate      = {2022-06-14},
  volume       = {25}
}

@article{lemoineCOVIDAlignAccurateOnline2020,
  abstract     = {The first cases of the COVID-19 pandemic emerged in December 2019. Until the end of February 2020, the number of available genomes was below 1,000, and their multiple alignment was easily achieved using standard approaches. Subsequently, the availability of genomes has grown dramatically. Moreover, some genomes are of low quality with sequencing/assembly errors, making accurate re-alignment of all genomes nearly impossible on a daily basis. A more efficient, yet accurate approach was clearly required to pursue all subsequent bioinformatics analyses of this crucial data.hCoV-19 genomes are highly conserved, with very few indels and no recombination. This makes the profile HMM approach particularly well suited to align new genomes, add them to an existing alignment and filter problematic ones. Using a core of ∼2,500 high quality genomes, we estimated a profile using HMMER, and implemented this profile in COVID-Align, a user-friendly interface to be used online or as standalone via Docker. The alignment of 1,000 genomes requires ∼50mn on our cluster. Moreover, COVID-Align provides summary statistics, which can be used to determine the sequencing quality and evolutionary novelty of input genomes (e.g. number of new mutations and indels).https://covalign.pasteur.cloud, hub.docker.com/r/evolbioinfo/covid-alignSupplementary information is available at Bioinformatics online.},
  author       = {Lemoine, Frédéric and Blassel, Luc and Voznica, Jakub and Gascuel, Olivier},
  date         = {2020-10-12},
  doi          = {10.1093/bioinformatics/btaa871},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/Lemoine et al_2020_COVID-Align.pdf;/Users/lucblassel/Google Drive/Zotero_papers/Lemoine et al_2020_COVID-Align2.pdf;/Users/lucblassel/Zotero/storage/TWPB6DK8/5921170.html;/Users/lucblassel/Zotero/storage/WMX2P5YE/5921170.html},
  issn         = {1367-4803},
  issue        = {btaa871},
  journaltitle = {Bioinformatics},
  keywords     = {published,resume},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{COVID-Align}}},
  title        = {{{COVID-Align}}: {{Accurate}} Online Alignment of {{hCoV-19}} Genomes Using a Profile {{HMM}}},
  url          = {https://doi.org/10.1093/bioinformatics/btaa871},
  urldate      = {2021-05-23}
}

@article{levenshteinBinaryCodesCapable1966,
  annotation   = {ADS Bibcode: 1966SPhD...10..707L},
  author       = {Levenshtein, V. I.},
  date         = {1966-02-01},
  journaltitle = {Soviet Physics Doklady},
  pages        = {707},
  title        = {Binary {{Codes Capable}} of {{Correcting Deletions}}, {{Insertions}} and {{Reversals}}},
  url          = {https://ui.adsabs.harvard.edu/abs/1966SPhD...10..707L},
  urldate      = {2022-06-14},
  volume       = {10}
}

@unpublished{liAligningSequenceReads2013,
  abstract      = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date. Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa. Contact: hengli@broadinstitute.org},
  archiveprefix = {arXiv},
  author        = {Li, Heng},
  date          = {2013-05-26},
  eprint        = {1303.3997},
  eprinttype    = {arxiv},
  file          = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Li_2013_Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM.pdf;/Users/lucblassel/Zotero/storage/J8JZAXHJ/1303.html},
  keywords      = {Quantitative Biology - Genomics},
  primaryclass  = {q-bio},
  title         = {Aligning Sequence Reads, Clone Sequences and Assembly Contigs with {{BWA-MEM}}},
  url           = {http://arxiv.org/abs/1303.3997},
  urldate       = {2021-10-27}
}

@article{liFastAccurateLongread2010,
  abstract     = {Motivation: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. Most of them are very efficient for short reads but inefficient or not applicable for reads \&gt;200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. However, some sequencing platforms already produce longer reads and others are expected to become available soon. For longer reads, hashing-based software such as BLAT and SSAHA2 remain the only choices. Nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time.Results: We designed and implemented a new algorithm, Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW), to align long sequences up to 1 Mb against a large sequence database (e.g. the human genome) with a few gigabytes of memory. The algorithm is as accurate as SSAHA2, more accurate than BLAT, and is several to tens of times faster than both.Availability:http://bio-bwa.sourceforge.netContact:rd@sanger.ac.uk},
  author       = {Li, Heng and Durbin, Richard},
  date         = {2010-03-01},
  doi          = {10.1093/bioinformatics/btp698},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li_Durbin_2010_Fast and accurate long-read alignment with Burrows–Wheeler transform.pdf;/Users/lucblassel/Zotero/storage/5JCNL88Z/211735.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {5},
  pages        = {589--595},
  shortjournal = {Bioinformatics},
  title        = {Fast and Accurate Long-Read Alignment with {{Burrows}}–{{Wheeler}} Transform},
  url          = {https://doi.org/10.1093/bioinformatics/btp698},
  urldate      = {2022-06-15},
  volume       = {26}
}

@article{liFastAccurateShort2009,
  abstract     = {Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package.Availability:http://maq.sourceforge.netContact:rd@sanger.ac.uk},
  author       = {Li, Heng and Durbin, Richard},
  date         = {2009-07-15},
  doi          = {10.1093/bioinformatics/btp324},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li_Durbin_2009_Fast and accurate short read alignment with Burrows–Wheeler transform.pdf;/Users/lucblassel/Zotero/storage/87GRYZLV/225615.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {14},
  pages        = {1754--1760},
  shortjournal = {Bioinformatics},
  title        = {Fast and Accurate Short Read Alignment with {{Burrows}}–{{Wheeler}} Transform},
  url          = {https://doi.org/10.1093/bioinformatics/btp324},
  urldate      = {2022-06-15},
  volume       = {25}
}

@article{liMappingShortDNA2008,
  abstract     = {New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.},
  author       = {Li, Heng and Ruan, Jue and Durbin, Richard},
  date         = {2008-01-11},
  doi          = {10.1101/gr.078212.108},
  eprint       = {18714091},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li et al_2008_Mapping short DNA sequencing reads and calling variants using mapping quality.pdf;/Users/lucblassel/Zotero/storage/ZKMCVE86/1851.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {11},
  pages        = {1851--1858},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  title        = {Mapping Short {{DNA}} Sequencing Reads and Calling Variants Using Mapping Quality Scores},
  url          = {https://genome.cshlp.org/content/18/11/1851},
  urldate      = {2022-09-06},
  volume       = {18}
}

@article{liMinimap2PairwiseAlignment2018,
  abstract     = {Recent advances in sequencing technologies promise ultra-long reads of ∼100 kb in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 Mb in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms.Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of ≥100\,bp in length, ≥1\,kb genomic reads at error rate ∼15\%, full-length noisy Direct RNA or cDNA reads and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions and introduces new heuristics to reduce spurious alignments. It is 3–4 times as fast as mainstream short-read mappers at comparable accuracy, and is ≥30 times faster than long-read genomic or cDNA mappers at higher accuracy, surpassing most aligners specialized in one type of alignment.https://github.com/lh3/minimap2Supplementary data are available at Bioinformatics online.},
  author       = {Li, Heng},
  date         = {2018-09-15},
  doi          = {10.1093/bioinformatics/bty191},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/Li_2018_Minimap2.pdf;/Users/lucblassel/Zotero/storage/UQDA2N7W/Li - 2018 - Minimap2 pairwise alignment for nucleotide sequen.pdf;/Users/lucblassel/Zotero/storage/7PJ533LA/4994778.html},
  ids          = {liMinimap2PairwiseAlignment2018a},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  keywords     = {mapping},
  number       = {18},
  pages        = {3094--3100},
  shortjournal = {Bioinformatics},
  shorttitle   = {Minimap2},
  title        = {Minimap2: Pairwise Alignment for Nucleotide Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/bty191},
  urldate      = {2021-04-18},
  volume       = {34}
}

@article{liMinimapMiniasmFast2016,
  abstract     = {Motivation: Single Molecule Real-Time (SMRT) sequencing technology and Oxford Nanopore technologies (ONT) produce reads over 10\,kb in length, which have enabled high-quality genome assembly at an affordable cost. However, at present, long reads have an error rate as high as 10–15\%. Complex and computationally intensive pipelines are required to assemble such reads.Results: We present a new mapper, minimap and a de novo assembler, miniasm, for efficiently mapping and assembling SMRT and ONT reads without an error correction stage. They can often assemble a sequencing run of bacterial data into a single contig in a few minutes, and assemble 45-fold Caenorhabditis elegans data in 9\,min, orders of magnitude faster than the existing pipelines, though the consensus sequence error rate is as high as raw reads. We also introduce a pairwise read mapping format and a graphical fragment assembly format, and demonstrate the interoperability between ours and current tools.Availability and implementation:https://github.com/lh3/minimap and https://github.com/lh3/miniasmContact:hengli@broadinstitute.orgSupplementary information:Supplementary data are available at Bioinformatics online.},
  author       = {Li, Heng},
  date         = {2016-07-15},
  doi          = {10.1093/bioinformatics/btw152},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li_2016_Minimap and miniasm.pdf;/Users/lucblassel/Zotero/storage/5J5CZJ5Y/1742895.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {14},
  pages        = {2103--2110},
  shortjournal = {Bioinformatics},
  shorttitle   = {Minimap and Miniasm},
  title        = {Minimap and Miniasm: Fast Mapping and de Novo Assembly for Noisy Long Sequences},
  url          = {https://doi.org/10.1093/bioinformatics/btw152},
  urldate      = {2022-09-05},
  volume       = {32}
}

@article{liNewStrategiesImprove2021,
  abstract      = {We present several recent improvements to minimap2, a versatile pairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more accurately map long reads to highly repetitive regions and align through insertions or deletions up to 100\,kb by default, addressing major weakness in minimap2 v2.18 or earlier.https://github.com/lh3/minimap2.},
  archiveprefix = {arXiv},
  author        = {Li, Heng},
  date          = {2021-12-01},
  doi           = {10.1093/bioinformatics/btab705},
  eprint        = {2108.03515},
  eprinttype    = {arxiv},
  file          = {/Users/lucblassel/Zotero/storage/QIFY72JM/Li - 2021 - New strategies to improve minimap2 alignment accur.pdf;/Users/lucblassel/Zotero/storage/RLKI9KHF/Li - 2021 - New strategies to improve minimap2 alignment accur.pdf;/Volumes/GoogleDrive/My Drive/Zotero_papers/Li_2021_New strategies to improve minimap2 alignment accuracy.pdf;/Users/lucblassel/Zotero/storage/LXE9VHQV/2108.html},
  ids           = {liNewStrategiesImprove2021b},
  issn          = {1367-4803},
  issue         = {23},
  journaltitle  = {Bioinformatics},
  keywords      = {Quantitative Biology - Genomics},
  number        = {arXiv:2108.03515},
  pages         = {4572--4574},
  shortjournal  = {Bioinformatics},
  title         = {New Strategies to Improve Minimap2 Alignment Accuracy},
  url           = {https://doi.org/10.1093/bioinformatics/btab705},
  urldate       = {2022-05-16},
  volume        = {37}
}

@article{linKartDivideandconquerAlgorithm2017,
  abstract     = {MOTIVATION: Next-generation sequencing (NGS) provides a great opportunity to investigate genome-wide variation at nucleotide resolution. Due to the huge amount of data, NGS applications require very fast and accurate alignment algorithms. Most existing algorithms for read mapping basically adopt seed-and-extend strategy, which is sequential in nature and takes much longer time on longer reads. RESULTS: We develop a divide-and-conquer algorithm, called Kart, which can process long reads as fast as short reads by dividing a read into small fragments that can be aligned independently. Our experiment result indicates that the average size of fragments requiring the more time-consuming gapped alignment is around 20\,bp regardless of the original read length. Furthermore, it can tolerate much higher error rates. The experiments show that Kart spends much less time on longer reads than other aligners and still produce reliable alignments even when the error rate is as high as 15\%. AVAILABILITY AND IMPLEMENTATION: Kart is available at https://github.com/hsinnan75/Kart/ . CONTACT: hsu@iis.sinica.edu.tw. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
  author       = {Lin, Hsin-Nan and Hsu, Wen-Lian},
  date         = {2017-08-01},
  doi          = {10.1093/bioinformatics/btx189},
  eprint       = {28379292},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Lin_Hsu_2017_Kart.pdf},
  issn         = {1367-4811},
  journaltitle = {Bioinformatics (Oxford, England)},
  keywords     = {Algorithms,Genetic Variation,Genome; Human,High-Throughput Nucleotide Sequencing,Humans,Sequence Alignment,Sequence Analysis; DNA,Software},
  langid       = {english},
  number       = {15},
  pages        = {2281--2287},
  pmcid        = {PMC5860120},
  shortjournal = {Bioinformatics},
  shorttitle   = {Kart},
  title        = {Kart: A Divide-and-Conquer Algorithm for {{NGS}} Read Alignment},
  volume       = {33}
}

@article{lipmanRapidSensitiveProtein1985,
  abstract     = {An algorithm was developed which facilitates the search for similarities between newly determined amino acid sequences and sequences already available in databases. Because of the algorithm's efficiency on many microcomputers, sensitive protein database searches may now become a routine procedure for molecular biologists. The method efficiently identifies regions of similar sequence and then scores the aligned identical and differing residues in those regions by means of an amino acid replacability matrix. This matrix increases sensitivity by giving high scores to those amino acid replacements which occur frequently in evolution. The algorithm has been implemented in a computer program designed to search protein databases very rapidly. For example, comparison of a 200-amino-acid sequence to the 500,000 residues in the National Biomedical Research Foundation library would take less than 2 minutes on a minicomputer, and less than 10 minutes on a microcomputer (IBM PC).},
  author       = {Lipman, D. J. and Pearson, W. R.},
  date         = {1985-03-22},
  doi          = {10.1126/science.2983426},
  eprint       = {2983426},
  eprinttype   = {pmid},
  issn         = {0036-8075},
  journaltitle = {Science},
  keywords     = {Amino Acid Sequence,Angiotensinogen,Animals,Biological Evolution,Bunyaviridae,Cattle,Computers,Cyclic AMP,Cytochrome c Group,Humans,Information Systems,Microcomputers,Nucleoproteins,Probability,Protein Kinases,Protein Precursors,Proteins,Rats,Software,Viral Proteins},
  langid       = {english},
  number       = {4693},
  pages        = {1435--1441},
  shortjournal = {Science},
  title        = {Rapid and Sensitive Protein Similarity Searches},
  volume       = {227}
}

@article{liSequenceAlignmentMap2009a,
  abstract     = {Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments.Availability:http://samtools.sourceforge.netContact:rd@sanger.ac.uk},
  author       = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard and {1000 Genome Project Data Processing Subgroup}},
  date         = {2009-08-15},
  doi          = {10.1093/bioinformatics/btp352},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Li et al_2009_The Sequence Alignment-Map format and SAMtools2.pdf;/Users/lucblassel/Zotero/storage/8TLEHG4K/204688.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {16},
  pages        = {2078--2079},
  shortjournal = {Bioinformatics},
  title        = {The {{Sequence Alignment}}/{{Map}} Format and {{SAMtools}}},
  url          = {https://doi.org/10.1093/bioinformatics/btp352},
  urldate      = {2022-09-06},
  volume       = {25}
}

@article{liSurveySequenceAlignment2010,
  abstract     = {Rapidly evolving sequencing technologies produce data on an unparalleled scale. A central challenge to the analysis of this data is sequence alignment, whereby sequence reads must be compared to a reference. A wide variety of alignment algorithms and software have been subsequently developed over the past two years. In this article, we will systematically review the current development of these algorithms and introduce their practical applications on different types of experimental data. We come to the conclusion that short-read alignment is no longer the bottleneck of data analyses. We also consider future development of alignment algorithms with respect to emerging long sequence reads and the prospect of cloud computing.},
  author       = {Li, Heng and Homer, Nils},
  date         = {2010-09-01},
  doi          = {10.1093/bib/bbq015},
  file         = {/Users/lucblassel/Zotero/storage/PW72YJU9/Li and Homer - 2010 - A survey of sequence alignment algorithms for next.pdf;/Users/lucblassel/Zotero/storage/N5PCMY87/264166.html},
  ids          = {liSurveySequenceAlignment2010a},
  issn         = {1467-5463},
  journaltitle = {Briefings in Bioinformatics},
  number       = {5},
  pages        = {473--483},
  shortjournal = {Briefings in Bioinformatics},
  title        = {A Survey of Sequence Alignment Algorithms for Next-Generation Sequencing},
  url          = {https://doi.org/10.1093/bib/bbq015},
  urldate      = {2022-05-16},
  volume       = {11}
}

@article{liuLongReadAlignment2012,
  abstract     = {Motivation: The explosive growth of next-generation sequencing datasets poses a challenge to the mapping of reads to reference genomes in terms of alignment quality and execution speed. With the continuing progress of high-throughput sequencing technologies, read length is constantly increasing and many existing aligners are becoming inefficient as generated reads grow larger.Results: We present CUSHAW2, a parallelized, accurate, and memory-efficient long read aligner. Our aligner is based on the seed-and-extend approach and uses maximal exact matches as seeds to find gapped alignments. We have evaluated and compared CUSHAW2 to the three other long read aligners BWA-SW, Bowtie2 and GASSST, by aligning simulated and real datasets to the human genome. The performance evaluation shows that CUSHAW2 is consistently among the highest-ranked aligners in terms of alignment quality for both single-end and paired-end alignment, while demonstrating highly competitive speed. Furthermore, our aligner shows good parallel scalability with respect to the number of CPU threads.Availability: CUSHAW2, written in C++, and all simulated datasets are available at http://cushaw2.sourceforge.netContact:liuy@uni-mainz.de; bertil.schmidt@uni-mainz.deSupplementary information:Supplementary data are available at Bioinformatics online.},
  author       = {Liu, Yongchao and Schmidt, Bertil},
  date         = {2012-09-15},
  doi          = {10.1093/bioinformatics/bts414},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Liu_Schmidt_2012_Long read alignment based on maximal exact match seeds.pdf;/Users/lucblassel/Zotero/storage/LK9EKBL3/251072.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {18},
  pages        = {i318-i324},
  shortjournal = {Bioinformatics},
  title        = {Long Read Alignment Based on Maximal Exact Match Seeds},
  url          = {https://doi.org/10.1093/bioinformatics/bts414},
  urldate      = {2022-06-15},
  volume       = {28}
}

@article{liuMSAProbsMultipleSequence2010,
  abstract     = {Motivation: Multiple sequence alignment is of central importance to bioinformatics and computational biology. Although a large number of algorithms for computing a multiple sequence alignment have been designed, the efficient computation of highly accurate multiple alignments is still a challenge.Results: We present MSAProbs, a new and practical multiple alignment algorithm for protein sequences. The design of MSAProbs is based on a combination of pair hidden Markov models and partition functions to calculate posterior probabilities. Furthermore, two critical bioinformatics techniques, namely weighted probabilistic consistency transformation and weighted profile–profile alignment, are incorporated to improve alignment accuracy. Assessed using the popular benchmarks: BAliBASE, PREFAB, SABmark and OXBENCH, MSAProbs achieves statistically significant accuracy improvements over the existing top performing aligners, including ClustalW, MAFFT, MUSCLE, ProbCons and Probalign. Furthermore, MSAProbs is optimized for multi-core CPUs by employing a multi-threaded design, leading to a competitive execution time compared to other aligners.Availability: The source code of MSAProbs, written in C++, is freely and publicly available from http://msaprobs.sourceforge.net.Contact:liuy0039@ntu.edu.sg},
  author       = {Liu, Yongchao and Schmidt, Bertil and Maskell, Douglas L.},
  date         = {2010-08-15},
  doi          = {10.1093/bioinformatics/btq338},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Liu et al_2010_MSAProbs.pdf;/Users/lucblassel/Zotero/storage/LREE4Q7Q/218540.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {16},
  pages        = {1958--1964},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{MSAProbs}}},
  title        = {{{MSAProbs}}: Multiple Sequence Alignment Based on Pair Hidden {{Markov}} Models and Partition Function Posterior Probabilities},
  url          = {https://doi.org/10.1093/bioinformatics/btq338},
  urldate      = {2022-06-17},
  volume       = {26}
}

@article{mahmoudStructuralVariantCalling2019,
  abstract     = {Recent research into structural variants (SVs) has established their importance to medicine and molecular biology, elucidating their role in various diseases, regulation of gene expression, ethnic diversity, and large-scale chromosome evolution—giving rise to the differences within populations and among species. Nevertheless, characterizing SVs and determining the optimal approach for a given experimental design remains a computational and scientific challenge. Multiple approaches have emerged to target various SV classes, zygosities, and size ranges. Here, we review these approaches with respect to their ability to infer SVs across the full spectrum of large, complex variations and present computational methods for each approach.},
  author       = {Mahmoud, Medhat and Gobet, Nastassia and Cruz-Dávalos, Diana Ivette and Mounier, Ninon and Dessimoz, Christophe and Sedlazeck, Fritz J.},
  date         = {2019-11-20},
  doi          = {10.1186/s13059-019-1828-7},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Mahmoud et al_2019_Structural variant calling.pdf},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {De novo assembly,Gene fusion,Hybrid,Long-read,Mapping,RNA-Seq,Short-read,Structural variant (SV) detection},
  langid       = {english},
  number       = {1},
  pages        = {246},
  shortjournal = {Genome Biol},
  shorttitle   = {Structural Variant Calling},
  title        = {Structural Variant Calling: The Long and the Short of It},
  url          = {https://doi.org/10.1186/s13059-019-1828-7},
  urldate      = {2022-06-14},
  volume       = {20}
}

@article{manberSuffixArraysNew1993,
  abstract     = {A new and conceptually simple data structure, called a suffix array, for on-line string searches is introduced in this paper. Constructing and querying suffix arrays is reduced to a sort and search paradigm that employs novel algorithms. The main advantage of suffix arrays over suffix trees is that, in practice, they use three to five times less space. From a complexity standpoint, suffix arrays permit on-line string searches of the type, “Is W a substring of A?” to be answered in time  𝑂(𝑃+log𝑁) O(P+log⁡N) , where P is the length of W and N is the length of A, which is competitive with (and in some cases slightly better than) suffix trees. The only drawback is that in those instances where the underlying alphabet is finite and small, suffix trees can be constructed in  𝑂(𝑁) O(N)  time in the worst case, versus  𝑂(𝑁log𝑁) O(Nlog⁡N)  time for suffix arrays. However, an augmented algorithm is given that, regardless of the alphabet size, constructs suffix arrays in  𝑂(𝑁) O(N) expected time, albeit with lesser space efficiency. It is believed that suffix arrays will prove to be better in practice than suffix trees for many applications.},
  author       = {Manber, Udi and Myers, Gene},
  date         = {1993-10},
  doi          = {10.1137/0222058},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Manber_Myers_1993_Suffix Arrays.pdf;/Users/lucblassel/Zotero/storage/4FLHHS89/Manber and Myers - 1993 - Suffix Arrays A New Method for On-Line String Sea.pdf},
  issn         = {0097-5397},
  journaltitle = {SIAM Journal on Computing},
  keywords     = {68P10,68P20,68Q25,68U15,algorithms,Google Scholar,inverted indices,pattern matching,string matching,string searching,suffix trees,text indexing},
  number       = {5},
  pages        = {935--948},
  publisher    = {{Society for Industrial and Applied Mathematics}},
  shortjournal = {SIAM J. Comput.},
  shorttitle   = {Suffix {{Arrays}}},
  title        = {Suffix {{Arrays}}: {{A New Method}} for {{On-Line String Searches}}},
  url          = {https://epubs.siam.org/doi/abs/10.1137/0222058},
  urldate      = {2022-09-05},
  volume       = {22}
}

@article{maPatternHunterFasterMore2002,
  abstract     = {Motivation: Genomics and proteomics studies routinely depend on homology searches based on the strategy of finding short seed matches which are then extended. The exploding genomic data growth presents a dilemma for DNA homology search techniques: increasing seed size decreases sensitivity whereas decreasing seed size slows down computation.Results: We present a new homology search algorithm ‘PatternHunter’ that uses a novel seed model for increased sensitivity and new hit-processing techniques for significantly increased speed. At Blast levels of sensitivity, PatternHunter is able to find homologies between sequences as large as human chromosomes, in mere hours on a desktop.Availability: PatternHunter is available at http://www.bioinformaticssolutions.com, as a commercial package. It runs on all platforms that support Java. PatternHunter technology is being patented; commercial use requires a license from BSI, while non-commercial use will be free.Contact: mli@cs.ucsb.edu},
  author       = {Ma, Bin and Tromp, John and Li, Ming},
  date         = {2002-03-01},
  doi          = {10.1093/bioinformatics/18.3.440},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ma et al_2002_PatternHunter.pdf;/Users/lucblassel/Zotero/storage/Z4GBVXLV/236636.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {3},
  pages        = {440--445},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{PatternHunter}}},
  title        = {{{PatternHunter}}: Faster and More Sensitive Homology Search},
  url          = {https://doi.org/10.1093/bioinformatics/18.3.440},
  urldate      = {2022-09-02},
  volume       = {18}
}

@article{marcaisImprovingPerformanceMinimizers2017,
  abstract     = {Motivation The minimizers scheme is a method for selecting k-mers from sequences. It is used in many bioinformatics software tools to bin comparable sequences or to sample a sequence in a deterministic fashion at approximately regular intervals, in order to reduce memory consumption and processing time. Although very useful, the minimizers selection procedure has undesirable behaviors (e.g. too many k-mers are selected when processing certain sequences). Some of these problems were already known to the authors of the minimizers technique, and the natural lexicographic ordering of k-mers used by minimizers was recognized as their origin. Many software tools using minimizers employ ad hoc variations of the lexicographic order to alleviate those issues. Results We provide an in-depth analysis of the effect of k-mer ordering on the performance of the minimizers technique. By using small universal hitting sets (a recently defined concept), we show how to significantly improve the performance of minimizers and avoid some of its worse behaviors. Based on these results, we encourage bioinformatics software developers to use an ordering based on a universal hitting set or, if not possible, a randomized ordering, rather than the lexicographic order. This analysis also settles negatively a conjecture (by Schleimer et al.) on the expected density of minimizers in a random sequence. Availability and Implementation The software used for this analysis is available on GitHub: https://github.com/gmarcais/minimizers.git.},
  author       = {Marçais, Guillaume and Pellow, David and Bork, Daniel and Orenstein, Yaron and Shamir, Ron and Kingsford, Carl},
  date         = {2017-07-15},
  doi          = {10.1093/bioinformatics/btx235},
  eprint       = {28881970},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Marçais et al_2017_Improving the performance of minimizers and winnowing schemes.pdf},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {14},
  pages        = {i110-i117},
  pmcid        = {PMC5870760},
  shortjournal = {Bioinformatics},
  title        = {Improving the Performance of Minimizers and Winnowing Schemes},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5870760/},
  urldate      = {2022-09-05},
  volume       = {33}
}

@article{marcaisMUMmer4FastVersatile2018,
  abstract     = {The MUMmer system and the genome sequence aligner nucmer included within it are among the most widely used alignment packages in genomics. Since the last major release of MUMmer version 3 in 2004, it has been applied to many types of problems including aligning whole genome sequences, aligning reads to a reference genome, and comparing different assemblies of the same genome. Despite its broad utility, MUMmer3 has limitations that can make it difficult to use for large genomes and for the very large sequence data sets that are common today. In this paper we describe MUMmer4, a substantially improved version of MUMmer that addresses genome size constraints by changing the 32-bit suffix tree data structure at the core of MUMmer to a 48-bit suffix array, and that offers improved speed through parallel processing of input query sequences. With a theoretical limit on the input size of 141Tbp, MUMmer4 can now work with input sequences of any biologically realistic length. We show that as a result of these enhancements, the nucmer program in MUMmer4 is easily able to handle alignments of large genomes; we illustrate this with an alignment of the human and chimpanzee genomes, which allows us to compute that the two species are 98\% identical across 96\% of their length. With the enhancements described here, MUMmer4 can also be used to efficiently align reads to reference genomes, although it is less sensitive and accurate than the dedicated read aligners. The nucmer aligner in MUMmer4 can now be called from scripting languages such as Perl, Python and Ruby. These improvements make MUMer4 one the most versatile genome alignment packages available.},
  author       = {Marçais, Guillaume and Delcher, Arthur L. and Phillippy, Adam M. and Coston, Rachel and Salzberg, Steven L. and Zimin, Aleksey},
  date         = {2018-01-26},
  doi          = {10.1371/journal.pcbi.1005944},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Marçais et al_2018_MUMmer4.pdf;/Users/lucblassel/Zotero/storage/QHE3FF57/article.html},
  issn         = {1553-7358},
  journaltitle = {PLOS Computational Biology},
  keywords     = {Animal genomics,Arabidopsis thaliana,Computer hardware,Computer software,Genomics,Human genomics,Plant genomics,Sequence alignment},
  langid       = {english},
  number       = {1},
  pages        = {e1005944},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS Computational Biology},
  shorttitle   = {{{MUMmer4}}},
  title        = {{{MUMmer4}}: {{A}} Fast and Versatile Genome Alignment System},
  url          = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005944},
  urldate      = {2022-09-05},
  volume       = {14}
}

@article{marco-solaFastGapaffinePairwise2020,
  abstract     = {Pairwise alignment of sequences is a fundamental method in modern molecular biology, implemented within multiple bioinformatics tools and libraries. Current advances in sequencing technologies press for the development of faster pairwise alignment algorithms that can scale with increasing read lengths and production yields.In this article, we present the wavefront alignment algorithm (WFA), an exact gap-affine algorithm that takes advantage of homologous regions between the sequences to accelerate the alignment process. As opposed to traditional dynamic programming algorithms that run in quadratic time, the WFA runs in time O(ns), proportional to the read length n and the alignment score s, using O(s2) memory. Furthermore, our algorithm exhibits simple data dependencies that can be easily vectorized, even by the automatic features of modern compilers, for different architectures, without the need to adapt the code. We evaluate the performance of our algorithm, together with other state-of-the-art implementations. As a result, we demonstrate that the WFA runs 20–300× faster than other methods aligning short Illumina-like sequences, and 10–100× faster using long noisy reads like those produced by Oxford Nanopore Technologies.The WFA algorithm is implemented within the wavefront-aligner library, and it is publicly available at https://github.com/smarco/WFA.},
  author       = {Marco-Sola, Santiago and Moure, Juan Carlos and Moreto, Miquel and Espinosa, Antonio},
  date         = {2020-09-11},
  doi          = {10.1093/bioinformatics/btaa777},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/Marco-Sola et al_2020_Fast gap-affine pairwise alignment using the wavefront algorithm.pdf;/Users/lucblassel/Zotero/storage/Y6QTZY4M/5904262.html},
  issn         = {1367-4803},
  issue        = {btaa777},
  journaltitle = {Bioinformatics},
  keywords     = {mapping},
  shortjournal = {Bioinformatics},
  title        = {Fast Gap-Affine Pairwise Alignment Using the Wavefront Algorithm},
  url          = {https://doi.org/10.1093/bioinformatics/btaa777},
  urldate      = {2021-04-18}
}

@article{masekFasterAlgorithmComputing1980,
  abstract     = {The edit distance between two character strings can be defined as the minimum cost of a sequence of editing operations which transforms one string into the other. The operations we admit are deleting, inserting and replacing one symbol at a time, with possibly different costs for each of these operations. The problem of finding the longest common subsequence of two strings is a special case of the problem of computing edit distances. We describe an algorithm for computing the edit distance between two strings of length n and m, n ⪖ m, which requires O(n · max(1, mlog n)) steps whenever the costs of edit operations are integral multiples of a single positive real number and the alphabet for the strings is finite. These conditions are necessary for the algorithm to achieve the time bound.},
  author       = {Masek, William J. and Paterson, Michael S.},
  date         = {1980-02-01},
  doi          = {10.1016/0022-0000(80)90002-1},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Masek_Paterson_1980_A faster algorithm computing string edit distances.pdf;/Users/lucblassel/Zotero/storage/BBEA96M4/0022000080900021.html},
  issn         = {0022-0000},
  journaltitle = {Journal of Computer and System Sciences},
  langid       = {english},
  number       = {1},
  pages        = {18--31},
  shortjournal = {Journal of Computer and System Sciences},
  title        = {A Faster Algorithm Computing String Edit Distances},
  url          = {https://www.sciencedirect.com/science/article/pii/0022000080900021},
  urldate      = {2022-06-13},
  volume       = {20}
}

@article{medvedevComputationalMethodsDiscovering2009,
  abstract     = {In the last several years, a number of studies have described large-scale structural variation in several genomes. Traditionally, such methods have used whole-genome array comparative genome hybridization or single-nucleotide polymorphism arrays to detect large regions subject to copy-number variation. Later techniques have been based on paired-end mapping of Sanger sequencing data, providing better resolution and accuracy. With the advent of next-generation sequencing, a new generation of methods is being developed to tackle the challenges of short reads, while taking advantage of the high coverage the new sequencing technologies provide. In this survey, we describe these methods, including their strengths and their limitations, and future research directions.},
  author       = {Medvedev, Paul and Stanciu, Monica and Brudno, Michael},
  date         = {2009-11},
  doi          = {10.1038/nmeth.1374},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Medvedev et al_2009_Computational methods for discovering structural variation with next-generation.pdf;/Users/lucblassel/Zotero/storage/RJCPTKKT/nmeth.html},
  issn         = {1548-7105},
  issue        = {11},
  journaltitle = {Nature Methods},
  keywords     = {Bioinformatics,Biological Microscopy,Biological Techniques,Biomedical Engineering/Biotechnology,general,Life Sciences,Proteomics},
  langid       = {english},
  number       = {11},
  pages        = {S13-S20},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Computational Methods for Discovering Structural Variation with Next-Generation Sequencing},
  url          = {https://www.nature.com/articles/nmeth.1374},
  urldate      = {2022-06-14},
  volume       = {6}
}

@article{millerSequenceComparisonConcave1988,
  abstract     = {We consider efficient methods for computing a difference metric between two sequences of symbols, where the cost of an operation to insert or delete a block of symbols is a concave function of the block's length. Alternatively, sequences can be optimally aligned when gap penalties are a concave function of the gap length. Two algorithms based on the ‘candidate list paradigm’ first used by Waterman (1984) are presented. The first computes significantly more parsimonious candidate lists than Waterman's method. The second method refines the first to the point of guaranteeingO(N2lgN) worst-case time complexity, and under certain conditionsO(N2). Experimental data show how various properties of the comparison problem affect the methods' relative performance. A number of extensions are discussed, among them a technique for constructing optimal alignments inO(N) space in expectation. This variation gives a practical method for comparing long amino sequences on a small computer.},
  author       = {Miller, Webb and Myers, Eugene W.},
  date         = {1988-03-01},
  doi          = {10.1007/BF02459948},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Miller_Myers_1988_Sequence comparison with concave weighting functions.pdf},
  issn         = {1522-9602},
  journaltitle = {Bulletin of Mathematical Biology},
  keywords     = {Candidate List,Concave Function,Optimal Alignment,Sequence Comparison,Weighting Function},
  langid       = {english},
  number       = {2},
  pages        = {97--120},
  shortjournal = {Bltn Mathcal Biology},
  title        = {Sequence Comparison with Concave Weighting Functions},
  url          = {https://doi.org/10.1007/BF02459948},
  urldate      = {2022-08-26},
  volume       = {50}
}

@article{morcosDirectcouplingAnalysisResidue2011,
  abstract     = {The similarity in the three-dimensional structures of homologous proteins imposes strong constraints on their sequence variability. It has long been suggested that the resulting correlations among amino acid compositions at different sequence positions can be exploited to infer spatial contacts within the tertiary protein structure. Crucial to this inference is the ability to disentangle direct and indirect correlations, as accomplished by the recently introduced direct-coupling analysis (DCA). Here we develop a computationally efficient implementation of DCA, which allows us to evaluate the accuracy of contact prediction by DCA for a large number of protein domains, based purely on sequence information. DCA is shown to yield a large number of correctly predicted contacts, recapitulating the global structure of the contact map for the majority of the protein domains examined. Furthermore, our analysis captures clear signals beyond intradomain residue contacts, arising, e.g., from alternative protein conformations, ligand-mediated residue couplings, and interdomain interactions in protein oligomers. Our findings suggest that contacts predicted by DCA can be used as a reliable guide to facilitate computational predictions of alternative protein conformations, protein complex formation, and even the de novo prediction of protein domain structures, contingent on the existence of a large number of homologous sequences which are being rapidly made available due to advances in genome sequencing.},
  author       = {Morcos, Faruck and Pagnani, Andrea and Lunt, Bryan and Bertolino, Arianna and Marks, Debora S. and Sander, Chris and Zecchina, Riccardo and Onuchic, José N. and Hwa, Terence and Weigt, Martin},
  date         = {2011-12-06},
  doi          = {10.1073/pnas.1111471108},
  eprint       = {22106262},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/morcos_et_al_2011_direct-coupling_analysis_of_residue_coevolution.pdf;/Users/lucblassel/Zotero/storage/RQQJ28W9/E1293.html},
  issn         = {0027-8424, 1091-6490},
  journaltitle = {Proceedings of the National Academy of Sciences},
  keywords     = {contact map prediction,maximum-entropy modeling,residue–residue covariation,statistical sequence analysis},
  langid       = {english},
  number       = {49},
  pages        = {E1293-E1301},
  shortjournal = {PNAS},
  title        = {Direct-Coupling Analysis of Residue Coevolution Captures Native Contacts across Many Protein Families},
  url          = {https://www.pnas.org/content/108/49/E1293},
  urldate      = {2019-08-19},
  volume       = {108}
}

@incollection{mottAlignmentStatisticalSignificance2005,
  abstract   = {Computation of the probability that an observed alignment between two protein or DNA sequences could have arisen by chance is useful for identifying genuinely related sequences.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1038/npg.els.0005264},
  author     = {Mott, Richard},
  booktitle  = {{{eLS}}},
  date       = {2005},
  doi        = {10.1038/npg.els.0005264},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Mott_2005_Alignment.pdf;/Users/lucblassel/Zotero/storage/NH63PXFM/npg.els.html},
  isbn       = {978-0-470-01590-2},
  keywords   = {DNA,homology,protein sequence,sequence alignment,statistical significance},
  langid     = {english},
  publisher  = {{John Wiley \& Sons, Ltd}},
  shorttitle = {Alignment},
  title      = {Alignment: {{Statistical Significance}}},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1038/npg.els.0005264},
  urldate    = {2022-06-15}
}

@article{mullerModelingAminoAcid2000,
  abstract     = {The estimation of amino acid replacement frequencies during molecular evolution is crucial for many applications in sequence analysis. Score matrices for database search programs or phylogenetic analysis rely on such models of protein evolution. Pioneering work was done by Dayhoff et al. (1978) who formulated a Markov model of evolution and derived the famous PAM score matrices. Her estimation procedure for amino acid exchange frequencies is restricted to pairs of proteins that have a constant and small degree of divergence. Here we present an improved estimator, called the resolvent method, that is not subject to these limitations. This extension of Dayhoff's approach enables us to estimate an amino acid substitution model from alignments of varying degree of divergence. Extensive simulations show the capability of the new estimator to recover accurately the exchange frequencies among amino acids. Based on the SYSTERS database of aligned protein families (Krause and Vingron, 1998) we recompute a series of score matrices.},
  author       = {Müller, T. and Vingron, M.},
  date         = {2000},
  doi          = {10.1089/10665270050514918},
  eprint       = {11382360},
  eprinttype   = {pmid},
  issn         = {1066-5277},
  journaltitle = {Journal of Computational Biology: A Journal of Computational Molecular Cell Biology},
  keywords     = {Amino Acid Substitution,Computer Simulation,Evolution; Molecular,Likelihood Functions,Markov Chains,Models; Biological,Proteins,Stochastic Processes,Time Factors},
  langid       = {english},
  number       = {6},
  pages        = {761--776},
  shortjournal = {J Comput Biol},
  title        = {Modeling Amino Acid Replacement},
  volume       = {7}
}

@article{mullerNonsymmetricScoreMatrices2001,
  abstract     = {Given a transmembrane protein, we wish to find related ones by a database search. Due to the strongly hydrophobic amino acid composition of transmembrane domains, suboptimal results are obtained when general-purpose scoring matrices such as BLOSUM are used. Recently, a transmembrane-specific score matrix called PHAT was shown to perform much better than BLOSUM. In this article, we derive a transmembrane score matrix family, called SLIM, which has several distinguishing features. In contrast to currently used matrices, SLIM is non-symmetric. The asymmetry arises because different background compositions are assumed for the transmembrane query and the unknown database sequences. We describe the mathematical model behind SLIM in detail and show that SLIM outperforms PHAT both on simulated data and in a realistic setting. Since non-symmetric score matrices are a new concept in database search methods, we discuss some important theoretical and practical issues.Contact: muelle\_t@molgen.mpg.de},
  author       = {Müller, Tobias and Rahmann, Sven and Rehmsmeier, Marc},
  date         = {2001-06-01},
  doi          = {10.1093/bioinformatics/17.suppl_1.S182},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Müller et al_2001_Non-symmetric score matrices and the detection of homologous transmembrane.pdf;/Users/lucblassel/Zotero/storage/C9755BUV/262106.html},
  issn         = {1367-4803},
  issue        = {suppl\_1},
  journaltitle = {Bioinformatics},
  pages        = {S182-S189},
  shortjournal = {Bioinformatics},
  title        = {Non-Symmetric Score Matrices and the Detection of Homologous Transmembrane Proteins},
  url          = {https://doi.org/10.1093/bioinformatics/17.suppl_1.S182},
  urldate      = {2022-06-14},
  volume       = {17}
}

@article{myersOptimalAlignmentsLinear1988,
  abstract     = {Space, not time, is often the limiting factor when computing optimal sequence alignments, and a number of recent papers in the biology literature have proposed space-saving strategies. However, a 1975 computer science paper by Hirschberg presented a method that is superior to the new proposals, both in theory and in practice. The goal of this paper is to give Hirschberg's idea the visibility it deserves by developing a linear-space version of Gotoh's algorithm, which accommodates affine gap penalties. A portable C-software package implementing this algorithm is available on the BIONET free of charge.},
  author       = {Myers, Eugene W. and Miller, Webb},
  date         = {1988-03-01},
  doi          = {10.1093/bioinformatics/4.1.11},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Myers_Miller_1988_Optimal alignments in linear space.pdf;/Users/lucblassel/Zotero/storage/WBG23AUA/205106.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {1},
  pages        = {11--17},
  shortjournal = {Bioinformatics},
  title        = {Optimal Alignments in Linear Space},
  url          = {https://doi.org/10.1093/bioinformatics/4.1.11},
  urldate      = {2022-06-14},
  volume       = {4}
}

@article{nazninProgressiveAlignmentMethod2012,
  abstract     = {In this paper, we have proposed a progressive alignment method using a genetic algorithm for multiple sequence alignment, named GAPAM. We have introduced two new mechanisms to generate an initial population: the first mechanism is to generate guide trees with randomly selected sequences and the second is shuffling the sequences inside such trees. Two different genetic operators have been implemented with GAPAM. To test the performance of our algorithm, we have compared it with existing well-known methods, such as PRRP, CLUSTALX, DIALIGN, HMMT, SB\_PIMA, ML\_PIMA, MULTALIGN, and PILEUP8, and also other methods, based on genetic algorithms (GA), such as SAGA, MSA-GA, and RBT-GA, by solving a number of benchmark datasets from BAliBase 2.0. To make a fairer comparison with the GA based algorithms such as MSA-GA and RBT-GA, we have performed further experiments covering all the datasets reported by those two algorithms. The experimental results showed that GAPAM achieved better solutions than the others for most of the cases, and also revealed that the overall performance of the proposed method outperformed the other methods mentioned above.},
  author       = {Naznin, Farhana and Sarker, Ruhul and Essam, Daryl},
  date         = {2012-10},
  doi          = {10.1109/TEVC.2011.2162849},
  eventtitle   = {{{IEEE Transactions}} on {{Evolutionary Computation}}},
  file         = {/Users/lucblassel/Zotero/storage/8P5GIH6V/6151111.html},
  issn         = {1941-0026},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  keywords     = {Algorithm design and analysis,Benchmark testing,Dynamic programming,Dynamic programming (DP),genetic algorithm (GA),Genetic algorithms,guide tree,Heuristic algorithms,Iterative methods,multiple sequence alignment (MSA),progressive alignment,Stochastic processes},
  number       = {5},
  pages        = {615--631},
  title        = {Progressive {{Alignment Method Using Genetic Algorithm}} for {{Multiple Sequence Alignment}}},
  volume       = {16}
}

@article{nazninVerticalDecompositionGenetic2011,
  abstract     = {Many Bioinformatics studies begin with a multiple sequence alignment as the foundation for their research. This is because multiple sequence alignment can be a useful technique for studying molecular evolution and analyzing sequence structure relationships.},
  author       = {Naznin, Farhana and Sarker, Ruhul and Essam, Daryl},
  date         = {2011-08-25},
  doi          = {10.1186/1471-2105-12-353},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Naznin et al_2011_Vertical decomposition with Genetic Algorithm for Multiple Sequence Alignment.pdf;/Users/lucblassel/Zotero/storage/XKYIPBC5/1471-2105-12-353.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Genetic Algorithm,Genetic Operator,Guide Tree,Initial Population,Multiple Sequence Alignment},
  number       = {1},
  pages        = {353},
  shortjournal = {BMC Bioinformatics},
  title        = {Vertical Decomposition with {{Genetic Algorithm}} for {{Multiple Sequence Alignment}}},
  url          = {https://doi.org/10.1186/1471-2105-12-353},
  urldate      = {2022-06-17},
  volume       = {12}
}

@article{needlemanGeneralMethodApplicable1970,
  abstract     = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.},
  author       = {Needleman, Saul B. and Wunsch, Christian D.},
  date         = {1970-03-28},
  doi          = {10.1016/0022-2836(70)90057-4},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/needleman_wunsch_1970_a_general_method_applicable_to_the_search_for.pdf;/Users/lucblassel/Zotero/storage/JVEXBQ75/0022283670900574.html},
  ids          = {needlemanGeneralMethodApplicable1970a},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  number       = {3},
  pages        = {443--453},
  shortjournal = {Journal of Molecular Biology},
  title        = {A General Method Applicable to the Search for Similarities in the Amino Acid Sequence of Two Proteins},
  url          = {http://www.sciencedirect.com/science/article/pii/0022283670900574},
  urldate      = {2019-08-19},
  volume       = {48}
}

@article{ngPHATTransmembranespecificSubstitution2000,
  abstract     = {MOTIVATION: Database searching algorithms for proteins use scoring matrices based on average protein properties, and thus are dominated by globular proteins. However, since transmembrane regions of a protein are in a distinctly different environment than globular proteins, one would expect generalized substitution matrices to be inappropriate for transmembrane regions. RESULTS: We present the PHAT (predicted hydrophobic and transmembrane) matrix, which significantly outperforms generalized matrices and a previously published transmembrane matrix in searches with transmembrane queries. We conclude that a better matrix can be constructed by using background frequencies characteristic of the twilight zone, where low-scoring true positives have scores indistinguishable from high-scoring false positives, rather than the amino acid frequencies of the database. The PHAT matrix may help improve the accuracy of sequence alignments and evolutionary trees of membrane proteins.},
  author       = {Ng, P. C. and Henikoff, J. G. and Henikoff, S.},
  date         = {2000-09},
  doi          = {10.1093/bioinformatics/16.9.760},
  eprint       = {11108698},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ng et al_2000_PHAT.pdf},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics (Oxford, England)},
  keywords     = {Algorithms,Amino Acid Sequence,Computational Biology,Consensus Sequence,Databases; Factual,Membrane Proteins,Models; Theoretical,Predictive Value of Tests,Proteins,Reproducibility of Results,Sequence Alignment,Sequence Homology; Amino Acid},
  langid       = {english},
  number       = {9},
  pages        = {760--766},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{PHAT}}},
  title        = {{{PHAT}}: A Transmembrane-Specific Substitution Matrix. {{Predicted}} Hydrophobic and Transmembrane},
  volume       = {16}
}

@article{nickleHIVSpecificProbabilisticModels2007,
  abstract     = {Comparative sequence analyses, including such fundamental bioinformatics techniques as similarity searching, sequence alignment and phylogenetic inference, have become a mainstay for researchers studying type 1 Human Immunodeficiency Virus (HIV-1) genome structure and evolution. Implicit in comparative analyses is an underlying model of evolution, and the chosen model can significantly affect the results. In general, evolutionary models describe the probabilities of replacing one amino acid character with another over a period of time. Most widely used evolutionary models for protein sequences have been derived from curated alignments of hundreds of proteins, usually based on mammalian genomes. It is unclear to what extent these empirical models are generalizable to a very different organism, such as HIV-1–the most extensively sequenced organism in existence. We developed a maximum likelihood model fitting procedure to a collection of HIV-1 alignments sampled from different viral genes, and inferred two empirical substitution models, suitable for describing between-and within-host evolution. Our procedure pools the information from multiple sequence alignments, and provided software implementation can be run efficiently in parallel on a computer cluster. We describe how the inferred substitution models can be used to generate scoring matrices suitable for alignment and similarity searches. Our models had a consistently superior fit relative to the best existing models and to parameter-rich data-driven models when benchmarked on independent HIV-1 alignments, demonstrating evolutionary biases in amino-acid substitution that are unique to HIV, and that are not captured by the existing models. The scoring matrices derived from the models showed a marked difference from common amino-acid scoring matrices. The use of an appropriate evolutionary model recovered a known viral transmission history, whereas a poorly chosen model introduced phylogenetic error. We argue that our model derivation procedure is immediately applicable to other organisms with extensive sequence data available, such as Hepatitis C and Influenza A viruses.},
  author       = {Nickle, David C. and Heath, Laura and Jensen, Mark A. and Gilbert, Peter B. and Mullins, James I. and Kosakovsky Pond, Sergei L.},
  date         = {2007-06-06},
  doi          = {10.1371/journal.pone.0000503},
  eprint       = {17551583},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Nickle et al_2007_HIV-Specific Probabilistic Models of Protein Evolution.pdf},
  issn         = {1932-6203},
  journaltitle = {PLoS ONE},
  number       = {6},
  pages        = {e503},
  pmcid        = {PMC1876811},
  shortjournal = {PLoS One},
  title        = {{{HIV-Specific Probabilistic Models}} of {{Protein Evolution}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1876811/},
  urldate      = {2022-06-14},
  volume       = {2}
}

@article{notredameCOFFEEObjectiveFunction1998,
  abstract     = {MOTIVATION: In order to increase the accuracy of multiple sequence alignments, we designed a new strategy for optimizing multiple sequence alignments by genetic algorithm. We named it COFFEE (Consistency based Objective Function For alignmEnt Evaluation). The COFFEE score reflects the level of consistency between a multiple sequence alignment and a library containing pairwise alignments of the same sequences. RESULTS: We show that multiple sequence alignments can be optimized for their COFFEE score with the genetic algorithm package SAGA. The COFFEE function is tested on 11 test cases made of structural alignments extracted from 3D\_ali. These alignments are compared to those produced using five alternative methods. Results indicate that COFFEE outperforms the other methods when the level of identity between the sequences is low. Accuracy is evaluated by comparison with the structural alignments used as references. We also show that the COFFEE score can be used as a reliability index on multiple sequence alignments. Finally, we show that given a library of structure-based pairwise sequence alignments extracted from FSSP, SAGA can produce high-quality multiple sequence alignments. The main advantage of COFFEE is its flexibility. With COFFEE, any method suitable for making pairwise alignments can be extended to making multiple alignments. AVAILABILITY: The package is available along with the test cases through the WWW: http://www. ebi.ac.uk/cedric CONTACT: cedric.notredame@ebi.ac.uk},
  author       = {Notredame, C and Holm, L and Higgins, D G},
  date         = {1998-06-01},
  doi          = {10.1093/bioinformatics/14.5.407},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Notredame et al_1998_COFFEE.pdf;/Users/lucblassel/Zotero/storage/WSRVI9JV/225478.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {5},
  pages        = {407--422},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{COFFEE}}},
  title        = {{{COFFEE}}: An Objective Function for Multiple Sequence Alignments.},
  url          = {https://doi.org/10.1093/bioinformatics/14.5.407},
  urldate      = {2022-06-16},
  volume       = {14}
}

@article{notredameRecentEvolutionsMultiple2007,
  author       = {Notredame, Cédric},
  date         = {2007-08-31},
  doi          = {10.1371/journal.pcbi.0030123},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Notredame_2007_Recent Evolutions of Multiple Sequence Alignment Algorithms.pdf;/Users/lucblassel/Zotero/storage/K5KYZXJA/article.html},
  issn         = {1553-7358},
  journaltitle = {PLOS Computational Biology},
  keywords     = {Algorithms,BLAST algorithm,Multiple alignment calculation,Phylogenetic analysis,Protein structure comparison,RNA structure,Sequence alignment,Trees},
  langid       = {english},
  number       = {8},
  pages        = {e123},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS Computational Biology},
  title        = {Recent {{Evolutions}} of {{Multiple Sequence Alignment Algorithms}}},
  url          = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030123},
  urldate      = {2022-06-16},
  volume       = {3}
}

@article{notredameRecentProgressMultiple2002,
  abstract     = {The assembly of a multiple sequence alignment (MSA) has become one of the most common tasks when dealing with sequence analysis. Unfortunately, the wide range of available methods and the differences in the results given by these methods makes it hard for a non-specialist to decide which program is best suited for a given purpose. In this review we briefly describe existing techniques and expose the potential strengths and weaknesses of the most widely used multiple alignment packages.},
  author       = {Notredame, Cédric},
  date         = {2002-01},
  doi          = {10.1517/14622416.3.1.131},
  issn         = {1462-2416},
  journaltitle = {Pharmacogenomics},
  keywords     = {BLAST,hidden Markov model,multiple sequence alignment,T-Coffee},
  number       = {1},
  pages        = {131--144},
  publisher    = {{Future Medicine}},
  shorttitle   = {Recent Progress in Multiple Sequence Alignment},
  title        = {Recent Progress in Multiple Sequence Alignment: A Survey},
  url          = {https://www.futuremedicine.com/doi/abs/10.1517/14622416.3.1.131},
  urldate      = {2022-05-16},
  volume       = {3}
}

@article{notredameSAGASequenceAlignment1996,
  abstract     = {We describe a new approach to multiple sequence alignment using genetic algorithms and an associated software package called SAGA. The method involves evolving a population of alignments in a quasi evolutionary manner and gradually improving the fitness of the population as measured by an objective function which measures multiple alignment quality. SAGA uses an automatic scheduling scheme to control the usage of 22 different operators for combining alignments or mutating them between generations. When used to optimise the well known sums of pairs objective function, SAGA performs better than some of the widely used alternative packages. This is seen with respect to the ability to achieve an optimal solution and with regard to the accuracy of alignment by comparison with reference alignments based on sequences of known tertiary structure. The general attraction of the approach is the ability to optimise any objective function that one can invent.},
  author       = {Notredame, C and Higgins, D G},
  date         = {1996-04-15},
  doi          = {10.1093/nar/24.8.1515},
  eprint       = {8628686},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/notredame_higgins_1996_saga.pdf},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {8},
  pages        = {1515--1524},
  pmcid        = {PMC145823},
  shortjournal = {Nucleic Acids Res},
  shorttitle   = {{{SAGA}}},
  title        = {{{SAGA}}: Sequence Alignment by Genetic Algorithm.},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC145823/},
  urldate      = {2019-08-19},
  volume       = {24}
}

@article{notredameTcoffeeNovelMethod2000,
  abstract     = {We describe a new method (T-Coffee) for multiple sequence alignment that provides a dramatic improvement in accuracy with a modest sacrifice in speed as compared to the most commonly used alternatives. The method is broadly based on the popular progressive approach to multiple alignment but avoids the most serious pitfalls caused by the greedy nature of this algorithm. With T-Coffee we pre-process a data set of all pair-wise alignments between the sequences. This provides us with a library of alignment information that can be used to guide the progressive alignment. Intermediate alignments are then based not only on the sequences to be aligned next but also on how all of the sequences align with each other. This alignment information can be derived from heterogeneous sources such as a mixture of alignment programs and/or structure superposition. Here, we illustrate the power of the approach by using a combination of local and global pair-wise alignments to generate the library. The resulting alignments are significantly more reliable, as determined by comparison with a set of 141 test cases, than any of the popular alternatives that we tried. The improvement, especially clear with the more difficult test cases, is always visible, regardless of the phylogenetic spread of the sequences in the tests.},
  author       = {Notredame, Cédric and Higgins, Desmond G and Heringa, Jaap},
  date         = {2000-09-08},
  doi          = {10.1006/jmbi.2000.4042},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/notredame_et_al_2000_t-coffee.pdf;/Users/lucblassel/Zotero/storage/I35LPMLB/S0022283600940427.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {global alignment,local alignment,multiple sequence alignment,pair-wise alignment,progressive alignment},
  langid       = {english},
  number       = {1},
  pages        = {205--217},
  shortjournal = {Journal of Molecular Biology},
  shorttitle   = {T-Coffee},
  title        = {T-Coffee: A Novel Method for Fast and Accurate Multiple Sequence {{alignment11Edited}} by {{J}}. {{Thornton}}},
  url          = {http://www.sciencedirect.com/science/article/pii/S0022283600940427},
  urldate      = {2019-10-22},
  volume       = {302}
}

@article{notredameTcoffeeNovelMethod2000a,
  abstract     = {We describe a new method (T-Coffee) for multiple sequence alignment that provides a dramatic improvement in accuracy with a modest sacrifice in speed as compared to the most commonly used alternatives. The method is broadly based on the popular progressive approach to multiple alignment but avoids the most serious pitfalls caused by the greedy nature of this algorithm. With T-Coffee we pre-process a data set of all pair-wise alignments between the sequences. This provides us with a library of alignment information that can be used to guide the progressive alignment. Intermediate alignments are then based not only on the sequences to be aligned next but also on how all of the sequences align with each other. This alignment information can be derived from heterogeneous sources such as a mixture of alignment programs and/or structure superposition. Here, we illustrate the power of the approach by using a combination of local and global pair-wise alignments to generate the library. The resulting alignments are significantly more reliable, as determined by comparison with a set of 141 test cases, than any of the popular alternatives that we tried. The improvement, especially clear with the more difficult test cases, is always visible, regardless of the phylogenetic spread of the sequences in the tests.},
  author       = {Notredame, Cédric and Higgins, Desmond G and Heringa, Jaap},
  date         = {2000-09-08},
  doi          = {10.1006/jmbi.2000.4042},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Notredame et al_2000_T-coffee.pdf;/Users/lucblassel/Zotero/storage/YGNRDAHY/S0022283600940427.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  keywords     = {global alignment,local alignment,multiple sequence alignment,pair-wise alignment,progressive alignment},
  langid       = {english},
  number       = {1},
  pages        = {205--217},
  shortjournal = {Journal of Molecular Biology},
  shorttitle   = {T-Coffee},
  title        = {T-Coffee: A Novel Method for Fast and Accurate Multiple Sequence {{alignment11Edited}} by {{J}}. {{Thornton}}},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022283600940427},
  urldate      = {2022-06-16},
  volume       = {302}
}

@inproceedings{olsonHardwareAccelerationShort2012,
  abstract   = {Bioinformatics is an emerging field with seemingly limitless possibilities for advances in numerous areas of research and applications. We propose a scalable FPGA-based solution to the short read mapping problem in DNA sequencing, which greatly accelerates the task of aligning short length reads to a known reference genome. We compare the runtime, power consumption, and sensitivity of the hardware system to the BFAST and Bowtie software tools. The hardware system demonstrates a 250X speedup versus BFAST and a 31X speedup versus Bowtie on eight CPU cores. Also, the hardware system is more sensitive than Bowtie, which aligns approximately 80\% of the short reads, as compared to 91\% aligned by the hardware.},
  author     = {Olson, Corey B. and Kim, Maria and Clauson, Cooper and Kogon, Boris and Ebeling, Carl and Hauck, Scott and Ruzzo, Walter L.},
  booktitle  = {2012 {{IEEE}} 20th {{International Symposium}} on {{Field-Programmable Custom Computing Machines}}},
  date       = {2012-04},
  doi        = {10.1109/FCCM.2012.36},
  eventtitle = {2012 {{IEEE}} 20th {{International Symposium}} on {{Field-Programmable Custom Computing Machines}}},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Olson et al_2012_Hardware Acceleration of Short Read Mapping.pdf;/Users/lucblassel/Zotero/storage/BLQ8MJMG/6239809.html},
  ids        = {olsonHardwareAccelerationShort2012a},
  keywords   = {Arrays,bioinformatics,Bioinformatics,Field programmable gate arrays,FPGA,Genomics,Hardware,Indexes,mapping,nextgeneration sequencing,short reads},
  pages      = {161--168},
  title      = {Hardware {{Acceleration}} of {{Short Read Mapping}}}
}

@inproceedings{orensteinCompactUniversalKmer2016,
  abstract  = {We address the problem of finding a minimum-size set of k-mers that hits L-long sequences. The problem arises in the design of compact hash functions and other data structures for efficient handling of large sequencing datasets. We prove that the problem of hitting a given set of L-long sequences is NP-hard and give a heuristic solution that finds a compact universal k-mer set that hits any set of L-long sequences. The algorithm, called DOCKS (design of compact k-mer sets), works in two phases: (i)~finding a minimum-size k-mer set that hits every infinite sequence; (ii)~greedily adding k-mers such that together they hit all remaining L-long sequences. We show that DOCKS works well in practice and produces a set of k-mers that is much smaller than a random choice of k-mers. We present results for various values of k and sequence lengths L and by applying them to two bacterial genomes show that universal hitting k-mers improve on minimizers. The software and exemplary sets are freely available at acgt.cs.tau.ac.il/docks/.},
  author    = {Orenstein, Yaron and Pellow, David and Marçais, Guillaume and Shamir, Ron and Kingsford, Carl},
  booktitle = {Algorithms in {{Bioinformatics}}},
  date      = {2016},
  doi       = {10.1007/978-3-319-43681-4_21},
  editor    = {Frith, Martin and Storm Pedersen, Christian Nørgaard},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Orenstein et al_2016_Compact Universal k-mer Hitting Sets.pdf},
  isbn      = {978-3-319-43681-4},
  keywords  = {Bloom Filter,Conjugacy Class,Directed Acyclic Graph,Greedy Heuristic,Infinite Sequence},
  langid    = {english},
  location  = {{Cham}},
  pages     = {257--268},
  publisher = {{Springer International Publishing}},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  title     = {Compact {{Universal}} K-Mer {{Hitting Sets}}}
}

@article{pachterApplicationsGeneralizedPair2002,
  abstract     = {Hidden Markov models (HMMs) have been successfully applied to a variety of problems in molecular biology, ranging from alignment problems to gene finding and annotation. Alignment problems can be solved with pair HMMs, while gene finding programs rely on generalized HMMs in order to model exon lengths. In this paper, we introduce the generalized pair HMM (GPHMM), which is an extension of both pair and generalized HMMs. We show how GPHMMs, in conjunction with approximate alignments, can be used for cross-species gene finding and describe applications to DNA-cDNA and DNA-protein alignment. GPHMMs provide a unifying and probabilistically sound theory for modeling these problems.},
  author       = {Pachter, Lior and Alexandersson, Marina and Cawley, Simon},
  date         = {2002},
  doi          = {10.1089/10665270252935520},
  eprint       = {12015888},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/pachter_et_al_2002_applications_of_generalized_pair_hidden_markov.pdf},
  issn         = {1066-5277},
  journaltitle = {Journal of Computational Biology: A Journal of Computational Molecular Cell Biology},
  keywords     = {Algorithms,Computational Biology,DNA,Markov Chains,Models; Statistical,Proteins,Sequence Alignment},
  langid       = {english},
  number       = {2},
  pages        = {389--399},
  shortjournal = {J. Comput. Biol.},
  title        = {Applications of Generalized Pair Hidden {{Markov}} Models to Alignment and Gene Finding Problems},
  volume       = {9}
}

@article{pailaGenomeBiasInfluences2008,
  abstract     = {The genomic era has seen a remarkable increase in the number of genomes being sequenced and annotated. Nonetheless, annotation remains a serious challenge for compositionally biased genomes. For the preliminary annotation, popular nucleotide and protein comparison methods such as BLAST are widely employed. These methods make use of matrices to score alignments such as the amino acid substitution matrices. Since a nucleotide bias leads to an overall bias in the amino acid composition of proteins, it is possible that a genome with nucleotide bias may have introduced atypical amino acid substitutions in its proteome. Consequently, standard matrices fail to perform well in sequence analysis of these genomes. To address this issue, we examined the amino acid substitution in the AT-rich genome of Plasmodium falciparum, chosen as a reference and reconstituted a substitution matrix in the genome's context. The matrix was used to generate protein sequence alignments for the parasite proteins that improved across the functional regions. We attribute this to the consistency that may have been achieved amid the target and background frequencies calculated exclusively in our study. This study has important implications on annotation of proteins that are of experimental interest but give poor sequence alignments with standard conventional matrices.},
  author       = {Paila, Umadevi and Kondam, Rohini and Ranjan, Akash},
  date         = {2008-12},
  doi          = {10.1093/nar/gkn635},
  eprint       = {18948281},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Paila et al_2008_Genome bias influences amino acid choices.pdf},
  issn         = {1362-4962},
  journaltitle = {Nucleic Acids Research},
  keywords     = {Amino Acid Sequence,Amino Acid Substitution,Animals,Aspartate-Ammonia Ligase,AT Rich Sequence,Codon,Cyclins,Databases; Protein,Genome; Protozoan,Genomics,HSP40 Heat-Shock Proteins,Plasmodium falciparum,Protozoan Proteins,Sequence Alignment,Sequence Analysis; Protein,Shikimic Acid,Thiamin Pyrophosphokinase},
  langid       = {english},
  number       = {21},
  pages        = {6664--6675},
  pmcid        = {PMC2588515},
  shortjournal = {Nucleic Acids Res},
  shorttitle   = {Genome Bias Influences Amino Acid Choices},
  title        = {Genome Bias Influences Amino Acid Choices: Analysis of Amino Acid Substitution and Re-Compilation of Substitution Matrices Exclusive to an {{AT-biased}} Genome},
  volume       = {36}
}

@article{paisAssessingEfficiencyMultiple2014,
  abstract     = {Multiple sequence alignment (MSA) is an extremely useful tool for molecular and evolutionary biology and there are several programs and algorithms available for this purpose. Although previous studies have compared the alignment accuracy of different MSA programs, their computational time and memory usage have not been systematically evaluated. Given the unprecedented amount of data produced by next generation deep sequencing platforms, and increasing demand for large-scale data analysis, it is imperative to optimize the application of software. Therefore, a balance between alignment accuracy and computational cost has become a critical indicator of the most suitable MSA program. We compared both accuracy and cost of nine popular MSA programs, namely CLUSTALW, CLUSTAL OMEGA, DIALIGN-TX, MAFFT, MUSCLE, POA, Probalign, Probcons and T-Coffee, against the benchmark alignment dataset BAliBASE and discuss the relevance of some implementations embedded in each program’s algorithm. Accuracy of alignment was calculated with the two standard scoring functions provided by BAliBASE, the sum-of-pairs and total-column scores, and computational costs were determined by collecting peak memory usage and time of execution.},
  author       = {Pais, Fabiano Sviatopolk-Mirsky and Ruy, Patrícia de Cássia and Oliveira, Guilherme and Coimbra, Roney Santos},
  date         = {2014-03-06},
  doi          = {10.1186/1748-7188-9-4},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Pais et al_2014_Assessing the efficiency of multiple sequence alignment programs.pdf},
  issn         = {1748-7188},
  journaltitle = {Algorithms for Molecular Biology},
  keywords     = {Accuracy,Computer programs,Multiple sequence alignment,Performance},
  langid       = {english},
  number       = {1},
  pages        = {4},
  shortjournal = {Algorithms Mol Biol},
  title        = {Assessing the Efficiency of Multiple Sequence Alignment Programs},
  url          = {https://doi.org/10.1186/1748-7188-9-4},
  urldate      = {2022-06-16},
  volume       = {9}
}

@incollection{pearson27DynamicProgramming1992,
  abstract  = {Efficient dynamic programming algorithms are available for a broad class of protein and DNA sequence comparison problems. These algorithms require computer time proportional to the product of the lengths of the two sequences being compared [O(N2)] but require memory space proportional only to the sum of these lengths [O(N)]. Although the requirement for O(N2) time limits use of the algorithms to the largest computers when searching protein and DNA sequence databases, many other applications of these algorithms, such as calculation of distances for evolutionary trees and comparison of a new sequence to a library of sequence profiles, are well within the capabilities of desktop computers. In particular, the results of library searches with rapid searching programs, such as FASTA2,48 or BLAST49, should be confirmed by performing a rigorous optimal alignment. Whereas rapid methods do not overlook significant sequence similarities,64 FASTA limits the number of gaps that can be inserted into an alignment, so that a rigorous alignment may extend the alignment substantially in some cases. BLAST does not allow gaps in the local regions that it reports; a calculation that allows gaps is very likely to extend the alignment substantially. Although a Monte Carlo evaluation of the statistical significance of a similarity score with a rigorous algorithm is much slower than the heuristic approach used by the RDF2 program,2 the dynamic programming approach should take less than 1 hr on a 386-based PC or desktop Unix workstation. For descriptive purposes, we have limited our discussion to methods for calculating similarity scores and distances that use gap penalties of the form g = rk. Nevertheless, programs for the more general case (g = q + rk) are readily available.9,23 Versions of these programs that run either on Unix workstations, IBM-PC class computers, or the Macintosh can be obtained from either of the authors.},
  author    = {Pearson, William R. and Miller, Webb},
  booktitle = {Methods in {{Enzymology}}},
  date      = {1992-01-01},
  doi       = {10.1016/0076-6879(92)10029-D},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Pearson_Miller_1992_[27] Dynamic programming algorithms for biological sequence comparison.pdf;/Users/lucblassel/Zotero/storage/YB2JQCHR/007668799210029D.html},
  langid    = {english},
  pages     = {575--601},
  publisher = {{Academic Press}},
  series    = {Numerical {{Computer Methods}}},
  title     = {[27] {{Dynamic}} Programming Algorithms for Biological Sequence Comparison},
  url       = {https://www.sciencedirect.com/science/article/pii/007668799210029D},
  urldate   = {2022-06-16},
  volume    = {210}
}

@article{pearsonImprovedToolsBiological1988,
  abstract     = {We have developed three computer programs for comparisons of protein and DNA sequences. They can be used to search sequence data bases, evaluate similarity scores, and identify periodic structures based on local sequence similarity. The FASTA program is a more sensitive derivative of the FASTP program, which can be used to search protein or DNA sequence data bases and can compare a protein sequence to a DNA sequence data base by translating the DNA data base as it is searched. FASTA includes an additional step in the calculation of the initial pairwise similarity score that allows multiple regions of similarity to be joined to increase the score of related sequences. The RDF2 program can be used to evaluate the significance of similarity scores using a shuffling method that preserves local sequence composition. The LFASTA program can display all the regions of local similarity between two sequences with scores greater than a threshold, using the same scoring parameters and a similar alignment algorithm; these local similarities can be displayed as a "graphic matrix" plot or as individual alignments. In addition, these programs have been generalized to allow comparison of DNA or protein sequences based on a variety of alternative scoring matrices.},
  author       = {Pearson, W. R. and Lipman, D. J.},
  date         = {1988-04},
  doi          = {10.1073/pnas.85.8.2444},
  eprint       = {3162770},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Pearson_Lipman_1988_Improved tools for biological sequence comparison.pdf},
  issn         = {0027-8424},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords     = {Amino Acid Sequence,Animals,Base Sequence,Globins,Humans,Information Systems,Molecular Sequence Data,Peptides,Receptors; Antigen; T-Cell,Sequence Homology; Nucleic Acid,Software,Transforming Growth Factors},
  langid       = {english},
  number       = {8},
  pages        = {2444--2448},
  pmcid        = {PMC280013},
  shortjournal = {Proc Natl Acad Sci U S A},
  title        = {Improved Tools for Biological Sequence Comparison},
  volume       = {85}
}

@article{pearsonSelectingRightSimilarityScoring2013,
  abstract     = {Protein sequence similarity searching programs like BLASTP, SSEARCH (UNIT 3.10), and FASTA use scoring matrices that are designed to identify distant evolutionary relationships (BLOSUM62 for BLAST, BLOSUM50 for SEARCH and FASTA). Different similarity scoring matrices are most effective at different evolutionary distances. "Deep" scoring matrices like BLOSUM62 and BLOSUM50 target alignments with 20 - 30\% identity, while "shallow" scoring matrices (e.g. VTML10 - VTML80), target alignments that share 90 - 50\% identity, reflecting much less evolutionary change. While "deep" matrices provide very sensitive similarity searches, they also require longer sequence alignments and can sometimes produce alignment overextension into non-homologous regions. Shallower scoring matrices are more effective when searching for short protein domains, or when the goal is to limit the scope of the search to sequences that are likely to be orthologous between recently diverged organisms. Likewise, in DNA searches, the match and mismatch parameters set evolutionary look-back times and domain boundaries. In this unit, we will discuss the theoretical foundations that drive practical choices of protein and DNA similarity scoring matrices and gap penalties. Deep scoring matrices (BLOSUM62 and BLOSUM50) should be used for sensitive searches with full-length protein sequences, but short domains or restricted evolutionary look-back require shallower scoring matrices.},
  author       = {Pearson, William R.},
  date         = {2013},
  doi          = {10.1002/0471250953.bi0305s43},
  eprint       = {24509512},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/pearson_2013_selecting_the_right_similarity-scoring_matrix.pdf},
  issn         = {1934-340X},
  journaltitle = {Current Protocols in Bioinformatics},
  keywords     = {Amino Acid Sequence,Amino Acid Substitution,BLOSUM matrices,DNA,Molecular Sequence Data,PAM matrices,Position-Specific Scoring Matrices,sequence alignment,Sequence Alignment,Sequence Homology; Amino Acid,similarity scoring matrices},
  langid       = {english},
  pages        = {3.5.1-9},
  pmcid        = {PMC3848038},
  shortjournal = {Curr Protoc Bioinformatics},
  title        = {Selecting the {{Right Similarity-Scoring Matrix}}},
  volume       = {43}
}

@article{priceFastTreeApproximatelyMaximumLikelihood2010,
  abstract     = {Background We recently described FastTree, a tool for inferring phylogenies for alignments with up to hundreds of thousands of sequences. Here, we describe improvements to FastTree that improve its accuracy without sacrificing scalability. Methodology/Principal Findings Where FastTree 1 used nearest-neighbor interchanges (NNIs) and the minimum-evolution criterion to improve the tree, FastTree 2 adds minimum-evolution subtree-pruning-regrafting (SPRs) and maximum-likelihood NNIs. FastTree 2 uses heuristics to restrict the search for better trees and estimates a rate of evolution for each site (the “CAT” approximation). Nevertheless, for both simulated and genuine alignments, FastTree 2 is slightly more accurate than a standard implementation of maximum-likelihood NNIs (PhyML 3 with default settings). Although FastTree 2 is not quite as accurate as methods that use maximum-likelihood SPRs, most of the splits that disagree are poorly supported, and for large alignments, FastTree 2 is 100–1,000 times faster. FastTree 2 inferred a topology and likelihood-based local support values for 237,882 distinct 16S ribosomal RNAs on a desktop computer in 22 hours and 5.8 gigabytes of memory. Conclusions/Significance FastTree 2 allows the inference of maximum-likelihood phylogenies for huge alignments. FastTree 2 is freely available at http://www.microbesonline.org/fasttree.},
  author       = {Price, Morgan N. and Dehal, Paramvir S. and Arkin, Adam P.},
  date         = {2010-03-10},
  doi          = {10.1371/journal.pone.0009490},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/price_et_al_2010_fasttree_2_–_approximately_maximum-likelihood.pdf;/Users/lucblassel/Zotero/storage/MKE6Q5PQ/article.html},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Biochemical simulations,Biophysical simulations,Evolutionary rate,Multiple alignment calculation,Phylogenetic analysis,Protein structure comparison,Ribosomal RNA,Sequence alignment},
  langid       = {english},
  number       = {3},
  pages        = {e9490},
  shortjournal = {PLOS ONE},
  title        = {{{FastTree}} 2 – {{Approximately Maximum-Likelihood Trees}} for {{Large Alignments}}},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009490},
  urldate      = {2018-12-11},
  volume       = {5}
}

@article{priceFastTreeApproximatelyMaximumLikelihood2010a,
  abstract     = {Background We recently described FastTree, a tool for inferring phylogenies for alignments with up to hundreds of thousands of sequences. Here, we describe improvements to FastTree that improve its accuracy without sacrificing scalability. Methodology/Principal Findings Where FastTree 1 used nearest-neighbor interchanges (NNIs) and the minimum-evolution criterion to improve the tree, FastTree 2 adds minimum-evolution subtree-pruning-regrafting (SPRs) and maximum-likelihood NNIs. FastTree 2 uses heuristics to restrict the search for better trees and estimates a rate of evolution for each site (the “CAT” approximation). Nevertheless, for both simulated and genuine alignments, FastTree 2 is slightly more accurate than a standard implementation of maximum-likelihood NNIs (PhyML 3 with default settings). Although FastTree 2 is not quite as accurate as methods that use maximum-likelihood SPRs, most of the splits that disagree are poorly supported, and for large alignments, FastTree 2 is 100–1,000 times faster. FastTree 2 inferred a topology and likelihood-based local support values for 237,882 distinct 16S ribosomal RNAs on a desktop computer in 22 hours and 5.8 gigabytes of memory. Conclusions/Significance FastTree 2 allows the inference of maximum-likelihood phylogenies for huge alignments. FastTree 2 is freely available at http://www.microbesonline.org/fasttree.},
  author       = {Price, Morgan N. and Dehal, Paramvir S. and Arkin, Adam P.},
  date         = {2010-03-10},
  doi          = {10.1371/journal.pone.0009490},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Price et al_2010_FastTree 2 – Approximately Maximum-Likelihood Trees for Large Alignments.pdf;/Users/lucblassel/Zotero/storage/2ZEM5YL6/article.html},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Animal phylogenetics,Biochemical simulations,Biophysical simulations,Evolutionary rate,Phylogenetic analysis,Protein structure comparison,Ribosomal RNA,Sequence alignment},
  langid       = {english},
  number       = {3},
  pages        = {e9490},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS ONE},
  title        = {{{FastTree}} 2 – {{Approximately Maximum-Likelihood Trees}} for {{Large Alignments}}},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0009490},
  urldate      = {2022-06-14},
  volume       = {5}
}

@incollection{prjibelskiSequenceAnalysis2019,
  author    = {Prjibelski, Andrey D. and Korobeynikov, Anton I. and Lapidus, Alla L.},
  booktitle = {Encyclopedia of {{Bioinformatics}} and {{Computational Biology}}},
  date      = {2019},
  doi       = {10.1016/B978-0-12-809633-8.20106-4},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Prjibelski et al_2019_Sequence Analysis.pdf},
  isbn      = {978-0-12-811432-2},
  langid    = {english},
  pages     = {292--322},
  publisher = {{Elsevier}},
  title     = {Sequence {{Analysis}}},
  url       = {https://linkinghub.elsevier.com/retrieve/pii/B9780128096338201064},
  urldate   = {2022-06-14}
}

@article{prodanovSensitiveAlignmentUsing2020a,
  abstract     = {The ability to characterize repetitive regions of the human genome is limited by the read lengths of short-read sequencing technologies. Although long-read sequencing technologies such as Pacific Biosciences (PacBio)~and Oxford Nanopore Technologies can potentially overcome this limitation, long segmental duplications with high sequence identity pose challenges for long-read mapping. We describe a probabilistic method, DuploMap, designed to improve the accuracy of long-read mapping in segmental duplications. It analyzes reads mapped to segmental duplications using existing long-read aligners and leverages paralogous sequence variants (PSVs)-sequence differences between paralogous sequences-to distinguish between multiple alignment locations. On simulated datasets, DuploMap increased the percentage of correctly mapped reads with high confidence for multiple long-read aligners including Minimap2 (74.3-90.6\%) and BLASR (82.9-90.7\%) while maintaining high precision. Across multiple whole-genome long-read datasets, DuploMap aligned an additional 8-21\% of the reads in segmental duplications with high confidence relative to Minimap2. Using DuploMap-aligned PacBio circular consensus sequencing reads, an additional 8.9 Mb of DNA sequence was mappable, variant calling achieved a higher F1~score and 14~713 additional variants supported by linked-read data were identified. Finally, we demonstrate that a significant fraction of PSVs in segmental duplications overlaps with variants and adversely impacts short-read variant calling.},
  author       = {Prodanov, Timofey and Bansal, Vikas},
  date         = {2020-11-04},
  doi          = {10.1093/nar/gkaa829},
  eprint       = {33035301},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Prodanov_Bansal_2020_Sensitive alignment using paralogous sequence variants improves long-read2.pdf},
  issn         = {1362-4962},
  journaltitle = {Nucleic Acids Research},
  keywords     = {Algorithms,Databases; Genetic,Datasets as Topic,Genome; Human,High-Throughput Nucleotide Sequencing,Humans,Segmental Duplications; Genomic,Sequence Analysis; DNA,Software},
  langid       = {english},
  number       = {19},
  pages        = {e114},
  pmcid        = {PMC7641771},
  shortjournal = {Nucleic Acids Res},
  title        = {Sensitive Alignment Using Paralogous Sequence Variants Improves Long-Read Mapping and Variant Calling in Segmental Duplications},
  volume       = {48}
}

@article{riceEMBOSSEuropeanMolecular2000,
  author       = {Rice, Peter and Longden, Ian and Bleasby, Alan},
  date         = {2000},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Rice et al_2000_EMBOSS.pdf},
  ids          = {riceEMBOSSEuropeanMolecular},
  journaltitle = {Trends in genetics},
  number       = {6},
  pages        = {276--277},
  publisher    = {{Elsevier current trends}},
  title        = {{{EMBOSS}}: The {{European}} Molecular Biology Open Software Suite},
  volume       = {16}
}

@article{robertsReducingStorageRequirements2004,
  abstract     = {Motivation: Comparison of nucleic acid and protein sequences is a fundamental tool of modern bioinformatics. A dominant method of such string matching is the ‘seed-and-extend’ approach, in which occurrences of short subsequences called ‘seeds’ are used to search for potentially longer matches in a large database of sequences. Each such potential match is then checked to see if it extends beyond the seed. To be effective, the seed-and-extend approach needs to catalogue seeds from virtually every substring in the database of search strings. Projects such as mammalian genome assemblies and large-scale protein matching, however, have such large sequence databases that the resulting list of seeds cannot be stored in RAM on a single computer. This significantly slows the matching process.Results: We present a simple and elegant method in which only a small fraction of seeds, called ‘minimizers’, needs to be stored. Using minimizers can speed up string-matching computations by a large factor while missing only a small fraction of the matches found using all seeds.},
  author       = {Roberts, Michael and Hayes, Wayne and Hunt, Brian R. and Mount, Stephen M. and Yorke, James A.},
  date         = {2004-12-12},
  doi          = {10.1093/bioinformatics/bth408},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Roberts et al_2004_Reducing storage requirements for biological sequence comparison.pdf},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {18},
  pages        = {3363--3369},
  shortjournal = {Bioinformatics},
  title        = {Reducing Storage Requirements for Biological Sequence Comparison},
  url          = {https://doi.org/10.1093/bioinformatics/bth408},
  urldate      = {2022-09-05},
  volume       = {20}
}

@article{ruffaloAccurateEstimationShort2012,
  abstract     = {Motivation: Several software tools specialize in the alignment of short next-generation sequencing reads to a reference sequence. Some of these tools report a mapping quality score for each alignment—in principle, this quality score tells researchers the likelihood that the alignment is correct. However, the reported mapping quality often correlates weakly with actual accuracy and the qualities of many mappings are underestimated, encouraging the researchers to discard correct mappings. Further, these low-quality mappings tend to correlate with variations in the genome (both single nucleotide and structural), and such mappings are important in accurately identifying genomic variants.Approach: We develop a machine learning tool, LoQuM (LOgistic regression tool for calibrating the Quality of short read mappings, to assign reliable mapping quality scores to mappings of Illumina reads returned by any alignment tool. LoQuM uses statistics on the read (base quality scores reported by the sequencer) and the alignment (number of matches, mismatches and deletions, mapping quality score returned by the alignment tool, if available, and number of mappings) as features for classification and uses simulated reads to learn a logistic regression model that relates these features to actual mapping quality.Results: We test the predictions of LoQuM on an independent dataset generated by the ART short read simulation software and observe that LoQuM can ‘resurrect’ many mappings that are assigned zero quality scores by the alignment tools and are therefore likely to be discarded by researchers. We also observe that the recalibration of mapping quality scores greatly enhances the precision of called single nucleotide polymorphisms.Availability: LoQuM is available as open source at http://compbio.case.edu/loqum/.Contact:matthew.ruffalo@case.edu.},
  author       = {Ruffalo, Matthew and Koyutürk, Mehmet and Ray, Soumya and LaFramboise, Thomas},
  date         = {2012-09-15},
  doi          = {10.1093/bioinformatics/bts408},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ruffalo et al_2012_Accurate estimation of short read mapping quality for next-generation genome.pdf;/Users/lucblassel/Zotero/storage/DI4ZIIGX/249968.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {18},
  pages        = {i349-i355},
  shortjournal = {Bioinformatics},
  title        = {Accurate Estimation of Short Read Mapping Quality for Next-Generation Genome Sequencing},
  url          = {https://doi.org/10.1093/bioinformatics/bts408},
  urldate      = {2022-09-06},
  volume       = {28}
}

@article{ruffaloComparativeAnalysisAlgorithms2011,
  abstract     = {MOTIVATION: The advent of next-generation sequencing (NGS) techniques presents many novel opportunities for many applications in life sciences. The vast number of short reads produced by these techniques, however, pose significant computational challenges. The first step in many types of genomic analysis is the mapping of short reads to a reference genome, and several groups have developed dedicated algorithms and software packages to perform this function. As the developers of these packages optimize their algorithms with respect to various considerations, the relative merits of different software packages remain unclear. However, for scientists who generate and use NGS data for their specific research projects, an important consideration is choosing the software that is most suitable for their application. RESULTS: With a view to comparing existing short read alignment software, we develop a simulation and evaluation suite, Seal, which simulates NGS runs for different configurations of various factors, including sequencing error, indels and coverage. We also develop criteria to compare the performances of software with disparate output structure (e.g. some packages return a single alignment while some return multiple possible alignments). Using these criteria, we comprehensively evaluate the performances of Bowtie, BWA, mr- and mrsFAST, Novoalign, SHRiMP and SOAPv2, with regard to accuracy and runtime. CONCLUSION: We expect that the results presented here will be useful to investigators in choosing the alignment software that is most suitable for their specific research aims. Our results also provide insights into the factors that should be considered to use alignment results effectively. Seal can also be used to evaluate the performance of algorithms that use deep sequencing data for various purposes (e.g. identification of genomic variants). AVAILABILITY: Seal is available as open source at http://compbio.case.edu/seal/. CONTACT: matthew.ruffalo@case.edu SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
  author       = {Ruffalo, Matthew and LaFramboise, Thomas and Koyutürk, Mehmet},
  date         = {2011-10-15},
  doi          = {10.1093/bioinformatics/btr477},
  eprint       = {21856737},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ruffalo et al_2011_Comparative analysis of algorithms for next-generation sequencing read alignment.pdf},
  issn         = {1367-4811},
  journaltitle = {Bioinformatics (Oxford, England)},
  keywords     = {Algorithms,Genome; Human,Genomics,High-Throughput Nucleotide Sequencing,Humans,INDEL Mutation,Sequence Alignment,Software},
  langid       = {english},
  number       = {20},
  pages        = {2790--2796},
  shortjournal = {Bioinformatics},
  title        = {Comparative Analysis of Algorithms for Next-Generation Sequencing Read Alignment},
  volume       = {27}
}

@book{russellMultipleSequenceAlignment2014,
  date      = {2014},
  doi       = {10.1007/978-1-62703-646-7},
  editor    = {Russell, David J},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Russell_2014_Multiple Sequence Alignment Methods.pdf},
  isbn      = {978-1-62703-645-0 978-1-62703-646-7},
  langid    = {english},
  location  = {{Totowa, NJ}},
  publisher = {{Humana Press}},
  series    = {Methods in {{Molecular Biology}}},
  title     = {Multiple {{Sequence Alignment Methods}}},
  url       = {http://link.springer.com/10.1007/978-1-62703-646-7},
  urldate   = {2022-06-16},
  volume    = {1079}
}

@article{sahlinEffectiveSequenceSimilarity2021,
  abstract     = {k-mer-based methods are widely used in bioinformatics for various types of sequence comparisons. However, a single mutation will mutate k consecutive k-mers and make most k-mer-based applications for sequence comparison sensitive to variable mutation rates. Many techniques have been studied to overcome this sensitivity, for example, spaced k-mers and k-mer permutation techniques, but these techniques do not handle indels well. For indels, pairs or groups of small k-mers are commonly used, but these methods first produce k-mer matches, and only in a second step, a pairing or grouping of k-mers is performed. Such techniques produce many redundant k-mer matches owing to the size of k. Here, we propose strobemers as an alternative to k-mers for sequence comparison. Intuitively, strobemers consist of two or more linked shorter k-mers, where the combination of linked k-mers is decided by a hash function. We use simulated data to show that strobemers provide more evenly distributed sequence matches and are less sensitive to different mutation rates than k-mers and spaced k-mers. Strobemers also produce higher match coverage across sequences. We further implement a proof-of-concept sequence-matching tool StrobeMap and use synthetic and biological Oxford Nanopore sequencing data to show the utility of using strobemers for sequence comparison in different contexts such as sequence clustering and alignment scenarios.},
  author       = {Sahlin, Kristoffer},
  date         = {2021-01-11},
  doi          = {10.1101/gr.275648.121},
  eprint       = {34667119},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sahlin_2021_Effective sequence similarity detection with strobemers.pdf;/Users/lucblassel/Zotero/storage/N2WGJVXX/2080.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {11},
  pages        = {2080--2094},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  title        = {Effective Sequence Similarity Detection with Strobemers},
  url          = {https://genome.cshlp.org/content/31/11/2080},
  urldate      = {2022-09-05},
  volume       = {31}
}

@misc{sahlinFlexibleSeedSize2022,
  abstract  = {Read alignment to genomes is a fundamental computational step used in many bioinformatic analyses, and often, it is the computational bottleneck. Therefore, it is desirable to perform the alignment step as fast as possible without compromising accuracy. Most alignment algorithms consider a seed-and-extend approach, where the time-consuming seeding step identifies and decides on candidate mapping locations. Recently, several advances have been made on seeding methods for fast sequence comparison. We combine two such methods, syncmers and strobemers, in a novel seeding approach for constructing dynamic-sized fuzzy seeds and implement the method in a short-read aligner, strobealign. Firstly, we show that our seeding is fast to construct and effectively reduces repetitiveness in the seeding step using a novel metric E-hits. Secondly, we benchmark strobealign to traditional and recently proposed aligners on simulated and biological data and show that strobealign is several times faster than traditional aligners such as BWA and Bowtie2 at similar and sometimes higher accuracy while being both faster and more accurate than more recently proposed aligners. Our aligner can free up substantial time and computing resources needed for read alignment in many pipelines. Availability https://github.com/ksahlin/strobealign.},
  author    = {Sahlin, Kristoffer},
  date      = {2022-05-25},
  doi       = {10.1101/2021.06.18.449070},
  file      = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sahlin_2022_Flexible seed size enables ultra-fast and accurate read alignment.pdf;/Users/lucblassel/Zotero/storage/CYDUSDXB/2021.06.18.449070v4.html},
  langid    = {english},
  pages     = {2021.06.18.449070},
  publisher = {{bioRxiv}},
  title     = {Flexible Seed Size Enables Ultra-Fast and Accurate Read Alignment},
  url       = {https://www.biorxiv.org/content/10.1101/2021.06.18.449070v4},
  urldate   = {2022-09-05}
}

@article{saitouNeighborjoiningMethodNew1987,
  abstract     = {A new method called the neighbor-joining method is proposed for reconstructing phylogenetic trees from evolutionary distance data. The principle of this method is to find pairs of operational taxonomic units (OTUs [= neighbors]) that minimize the total branch length at each stage of clustering of OTUs starting with a starlike tree. The branch lengths as well as the topology of a parsimonious tree can quickly be obtained by using this method. Using computer simulation, we studied the efficiency of this method in obtaining the correct unrooted tree in comparison with that of five other tree-making methods: the unweighted pair group method of analysis, Farris's method, Sattath and Tversky's method, Li's method, and Tateno et al.'s modified Farris method. The new, neighbor-joining method and Sattath and Tversky's method are shown to be generally better than the other methods.},
  author       = {Saitou, N and Nei, M},
  date         = {1987-07-01},
  doi          = {10.1093/oxfordjournals.molbev.a040454},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Saitou_Nei_1987_The neighbor-joining method.pdf;/Users/lucblassel/Zotero/storage/Y3Y8SD47/1029664.html},
  issn         = {0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  number       = {4},
  pages        = {406--425},
  shortjournal = {Molecular Biology and Evolution},
  shorttitle   = {The Neighbor-Joining Method},
  title        = {The Neighbor-Joining Method: A New Method for Reconstructing Phylogenetic Trees.},
  url          = {https://doi.org/10.1093/oxfordjournals.molbev.a040454},
  urldate      = {2022-09-06},
  volume       = {4}
}

@article{salmelaCorrectingErrorsShort2011,
  abstract     = {Motivation: Current sequencing technologies produce a large number of erroneous reads. The sequencing errors present a major challenge in utilizing the data in de novo sequencing projects as assemblers have difficulties in dealing with errors.Results: We present Coral which corrects sequencing errors by forming multiple alignments. Unlike previous tools for error correction, Coral can utilize also bases distant from the error in the correction process because the whole read is present in the alignment. Coral is easily adjustable to reads produced by different sequencing technologies like Illumina Genome Analyzer and Roche/454 Life Sciences sequencing platforms because the sequencing error model can be defined by the user. We show that our method is able to reduce the error rate of reads more than previous methods.Availability: The source code of Coral is freely available at http://www.cs.helsinki.fi/u/lmsalmel/coral/.Contact:leena.salmela@cs.helsinki.fi},
  author       = {Salmela, Leena and Schröder, Jan},
  date         = {2011-06-01},
  doi          = {10.1093/bioinformatics/btr170},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Salmela_Schröder_2011_Correcting errors in short reads by multiple alignments.pdf;/Users/lucblassel/Zotero/storage/Y7XE3BUL/217071.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {11},
  pages        = {1455--1461},
  shortjournal = {Bioinformatics},
  title        = {Correcting Errors in Short Reads by Multiple Alignments},
  url          = {https://doi.org/10.1093/bioinformatics/btr170},
  urldate      = {2022-06-14},
  volume       = {27}
}

@article{sardiuScoreStatisticsGlobal2005,
  abstract     = {Sequence alignment is one of the most important bioinformatics tools for modern molecular biology. The statistical characterization of gapped alignment scores has been a long-standing problem in sequence alignment research. Using a variant of the directed path in random media model, we investigate the score statistics of global sequence alignment taking into account, in particular, the compositional bias of the sequences compared. Such statistics are used to distinguish accidental similarity due to compositional similarity from biologically significant similarity. To accommodate the compositional bias, we introduce an extra parameter p indicating the probability for positive matching scores to occur. When p is small, a high scoring alignment obviously cannot come from compositional similarity. When p is large, the highest scoring point within a global alignment tends to be close to the end of both sequences, in which case we say the system percolates. By applying finite-size scaling theory on percolating probability functions of various sizes (sequence lengths), the critical p at infinite size is obtained. For alignment of length t, the fact that the score fluctuation grows as chi(t)1/3 is confirmed upon investigating the scaling form of the alignment score. Using the Kolmogorov-Smirnov statistics test, we show that the random variable , if properly scaled, follows the Tracy-Widom distributions: Gaussian orthogonal ensemble for p slightly larger than pc and Gaussian unitary ensemble for larger p. Although these results deepen our understanding of the distribution of alignment scores, the use of these results in practical applications remains somewhat heuristic and needs to be further developed. Nevertheless, the possibility of characterizing score statistics for modest system size (sequence lengths), via proper reparametrization of alignment scores, is illustrated.},
  author       = {Sardiu, Mihaela E. and Alves, Gelio and Yu, Yi-Kuo},
  date         = {2005-12},
  doi          = {10.1103/PhysRevE.72.061917},
  eprint       = {16485984},
  eprinttype   = {pmid},
  issn         = {1539-3755},
  issue        = {6 Pt 1},
  journaltitle = {Physical Review. E},
  keywords     = {Algorithms,Biopolymers,Computer Simulation,Models; Chemical,Models; Statistical,Sequence Alignment,Sequence Analysis},
  langid       = {english},
  pages        = {061917},
  shortjournal = {Phys Rev E Stat Nonlin Soft Matter Phys},
  title        = {Score Statistics of Global Sequence Alignment from the Energy Distribution of a Modified Directed Polymer and Directed Percolation Problem},
  volume       = {72}
}

@article{saripellaBenchmarkingNextGeneration2016,
  abstract     = {Motivation: Over the last decades, vast numbers of sequences were deposited in public databases. Bioinformatics tools allow homology and consequently functional inference for these sequences. New profile-based homology search tools have been introduced, ...},
  author       = {Saripella, Ganapathi Varma and Sonnhammer, Erik L. L. and Forslund, Kristoffer},
  date         = {2016-09-09},
  doi          = {10.1093/bioinformatics/btw305},
  eprint       = {27256311},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Saripella et al_2016_Benchmarking the next generation of homology inference tools.pdf;/Users/lucblassel/Zotero/storage/5RX7VM2V/PMC5013910.html},
  journaltitle = {Bioinformatics},
  langid       = {english},
  number       = {17},
  pages        = {2636},
  publisher    = {{Oxford University Press}},
  title        = {Benchmarking the next Generation of Homology Inference Tools},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5013910/},
  urldate      = {2022-06-15},
  volume       = {32}
}

@article{schbathMappingReadsGenomic2012,
  abstract     = {Mapping short reads against a reference genome is classically the first step of many next-generation sequencing data analyses, and it should be as accurate as possible. Because of the large number of reads to handle, numerous sophisticated algorithms have been developped in the last 3 years to tackle this problem. In this article, we first review the underlying algorithms used in most of the existing mapping tools, and then we compare the performance of nine of these tools on a well controled benchmark built for this purpose. We built a set of reads that exist in single or multiple copies in a reference genome and for which there is no mismatch, and a set of reads with three mismatches. We considered as reference genome both the human genome and a concatenation of all complete bacterial genomes. On each dataset, we quantified the capacity of the different tools to retrieve all the occurrences of the reads in the reference genome. Special attention was paid to reads uniquely reported and to reads with multiple hits.},
  author       = {Schbath, Sophie and Martin, Véronique and Zytnicki, Matthias and Fayolle, Julien and Loux, Valentin and Gibrat, Jean-François},
  date         = {2012-06},
  doi          = {10.1089/cmb.2012.0022},
  eprint       = {22506536},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Schbath et al_2012_Mapping Reads on a Genomic Sequence.pdf},
  issn         = {1066-5277},
  journaltitle = {Journal of Computational Biology},
  number       = {6},
  pages        = {796--813},
  pmcid        = {PMC3375638},
  shortjournal = {J Comput Biol},
  shorttitle   = {Mapping {{Reads}} on a {{Genomic Sequence}}},
  title        = {Mapping {{Reads}} on a {{Genomic Sequence}}: {{An Algorithmic Overview}} and a {{Practical Comparative Analysis}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3375638/},
  urldate      = {2022-06-15},
  volume       = {19}
}

@inproceedings{schleimerWinnowingLocalAlgorithms2003,
  abstract   = {Digital content is for copying: quotation, revision, plagiarism, and file sharing all create copies. Document fingerprinting is concerned with accurately identifying copying, including small partial copies, within large sets of documents.We introduce the class of local document fingerprinting algorithms, which seems to capture an essential property of any finger-printing technique guaranteed to detect copies. We prove a novel lower bound on the performance of any local algorithm. We also develop winnowing, an efficient local fingerprinting algorithm, and show that winnowing's performance is within 33\% of the lower bound. Finally, we also give experimental results on Web data, and report experience with MOSS, a widely-used plagiarism detection service.},
  author     = {Schleimer, Saul and Wilkerson, Daniel S. and Aiken, Alex},
  booktitle  = {Proceedings of the 2003 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  date       = {2003-06-09},
  doi        = {10.1145/872757.872770},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Schleimer et al_2003_Winnowing.pdf},
  isbn       = {978-1-58113-634-0},
  location   = {{New York, NY, USA}},
  pages      = {76--85},
  publisher  = {{Association for Computing Machinery}},
  series     = {{{SIGMOD}} '03},
  shorttitle = {Winnowing},
  title      = {Winnowing: Local Algorithms for Document Fingerprinting},
  url        = {https://doi.org/10.1145/872757.872770},
  urldate    = {2022-09-05}
}

@article{schwartzHumanMouseAlignments2003,
  abstract     = {The Mouse Genome Analysis Consortium aligned the human and mouse genome sequences for a variety of purposes, using alignment programs that suited the various needs. For investigating issues regarding genome evolution, a particularly sensitive method was needed to permit alignment of a large proportion of the neutrally evolving regions. We selected a program called BLASTZ, an independent implementation of the Gapped BLAST algorithm specifically designed for aligning two long genomic sequences. BLASTZ was subsequently modified, both to attain efficiency adequate for aligning entire mammalian genomes and to increase its sensitivity. This work describes BLASTZ, its modifications, the hardware environment on which we run it, and several empirical studies to validate its results.},
  author       = {Schwartz, Scott and Kent, W. James and Smit, Arian and Zhang, Zheng and Baertsch, Robert and Hardison, Ross C. and Haussler, David and Miller, Webb},
  date         = {2003-01-01},
  doi          = {10.1101/gr.809403},
  eprint       = {12529312},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Schwartz et al_2003_Human–Mouse Alignments with BLASTZ.pdf;/Users/lucblassel/Zotero/storage/EAK7W27Q/103.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {1},
  pages        = {103--107},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  title        = {Human–{{Mouse Alignments}} with {{BLASTZ}}},
  url          = {https://genome.cshlp.org/content/13/1/103},
  urldate      = {2022-09-02},
  volume       = {13}
}

@article{sedlazeckAccurateDetectionComplex2018,
  abstract     = {Structural variations are the greatest source of genetic variation, but they remain poorly understood because of technological limitations. Single-molecule long-read sequencing has the potential to dramatically advance the field, although high error rates are a challenge with existing methods. Addressing this need, we introduce open-source methods for long-read alignment (NGMLR; https://github.com/philres/ngmlr) and structural variant identification (Sniffles; https://github.com/fritzsedlazeck/Sniffles) that provide unprecedented sensitivity and precision for variant detection, even in repeat-rich regions and for complex nested events that can have substantial effects on human health. In several long-read datasets, including healthy and cancerous human genomes, we discovered thousands of novel variants and categorized systematic errors in short-read approaches. NGMLR and Sniffles can automatically filter false events and operate on low-coverage data, thereby reducing the high costs that have hindered the application of long reads in clinical and research settings.},
  author       = {Sedlazeck, Fritz J. and Rescheneder, Philipp and Smolka, Moritz and Fang, Han and Nattestad, Maria and von Haeseler, Arndt and Schatz, Michael C.},
  date         = {2018-06},
  doi          = {10.1038/s41592-018-0001-7},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sedlazeck et al_2018_Accurate detection of complex structural variations using single-molecule.pdf;/Users/lucblassel/Zotero/storage/54S8GDTB/s41592-018-0001-7.html},
  issn         = {1548-7105},
  issue        = {6},
  journaltitle = {Nature Methods},
  keywords     = {Genome informatics,Software,Structural variation},
  langid       = {english},
  number       = {6},
  options      = {useprefix=true},
  pages        = {461--468},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Accurate Detection of Complex Structural Variations Using Single-Molecule Sequencing},
  url          = {https://www.nature.com/articles/s41592-018-0001-7},
  urldate      = {2022-06-17},
  volume       = {15}
}

@article{shpaerSensitivitySelectivityProtein1996,
  abstract     = {To predict the functions of a possible protein product of any new or uncharacterized DNA sequence, it is important first to detect all significant similarities between the encoded amino acid sequence and any accumulated protein sequence data. We have implemented a set of queries and database sequences and proceeded to test and compare various similarity search methods and their parameterizations. We demonstrate here that the Smith–Waterman (S-W) dynamic programming method and the optimized version of FASTA are significantly better able to distinguish true similarities from statistical noise than is the popular database search tool BLAST. Also, a simple “log-length normalization” of S-W scores based on the query and target sequence lengths greatly increased the selectivity of the S-W searches, exceeding the default normalization method of FASTA. An implementation of the modified S-W algorithm in hardware (the Fast Data Finder) is able to match the accuracy of software versions while greatly speeding up its execution. We present here the selectivity and sensitivity data from these tests as well as results for various scoring matrices. We present data that will help users to choose threshold score values for evaluation of database search results. We also illustrate the impact of using simple-sequence masking tools such as SEG or XNU.},
  author       = {Shpaer, Eugene G. and Robinson, Max and Yee, David and Candlin, James D. and Mines, Robert and Hunkapiller, Tim},
  date         = {1996-12-01},
  doi          = {10.1006/geno.1996.0614},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Shpaer et al_1996_Sensitivity and Selectivity in Protein Similarity Searches.pdf;/Users/lucblassel/Zotero/storage/TDEZ9LHC/S088875439690614X.html},
  ids          = {shpaerSensitivitySelectivityProtein1996a},
  issn         = {0888-7543},
  journaltitle = {Genomics},
  langid       = {english},
  number       = {2},
  pages        = {179--191},
  shortjournal = {Genomics},
  shorttitle   = {Sensitivity and {{Selectivity}} in {{Protein Similarity Searches}}},
  title        = {Sensitivity and {{Selectivity}} in {{Protein Similarity Searches}}: {{A Comparison}} of {{Smith}}–{{Waterman}} in {{Hardware}} to {{BLAST}} and {{FASTA}}},
  url          = {https://www.sciencedirect.com/science/article/pii/S088875439690614X},
  urldate      = {2022-06-15},
  volume       = {38}
}

@article{sieversFastScalableGeneration2011,
  author       = {Sievers, Fabian and Wilm, Andreas and Dineen, David and Gibson, Toby J and Karplus, Kevin and Li, Weizhong and Lopez, Rodrigo and McWilliam, Hamish and Remmert, Michael and Söding, Johannes and Thompson, Julie D and Higgins, Desmond G},
  date         = {2011-01},
  doi          = {10.1038/msb.2011.75},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sievers et al_2011_Fast, scalable generation of high‐quality protein multiple sequence alignments.pdf},
  issn         = {1744-4292, 1744-4292},
  journaltitle = {Molecular Systems Biology},
  langid       = {english},
  number       = {1},
  pages        = {539},
  shortjournal = {Mol Syst Biol},
  title        = {Fast, Scalable Generation of High‐quality Protein Multiple Sequence Alignments Using {{Clustal Omega}}},
  url          = {https://onlinelibrary.wiley.com/doi/10.1038/msb.2011.75},
  urldate      = {2022-09-06},
  volume       = {7}
}

@inproceedings{singhRegularPaperDetection2018,
  abstract   = {Whole-genome multiple alignments are widely used in genomics and evolution, and yet their accuracy is imperfect, due in part to the computational complexity of the task at hand. Identifying portions of these alignments that are likely to be incorrect would allow researchers to either work on improving them or flagging them for exclusion from downstream analyses. We introduce MSA-ED, a machine learning tool for the detection of errors in whole-genome multiple alignments. MSA-ED uses random forests or artificial neural networks to identify and classify several types of alignment errors. It is trained on labeled data obtained by using an evolution simulator to generate fake orthologous sequences and their correct alignment, and comparing it to the alignment produced by Multiz, a popular whole-genome aligner. Key to the success of MSA-ED is the engineering of several types of evolutionarily-inspired features that boost prediction accuracy. MSA-ED is shown to be able to detect certain types of errors with good accuracy. It is then applied to actual genomic alignments to identify putative alignment errors.},
  author     = {Singh, J. and Ramakrishnan, R. Kinattinkara and Blanchette, M.},
  booktitle  = {2018 {{IEEE}} 18th {{International Conference}} on {{Bioinformatics}} and {{Bioengineering}} ({{BIBE}})},
  date       = {2018-10},
  doi        = {10.1109/BIBE.2018.00017},
  eventtitle = {2018 {{IEEE}} 18th {{International Conference}} on {{Bioinformatics}} and {{Bioengineering}} ({{BIBE}})},
  file       = {/Users/lucblassel/Zotero/storage/WQX73T6G/8567456.html},
  keywords   = {actual genomic alignments,Bioinformatics,bioinformatics; machine learning; evolution; multiple sequence alignment; artificial neural networks,biology computing,error detection,genomics,Genomics,Machine learning,machine learning approaches,MSA-ED,multigenome alignments,neural nets,Phylogeny,putative alignment errors,random forests,Task analysis,Tools,Vegetation,whole-genome aligner,whole-genome multiple alignments},
  pages      = {47--53},
  title      = {[{{Regular Paper}}] {{Detection}} of {{Errors}} in {{Multi-genome Alignments Using Machine Learning Approaches}}}
}

@article{smithIdentificationCommonMolecular1981,
  abstract     = {Drug-target interaction (DTI) prediction performs a crucial part in drug discovery and design. Although many computational approaches for such prediction have been proposed, current researches still generally adopt chemical similarities of drugs or the sequence similarities of targets. However, the valuable information of known interactions has not been noticed, and the existing noise and useless information reduce the accuracy of DTI prediction. In addition, many existing computational approaches ignore the behavior information between nodes of the DTI network. In this paper, we develop an ensemble computational approach called integrated multi-similarity fusion and heterogeneous graph inference. First, based on the known DTI network, the degree distribution of drug and target similarities are analyzed and the noise and useless information are removed to improve prediction accuracy. Second, based on drug and target similarities and known DTIs, a strategy of multi-similarity fusion is proposed to capture potential useful information from known interactions that is used for enhancing drug and target similarities. Third, the heterogeneous graph inference is used to predict the DTIs to capture the edge weight (closeness) and behavior information (diffusion) between nodes of a heterogeneous network. To assist the reproducibility of our work and its comparison to published results, we perform experiments on four benchmark datasets. Results show that our approach outperforms some existing approaches and can contribute to predicting potential DTIs. The fundamental role of microRNAs (miRNAs) has long been associated with regulation of gene expression during transcription and post transcription of mRNA's 3′UTR by the RNA interference mechanism. Also, the process of how miRNAs tend to induce mRNA degradation has been predominantly studied in many infectious diseases. In this article, we would like to discuss the interaction of dietary plant miRNAs derived from fresh fruits against the viral genome of the causative agent of COVID-19, specifically targeting the 3′UTR of SARS-CoV-2 (Severe acute respiratory syndrome coronavirus 2) genome. Expanding the analysis, we have also identified plant miRNAs that interact against the Omicron (B.1.1.529) variant of SARS-CoV-2 across 37 countries/territories throughout the world. This cross-species virus-plant interaction led us to identify the alignment of dietary plant miRNAs found in fruits like Citrus sinensis (Orange), Prunus persica (Peaches), Vitis vinifera (Grapes) and Malus domestica (Apple) onto the viral genomes. In particular, the interaction of C. sinensis miRNA - csi-miR169–3p and SARS-CoV-2 is noteworthy, as the targeted 3′UTR region “CTGCCT” is found conserved amongst all curated 772 Omicron variants across the globe. Hence this site “CTGCCT” and miRNA csi-miR169–3p may become promising therapeutic candidates to induce viral genome silencing. Thereby, this study reveals the mechanistic way of how fruits tend to enact a fight against viruses like SARS-CoV-2 and aid in maintaining a strong immune system of an individual. The reductive glycine pathway was described as the most energetically favorable synthetic route of aerobic formate assimilation. Here we report the successful implementation of formatotrophy in Escherichia coli by means of a stepwise adaptive evolution strategy. Medium swap and turbidostat regimes of continuous culture were applied to force the channeling of carbon flux through the synthetic pathway to pyruvate establishing growth on formate and CO2 as sole carbon sources. Labeling with 13C-formate proved the assimilation of the C1 substrate via the pathway metabolites. Genetic analysis of intermediate isolates revealed a mutational path followed throughout the adaptation process. Mutations were detected affecting the copy number (gene ftfL) or the coding sequence (genes folD and lpd) of genes which specify enzymes implicated in the three steps forming glycine from formate and CO2, the central metabolite of the synthetic pathway. The mutation R191S present in methylene-tetrahydrofolate dehydrogenase/cyclohydrolase (FolD) abolishes the inhibition of cyclohydrolase activity by the substrate formyl-tetrahydrofolate. The mutation R273H in lipoamide dehydrogenase (Lpd) alters substrate affinities as well as kinetics at physiological substrate concentrations likely favoring a reactional shift towards lipoamide reduction. In addition, genetic reconstructions proved the necessity of all three mutations for formate assimilation by the adapted cells. The largely unpredictable nature of these changes demonstrates the usefulness of the evolutionary approach enabling the selection of adaptive mutations crucial for pathway engineering of biotechnological model organisms. Expression of mRNA is often regulated by the binding of a small RNA (miRNA, snoRNA, siRNA). While the pairing contribution to the net free energy is well parameterized and can be computed in O(N){$<$}math{$><$}mrow is="true"{$><$}mi is="true"{$>$}O{$<$}/mi{$><$}mo stretchy="false" is="true"{$>$}({$<$}/mo{$><$}mi is="true"{$>$}N{$<$}/mi{$><$}mo stretchy="false" is="true"{$>$}){$<$}/mo{$><$}/mrow{$><$}/math{$>$} time, the cost of removing pre-existing mRNA secondary structure has not received sufficient attention. Conventional methods for computing the unfolding free energy of a target mRNA are costly, scaling like the cube of the number of target bases O(N3){$<$}math{$><$}mrow is="true"{$><$}mi is="true"{$>$}O{$<$}/mi{$><$}mo stretchy="false" is="true"{$>$}({$<$}/mo{$><$}msup is="true"{$><$}mrow is="true"{$><$}mi is="true"{$>$}N{$<$}/mi{$><$}/mrow{$><$}mrow is="true"{$><$}mn is="true"{$>$}3{$<$}/mn{$><$}/mrow{$><$}/msup{$><$}mo stretchy="false" is="true"{$>$}){$<$}/mo{$><$}/mrow{$><$}/math{$>$}. Here we introduce a model to describe the unfolding costs of the binding site, which features surprisingly big differences in the free energy parameters for the four bases. The model is implemented in our O(N){$<$}math{$><$}mrow is="true"{$><$}mi is="true"{$>$}O{$<$}/mi{$><$}mo stretchy="false" is="true"{$>$}({$<$}/mo{$><$}mi is="true"{$>$}N{$<$}/mi{$><$}mo stretchy="false" is="true"{$>$}){$<$}/mo{$><$}/mrow{$><$}/math{$>$} algorithm, BindOligoNet. Donor splice site prediction is more accurate when using our calculation of spliceosomal U1-snRNA to mRNA net binding free energy. Our base-dependent free energies also correlate with efficient ribosome docking near the start codon.},
  author       = {Smith, T. F. and Waterman, M. S.},
  date         = {1981-03-25},
  doi          = {10.1016/0022-2836(81)90087-5},
  file         = {/Users/lucblassel/Zotero/storage/LG7DPHR7/0022283681900875.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {1},
  pages        = {195--197},
  shortjournal = {Journal of Molecular Biology},
  title        = {Identification of Common Molecular Subsequences},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283681900875},
  urldate      = {2022-06-13},
  volume       = {147}
}

@article{sodingProteinHomologyDetection2005,
  abstract     = {MOTIVATION: Protein homology detection and sequence alignment are at the basis of protein structure prediction, function prediction and evolution. RESULTS: We have generalized the alignment of protein sequences with a profile hidden Markov model (HMM) to the case of pairwise alignment of profile HMMs. We present a method for detecting distant homologous relationships between proteins based on this approach. The method (HHsearch) is benchmarked together with BLAST, PSI-BLAST, HMMER and the profile-profile comparison tools PROF\_SIM and COMPASS, in an all-against-all comparison of a database of 3691 protein domains from SCOP 1.63 with pairwise sequence identities below 20\%.Sensitivity: When the predicted secondary structure is included in the HMMs, HHsearch is able to detect between 2.7 and 4.2 times more homologs than PSI-BLAST or HMMER and between 1.44 and 1.9 times more than COMPASS or PROF\_SIM for a rate of false positives of 10\%. Approximately half of the improvement over the profile-profile comparison methods is attributable to the use of profile HMMs in place of simple profiles. Alignment quality: Higher sensitivity is mirrored by an increased alignment quality. HHsearch produced 1.2, 1.7 and 3.3 times more good alignments ('balanced' score {$>$}0.3) than the next best method (COMPASS), and 1.6, 2.9 and 9.4 times more than PSI-BLAST, at the family, superfamily and fold level, respectively.Speed: HHsearch scans a query of 200 residues against 3691 domains in 33 s on an AMD64 2GHz PC. This is 10 times faster than PROF\_SIM and 17 times faster than COMPASS.},
  author       = {Söding, Johannes},
  date         = {2005-04-01},
  doi          = {10.1093/bioinformatics/bti125},
  eprint       = {15531603},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Söding_2005_Protein homology detection by HMM-HMM comparison.pdf},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics (Oxford, England)},
  keywords     = {Algorithms,Amino Acid Sequence,Artificial Intelligence,Computer Simulation,Markov Chains,Models; Chemical,Models; Statistical,Molecular Sequence Data,Proteins,Sequence Alignment,Sequence Analysis; Protein,Sequence Homology; Amino Acid,Software},
  langid       = {english},
  number       = {7},
  pages        = {951--960},
  shortjournal = {Bioinformatics},
  title        = {Protein Homology Detection by {{HMM-HMM}} Comparison},
  volume       = {21}
}

@article{songAnchorWaveSensitiveAlignment2022,
  author       = {Song, Baoxing and Marco-Sola, Santiago and Moreto, Miquel and Johnson, Lynn and Buckler, Edward S. and Stitzer, Michelle C.},
  date         = {2022-01-04},
  doi          = {10.1073/pnas.2113075119},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Song et al_2022_AnchorWave.pdf},
  journaltitle = {Proceedings of the National Academy of Sciences},
  number       = {1},
  pages        = {e2113075119},
  publisher    = {{Proceedings of the National Academy of Sciences}},
  shorttitle   = {{{AnchorWave}}},
  title        = {{{AnchorWave}}: {{Sensitive}} Alignment of Genomes with High Sequence Diversity, Extensive Structural Polymorphism, and Whole-Genome Duplication},
  url          = {https://www.pnas.org/doi/10.1073/pnas.2113075119},
  urldate      = {2022-08-26},
  volume       = {119}
}

@article{sovicFastSensitiveMapping2016,
  abstract     = {Realizing the democratic promise of nanopore sequencing requires the development of new bioinformatics approaches to deal with its specific error characteristics. Here we present GraphMap, a mapping algorithm designed to analyse nanopore sequencing reads, which progressively refines candidate alignments to robustly handle potentially high-error rates and a fast graph traversal to align long reads with speed and high precision ({$>$}95\%). Evaluation on MinION sequencing data sets against short- and long-read mappers indicates that GraphMap increases mapping sensitivity by 10–80\% and maps {$>$}95\% of bases. GraphMap alignments enabled single-nucleotide variant calling on the human genome with increased sensitivity (15\%) over the next best mapper, precise detection of structural variants from length 100\,bp to 4\,kbp, and species and strain-specific identification of pathogens using MinION reads. GraphMap is available open source under the MIT license at https://github.com/isovic/graphmap.},
  author       = {Sović, Ivan and Šikić, Mile and Wilm, Andreas and Fenlon, Shannon Nicole and Chen, Swaine and Nagarajan, Niranjan},
  date         = {2016-04-15},
  doi          = {10.1038/ncomms11307},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sović et al_2016_Fast and sensitive mapping of nanopore sequencing reads with GraphMap.pdf;/Users/lucblassel/Zotero/storage/SFXUFTG8/ncomms11307.html},
  issn         = {2041-1723},
  issue        = {1},
  journaltitle = {Nature Communications},
  keywords     = {Bioinformatics,DNA sequencing,Molecular biology},
  langid       = {english},
  number       = {1},
  pages        = {11307},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Commun},
  title        = {Fast and Sensitive Mapping of Nanopore Sequencing Reads with {{GraphMap}}},
  url          = {https://www.nature.com/articles/ncomms11307},
  urldate      = {2022-06-17},
  volume       = {7}
}

@article{spougeSpeedingDynamicProgramming1989,
  abstract     = {Many problems can be reduced to finding an optimal lattice path. For example, minimum path integrals can be computed by discretizing to a lattice graph and then using the optimal lattice path to approximate the minimum continuous path. Finding an optimal alignment between two sequences can also be reduced to finding an optimal lattice path. Dynamic programming algorithms are generally, well-suited to such problems, but can be slow and require too much storage if the lattice is too large, for example, if the lattice dimension is too high. Faster algorithms requiring less computer storage can often be constructed by restricting calculations to a “computational volume” known to contain the optimal path. Upper and lower bounds on path distances from the problem domain can often help to produce small computational volumes.},
  author       = {Spouge, John L.},
  date         = {1989-10},
  doi          = {10.1137/0149094},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Spouge_1989_Speeding up Dynamic Programming Algorithms for Finding Optimal Lattice Paths.pdf},
  issn         = {0036-1399},
  journaltitle = {SIAM Journal on Applied Mathematics},
  keywords     = {49,68,92,calculus of variations,dynamic programming,sequence alignment},
  number       = {5},
  pages        = {1552--1566},
  publisher    = {{Society for Industrial and Applied Mathematics}},
  shortjournal = {SIAM J. Appl. Math.},
  title        = {Speeding up {{Dynamic Programming Algorithms}} for {{Finding Optimal Lattice Paths}}},
  url          = {https://epubs.siam.org/doi/abs/10.1137/0149094},
  urldate      = {2022-06-15},
  volume       = {49}
}

@article{stajichBioperlToolkitPerl2002,
  abstract     = {The Bioperl project is an international open-source collaboration of biologists, bioinformaticians, and computer scientists that has evolved over the past 7 yr into the most comprehensive library of Perl modules available for managing and manipulating life-science information. Bioperl provides an easy-to-use, stable, and consistent programming interface for bioinformatics application programmers. The Bioperl modules have been successfully and repeatedly used to reduce otherwise complex tasks to only a few lines of code. The Bioperl object model has been proven to be flexible enough to support enterprise-level applications such as EnsEMBL, while maintaining an easy learning curve for novice Perl programmers. Bioperl is capable of executing analyses and processing results from programs such as BLAST, ClustalW, or the EMBOSS suite. Interoperation with modules written in Python and Java is supported through the evolving BioCORBA bridge. Bioperl provides access to data stores such as GenBank and SwissProt via a flexible series of sequence input/output modules, and to the emerging common sequence data storage format of the Open Bioinformatics Database Access project. This study describes the overall architecture of the toolkit, the problem domains that it addresses, and gives specific examples of how the toolkit can be used to solve common life-sciences problems. We conclude with a discussion of how the open-source nature of the project has contributed to the development effort. [Supplemental material is available online at www.genome.org. Bioperl is available as open-source software free of charge and is licensed under the Perl Artistic License (http://www.perl.com/pub/a/language/misc/Artistic.html). It is available for download at http://www.bioperl.org. Support inquiries should be addressed to bioperl-l\{at\}bioperl.org.]},
  author       = {Stajich, Jason E. and Block, David and Boulez, Kris and Brenner, Steven E. and Chervitz, Stephen A. and Dagdigian, Chris and Fuellen, Georg and Gilbert, James G. R. and Korf, Ian and Lapp, Hilmar and Lehväslaiho, Heikki and Matsalla, Chad and Mungall, Chris J. and Osborne, Brian I. and Pocock, Matthew R. and Schattner, Peter and Senger, Martin and Stein, Lincoln D. and Stupka, Elia and Wilkinson, Mark D. and Birney, Ewan},
  date         = {2002-01-10},
  doi          = {10.1101/gr.361602},
  eprint       = {12368254},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Stajich et al_2002_The Bioperl Toolkit.pdf;/Users/lucblassel/Zotero/storage/SGGZTFC5/1611.html},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {10},
  pages        = {1611--1618},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  shorttitle   = {The {{Bioperl Toolkit}}},
  title        = {The {{Bioperl Toolkit}}: {{Perl Modules}} for the {{Life Sciences}}},
  url          = {https://genome.cshlp.org/content/12/10/1611},
  urldate      = {2022-06-14},
  volume       = {12}
}

@article{suMultipleSequenceAlignment2017,
  abstract     = {Multiple sequence alignment (MSA) is an essential prerequisite and dominant method to deduce the biological facts from a set of molecular biological sequences. It refers to a series of algorithmic solutions for the alignment of evolutionarily related sequences while taking into account evolutionary events such as mutations, insertions, deletions, and rearrangements under certain conditions. These methods can be applied to DNA, RNA, or protein sequences. In this work, we take advantage of a center-star strategy to reduce the MSA problem to pairwise alignments, and we use a suffix tree to match identical substrings between two pairwise sequences. Multiple sequence alignment based on a suffix tree and center-star strategy (MASC) can accomplish MSA in O(mn), which is linear time complexity, wheremis the number of sequences andnis the average length of sequences. Furthermore, we execute our method on the Spark-distributed parallel framework to deal with ever-increasing massive data sets. Our method is significantly faster than previous techniques, with no loss in accuracy for highly similar nucleotide sequences like homologous sequences, which we experimentally demonstrate. Comparing with mainstream MSA tools (e.g., MAFFT), MASC could finish the alignment of 67,200 sequences, longer than 10,000\,bps, in 9 minutes, which takes MAFFT {$>$}3.5 days.},
  author       = {Su, Wenhe and Liao, Xiangke and Lu, Yutong and Zou, Quan and Peng, Shaoliang},
  date         = {2017-11-08},
  doi          = {10.1089/cmb.2017.0040},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/su_et_al_2017_multiple_sequence_alignment_based_on_a_suffix.pdf;/Users/lucblassel/Zotero/storage/JDPP74D7/cmb.2017.html},
  journaltitle = {Journal of Computational Biology},
  number       = {12},
  pages        = {1230--1242},
  shortjournal = {Journal of Computational Biology},
  shorttitle   = {Multiple {{Sequence Alignment Based}} on a {{Suffix Tree}} and {{Center-Star Strategy}}},
  title        = {Multiple {{Sequence Alignment Based}} on a {{Suffix Tree}} and {{Center-Star Strategy}}: {{A Linear Method}} for {{Multiple Nucleotide Sequence Alignment}} on {{Spark Parallel Framework}}},
  url          = {https://www.liebertpub.com/doi/10.1089/cmb.2017.0040},
  urldate      = {2019-08-13},
  volume       = {24}
}

@article{sunChoosingBestHeuristic2006,
  abstract     = {Seeded alignment is an important component of algorithms for fast, large-scale DNA similarity search. A good seed matching heuristic can reduce the execution time of genomic-scale sequence comparison without degrading sensitivity. Recently, many types of seed have been proposed to improve on the performance of traditional contiguous seeds as used in, e.g., NCBI BLASTN. Choosing among these seed types, particularly those that use information besides the presence or absence of matching residue pairs, requires practical guidance based on a rigorous comparison, including assessment of sensitivity, specificity, and computational efficiency. This work performs such a comparison, focusing on alignments in DNA outside widely studied coding regions.},
  author       = {Sun, Yanni and Buhler, Jeremy},
  date         = {2006-03-13},
  doi          = {10.1186/1471-2105-7-133},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sun_Buhler_2006_Choosing the best heuristic for seeded alignment of DNA sequences.pdf;/Users/lucblassel/Zotero/storage/XVM8XRBA/1471-2105-7-133.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Hash Table,Match Position,Residue Pair,Seed Match,Seed Type},
  number       = {1},
  pages        = {133},
  shortjournal = {BMC Bioinformatics},
  title        = {Choosing the Best Heuristic for Seeded Alignment of {{DNA}} Sequences},
  url          = {https://doi.org/10.1186/1471-2105-7-133},
  urldate      = {2022-06-15},
  volume       = {7}
}

@article{sundfeldPAStarDiskassistedParallel2018,
  abstract     = {Multiple Sequence Alignment (MSA) is a basic operation in Bioinformatics, and is used to highlight the similarities among a set of sequences. The MSA problem was proven NP-Hard, thus requiring a high amount of memory and computing power. This problem can be modeled as a search for the path with minimum cost in a graph, and the A-Star algorithm has been adapted to solve it sequentially and in parallel. The design of a parallel version for MSA with A-Star is subject to challenges such as irregular dependency pattern and substantial memory requirements. In this paper, we propose PA-Star, a locality-sensitive multithreaded strategy based on A-Star, which computes optimal MSAs using both RAM and disk to store nodes. The experimental results obtained in 3 different machines show that the optimizations used in PA-Star can achieve an acceleration of 1.88× in the serial execution, and the parallel execution can attain an acceleration of 5.52× with 8 cores. We also show that PA-Star outperforms a state-of-the-art MSA tool based on A-Star, executing up to 4.77× faster. Finally, we show that our disk-assisted strategy is able to retrieve the optimal alignment when other tools fail.},
  author       = {Sundfeld, Daniel and Razzolini, Caina and Teodoro, George and Boukerche, Azzedine and de Melo, Alba Cristina Magalhaes Alves},
  date         = {2018-02-01},
  doi          = {10.1016/j.jpdc.2017.04.014},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/sundfeld_et_al_2018_pa-star.pdf;/Users/lucblassel/Zotero/storage/G9S3Q3LQ/S0743731517301508.html},
  issn         = {0743-7315},
  journaltitle = {Journal of Parallel and Distributed Computing},
  keywords     = {A-Star,Locality-sensitive hash,Multiple sequence alignment,Parallel algorithms},
  options      = {useprefix=true},
  pages        = {154--165},
  series       = {Parallel {{Optimization}} Using/for {{Multi}} and {{Many-core High Performance Computing}}},
  shortjournal = {Journal of Parallel and Distributed Computing},
  shorttitle   = {{{PA-Star}}},
  title        = {{{PA-Star}}: {{A}} Disk-Assisted Parallel {{A-Star}} Strategy with Locality-Sensitive Hash for Multiple Sequence Alignment},
  url          = {http://www.sciencedirect.com/science/article/pii/S0743731517301508},
  urldate      = {2019-08-13},
  volume       = {112}
}

@book{sungAlgorithmsBioinformaticsPractical2011,
  abstract   = {Thoroughly Describes Biological Applications, Computational Problems, and Various Algorithmic Solutions Developed from the author's own teaching material, Algorithms in Bioinformatics: A Practical Introduction provides an in-depth introduction to the algorithmic techniques applied in bioinformatics. For each topic, the author clearly details the bi},
  author     = {Sung, Wing-Kin},
  date       = {2011-10-10},
  doi        = {10.1201/9781420070347},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Sung_2011_Algorithms in Bioinformatics.pdf},
  isbn       = {978-0-429-14149-2},
  location   = {{New York}},
  pagetotal  = {407},
  publisher  = {{Chapman and Hall/CRC}},
  shorttitle = {Algorithms in {{Bioinformatics}}},
  title      = {Algorithms in {{Bioinformatics}}: {{A Practical Introduction}}}
}

@article{suzukiIntroducingDifferenceRecurrence2018,
  abstract     = {The read length of single-molecule DNA sequencers is reaching 1 Mb. Popular alignment software tools widely used for analyzing such long reads often take advantage of single-instruction multiple-data (SIMD) operations to accelerate calculation of dynamic programming (DP) matrices in the Smith–Waterman–Gotoh (SWG) algorithm with a fixed alignment start position at the origin. Nonetheless, 16-bit or 32-bit integers are necessary for storing the values in a DP matrix when sequences to be aligned are long; this situation hampers the use of the full SIMD width of modern processors.},
  author       = {Suzuki, Hajime and Kasahara, Masahiro},
  date         = {2018-02-19},
  doi          = {10.1186/s12859-018-2014-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Suzuki_Kasahara_2018_Introducing difference recurrence relations for faster semi-global alignment of.pdf;/Users/lucblassel/Zotero/storage/H5M7VP63/s12859-018-2014-8.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Alignment,Long read,Sequence analysis},
  number       = {1},
  pages        = {45},
  shortjournal = {BMC Bioinformatics},
  title        = {Introducing Difference Recurrence Relations for Faster Semi-Global Alignment of Long Sequences},
  url          = {https://doi.org/10.1186/s12859-018-2014-8},
  urldate      = {2022-06-17},
  volume       = {19}
}

@article{tangHAlignFastMultiple2022,
  abstract     = {HAlign is a cross-platform program that performs multiple sequence alignments based on the center star strategy. Here we present two major updates of HAlign 3, which helped improve the time efficiency and the alignment quality, and made HAlign 3 a specialized program to process ultra-large numbers of similar DNA/RNA sequences, such as closely related viral or prokaryotic genomes. HAlign 3 can be easily installed via the Anaconda and Java release package on macOS, Linux, Windows subsystem for Linux, and Windows systems, and the source code is available on GitHub (https://github.com/malabz/HAlign-3).},
  author       = {Tang, Furong and Chao, Jiannan and Wei, Yanming and Yang, Fenglong and Zhai, Yixiao and Xu, Lei and Zou, Quan},
  date         = {2022-08-01},
  doi          = {10.1093/molbev/msac166},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Tang et al_2022_HAlign 3.pdf;/Users/lucblassel/Zotero/storage/GUW69KDH/6653123.html},
  issn         = {1537-1719},
  journaltitle = {Molecular Biology and Evolution},
  number       = {8},
  pages        = {msac166},
  shortjournal = {Molecular Biology and Evolution},
  shorttitle   = {{{HAlign}} 3},
  title        = {{{HAlign}} 3: {{Fast Multiple Alignment}} of {{Ultra-Large Numbers}} of {{Similar DNA}}/{{RNA Sequences}}},
  url          = {https://doi.org/10.1093/molbev/msac166},
  urldate      = {2022-09-06},
  volume       = {39}
}

@article{thompsonBAliBASEBenchmarkAlignment1999,
  abstract     = {Abstract.  SUMMARY: BAliBASE is a database of manually refined multiple sequence alignments categorized by core blocks of conservation sequence length, similari},
  author       = {Thompson, J. D. and Plewniak, F. and Poch, O.},
  date         = {1999-01-01},
  doi          = {10.1093/bioinformatics/15.1.87},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/thompson_et_al_1999_balibase.pdf;/Users/lucblassel/Zotero/storage/UC2J6WBT/218377.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  langid       = {english},
  number       = {1},
  pages        = {87--88},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{BAliBASE}}},
  title        = {{{BAliBASE}}: A Benchmark Alignment Database for the Evaluation of Multiple Alignment Programs.},
  url          = {https://academic.oup.com/bioinformatics/article/15/1/87/218377},
  urldate      = {2019-08-14},
  volume       = {15}
}

@article{thompsonBAliBASEBenchmarkAlignment1999a,
  abstract     = {SUMMARY: BAliBASE is a database of manually refined multiple sequence alignments categorized by core blocks of conservation sequence length, similarity, and the presence of insertions and N/C-terminal extensions. AVAILABILITY: From http://www-igbmc. u-strasbg.fr/BioInfo/BAliBASE/index.html},
  author       = {Thompson, J D and Plewniak, F and Poch, O},
  date         = {1999-01-01},
  doi          = {10.1093/bioinformatics/15.1.87},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Thompson et al_1999_BAliBASE.pdf;/Users/lucblassel/Zotero/storage/GAVHNS7V/218377.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {1},
  pages        = {87--88},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{BAliBASE}}},
  title        = {{{BAliBASE}}: A Benchmark Alignment Database for the Evaluation of Multiple Alignment Programs.},
  url          = {https://doi.org/10.1093/bioinformatics/15.1.87},
  urldate      = {2022-06-16},
  volume       = {15}
}

@article{thompsonCLUSTALImprovingSensitivity1994,
  abstract     = {Abstract.  The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein},
  author       = {Thompson, Julie D. and Higgins, Desmond G. and Gibson, Toby J.},
  date         = {1994-11-11},
  doi          = {10.1093/nar/22.22.4673},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/thompson_et_al_1994_clustal_w.pdf;/Users/lucblassel/Zotero/storage/FCQVHLTS/2400290.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  langid       = {english},
  number       = {22},
  pages        = {4673--4680},
  shortjournal = {Nucleic Acids Res},
  shorttitle   = {{{CLUSTAL W}}},
  title        = {{{CLUSTAL W}}: Improving the Sensitivity of Progressive Multiple Sequence Alignment through Sequence Weighting, Position-Specific Gap Penalties and Weight Matrix Choice},
  url          = {https://academic.oup.com/nar/article/22/22/4673/2400290},
  urldate      = {2019-08-14},
  volume       = {22}
}

@article{thompsonCLUSTALImprovingSensitivity1994a,
  abstract     = {The sensitivity of the commonly used progressive multiple sequence alignment method has been greatly improved for the alignment of divergent protein sequences. Firstly, individual weights are assigned to each sequence in a partial alignment in order to downweight near-duplicate sequences and up-weight the most divergent ones. Secondly, amino acid substitution matrices are varied at different alignment stages according to the divergence of the sequences to be aligned. Thirdly, residue-specific gap penalties and locally reduced gap penalties in hydrophilic regions encourage new gaps in potential loop regions rather than regular secondary structure. Fourthly, positions in early alignments where gaps have been opened receive locally reduced gap penalties to encourage the opening up of new gaps at these positions. These modifications are incorporated into a new program, CLUSTAL W which is freely available.},
  author       = {Thompson, Julie D. and Higgins, Desmond G. and Gibson, Toby J.},
  date         = {1994-11-11},
  doi          = {10.1093/nar/22.22.4673},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Thompson et al_1994_CLUSTAL W.pdf;/Users/lucblassel/Zotero/storage/JBRRCZL4/2400290.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {22},
  pages        = {4673--4680},
  shortjournal = {Nucleic Acids Research},
  shorttitle   = {{{CLUSTAL W}}},
  title        = {{{CLUSTAL W}}: Improving the Sensitivity of Progressive Multiple Sequence Alignment through Sequence Weighting, Position-Specific Gap Penalties and Weight Matrix Choice},
  url          = {https://doi.org/10.1093/nar/22.22.4673},
  urldate      = {2022-06-16},
  volume       = {22}
}

@article{thompsonCLUSTALWindowsInterface1997,
  abstract     = {CLUSTAL X is a new windows interface for the widely-used progressive multiple sequence alignment program CLUSTAL W. The new system is easy to use, providing an integrated system for performing multiple sequence and profile alignments and analysing the results. CLUSTAL X displays the sequence alignment in a window on the screen. A versatile sequence colouring scheme allows the user to highlight conserved features in the alignment. Pull-down menus provide all the options required for traditional multiple sequence and profile alignment. New features include: the ability to cut-and-paste sequences to change the order of the alignment, selection of a subset of the sequences to be realigned, and selection of a sub-range of the alignment to be realigned and inserted back into the original alignment. Alignment quality analysis can be performed and low-scoring segments or exceptional residues can be highlighted. Quality analysis and realignment of selected residue ranges provide the user with a powerful tool to improve and refine difficult alignments and to trap errors in input sequences. CLUSTAL X has been compiled on SUN Solaris, IRIX5.3 on Silicon Graphics, Digital UNIX on DECstations, Microsoft Windows (32 bit) for PCs, Linux ELF for x86 PCs, and Macintosh PowerMac.},
  author       = {Thompson, Julie D. and Gibson, Toby J. and Plewniak, Frédéric and Jeanmougin, François and Higgins, Desmond G.},
  date         = {1997-12-01},
  doi          = {10.1093/nar/25.24.4876},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Thompson et al_1997_The CLUSTAL_X Windows Interface.pdf;/Users/lucblassel/Zotero/storage/PB3E9AKU/1747529.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {24},
  pages        = {4876--4882},
  shortjournal = {Nucleic Acids Research},
  shorttitle   = {The {{CLUSTAL}}\_{{X Windows Interface}}},
  title        = {The {{CLUSTAL}}\_{{X Windows Interface}}: {{Flexible Strategies}} for {{Multiple Sequence Alignment Aided}} by {{Quality Analysis Tools}}},
  url          = {https://doi.org/10.1093/nar/25.24.4876},
  urldate      = {2022-06-16},
  volume       = {25}
}

@article{trivediAminoAcidSubstitution2019,
  abstract     = {An amino acid substitution scoring matrix encapsulates the rates at which various amino acid residues in proteins are substituted by other amino acid residues, over time. Database search methods make use of substitution scoring matrices to identify sequences with homologous relationships. However, widely used substitution scoring matrices, such as BLOSUM series, have been developed using aligned blocks that are mostly devoid of disordered regions in proteins. Hence, these substitution-scoring matrices are mostly inappropriate for homology searches involving proteins enriched with disordered regions as the disordered regions have distinct amino acid compositional bias, and therefore expected to have undergone amino acid substitutions that are distinct from those in the ordered regions. We, therefore, developed a novel series of substitution scoring matrices referred to as EDSSMat by exclusively considering the substitution frequencies of amino acids in the disordered regions of the eukaryotic proteins. The newly developed matrices were tested for their ability to detect homologs of proteins enriched with disordered regions by means of SSEARCH tool. The results unequivocally demonstrate that EDSSMat matrices detect more number of homologs than the widely used BLOSUM, PAM and other standard matrices, indicating their utility value for homology searches of intrinsically disordered proteins.},
  author       = {Trivedi, Rakesh and Nagarajaram, Hampapathalu Adimurthy},
  date         = {2019-11-08},
  doi          = {10.1038/s41598-019-52532-8},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Trivedi_Nagarajaram_2019_Amino acid substitution scoring matrices specific to intrinsically disordered.pdf;/Users/lucblassel/Zotero/storage/FPA8LMGP/s41598-019-52532-8.html},
  issn         = {2045-2322},
  issue        = {1},
  journaltitle = {Scientific Reports},
  keywords     = {Intrinsically disordered proteins,Protein sequence analyses},
  langid       = {english},
  number       = {1},
  pages        = {16380},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Sci Rep},
  title        = {Amino Acid Substitution Scoring Matrices Specific to Intrinsically Disordered Regions in Proteins},
  url          = {https://www.nature.com/articles/s41598-019-52532-8},
  urldate      = {2022-06-14},
  volume       = {9}
}

@article{tsengEstimationAminoAcid2006,
  abstract     = {Amino acid sequences are an important source of information for inferring distant phylogenetic relationships and for predicting the biochemical functions of protein. Because the substitutions of nucleotides can become rapidly saturated, and the likelihood of unrelated identical substitutions is high for nucleotides, the information of evolutionary conservation of nucleotides is quickly obscured after a number of generations. The mapping of DNA sequences by the genetic code to amino acid sequences frequently can reveal more remote evolutionary relation with more interpretable sequence similarity (Lio` and Goldman 1999). In addition, statistical analysis of protein sequence alignment is also more reliable as it is much more difficult to detect and correct for deviations from independent identical distributions in DNA sequences due to possible translation of normal complexity DNA sequences into low complexity protein sequences such as tandem repeats of simple patterns of a few residues (Pearson 1998). The success in detecting evolutionarily related protein sequences through sequence alignment depends on the use of a scoring matrix, which determines the similarity between residues. Rate matrices of amino acid residue substitutions can be the basis for developing many scoring matrices for sequence alignment. Dayhoff, Schwartz, and Orcutt (1978) were the first to develop empirical models of amino acid residue substitutions. They used a counting method to obtain accepted point mutation matrices (called Pam matrices). The widely used Blosum matrices can be viewed as analogous to transition matrices of residues at different time intervals (S. Henikoff and J. G. Henikoff 1992; Lio` and Goldman 1998). They were developed following a heuristic counting approach similar to that of Pam and were derived from structure-based alignments of blocks of sequences of related proteins (S. Henikoff and J. G.},
  author       = {Tseng, Yan Y. and Liang, Jie},
  date         = {2006-02-01},
  doi          = {10.1093/molbev/msj048},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/tseng_liang_2006_estimation_of_amino_acid_residue_substitution.pdf;/Users/lucblassel/Google Drive/Zotero_papers/tseng_liang_2006_estimation_of_amino_acid_residue_substitution2.pdf;/Users/lucblassel/Zotero/storage/2IX3XTU5/1119081.html},
  ids          = {tseng2006Estimation,tseng2006Estimationb},
  issn         = {1537-1719, 0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  langid       = {english},
  number       = {2},
  pages        = {421--436},
  shorttitle   = {Estimation of {{Amino Acid Residue Substitution Rates}} at {{Local Spatial Regions}} and {{Application}} in {{Protein Function Inference}}},
  title        = {Estimation of {{Amino Acid Residue Substitution Rates}} at {{Local Spatial Regions}} and {{Application}} in {{Protein Function Inference}}: {{A Bayesian Monte Carlo Approach}}},
  url          = {http://academic.oup.com/mbe/article/23/2/421/1119081/Estimation-of-Amino-Acid-Residue-Substitution},
  urldate      = {2019-08-19},
  volume       = {23}
}

@article{ullmanBoundsComplexityLongest1976,
  abstract     = {The problem of finding a longest common subsequence of two strings is discussed. This problem arises in data processing applications such as comparing two files and in genetic applications such as studying molecular evolution. The difficulty of computing a longest common subsequence of two strings is examined using the decision tree model of computation, in which vertices represent “equal - unequal” comparisons. It is shown that unless a bound on the total number of distinct symbols is assumed, every solution to the problem can consume an amount of time that is proportional to the product of the lengths of the two strings. A general lower bound as a function of the ratio of alphabet size to string length is derived. The case where comparisons between symbols of the same string are forbidden is also considered and it is shown that this problem is of linear complexity for a two-symbol alphabet and quadratic for an alphabet of three or more symbols.},
  author       = {Ullman, J. D. and Aho, A. V. and Hirschberg, D. S.},
  date         = {1976-01-01},
  doi          = {10.1145/321921.321922},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Ullman et al_1976_Bounds on the Complexity of the Longest Common Subsequence Problem.pdf},
  issn         = {0004-5411},
  journaltitle = {Journal of the ACM},
  number       = {1},
  pages        = {1--12},
  shortjournal = {J. ACM},
  title        = {Bounds on the {{Complexity}} of the {{Longest Common Subsequence Problem}}},
  url          = {https://doi.org/10.1145/321921.321922},
  urldate      = {2022-06-13},
  volume       = {23}
}

@online{UnderstandingMAPQScores,
  abstract     = {Distribution of MAPQ scores from two experiments:\&nbsp; bottom panel shows zoomed in view of MAPQ scores with frequencies \&lt; 1\%. Click to enlarge.},
  file         = {/Users/lucblassel/Zotero/storage/WSBNUFXW/understanding-mapq-scores-in-sam-files-does-37-42.html},
  langid       = {british},
  organization = {{ACGT blog}},
  shorttitle   = {Understanding {{MAPQ}} Scores in {{SAM}} Files},
  title        = {Understanding {{MAPQ}} Scores in {{SAM}} Files: Does 37 = 42?},
  url          = {http://www.acgt.me/blog/2014/12/16/understanding-mapq-scores-in-sam-files-does-37-42},
  urldate      = {2022-09-06}
}

@article{vannesteForensicSTRAnalysis2012,
  abstract     = {We explore the applicability of second generation sequencing (SGS) to sequence multiplexed forensic STR amplicons, both in a single contributor sample as in multiple-person mixtures with different ratios. We compare the results of a commercial STR profiling kit (Applied Biosystems AmpFlSTR® Profiler Plus®), analyzed both with capillary electrophoresis and with Roche GS FLX sequencing. An easy to use open-source software pipeline is provided, chaining together the different steps needed to start the analysis from a GS FLX FASTA file, resulting in a FASTA file containing the called and quantified alleles present in the data. Sequencing of multiplexed STR amplicons using Roche GS FLX titanium technology is technically feasible but the technology is not ideal for this purpose. The fraction of full length reads is small and the homopolymer sequencing error rate is high. The pipeline compresses the homopolymers to a single base to avoid false results caused by these homopolymers. The qualitative and quantitative results from the SGS STR analysis pipeline are comparable to the electrophoresis method. Additionally, the SGS method provides extra information and is able to call allele subtypes based on STR sequences in a database. In mixed samples, all alleles were reported from individuals that contributed at least 10\% to the mixture.},
  author       = {Van Neste, Christophe and Van Nieuwerburgh, Filip and Van Hoofstat, David and Deforce, Dieter},
  date         = {2012-12-01},
  doi          = {10.1016/j.fsigen.2012.03.004},
  file         = {/Users/lucblassel/Zotero/storage/FQNF69B7/S1872497312000798.html},
  issn         = {1872-4973},
  journaltitle = {Forensic Science International: Genetics},
  keywords     = {Forensic,Next generation sequencing,Pyrosequencing,Roche GS FLX,Second generation sequencing,STR},
  langid       = {english},
  number       = {6},
  pages        = {810--818},
  series       = {Analysis and Biostatistical Interpretation of Complex and Low Template {{DNA}} Samples},
  shortjournal = {Forensic Science International: Genetics},
  title        = {Forensic {{STR}} Analysis Using Massive Parallel Sequencing},
  url          = {https://www.sciencedirect.com/science/article/pii/S1872497312000798},
  urldate      = {2022-06-17},
  volume       = {6}
}

@article{vyvermanProspectsLimitationsFulltext2012,
  abstract     = {The combination of incessant advances in sequencing technology producing large amounts of data and innovative bioinformatics approaches, designed to cope with this data flood, has led to new interesting results in the life sciences. Given the magnitude of sequence data to be processed, many bioinformatics tools rely on efficient solutions to a variety of complex string problems. These solutions include fast heuristic algorithms and advanced data structures, generally referred to as index structures. Although the importance of index structures is generally known to the bioinformatics community, the design and potency of these data structures, as well as their properties and limitations, are less understood. Moreover, the last decade has seen a boom in the number of variant index structures featuring complex and diverse memory-time trade-offs. This article brings a comprehensive state-of-the-art overview of the most popular index structures and their recently developed variants. Their features, interrelationships, the trade-offs they impose, but also their practical limitations, are explained and compared.},
  author       = {Vyverman, Michaël and De Baets, Bernard and Fack, Veerle and Dawyndt, Peter},
  date         = {2012-08-01},
  doi          = {10.1093/nar/gks408},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Vyverman et al_2012_Prospects and limitations of full-text index structures in genome analysis.pdf;/Users/lucblassel/Zotero/storage/IXQHCW2S/1212259.html},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {15},
  pages        = {6993--7015},
  shortjournal = {Nucleic Acids Research},
  title        = {Prospects and Limitations of Full-Text Index Structures in Genome Analysis},
  url          = {https://doi.org/10.1093/nar/gks408},
  urldate      = {2022-09-05},
  volume       = {40}
}

@article{wallaceMultipleSequenceAlignments2005,
  abstract     = {Multiple sequence alignments are very widely used in all areas of DNA and protein sequence analysis. The main methods that are still in use are based on ‘progressive alignment’ and date from the mid to late 1980s. Recently, some dramatic improvements have been made to the methodology with respect either to speed and capacity to deal with large numbers of sequences or to accuracy. There have also been some practical advances concerning how to combine three-dimensional structural information with primary sequences to give more accurate alignments, when structures are available.},
  author       = {Wallace, Iain M and Blackshields, Gordon and Higgins, Desmond G},
  date         = {2005-06-01},
  doi          = {10.1016/j.sbi.2005.04.002},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wallace et al_2005_Multiple sequence alignments.pdf;/Users/lucblassel/Zotero/storage/U5DLGQE4/S0959440X05000813.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  number       = {3},
  pages        = {261--266},
  series       = {Sequences and Topology/{{Nucleic}} Acids},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Multiple Sequence Alignments},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X05000813},
  urldate      = {2022-06-14},
  volume       = {15}
}

@article{wangComparisonLinearGap2011,
  abstract     = {Profile–profile alignment algorithms have proven powerful for recognizing remote homologs and generating alignments by effectively integrating sequence evolutionary information into scoring functions. In comparison to scoring function, the development of gap penalty functions has rarely been addressed in profile–profile alignment algorithms. Although indel frequency profiles have been used to construct profile-based variable gap penalties in some profile–profile alignment algorithms, there is still no fair comparison between variable gap penalties and traditional linear gap penalties to quantify the improvement of alignment accuracy. We compared two linear gap penalty functions, the traditional affine gap penalty (AGP) and the bilinear gap penalty (BGP), with two profile-based variable gap penalty functions, the Profile-based Gap Penalty used in SP5 (SPGP) and a new Weighted Profile-based Gap Penalty (WPGP) developed by us, on some well-established benchmark datasets. Our results show that profile-based variable gap penalties get limited improvements than linear gap penalties, whether incorporated with secondary structure information or not. Secondary structure information appears less powerful to be incorporated into gap penalties than into scoring functions. Analysis of gap length distributions indicates that gap penalties could stably maintain corresponding distributions of gap lengths in their alignments, but the distribution difference from reference alignments does not reflect the performance of gap penalties. There is useful information in indel frequency profiles, but it is still not good enough for improving alignment accuracy when used in profile-based variable gap penalties. All of the methods tested in this work are freely accessible at http://protein.cau.edu.cn/gppat/.},
  author       = {Wang, Chuan and Yan, Ren-Xiang and Wang, Xiao-Feng and Si, Jing-Na and Zhang, Ziding},
  date         = {2011-10-12},
  doi          = {10.1016/j.compbiolchem.2011.07.006},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2011_Comparison of linear gap penalties and profile-based variable gap penalties in.pdf;/Users/lucblassel/Zotero/storage/KADVBAIP/S147692711100082X.html},
  issn         = {1476-9271},
  journaltitle = {Computational Biology and Chemistry},
  keywords     = {Gap distribution,Indel frequency profile,Parameter optimization},
  langid       = {english},
  number       = {5},
  pages        = {308--318},
  shortjournal = {Computational Biology and Chemistry},
  title        = {Comparison of Linear Gap Penalties and Profile-Based Variable Gap Penalties in Profile–Profile Alignments},
  url          = {https://www.sciencedirect.com/science/article/pii/S147692711100082X},
  urldate      = {2022-08-26},
  volume       = {35}
}

@article{wangComplexityMultipleSequence1994,
  abstract     = {We study the computational complexity of two popular problems in multiple sequence alignment: multiple alignment with SP-score and multiple tree alignment. It is shown that the first problem is NP-complete and the second is MAX SNP-hard. The complexity of tree alignment with a given phylogeny is also considered.},
  author       = {Wang, Lusheng and Jiang, Tao},
  date         = {1994-01},
  doi          = {10.1089/cmb.1994.1.337},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang_Jiang_1994_On the Complexity of Multiple Sequence Alignment.pdf},
  journaltitle = {Journal of Computational Biology},
  number       = {4},
  pages        = {337--348},
  publisher    = {{Mary Ann Liebert, Inc., publishers}},
  title        = {On the {{Complexity}} of {{Multiple Sequence Alignment}}},
  url          = {https://www.liebertpub.com/doi/abs/10.1089/cmb.1994.1.337},
  urldate      = {2022-06-16},
  volume       = {1}
}

@article{wangMCALIGN2FasterAccurate2006,
  abstract     = {Non-coding DNA sequences comprise a very large proportion of the total genomic content of mammals, most other vertebrates, many invertebrates, and most plants. Unraveling the functional significance of non-coding DNA depends on how well we are able to align non-coding DNA sequences. However, the alignment of non-coding DNA sequences is more difficult than aligning protein-coding sequences.},
  author       = {Wang, Jun and Keightley, Peter D. and Johnson, Toby},
  date         = {2006-06-08},
  doi          = {10.1186/1471-2105-7-292},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang et al_2006_MCALIGN2.pdf;/Users/lucblassel/Zotero/storage/TMN8U7I8/1471-2105-7-292.html},
  issn         = {1471-2105},
  journaltitle = {BMC Bioinformatics},
  keywords     = {Dynamic Programming Method,General Time Reversible,General Time Reversible Model,Indel Event,Monte Carlo},
  number       = {1},
  pages        = {292},
  shortjournal = {BMC Bioinformatics},
  shorttitle   = {{{MCALIGN2}}},
  title        = {{{MCALIGN2}}: {{Faster}}, Accurate Global Pairwise Alignment of Non-Coding {{DNA}} Sequences Based on Explicit Models of Indel Evolution},
  url          = {https://doi.org/10.1186/1471-2105-7-292},
  urldate      = {2022-06-15},
  volume       = {7}
}

@article{wangScoringProfiletoprofileSequence2004,
  abstract     = {Sequence alignment profiles have been shown to be very powerful in creating accurate sequence alignments. Profiles are often used to search a sequence database with a local alignment algorithm. More accurate and longer alignments have been obtained with profile-to-profile comparison. There are several steps that must be performed in creating profile–profile alignments, and each involves choices in parameters and algorithms. These steps include (1) what sequences to include in a multiple alignment used to build each profile, (2) how to weight similar sequences in the multiple alignment and how to determine amino acid frequencies from the weighted alignment, (3) how to score a column from one profile aligned to a column of the other profile, (4) how to score gaps in the profile–profile alignment, and (5) how to include structural information. Large-scale benchmarks consisting of pairs of homologous proteins with structurally determined sequence alignments are necessary for evaluating the efficacy of each scoring scheme. With such a benchmark, we have investigated the properties of profile–profile alignments and found that (1) with optimized gap penalties, most column–column scoring functions behave similarly to one another in alignment accuracy; (2) some functions, however, have much higher search sensitivity and specificity; (3) position-specific weighting schemes in determining amino acid counts in columns of multiple sequence alignments are better than sequence-specific schemes; (4) removing positions in the profile with gaps in the query sequence results in better alignments; and (5) adding predicted and known secondary structure information improves alignments.},
  annotation   = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1110/ps.03601504},
  author       = {Wang, Guoli and Dunbrack Jr., Roland L.},
  date         = {2004},
  doi          = {10.1110/ps.03601504},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wang_Dunbrack Jr._2004_Scoring profile-to-profile sequence alignments.pdf;/Users/lucblassel/Zotero/storage/GDPWDGCY/ps.html},
  issn         = {1469-896X},
  journaltitle = {Protein Science},
  keywords     = {profile–profile alignment,PSI-BLAST,sequence profiles},
  langid       = {english},
  number       = {6},
  pages        = {1612--1626},
  title        = {Scoring Profile-to-Profile Sequence Alignments},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1110/ps.03601504},
  urldate      = {2022-06-16},
  volume       = {13}
}

@article{watermanBiologicalSequenceMetrics1976,
  abstract     = {Some new metrics are introduced to measure the distance between biological sequences, such as amino acid sequences or nucleotide sequences. These metrics generalize a metric of Sellers, who considered only single deletions, mutations, and insertions. The present metrics allow, for example, multiple deletions and insertions and single mutations. They also allow computation of the distance among more than two sequences. Algorithms for computing the values of the metrics are given which also compute best alignments. The connection with the information theory approach of Reichert, Cohen, and Wong is discussed.},
  author       = {Waterman, M. S and Smith, T. F and Beyer, W. A},
  date         = {1976-06-01},
  doi          = {10.1016/0001-8708(76)90202-4},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Waterman et al_1976_Some biological sequence metrics.pdf;/Users/lucblassel/Zotero/storage/NDPTIX88/0001870876902024.html},
  issn         = {0001-8708},
  journaltitle = {Advances in Mathematics},
  langid       = {english},
  number       = {3},
  pages        = {367--387},
  shortjournal = {Advances in Mathematics},
  title        = {Some Biological Sequence Metrics},
  url          = {https://www.sciencedirect.com/science/article/pii/0001870876902024},
  urldate      = {2022-08-26},
  volume       = {20}
}

@article{watermanEfficientSequenceAlignment1984,
  abstract     = {Sequence alignments are becoming more important with the increase of nucleic acid data. Fitch and Smith have recently given an example where multiple insertion/deletions (rather than a series of adjacent single insertion/deletions) are necessary to achieve the correct alignment. Multiple insertion/deletions are known to increase computation time from O(n2) to O(n3) although Gotoh has presented an O(n2) algorithm in the case the multiple insertion/deletion weighting function is linear. It is argued in this paper that it could be desirable to use concave weighting functions. For that case, an algorithm is derived that is conjectured to be O(n2).},
  author       = {Waterman, Michael S.},
  date         = {1984-06-07},
  doi          = {10.1016/S0022-5193(84)80037-5},
  file         = {/Users/lucblassel/Zotero/storage/LFNC8MZH/S0022519384800375.html},
  issn         = {0022-5193},
  journaltitle = {Journal of Theoretical Biology},
  langid       = {english},
  number       = {3},
  pages        = {333--337},
  shortjournal = {Journal of Theoretical Biology},
  title        = {Efficient Sequence Alignment Algorithms},
  url          = {https://www.sciencedirect.com/science/article/pii/S0022519384800375},
  urldate      = {2022-06-14},
  volume       = {108}
}

@article{watermanNewAlgorithmBest1987,
  abstract     = {The algorithm of Smith \& Waterman for identification of maximally similar subsequences is extended to allow identification of all non-intersecting similar subsequences with similarity score at or above some preset level. The resulting alignments are found in order of score, with the highest scoring alignment first. In the case of single gaps or multiple gaps weighted linear with gap length, the algorithm is extremely efficient, taking very little time beyond that of the initial calculation of the matrix. The algorithm is applied to comparisons of tRNA-rRNA sequences from Escherichia coli. A statistical analysis is important for proper evaluation of the results, which differ substantially from the results of an earlier analysis of the same sequences by Bloch and colleagues.},
  author       = {Waterman, Michael S. and Eggert, Mark},
  date         = {1987-10-20},
  doi          = {10.1016/0022-2836(87)90478-5},
  file         = {/Users/lucblassel/Zotero/storage/E6EJKM3K/0022283687904785.html},
  issn         = {0022-2836},
  journaltitle = {Journal of Molecular Biology},
  langid       = {english},
  number       = {4},
  pages        = {723--728},
  shortjournal = {Journal of Molecular Biology},
  title        = {A New Algorithm for Best Subsequence Alignments with Application to {{tRNA-rRNA}} Comparisons},
  url          = {https://www.sciencedirect.com/science/article/pii/0022283687904785},
  urldate      = {2022-06-14},
  volume       = {197}
}

@article{watsonPredictingProteinFunction2005,
  abstract     = {When a protein's function cannot be experimentally determined, it can often be inferred from sequence similarity. Should this process fail, analysis of the protein structure can provide functional clues or confirm tentative functional assignments inferred from the sequence. Many structure-based approaches exist (e.g. fold similarity, three-dimensional templates), but as no single method can be expected to be successful in all cases, a more prudent approach involves combining multiple methods. Several automated servers that integrate evidence from multiple sources have been released this year and particular improvements have been seen with methods utilizing the Gene Ontology functional annotation schema.},
  author       = {Watson, James D and Laskowski, Roman A and Thornton, Janet M},
  date         = {2005-06-01},
  doi          = {10.1016/j.sbi.2005.04.003},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Watson et al_2005_Predicting protein function from sequence and structural data.pdf;/Users/lucblassel/Zotero/storage/4ZP7JFZC/S0959440X05000825.html},
  issn         = {0959-440X},
  journaltitle = {Current Opinion in Structural Biology},
  langid       = {english},
  number       = {3},
  pages        = {275--284},
  series       = {Sequences and Topology/{{Nucleic}} Acids},
  shortjournal = {Current Opinion in Structural Biology},
  title        = {Predicting Protein Function from Sequence and Structural Data},
  url          = {https://www.sciencedirect.com/science/article/pii/S0959440X05000825},
  urldate      = {2022-06-14},
  volume       = {15}
}

@article{weeBioinformaticsToolsGenome2019,
  abstract     = {The application of third-generation sequencing (TGS) technology in genetics and genomics have provided opportunities to categorize and explore the individual genomic landscapes and mutations relevant for diagnosis and therapy using whole genome sequencing and de novo genome assembly. In general, the emerging TGS technology can produce high quality long reads for the determination of overlapping reads and transcript isoforms. However, this technology still faces challenges such as the accuracy for the identification of nucleotide bases and high error rates. Here, we surveyed 39 TGS-related tools for de novo assembly and genome analysis to identify the differences among their characteristics, such as the required input, the interaction with the user, sequencing platforms, type of reads, error models, the possibility of introducing coverage bias, the simulation of genomic variants and outputs provided. The decision trees are summarized to help researchers to find out the most suitable tools to analyze the TGS data. Our comprehensive survey and evaluation of computational features of existing methods for TGS may provide a valuable guideline for researchers.},
  author       = {Wee, YongKiat and Bhyan, Salma Begum and Liu, Yining and Lu, Jiachun and Li, Xiaoyan and Zhao, Min},
  date         = {2019-02-14},
  doi          = {10.1093/bfgp/ely037},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Wee et al_2019_The bioinformatics tools for the genome assembly and analysis based on.pdf;/Users/lucblassel/Zotero/storage/JKXXJ77J/5181442.html},
  issn         = {2041-2657},
  journaltitle = {Briefings in Functional Genomics},
  number       = {1},
  pages        = {1--12},
  shortjournal = {Briefings in Functional Genomics},
  title        = {The Bioinformatics Tools for the Genome Assembly and Analysis Based on Third-Generation Sequencing},
  url          = {https://doi.org/10.1093/bfgp/ely037},
  urldate      = {2022-06-15},
  volume       = {18}
}

@inproceedings{weinerLinearPatternMatching1973,
  abstract   = {In 1970, Knuth, Pratt, and Morris [1] showed how to do basic pattern matching in linear time. Related problems, such as those discussed in [4], have previously been solved by efficient but sub-optimal algorithms. In this paper, we introduce an interesting data structure called a bi-tree. A linear time algorithm for obtaining a compacted version of a bi-tree associated with a given string is presented. With this construction as the basic tool, we indicate how to solve several pattern matching problems, including some from [4] in linear time.},
  author     = {Weiner, Peter},
  booktitle  = {14th {{Annual Symposium}} on {{Switching}} and {{Automata Theory}} (Swat 1973)},
  date       = {1973-10},
  doi        = {10.1109/SWAT.1973.13},
  eventtitle = {14th {{Annual Symposium}} on {{Switching}} and {{Automata Theory}} (Swat 1973)},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Weiner_1973_Linear pattern matching algorithms.pdf;/Users/lucblassel/Zotero/storage/YDKYV6AV/4569722.html},
  issn       = {0272-4847},
  keywords   = {Data structures,Pattern matching,Terminology},
  pages      = {1--11},
  title      = {Linear Pattern Matching Algorithms}
}

@article{whelanGeneralEmpiricalModel2001,
  abstract     = {Phylogenetic inference from amino acid sequence data uses mainly empirical models of amino acid replacement and is therefore dependent on those models. Two of the more widely used models, the Dayhoff and JTT models, are estimated using similar methods that can utilize large numbers of sequences from many unrelated protein families but are somewhat unsatisfactory because they rely on assumptions that may lead to systematic error and discard a large amount of the information within the sequences. The alternative method of maximum-likelihood estimation may utilize the information in the sequence data more efficiently and suffers from no systematic error, but it has previously been applicable to relatively few sequences related by a single phylogenetic tree. Here, we combine the best attributes of these two methods using an approximate maximum-likelihood method. We implemented this approach to estimate a new model of amino acid replacement from a database of globular protein sequences comprising 3,905 amino acid sequences split into 182 protein families. While the new model has an overall structure similar to those of other commonly used models, there are significant differences. The new model outperforms the Dayhoff and JTT models with respect to maximum-likelihood values for a large majority of the protein families in our database. This suggests that it provides a better overall fit to the evolutionary process in globular proteins and may lead to more accurate phylogenetic tree estimates. Potentially, this matrix, and the methods used to generate it, may also be useful in other areas of research, such as biological sequence database searching, sequence alignment, and protein structure prediction, for which an accurate description of amino acid replacement is required.},
  author       = {Whelan, S. and Goldman, N.},
  date         = {2001-05},
  doi          = {10.1093/oxfordjournals.molbev.a003851},
  eprint       = {11319253},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Whelan_Goldman_2001_A general empirical model of protein evolution derived from multiple protein.pdf},
  issn         = {0737-4038},
  journaltitle = {Molecular Biology and Evolution},
  keywords     = {Algorithms,Amino Acid Sequence,Amino Acids,Computer Simulation,Evolution; Molecular,Likelihood Functions,Models; Biological,Phylogeny,Probability,Proteins,Sequence Alignment},
  langid       = {english},
  number       = {5},
  pages        = {691--699},
  shortjournal = {Mol Biol Evol},
  title        = {A General Empirical Model of Protein Evolution Derived from Multiple Protein Families Using a Maximum-Likelihood Approach},
  volume       = {18}
}

@article{wrablGapsStructurallySimilar2004,
  abstract     = {An algorithm was developed to locally optimize gaps from the FSSP database. Over 2 million gaps were identified from all versus all FSSP structure comparisons, and datasets of non-identical gaps and flanking regions comprising between 90,000 and 135,000 sequence fragments were extracted for statistical analysis. Relative to background frequencies, gaps were enriched in residue types with small side chains and high turn propensity (D, G, N, P, S), and were depleted in residue types with hydrophobic side chains (C, F, I, L, V, W, Y). In contrast, regions flanking a gap exhibited opposite trends in amino acid frequencies, i.e., enrichment in hydrophobic residues and a high degree of secondary structure. Log-odds scores of residue type as a function of position in or around a gap were derived from the statistics. Three simple experiments demonstrated that these scores contained significant predictive information. First, regions where gaps were observed in single sequences taken from HOMSTRAD structure-based multiple sequence alignments generally scored higher than regions where gaps were not observed. Second, given the correct pairwise-aligned cores, the actual positions of gaps could be reproduced from sequence more accurately using the structurally-derived statistics than by using random pairwise alignments. Finally, revision of the Clustal-W residue-specific gap opening parameters with this new information improved the agreement of Clustal-W alignments with the structure-based alignments. At least three applications for these results are envisioned: improvement of gap penalties in pairwise (or multiple) sequence alignment, prediction of regions of single sequences likely (or unlikely) to contain indels, and more accurate placement of gaps in automated pairwise structure alignment. Proteins 2003;53:000–000. © 2003 Wiley-Liss, Inc.},
  annotation   = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/prot.10508},
  author       = {Wrabl, James O. and Grishin, Nick V.},
  date         = {2004},
  doi          = {10.1002/prot.10508},
  file         = {/Users/lucblassel/Zotero/storage/N7KH9YIX/prot.html},
  issn         = {1097-0134},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  keywords     = {gap prediction,indels,local structure optimization,pairwise alignment},
  langid       = {english},
  number       = {1},
  pages        = {71--87},
  shorttitle   = {Gaps in Structurally Similar Proteins},
  title        = {Gaps in Structurally Similar Proteins: {{Towards}} Improvement of Multiple Sequence Alignment},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.10508},
  urldate      = {2022-08-26},
  volume       = {54}
}

@article{yoonHiddenMarkovModels2009,
  abstract     = {Hidden Markov models (HMMs) have been extensively used in biological sequence analysis. In this paper, we give a tutorial review of HMMs and their applications in a variety of problems in molecular biology. We especially focus on three types of HMMs: the profile-HMMs, pair-HMMs, and context-sensitive HMMs. We show how these HMMs can be used to solve various sequence analysis problems, such as pairwise and multiple sequence alignments, gene annotation, classification, similarity search, and many others.},
  author       = {Yoon, Byung-Jun},
  date         = {2009-09},
  doi          = {10.2174/138920209789177575},
  eprint       = {20190955},
  eprinttype   = {pmid},
  file         = {/Users/lucblassel/Google Drive/Zotero_papers/yoon_2009_hidden_markov_models_and_their_applications_in.pdf},
  issn         = {1389-2029},
  journaltitle = {Current Genomics},
  number       = {6},
  pages        = {402--415},
  pmcid        = {PMC2766791},
  shortjournal = {Curr Genomics},
  title        = {Hidden {{Markov Models}} and Their {{Applications}} in {{Biological Sequence Analysis}}},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2766791/},
  urldate      = {2019-08-19},
  volume       = {10}
}

@inproceedings{zeniLOGANHighPerformanceGPUBased2020,
  abstract   = {Pairwise sequence alignment is one of the most computationally intensive kernels in genomic data analysis, accounting for more than 90\% of the runtime for key bioinformatics applications. This method is particularly expensive for third-generation sequences due to the high computational cost of analyzing sequences of length between 1Kb and 1Mb. Given the quadratic overhead of exact pairwise algorithms for long alignments, the community primarily relies on approximate algorithms that search only for high-quality alignments and stop early when one is not found. In this work, we present the first GPU optimization of the popular X-drop alignment algorithm, that we named LOGAN. Results show that our high-performance multi-GPU implementation achieves up to 181.6 GCUPS and speed-ups up to 6.6× and 30.7× using 1 and 6 NVIDIA Tesla V100, respectively, over the state-of-the-art software running on two IBM Power9 processors using 168 CPU threads, with equivalent accuracy. We also demonstrate a 2.3× LOGAN speed-up versus ksw2, a state-of-art vectorized algorithm for sequence alignment implemented in minimap2, a long-read mapping software. To highlight the impact of our work on a real-world application, we couple LOGAN with a many-to-many long-read alignment software called BELLA, and demonstrate that our implementation improves the overall BELLA runtime by up to 10.6×. Finally, we adapt the Roofline model for LOGAN and demonstrate that our implementation is near optimal on the NVIDIA Tesla V100s.},
  author     = {Zeni, Alberto and Guidi, Giulia and Ellis, Marquita and Ding, Nan and Santambrogio, Marco D. and Hofmeyr, Steven and Buluç, Aydın and Oliker, Leonid and Yelick, Katherine},
  booktitle  = {2020 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  date       = {2020-05},
  doi        = {10.1109/IPDPS47924.2020.00055},
  eventtitle = {2020 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  file       = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zeni et al_2020_LOGAN.pdf;/Users/lucblassel/Zotero/storage/2EXSPZNU/9139808.html},
  issn       = {1530-2075},
  keywords   = {Acceleration,Computer architecture,Graphics processing units,Heuristic algorithms,Parallel processing,Software algorithms},
  pages      = {462--471},
  shorttitle = {{{LOGAN}}},
  title      = {{{LOGAN}}: {{High-Performance GPU-Based X-Drop Long-Read Alignment}}}
}

@article{zhangGeneticAlgorithmMultiple1997,
  abstract     = {Multiple molecular sequence alignment is among the most important and most challenging tasks in computational biology. The currently used alignment techniques are characterized by great computational complexity. which prevents their wider use. This research is aimed at developing a new technique for efficient multiple sequence alignment.The new method is based on genetic algorithms. Genetic algorithms are stochastic approaches for efficient and robust searching. By converting hiomolecular sequence alignment into a problem of searching for optimal or near-optimal points in an ‘alignment space’, a genetic algorithm can be used to find good alignments very efficiently.Experiments on real data sets have shown that the average computing time of this technique may he two or three orders lower than that of a technique based on pairwise dynamic programming, while the alignment qualities are very similar.A C program on UNIX has been written to implement the technique. It is available on request from the authors.E-mail: czhang@watnow.uwaterloo.ca},
  author       = {Zhang, Ching and Wong, Andrew K.C.},
  date         = {1997-12-01},
  doi          = {10.1093/bioinformatics/13.6.565},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zhang_Wong_1997_A genetic algorithm for multiple molecular sequence alignment2.pdf;/Users/lucblassel/Zotero/storage/G8XLN3G4/323539.html},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {6},
  pages        = {565--581},
  shortjournal = {Bioinformatics},
  title        = {A Genetic Algorithm for Multiple Molecular Sequence Alignment},
  url          = {https://doi.org/10.1093/bioinformatics/13.6.565},
  urldate      = {2022-06-17},
  volume       = {13}
}

@article{zhangGeneticAlgorithmMultiple1997a,
  abstract     = {Motivation: Multiple molecular sequence alignment is among the most important and most challenging tasks in computational biology. The currently used alignment techniques are characterized by great computational complexity, which prevents their wider use. This research is aimed at developing a new technique for efficient multiple sequence alignment.},
  author       = {Zhang, Ching and Wong, Andrew K.C.},
  date         = {1997},
  doi          = {10.1093/bioinformatics/13.6.565},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zhang_Wong_1997_A genetic algorithm for multiple molecular sequence alignment.pdf},
  issn         = {1367-4803, 1460-2059},
  journaltitle = {Bioinformatics},
  langid       = {english},
  number       = {6},
  pages        = {565--581},
  shortjournal = {Bioinformatics},
  title        = {A Genetic Algorithm for Multiple Molecular Sequence Alignment},
  url          = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/13.6.565},
  urldate      = {2022-06-17},
  volume       = {13}
}

@article{zhangSP5ImprovingProtein2008,
  abstract     = {How to recognize the structural fold of a protein is one of the challenges in protein structure prediction. We have developed a series of single (non-consensus) methods (SPARKS, SP2, SP3, SP4) that are based on weighted matching of two to four sequence and structure-based profiles. There is a robust improvement of the accuracy and sensitivity of fold recognition as the number of matching profiles increases. Here, we introduce a new profile-profile comparison term based on real-value dihedral torsion angles. Together with updated real-value solvent accessibility profile and a new variable gap-penalty model based on fractional power of insertion/deletion profiles, the new method (SP5) leads to a robust improvement over previous SP method. There is a 2\% absolute increase (5\% relative improvement) in alignment accuracy over SP4 based on two independent benchmarks. Moreover, SP5 makes 7\% absolute increase (22\% relative improvement) in success rate of recognizing correct structural folds, and 32\% relative improvement in model accuracy of models within the same fold in Lindahl benchmark. In addition, modeling accuracy of top-1 ranked models is improved by 12\% over SP4 for the difficult targets in CASP 7 test set. These results highlight the importance of harnessing predicted structural properties in challenging remote-homolog recognition. The SP5 server is available at http://sparks.informatics.iupui.edu.},
  author       = {Zhang, Wei and Liu, Song and Zhou, Yaoqi},
  date         = {2008-06-04},
  doi          = {10.1371/journal.pone.0002325},
  file         = {/Users/lucblassel/Library/CloudStorage/GoogleDrive-luc.blassel@gmail.com/My Drive/Zotero_papers/Zhang et al_2008_SP5.pdf;/Users/lucblassel/Zotero/storage/JJAC3UHB/article.html},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Biochemical simulations,Built structures,Multiple alignment calculation,Protein folding,Protein structure comparison,Protein structure prediction,Sequence alignment,Structural proteins},
  langid       = {english},
  number       = {6},
  pages        = {e2325},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS ONE},
  shorttitle   = {{{SP5}}},
  title        = {{{SP5}}: {{Improving Protein Fold Recognition}} by {{Using Torsion Angle Profiles}} and {{Profile-Based Gap Penalty Model}}},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0002325},
  urldate      = {2022-08-26},
  volume       = {3}
}

@article{zhengImprovedDesignAnalysis2020,
  abstract     = {Minimizers are methods to sample k-mers from a string, with the guarantee that similar set of k-mers will be chosen on similar strings. It is parameterized by the k-mer length k, a window length w and an order on the k-mers. Minimizers are used in a large number of softwares and pipelines to improve computation efficiency and decrease memory usage. Despite the method’s popularity, many theoretical questions regarding its performance remain open. The core metric for measuring performance of a minimizer is the density, which measures the sparsity of sampled k-mers. The theoretical optimal density for a minimizer is 1/w, provably not achievable in general. For given k and w, little is known about asymptotically optimal minimizers, that is minimizers with density O(1/w).We derive a necessary and sufficient condition for existence of asymptotically optimal minimizers. We also provide a randomized algorithm, called the Miniception, to design minimizers with the best theoretical guarantee to date on density in practical scenarios. Constructing and using the Miniception is as easy as constructing and using a random minimizer, which allows the design of efficient minimizers that scale to the values of k and w used in current bioinformatics software programs.Reference implementation of the Miniception and the codes for analysis can be found at https://github.com/kingsford-group/miniception.Supplementary data are available at Bioinformatics online.},
  author       = {Zheng, Hongyu and Kingsford, Carl and Marçais, Guillaume},
  date         = {2020-07-01},
  doi          = {10.1093/bioinformatics/btaa472},
  file         = {/Volumes/GoogleDrive/My Drive/Zotero_papers/Zheng et al_2020_Improved design and analysis of practical minimizers.pdf;/Users/lucblassel/Zotero/storage/MDP2HDKT/5870484.html},
  issn         = {1367-4803},
  issue        = {Supplement\_1},
  journaltitle = {Bioinformatics},
  pages        = {i119-i127},
  shortjournal = {Bioinformatics},
  title        = {Improved Design and Analysis of Practical Minimizers},
  url          = {https://doi.org/10.1093/bioinformatics/btaa472},
  urldate      = {2022-06-02},
  volume       = {36}
}


