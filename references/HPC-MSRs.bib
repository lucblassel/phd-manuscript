
@article{adamsGenomeSequenceDrosophila2000,
  abstract     = {The fly Drosophila melanogaster is one of the most intensively studied organisms in biology and serves as a model system for the investigation of many developmental and cellular processes common to higher eukaryotes, including humans. We have determined the nucleotide sequence of nearly all of the approximately 120-megabase euchromatic portion of the Drosophila genome using a whole-genome shotgun sequencing strategy supported by extensive clone-based sequence and a high-quality bacterial artificial chromosome physical map. Efforts are under way to close the remaining gaps; however, the sequence is of sufficient accuracy and contiguity to be declared substantially complete and to support an initial analysis of genome structure and preliminary gene annotation and interpretation. The genome encodes approximately 13,600 genes, somewhat fewer than the smaller Caenorhabditis elegans genome, but with comparable functional diversity.},
  author       = {Adams, M. D. and Celniker, S. E. and Holt, R. A. and Evans, C. A. and Gocayne, J. D. and Amanatides, P. G. and Scherer, S. E. and Li, P. W. and Hoskins, R. A. and Galle, R. F. and George, R. A. and Lewis, S. E. and Richards, S. and Ashburner, M. and Henderson, S. N. and Sutton, G. G. and Wortman, J. R. and Yandell, M. D. and Zhang, Q. and Chen, L. X. and Brandon, R. C. and Rogers, Y. H. and Blazej, R. G. and Champe, M. and Pfeiffer, B. D. and Wan, K. H. and Doyle, C. and Baxter, E. G. and Helt, G. and Nelson, C. R. and Gabor, G. L. and Abril, J. F. and Agbayani, A. and An, H. J. and Andrews-Pfannkoch, C. and Baldwin, D. and Ballew, R. M. and Basu, A. and Baxendale, J. and Bayraktaroglu, L. and Beasley, E. M. and Beeson, K. Y. and Benos, P. V. and Berman, B. P. and Bhandari, D. and Bolshakov, S. and Borkova, D. and Botchan, M. R. and Bouck, J. and Brokstein, P. and Brottier, P. and Burtis, K. C. and Busam, D. A. and Butler, H. and Cadieu, E. and Center, A. and Chandra, I. and Cherry, J. M. and Cawley, S. and Dahlke, C. and Davenport, L. B. and Davies, P. and de Pablos, B. and Delcher, A. and Deng, Z. and Mays, A. D. and Dew, I. and Dietz, S. M. and Dodson, K. and Doup, L. E. and Downes, M. and Dugan-Rocha, S. and Dunkov, B. C. and Dunn, P. and Durbin, K. J. and Evangelista, C. C. and Ferraz, C. and Ferriera, S. and Fleischmann, W. and Fosler, C. and Gabrielian, A. E. and Garg, N. S. and Gelbart, W. M. and Glasser, K. and Glodek, A. and Gong, F. and Gorrell, J. H. and Gu, Z. and Guan, P. and Harris, M. and Harris, N. L. and Harvey, D. and Heiman, T. J. and Hernandez, J. R. and Houck, J. and Hostin, D. and Houston, K. A. and Howland, T. J. and Wei, M. H. and Ibegwam, C. and Jalali, M. and Kalush, F. and Karpen, G. H. and Ke, Z. and Kennison, J. A. and Ketchum, K. A. and Kimmel, B. E. and Kodira, C. D. and Kraft, C. and Kravitz, S. and Kulp, D. and Lai, Z. and Lasko, P. and Lei, Y. and Levitsky, A. A. and Li, J. and Li, Z. and Liang, Y. and Lin, X. and Liu, X. and Mattei, B. and McIntosh, T. C. and McLeod, M. P. and McPherson, D. and Merkulov, G. and Milshina, N. V. and Mobarry, C. and Morris, J. and Moshrefi, A. and Mount, S. M. and Moy, M. and Murphy, B. and Murphy, L. and Muzny, D. M. and Nelson, D. L. and Nelson, D. R. and Nelson, K. A. and Nixon, K. and Nusskern, D. R. and Pacleb, J. M. and Palazzolo, M. and Pittman, G. S. and Pan, S. and Pollard, J. and Puri, V. and Reese, M. G. and Reinert, K. and Remington, K. and Saunders, R. D. and Scheeler, F. and Shen, H. and Shue, B. C. and Sidén-Kiamos, I. and Simpson, M. and Skupski, M. P. and Smith, T. and Spier, E. and Spradling, A. C. and Stapleton, M. and Strong, R. and Sun, E. and Svirskas, R. and Tector, C. and Turner, R. and Venter, E. and Wang, A. H. and Wang, X. and Wang, Z. Y. and Wassarman, D. A. and Weinstock, G. M. and Weissenbach, J. and Williams, S. M. and WoodageT, null and Worley, K. C. and Wu, D. and Yang, S. and Yao, Q. A. and Ye, J. and Yeh, R. F. and Zaveri, J. S. and Zhan, M. and Zhang, G. and Zhao, Q. and Zheng, L. and Zheng, X. H. and Zhong, F. N. and Zhong, W. and Zhou, X. and Zhu, S. and Zhu, X. and Smith, H. O. and Gibbs, R. A. and Myers, E. W. and Rubin, G. M. and Venter, J. C.},
  date         = {2000-03-24},
  doi          = {10.1126/science.287.5461.2185},
  eprint       = {10731132},
  eprinttype   = {pmid},
  issn         = {0036-8075},
  journaltitle = {Science (New York, N.Y.)},
  keywords     = {Animals,Biological Transport,Chromatin,Cloning; Molecular,Computational Biology,Contig Mapping,Cytochrome P-450 Enzyme System,DNA Repair,DNA Replication,Drosophila melanogaster,Euchromatin,Gene Library,Genes; Insect,Genome,Heterochromatin,Insect Proteins,Nuclear Proteins,Protein Biosynthesis,Sequence Analysis; DNA,Transcription; Genetic},
  langid       = {english},
  number       = {5461},
  options      = {useprefix=true},
  pages        = {2185--2195},
  shortjournal = {Science},
  title        = {The Genome Sequence of {{Drosophila}} Melanogaster},
  volume       = {287}
}

@article{bzikadzeAutomatedAssemblyCentromeres2020,
  abstract     = {Centromeric variation has been linked to cancer and infertility, but centromere sequences contain multiple tandem repeats and can only be assembled manually from long error-prone reads. Here we describe the centroFlye algorithm for centromere assembly using long error-prone reads, and apply it to assemble human centromeres on chromosomes 6 and X. Our analyses reveal putative breakpoints in the manual reconstruction of the human X centromere, demonstrate that human X chromosome is partitioned into repeat subfamilies and provide initial insights into centromere evolution. We anticipate that centroFlye could be applied to automatically close remaining multimegabase gaps in the reference human genome.},
  annotation   = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Genetics;Genome assembly algorithms Subject\_term\_id: genetics;genome-assembly-algorithms},
  author       = {Bzikadze, Andrey V. and Pevzner, Pavel A.},
  date         = {2020-11},
  doi          = {10.1038/s41587-020-0582-4},
  issn         = {1546-1696},
  issue        = {11},
  journaltitle = {Nature Biotechnology},
  keywords     = {Genetics,Genome assembly algorithms},
  langid       = {english},
  number       = {11},
  pages        = {1309--1316},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Biotechnol},
  title        = {Automated Assembly of Centromeres from Ultra-Long Error-Prone Reads},
  volume       = {38}
}

@article{dohmBenchmarkingLongreadCorrection2020,
  abstract     = {Third-generation sequencing technologies provided by Pacific Biosciences and Oxford Nanopore Technologies generate read lengths in the scale of kilobasepairs. However, these reads display high error rates, and correction steps are necessary to realize their great potential in genomics and transcriptomics. Here, we compare properties of PacBio and Nanopore data and assess correction methods by Canu, MARVEL and proovread in various combinations. We found total error rates of around 13\% in the raw datasets. PacBio reads showed a high rate of insertions (around 8\%) whereas Nanopore reads showed similar rates for substitutions, insertions and deletions of around 4\% each. In data from both technologies the errors were uniformly distributed along reads apart from noisy 5′ ends, and homopolymers appeared among the most over-represented kmers relative to a reference. Consensus correction using read overlaps reduced error rates to about 1\% when using Canu or MARVEL after patching. The lowest error rate in Nanopore data (0.45\%) was achieved by applying proovread on MARVEL-patched data including Illumina short-reads, and the lowest error rate in PacBio data (0.42\%) was the result of Canu correction with minimap2 alignment after patching. Our study provides valuable insights and benchmarks regarding long-read data and correction methods.},
  author       = {Dohm, Juliane C and Peters, Philipp and Stralis-Pavese, Nancy and Himmelbauer, Heinz},
  date         = {2020-06-01},
  doi          = {10.1093/nargab/lqaa037},
  issn         = {2631-9268},
  journaltitle = {NAR Genomics and Bioinformatics},
  number       = {2},
  shortjournal = {NAR Genomics and Bioinformatics},
  title        = {Benchmarking of Long-Read Correction Methods},
  volume       = {2}
}

@article{ekimMinimizerspaceBruijnGraphs2021,
  abstract     = {DNA sequencing data continue to progress toward longer reads with increasingly lower sequencing error rates. Here, we define an algorithmic approach, mdBG, that makes use of minimizer-space de Bruijn graphs to enable long-read genome assembly. mdBG achieves orders-of-magnitude improvement in both speed and memory usage over existing methods without compromising accuracy. A human genome is assembled in under 10~min using 8 cores and 10 GB RAM, and 60 Gbp of metagenome reads are assembled in 4~min using 1 GB RAM. In addition, we constructed a minimizer-space de Bruijn graph-based representation of 661,405 bacterial genomes, comprising 16 million nodes and 45 million edges, and successfully search it for anti-microbial resistance (AMR) genes in 12~min. We expect our advances to be essential to sequence analysis, given the rise of long-read sequencing in genomics, metagenomics, and pangenomics. Code for constructing mdBGs is freely available for download at https://github.com/ekimb/rust-mdbg/.},
  author       = {Ekim, Barış and Berger, Bonnie and Chikhi, Rayan},
  date         = {2021-10-20},
  doi          = {10.1016/j.cels.2021.08.009},
  issn         = {2405-4712},
  journaltitle = {Cell Systems},
  keywords     = {bacterial genomes,data structures,de Bruijn graphs,genome assembly,genome graphs,long-read sequencing,metagenomics,minimizers,pangenomics,partial order alignment},
  langid       = {english},
  number       = {10},
  pages        = {958-968.e6},
  shortjournal = {Cell Systems},
  shorttitle   = {Minimizer-Space de {{Bruijn}} Graphs},
  title        = {Minimizer-Space de {{Bruijn}} Graphs: Whole-Genome Assembly of Long Reads in Minutes on a Personal Computer},
  volume       = {12}
}

@book{grahamConcreteMathematicsFoundation1994,
  author     = {Graham, Ronald L. and Knuth, Donald Ervin and Patashnik, Oren},
  date       = {1994},
  edition    = {2nd ed},
  isbn       = {978-0-201-55802-9},
  keywords   = {Computer science,Mathematics},
  location   = {{Reading, Mass}},
  pagetotal  = {657},
  publisher  = {{Addison-Wesley}},
  shorttitle = {Concrete Mathematics},
  title      = {Concrete Mathematics: A Foundation for Computer Science}
}

@article{jainWeightedMinimizerSampling2020,
  abstract     = {In this era of exponential data growth, minimizer sampling has become a standard algorithmic technique for rapid genome sequence comparison. This technique yields a sub-linear representation of sequences, enabling their comparison in reduced space and time. A key property of the minimizer technique is that if two sequences share a substring of a specified length, then they can be guaranteed to have a matching minimizer. However, because the k-mer distribution in eukaryotic genomes is highly uneven, minimizer-based tools (e.g. Minimap2, Mashmap) opt to discard the most frequently occurring minimizers from the genome to avoid excessive false positives. By doing so, the underlying guarantee is lost and accuracy is reduced in repetitive genomic regions.We introduce a novel weighted-minimizer sampling algorithm. A unique feature of the proposed algorithm is that it performs minimizer sampling while considering a weight for each k-mer; i.e. the higher the weight of a k-mer, the more likely it is to be selected. By down-weighting frequently occurring k-mers, we are able to meet both objectives: (i) avoid excessive false-positive matches and (ii) maintain the minimizer match guarantee. We tested our algorithm, Winnowmap, using both simulated and real long-read data and compared it to a state-of-the-art long read mapper, Minimap2. Our results demonstrate a reduction in the mapping error-rate from 0.14\% to 0.06\% in the recently finished human X chromosome (154.3 Mbp), and from 3.6\% to 0\% within the highly repetitive X centromere (3.1 Mbp). Winnowmap improves mapping accuracy within repeats and achieves these results with sparser sampling, leading to better index compression and competitive runtimes. Winnowmap is built on top of the Minimap2 codebase and is available at https://github.com/marbl/winnowmap.},
  author       = {Jain, Chirag and Rhie, Arang and Zhang, Haowen and Chu, Claudia and Walenz, Brian P and Koren, Sergey and Phillippy, Adam M},
  date         = {2020-07-01},
  doi          = {10.1093/bioinformatics/btaa435},
  issn         = {1367-4803},
  issue        = {Supplement\_1},
  journaltitle = {Bioinformatics},
  keywords     = {mapping},
  pages        = {i111-i118},
  shortjournal = {Bioinformatics},
  title        = {Weighted Minimizer Sampling Improves Long Read Mapping},
  volume       = {36}
}

@article{langmeadFastGappedreadAlignment2012,
  abstract     = {The Bowtie 2 software achieves fast, sensitive, accurate and memory-efficient gapped alignment of sequencing reads using the full-text minute index and hardware-accelerated dynamic programming algorithms.},
  annotation   = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Bioinformatics;Genomics;Sequencing Subject\_term\_id: bioinformatics;genomics;sequencing},
  author       = {Langmead, Ben and Salzberg, Steven L.},
  date         = {2012-04},
  doi          = {10.1038/nmeth.1923},
  issn         = {1548-7105},
  issue        = {4},
  journaltitle = {Nature Methods},
  keywords     = {Bioinformatics,Genomics,Sequencing},
  langid       = {english},
  number       = {4},
  pages        = {357--359},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Fast Gapped-Read Alignment with {{Bowtie}} 2},
  volume       = {9}
}

@online{liAligningSequenceReads2013,
  abstract      = {Summary: BWA-MEM is a new alignment algorithm for aligning sequence reads or long query sequences against a large reference genome such as human. It automatically chooses between local and end-to-end alignments, supports paired-end reads and performs chimeric alignment. The algorithm is robust to sequencing errors and applicable to a wide range of sequence lengths from 70bp to a few megabases. For mapping 100bp sequences, BWA-MEM shows better performance than several state-of-art read aligners to date. Availability and implementation: BWA-MEM is implemented as a component of BWA, which is available at http://github.com/lh3/bwa. Contact: hengli@broadinstitute.org},
  archiveprefix = {arXiv},
  author        = {Li, Heng},
  date          = {2013-05-26},
  eprint        = {1303.3997},
  eprinttype    = {arxiv},
  keywords      = {Quantitative Biology - Genomics},
  primaryclass  = {q-bio},
  title         = {Aligning Sequence Reads, Clone Sequences and Assembly Contigs with {{BWA}}-{{MEM}}}
}

@article{liMinimap2PairwiseAlignment2018,
  abstract     = {Recent advances in sequencing technologies promise ultra-long reads of ∼100 kb in average, full-length mRNA or cDNA reads in high throughput and genomic contigs over 100 Mb in length. Existing alignment programs are unable or inefficient to process such data at scale, which presses for the development of new alignment algorithms.Minimap2 is a general-purpose alignment program to map DNA or long mRNA sequences against a large reference database. It works with accurate short reads of ≥100\,bp in length, ≥1\,kb genomic reads at error rate ∼15\%, full-length noisy Direct RNA or cDNA reads and assembly contigs or closely related full chromosomes of hundreds of megabases in length. Minimap2 does split-read alignment, employs concave gap cost for long insertions and deletions and introduces new heuristics to reduce spurious alignments. It is 3–4 times as fast as mainstream short-read mappers at comparable accuracy, and is ≥30 times faster than long-read genomic or cDNA mappers at higher accuracy, surpassing most aligners specialized in one type of alignment.https://github.com/lh3/minimap2Supplementary data are available at Bioinformatics online.},
  author       = {Li, Heng},
  date         = {2018-09-15},
  doi          = {10.1093/bioinformatics/bty191},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  keywords     = {mapping},
  number       = {18},
  pages        = {3094--3100},
  shortjournal = {Bioinformatics},
  shorttitle   = {Minimap2},
  title        = {Minimap2: Pairwise Alignment for Nucleotide Sequences},
  volume       = {34}
}

@online{liNewStrategiesImprove2021,
  abstract      = {Summary: We present several recent improvements to minimap2, a versatile pairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more accurately map long reads to highly repetitive regions and align through insertions or deletions up to 100kb by default, addressing major weakness in minimap2 v2.18 or earlier. Availability and implementation: https://github.com/lh3/minimap2},
  archiveprefix = {arXiv},
  author        = {Li, Heng},
  date          = {2021-08-07},
  eprint        = {2108.03515},
  eprinttype    = {arxiv},
  keywords      = {Quantitative Biology - Genomics},
  primaryclass  = {q-bio},
  title         = {New Strategies to Improve Minimap2 Alignment Accuracy}
}

@article{liSyntheticdiploidBenchmarkAccurate2018,
  abstract     = {Existing benchmark datasets for use in evaluating variant-calling accuracy are constructed from a consensus of known short-variant callers, and they are thus biased toward easy regions that are accessible by these algorithms. We derived a new benchmark dataset from the de novo PacBio assemblies of two fully homozygous human cell lines, which provides a relatively more accurate and less biased estimate of small-variant-calling error rates in a realistic context.},
  annotation   = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Genome informatics;Standards Subject\_term\_id: genome-informatics;standards},
  author       = {Li, Heng and Bloom, Jonathan M. and Farjoun, Yossi and Fleharty, Mark and Gauthier, Laura and Neale, Benjamin and MacArthur, Daniel},
  date         = {2018-08},
  doi          = {10.1038/s41592-018-0054-7},
  issn         = {1548-7105},
  issue        = {8},
  journaltitle = {Nature Methods},
  keywords     = {Genome informatics,Standards},
  langid       = {english},
  number       = {8},
  pages        = {595--597},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {A Synthetic-Diploid Benchmark for Accurate Variant-Calling Evaluation},
  volume       = {15}
}

@article{liuSMARTdenovoNovoAssembler2021,
  abstract     = {Long-read single-molecule sequencing has revolutionized de novo genome assembly and enabled the automated reconstruction of reference-quality genomes. It has also been widely used to study structural variants, phase haplotypes and more. Here, we introduce the assembler SMARTdenovo, a single-molecule sequencing (SMS) assembler that follows the overlap-layout-consensus (OLC) paradigm. SMARTdenovo (RRID: SCR\_017622) was designed to be a rapid assembler, which, unlike contemporaneous SMS assemblers, does not require highly accurate raw reads for error correction. It has performed well in the evaluation of congeneric assemblers and has been successfully users for various assembly projects. It is compatible with Canu for assembling high-quality genomes, and several of the assembly strategies in this program have been incorporated into subsequent popular assemblers. The assembler has been in use since 2015; here we provide information on the development of SMARTdenovo and how to implement its algorithms into current projects.},
  author       = {Liu, Hailin and Wu, Shigang and Li, Alun and Ruan, Jue and Wu, Shigang and Li, Alun and Ruan, Jue},
  date         = {2021-03-08},
  doi          = {10.46471/gigabyte.15},
  journaltitle = {Gigabyte},
  langid       = {english},
  pages        = {1--9},
  publisher    = {{GigaScience Press}},
  shorttitle   = {{{SMARTdenovo}}},
  title        = {{{SMARTdenovo}}: A de Novo Assembler Using Long Noisy Reads},
  volume       = {2021}
}

@article{mikheenkoTandemToolsMappingLong2020,
  abstract     = {Extra-long tandem repeats (ETRs) are widespread in eukaryotic genomes and play an important role in fundamental cellular processes, such as chromosome segregation. Although emerging long-read technologies have enabled ETR assemblies, the accuracy of such assemblies is difficult to evaluate since there are no tools for their quality assessment. Moreover, since the mapping of error-prone reads to ETRs remains an open problem, it is not clear how to polish draft ETR assemblies.To address these problems, we developed the TandemTools software that includes the TandemMapper tool for mapping reads to ETRs and the TandemQUAST tool for polishing ETR assemblies and their quality assessment. We demonstrate that TandemTools not only reveals errors in ETR assemblies but also improves the recently generated assemblies of human centromeres.https://github.com/ablab/TandemTools.Supplementary data are available at Bioinformatics online.},
  author       = {Mikheenko, Alla and Bzikadze, Andrey V and Gurevich, Alexey and Miga, Karen H and Pevzner, Pavel A},
  date         = {2020-07-01},
  doi          = {10.1093/bioinformatics/btaa440},
  issn         = {1367-4803},
  issue        = {Supplement\_1},
  journaltitle = {Bioinformatics},
  keywords     = {mapping},
  pages        = {i75-i83},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{TandemTools}}},
  title        = {{{TandemTools}}: Mapping Long Reads and Assessing/Improving Assembly Quality in Extra-Long Tandem Repeats},
  volume       = {36}
}

@article{nurkCompleteSequenceHuman2021,
  abstract     = {In 2001, Celera Genomics and the International Human Genome Sequencing Consortium published their initial drafts of the human genome, which revolutionized the field of genomics. While these drafts and the updates that followed effectively covered the euchromatic fraction of the genome, the heterochromatin and many other complex regions were left unfinished or erroneous. Addressing this remaining 8\% of the genome, the Telomere-to-Telomere (T2T) Consortium has finished the first truly complete 3.055 billion base pair (bp) sequence of a human genome, representing the largest improvement to the human reference genome since its initial release. The new T2T-CHM13 reference includes gapless assemblies for all 22 autosomes plus Chromosome X, corrects numerous errors, and introduces nearly 200 million bp of novel sequence containing 2,226 paralogous gene copies, 115 of which are predicted to be protein coding. The newly completed regions include all centromeric satellite arrays and the short arms of all five acrocentric chromosomes, unlocking these complex regions of the genome to variational and functional studies for the first time.Competing Interest StatementAF and CSC are employees of DNAnexus; IS, JK, MWH, PP, and AW are employees of Pacific Biosciences; FJS has received travel funds to speak at events hosted by Pacific Biosciences; SK and FJS have received travel funds to speak at events hosted by Oxford Nanopore Technologies. WT has licensed two patents to Oxford Nanopore Technologies (US 8748091 and 8394584).},
  author       = {Nurk, Sergey and Koren, Sergey and Rhie, Arang and Rautiainen, Mikko and Bzikadze, Andrey V. and Mikheenko, Alla and Vollger, Mitchell R. and Altemose, Nicolas and Uralsky, Lev and Gershman, Ariel and Aganezov, Sergey and Hoyt, Savannah J. and Diekhans, Mark and Logsdon, Glennis A. and Alonge, Michael and Antonarakis, Stylianos E. and Borchers, Matthew and Bouffard, Gerard G. and Brooks, Shelise Y. and Caldas, Gina V. and Cheng, Haoyu and Chin, Chen-Shan and Chow, William and de Lima, Leonardo G. and Dishuck, Philip C. and Durbin, Richard and Dvorkina, Tatiana and Fiddes, Ian T. and Formenti, Giulio and Fulton, Robert S. and Fungtammasan, Arkarachai and Garrison, Erik and Grady, Patrick G.S. and Graves-Lindsay, Tina A. and Hall, Ira M. and Hansen, Nancy F. and Hartley, Gabrielle A. and Haukness, Marina and Howe, Kerstin and Hunkapiller, Michael W. and Jain, Chirag and Jain, Miten and Jarvis, Erich D. and Kerpedjiev, Peter and Kirsche, Melanie and Kolmogorov, Mikhail and Korlach, Jonas and Kremitzki, Milinn and Li, Heng and Maduro, Valerie V. and Marschall, Tobias and McCartney, Ann M. and McDaniel, Jennifer and Miller, Danny E. and Mullikin, James C. and Myers, Eugene W. and Olson, Nathan D. and Paten, Benedict and Peluso, Paul and Pevzner, Pavel A. and Porubsky, David and Potapova, Tamara and Rogaev, Evgeny I. and Rosenfeld, Jeffrey A. and Salzberg, Steven L. and Schneider, Valerie A. and Sedlazeck, Fritz J. and Shafin, Kishwar and Shew, Colin J. and Shumate, Alaina and Sims, Yumi and Smit, Arian F. A. and Soto, Daniela C. and Sović, Ivan and Storer, Jessica M. and Streets, Aaron and Sullivan, Beth A. and Thibaud-Nissen, Françoise and Torrance, James and Wagner, Justin and Walenz, Brian P. and Wenger, Aaron and Wood, Jonathan M. D. and Xiao, Chunlin and Yan, Stephanie M. and Young, Alice C. and Zarate, Samantha and Surti, Urvashi and McCoy, Rajiv C. and Dennis, Megan Y. and Alexandrov, Ivan A. and Gerton, Jennifer L. and O’Neill, Rachel J. and Timp, Winston and Zook, Justin M. and Schatz, Michael C. and Eichler, Evan E. and Miga, Karen H. and Phillippy, Adam M.},
  date         = {2021},
  doi          = {10.1101/2021.05.26.445798},
  elocation-id = {2021.05.26.445798},
  journaltitle = {bioRxiv : the preprint server for biology},
  options      = {useprefix=true},
  publisher    = {{Cold Spring Harbor Laboratory}},
  shortjournal = {bioRxiv},
  title        = {The Complete Sequence of a Human Genome}
}

@article{nurkHiCanuAccurateAssembly2020,
  abstract     = {Complete and accurate genome assemblies form the basis of most downstream genomic analyses and are of critical importance. Recent genome assembly projects have relied on a combination of noisy long-read sequencing and accurate short-read sequencing, with the former offering greater assembly continuity and the latter providing higher consensus accuracy. The recently introduced Pacific Biosciences (PacBio) HiFi sequencing technology bridges this divide by delivering long reads ({$>$}10 kbp) with high per-base accuracy ({$>$}99.9\%). Here we present HiCanu, a modification of the Canu assembler designed to leverage the full potential of HiFi reads via homopolymer compression, overlap-based error correction, and aggressive false overlap filtering. We benchmark HiCanu with a focus on the recovery of haplotype diversity, major histocompatibility complex (MHC) variants, satellite DNAs, and segmental duplications. For diploid human genomes sequenced to 30× HiFi coverage, HiCanu achieved superior accuracy and allele recovery compared to the current state of the art. On the effectively haploid CHM13 human cell line, HiCanu achieved an NG50 contig size of 77 Mbp with a per-base consensus accuracy of 99.999\% (QV50), surpassing recent assemblies of high-coverage, ultralong Oxford Nanopore Technologies (ONT) reads in terms of both accuracy and continuity. This HiCanu assembly correctly resolves 337 out of 341 validation BACs sampled from known segmental duplications and provides the first preliminary assemblies of nine complete human centromeric regions. Although gaps and errors still remain within the most challenging regions of the genome, these results represent a significant advance toward the complete assembly of human genomes.},
  author       = {Nurk, Sergey and Walenz, Brian P. and Rhie, Arang and Vollger, Mitchell R. and Logsdon, Glennis A. and Grothe, Robert and Miga, Karen H. and Eichler, Evan E. and Phillippy, Adam M. and Koren, Sergey},
  date         = {2020-01-09},
  doi          = {10.1101/gr.263566.120},
  eprint       = {32801147},
  eprinttype   = {pmid},
  issn         = {1088-9051, 1549-5469},
  journaltitle = {Genome Research},
  langid       = {english},
  number       = {9},
  pages        = {1291--1305},
  publisher    = {{Cold Spring Harbor Lab}},
  shortjournal = {Genome Res.},
  shorttitle   = {{{HiCanu}}},
  title        = {{{HiCanu}}: Accurate Assembly of Segmental Duplications, Satellites, and Allelic Variants from High-Fidelity Long Reads},
  volume       = {30}
}

@article{prodanovSensitiveAlignmentUsing2020,
  abstract     = {The ability to characterize repetitive regions of the human genome is limited by the read lengths of short-read sequencing technologies. Although long-read sequencing technologies such as Pacific Biosciences (PacBio)~and Oxford Nanopore Technologies can potentially overcome this limitation, long segmental duplications with high sequence identity pose challenges for long-read mapping. We describe a probabilistic method, DuploMap, designed to improve the accuracy of long-read mapping in segmental duplications. It analyzes reads mapped to segmental duplications using existing long-read aligners and leverages paralogous sequence variants (PSVs)—sequence differences between paralogous sequences—to distinguish between multiple alignment locations. On simulated datasets, DuploMap increased the percentage of correctly mapped reads with high confidence for multiple long-read aligners including Minimap2 (74.3–90.6\%) and BLASR (82.9–90.7\%) while maintaining high precision. Across multiple whole-genome long-read datasets, DuploMap aligned an additional 8–21\% of the reads in segmental duplications with high confidence relative to Minimap2. Using DuploMap-aligned PacBio circular consensus sequencing reads, an additional 8.9 Mb of DNA sequence was mappable, variant calling achieved a higher F1~score and 14~713 additional variants supported by linked-read data were identified. Finally, we demonstrate that a significant fraction of PSVs in segmental duplications overlaps with variants and adversely impacts short-read variant calling.},
  author       = {Prodanov, Timofey and Bansal, Vikas},
  date         = {2020-11-04},
  doi          = {10.1093/nar/gkaa829},
  issn         = {0305-1048},
  journaltitle = {Nucleic Acids Research},
  number       = {19},
  pages        = {e114},
  shortjournal = {Nucleic Acids Research},
  title        = {Sensitive Alignment Using Paralogous Sequence Variants Improves Long-Read Mapping and Variant Calling in Segmental Duplications},
  volume       = {48}
}

@article{rhieMerquryReferencefreeQuality2020,
  abstract     = {Recent long-read assemblies often exceed the quality and completeness of available reference genomes, making validation challenging. Here we present Merqury, a novel tool for reference-free assembly evaluation based on efficient k-mer set operations. By comparing k-mers in a de novo assembly to those found in unassembled high-accuracy reads, Merqury estimates base-level accuracy and completeness. For trios, Merqury can also evaluate haplotype-specific accuracy, completeness, phase block continuity, and switch errors. Multiple visualizations, such as k-mer spectrum plots, can be generated for evaluation. We demonstrate on both human and plant genomes that Merqury is a fast and robust method for assembly validation.},
  author       = {Rhie, Arang and Walenz, Brian P. and Koren, Sergey and Phillippy, Adam M.},
  date         = {2020-09-14},
  doi          = {10.1186/s13059-020-02134-9},
  issn         = {1474-760X},
  journaltitle = {Genome Biology},
  keywords     = {Assembly validation,Benchmarking,Genome assembly,Haplotype phasing,K-mers,Trio binning},
  number       = {1},
  pages        = {245},
  shortjournal = {Genome Biology},
  shorttitle   = {Merqury},
  title        = {Merqury: Reference-Free Quality, Completeness, and Phasing Assessment for Genome Assemblies},
  volume       = {21}
}

@article{yangNanoSimNanoporeSequence2017,
  abstract     = {The MinION sequencing instrument from Oxford Nanopore Technologies (ONT) produces long read lengths from single-molecule sequencing – valuable features for detailed genome characterization. To realize the potential of this platform, a number of groups are developing bioinformatics tools tuned for the unique characteristics of its data. We note that these development efforts would benefit from a simulator software, the output of which could be used to benchmark analysis tools. ~Here, we introduce NanoSim, a fast and scalable read simulator that captures the technology-specific features of ONT data and allows for adjustments upon improvement of nanopore sequencing technology. The first step of NanoSim is read characterization, which provides a comprehensive alignment-based analysis and generates a set of read profiles serving as the input to the next step, the simulation stage. The simulation stage uses the model built in the previous step to produce in silico reads for a given reference genome. NanoSim is written in Python and R. The source files and manual are available at the Genome Sciences Centre website: http://www.bcgsc.ca/platform/bioinfo/software/nanosim. In this work, we model the base-calling errors of ONT reads to inform the simulation of sequences with similar characteristics. We showcase the performance of NanoSim on publicly available datasets generated using the R7 and R7.3 chemistries and different sequencing kits and compare the resulting synthetic reads to those of other long-sequence simulators and experimental ONT reads. We expect NanoSim to have an enabling role in the field and benefit the development of scalable next-generation sequencing technologies for the long nanopore reads, including genome assembly, mutation detection, and even metagenomic analysis software.},
  author       = {Yang, Chen and Chu, Justin and Warren, René L and Birol, Inanç},
  date         = {2017-04-01},
  doi          = {10.1093/gigascience/gix010},
  issn         = {2047-217X},
  journaltitle = {GigaScience},
  number       = {4},
  shortjournal = {GigaScience},
  shorttitle   = {{{NanoSim}}},
  title        = {{{NanoSim}}: Nanopore Sequence Read Simulator Based on Statistical Characterization},
  volume       = {6}
}


@software{smitRepeatMasker2013,
  author  = {Smit, Adrian FA. and Hubley, Robert and Green, P.},
  date    = {2013},
  title   = {{RepeatMasker Open-4.0}},
  url     = {http://www.repeatmasker.org},
  version = {4.0.5}
}

@article{miller2008aggressive,
  author    = {Miller, Jason R and Delcher, Arthur L and Koren, Sergey and Venter, Eli and Walenz, Brian P and Brownley, Anushka and Johnson, Justin and Li, Kelvin and Mobarry, Clark and Sutton, Granger},
  journal   = {Bioinformatics},
  number    = {24},
  pages     = {2818--2824},
  publisher = {Oxford University Press},
  title     = {Aggressive assembly of pyrosequencing reads with mates},
  volume    = {24},
  year      = {2008}
}

@article{sahlin2021error,
  author    = {Sahlin, Kristoffer and Medvedev, Paul},
  journal   = {Nature communications},
  number    = {1},
  pages     = {1--13},
  publisher = {Nature Publishing Group},
  title     = {Error correction enables use of Oxford Nanopore technology for reference-free transcriptome analysis},
  volume    = {12},
  year      = {2021}
}

@article{bragg2012fast,
  author    = {Bragg, Lauren and Stone, Glenn and Imelfort, Michael and Hugenholtz, Philip and Tyson, Gene W},
  journal   = {Nature methods},
  number    = {5},
  pages     = {425--426},
  publisher = {Nature Publishing Group},
  title     = {Fast, accurate error-correction of amplicon pyrosequences using Acacia},
  volume    = {9},
  year      = {2012}
}

@article{au2012improving,
  author    = {Au, Kin Fai and Underwood, Jason G and Lee, Lawrence and Wong, Wing Hung},
  publisher = {Public Library of Science San Francisco, USA},
  title     = {Improving PacBio long read accuracy by short read alignment},
  year      = {2012}
}

@article{sahlin2020novo,
  author    = {Sahlin, Kristoffer and Medvedev, Paul},
  journal   = {Journal of Computational Biology},
  number    = {4},
  pages     = {472--484},
  publisher = {Mary Ann Liebert, Inc., publishers 140 Huguenot Street, 3rd Floor New~…},
  title     = {De novo clustering of long-read transcriptome data using a greedy, quality value-based algorithm},
  volume    = {27},
  year      = {2020}
}


@article{auImprovingPacBioLong2012,
  abstract     = {The recent development of third generation sequencing (TGS) generates much longer reads than second generation sequencing (SGS) and thus provides a chance to solve problems that are difficult to study through SGS alone. However, higher raw read error rates are an intrinsic drawback in most TGS technologies. Here we present a computational method, LSC, to perform error correction of TGS long reads (LR) by SGS short reads (SR). Aiming to reduce the error rate in homopolymer runs in the main TGS platform, the PacBio® RS, LSC applies a homopolymer compression (HC) transformation strategy to increase the sensitivity of SR-LR alignment without scarifying alignment accuracy. We applied LSC to 100,000 PacBio long reads from human brain cerebellum RNA-seq data and 64 million single-end 75 bp reads from human brain RNA-seq data. The results show LSC can correct PacBio long reads to reduce the error rate by more than 3 folds. The improved accuracy greatly benefits many downstream analyses, such as directional gene isoform detection in RNA-seq study. Compared with another hybrid correction tool, LSC can achieve over double the sensitivity and similar specificity.},
  author       = {Au, Kin Fai and Underwood, Jason G. and Lee, Lawrence and Wong, Wing Hung},
  date         = {2012-10-04},
  doi          = {10.1371/journal.pone.0046679},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Chromosomes,Genome sequencing,Genomics,Human genomics,Quality control,RNA sequencing,Sequence alignment,Transcriptome analysis},
  langid       = {english},
  number       = {10},
  pages        = {e46679},
  publisher    = {{Public Library of Science}},
  shortjournal = {PLOS ONE},
  title        = {Improving {{PacBio Long Read Accuracy}} by {{Short Read Alignment}}},
  volume       = {7}
}

@article{braggFastAccurateErrorcorrection2012,
  author       = {Bragg, Lauren and Stone, Glenn and Imelfort, Michael and Hugenholtz, Philip and Tyson, Gene W.},
  date         = {2012-05},
  doi          = {10.1038/nmeth.1990},
  issn         = {1548-7105},
  issue        = {5},
  journaltitle = {Nature Methods},
  keywords     = {Bioinformatics,Microbial communities,Sequencing},
  langid       = {english},
  number       = {5},
  pages        = {425--426},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Methods},
  title        = {Fast, Accurate Error-Correction of Amplicon Pyrosequences Using {{Acacia}}},
  volume       = {9}
}

@article{millerAggressiveAssemblyPyrosequencing2008,
  abstract     = {Motivation: DNA sequence reads from Sanger and pyrosequencing platforms differ in cost, accuracy, typical coverage, average read length and the variety of available paired-end protocols. Both read types can complement one another in a ‘hybrid’ approach to whole-genome shotgun sequencing projects, but assembly software must be modified to accommodate their different characteristics. This is true even of pyrosequencing mated and unmated read combinations. Without special modifications, assemblers tuned for homogeneous sequence data may perform poorly on hybrid data.Results: Celera Assembler was modified for combinations of ABI 3730 and 454 FLX reads. The revised pipeline called CABOG (Celera Assembler with the Best Overlap Graph) is robust to homopolymer run length uncertainty, high read coverage and heterogeneous read lengths. In tests on four genomes, it generated the longest contigs among all assemblers tested. It exploited the mate constraints provided by paired-end reads from either platform to build larger contigs and scaffolds, which were validated by comparison to a finished reference sequence. A low rate of contig mis-assembly was detected in some CABOG assemblies, but this was reduced in the presence of sufficient mate pair data.Availability: The software is freely available as open-source from http://wgs-assembler.sf.net under the GNU Public License.Contact:jmiller@jcvi.orgSupplementary information:Supplementary data are available at Bioinformatics online.},
  author       = {Miller, Jason R. and Delcher, Arthur L. and Koren, Sergey and Venter, Eli and Walenz, Brian P. and Brownley, Anushka and Johnson, Justin and Li, Kelvin and Mobarry, Clark and Sutton, Granger},
  date         = {2008-12-15},
  doi          = {10.1093/bioinformatics/btn548},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {24},
  pages        = {2818--2824},
  shortjournal = {Bioinformatics},
  title        = {Aggressive Assembly of Pyrosequencing Reads with Mates},
  volume       = {24}
}

@article{sahlinErrorCorrectionEnables2021,
  abstract     = {Oxford Nanopore (ONT) is a leading long-read technology which has been revolutionizing transcriptome analysis through its capacity to sequence the majority of transcripts from end-to-end. This has greatly increased our ability to study the diversity of transcription mechanisms such as transcription initiation, termination, and alternative splicing. However, ONT still suffers from high error rates which have thus far limited its scope to reference-based analyses. When a reference is not available or is not a viable option due to reference-bias, error correction is a crucial step towards the reconstruction of the sequenced transcripts and downstream sequence analysis of transcripts. In this paper, we present a novel computational method to error correct ONT cDNA sequencing data, called isONcorrect. IsONcorrect is able to jointly use all isoforms from a gene during error correction, thereby allowing it to correct reads at low sequencing depths. We are able to obtain a median accuracy of 98.9–99.6\%, demonstrating the feasibility of applying cost-effective cDNA full transcript length sequencing for reference-free transcriptome analysis.},
  author       = {Sahlin, Kristoffer and Medvedev, Paul},
  date         = {2021-01-04},
  doi          = {10.1038/s41467-020-20340-8},
  issn         = {2041-1723},
  issue        = {1},
  journaltitle = {Nature Communications},
  keywords     = {Data processing,RNA sequencing,Transcriptomics},
  langid       = {english},
  number       = {1},
  pages        = {2},
  publisher    = {{Nature Publishing Group}},
  shortjournal = {Nat Commun},
  title        = {Error Correction Enables Use of {{Oxford Nanopore}} Technology for Reference-Free Transcriptome Analysis},
  volume       = {12}
}

@article{sahlinNovoClusteringLongRead2020,
  abstract     = {Long-read sequencing of transcripts with Pacific Biosciences (PacBio) Iso-Seq and Oxford Nanopore Technologies has proven to be central to the study of complex isoform landscapes in many organisms. However, current de novo transcript reconstruction algorithms from long-read data are limited, leaving the potential of these technologies unfulfilled. A common bottleneck is the dearth of scalable and accurate algorithms for clustering long reads according to their gene family of origin. To address this challenge, we develop isONclust, a clustering algorithm that is greedy (to scale) and makes use of quality values (to handle variable error rates). We test isONclust on three simulated and five biological data sets, across a breadth of organisms, technologies, and read depths. Our results demonstrate that isONclust is a substantial improvement over previous approaches, both in terms of overall accuracy and/or scalability to large data sets.},
  author       = {Sahlin, Kristoffer and Medvedev, Paul},
  date         = {2020-04-01},
  doi          = {10.1089/cmb.2019.0299},
  journaltitle = {Journal of Computational Biology},
  keywords     = {algorithms,clustering,long-read sequencing,sequencing data analysis,third-generation sequencing,transcriptomics},
  number       = {4},
  pages        = {472--484},
  publisher    = {{Mary Ann Liebert, Inc., publishers}},
  title        = {De {{Novo Clustering}} of {{Long-Read Transcriptome Data Using}} a {{Greedy}}, {{Quality Value-Based Algorithm}}},
  volume       = {27}
}

@article{onoPBSIM2SimulatorLongread2021,
  abstract     = {Recent advances in high-throughput long-read sequencers, such as PacBio and Oxford Nanopore sequencers, produce longer reads with more errors than short-read sequencers. In addition to the high error rates of reads, non-uniformity of errors leads to difficulties in various downstream analyses using long reads. Many useful simulators, which characterize long-read error patterns and simulate them, have been developed. However, there is still room for improvement in the simulation of the non-uniformity of errors.To capture characteristics of errors in reads for long-read sequencers, here, we introduce a generative model for quality scores, in which a hidden Markov Model with a latest model selection method, called factorized information criteria, is utilized. We evaluated our developed simulator from various points, indicating that our simulator successfully simulates reads that are consistent with real reads.The source codes of PBSIM2 are freely available from https://github.com/yukiteruono/pbsim2.Supplementary data are available at Bioinformatics online.},
  author       = {Ono, Yukiteru and Asai, Kiyoshi and Hamada, Michiaki},
  date         = {2021-03-01},
  doi          = {10.1093/bioinformatics/btaa835},
  issn         = {1367-4803},
  journaltitle = {Bioinformatics},
  number       = {5},
  pages        = {589--595},
  shortjournal = {Bioinformatics},
  shorttitle   = {{{PBSIM2}}},
  title        = {{{PBSIM2}}: A Simulator for Long-Read Sequencers with a Novel Generative Model of Quality Scores},
  volume       = {37}
}

@article{gusfieldbook,
  author    = {Gusfield, Dan},
  journal   = {Acm Sigact News},
  number    = {4},
  pages     = {41--60},
  publisher = {ACM New York, NY, USA},
  title     = {Algorithms on stings, trees, and sequences: Computer science and computational biology},
  volume    = {28},
  year      = {1997}
}